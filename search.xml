<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>hadoop配置</title>
    <url>/2020/04/06/20200406hadoop%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h3 id="SSH远程"><a href="#SSH远程" class="headerlink" title="SSH远程"></a>SSH远程</h3><p>1，开启一个Ubuntu16的虚拟机。</p><p>注意设置里换源，中国区的快些。</p><p>然后进行更新 (sudo apt-get update ,  然后sudo apt-get upgrade)</p><p>然后安装ssh（sudo apt-get install openssh-server）。</p><p>然后我在本机mac这边用ssh远程登录ubuntu。将mac的ssh公钥发送给ubunt，（ssh-copy-id <em>*</em>@10.211.55…IP），以后就可以直接ssh user@IP登录ubuntu了。</p><a id="more"></a>




<h3 id="下载资源"><a href="#下载资源" class="headerlink" title="下载资源"></a>下载资源</h3><h4 id="Java环境"><a href="#Java环境" class="headerlink" title="Java环境"></a>Java环境</h4><p>在 Linux 中下载java JDK，下载的Linux X64的1.7版本的jdk-7u80</p>
<p><a href="https://www.oracle.com/java/technologies/javase/javase7-archive-downloads.html#jdk-7u80-oth-JPR" target="_blank" rel="noopener">https://www.oracle.com/java/technologies/javase/javase7-archive-downloads.html#jdk-7u80-oth-JPR</a></p>
<p><img src="/Users/wangxue/Desktop/JavaJDK.png" alt="JavaJDK"></p>
<p>我远程scp传到ubuntu的时候提醒connection refused，这个是因为我mac的setting里的sharing的remote login没有开启，这里得开启一下。</p>
<p>接着配置Java环境变量，配置在/etc/profile中，作为<strong>全局系统变量</strong>，使用<strong>sudo vi /etc/profile</strong>进行环境变量编辑，</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 添加并保存</span></span><br><span class="line">export JAVA_HOME=/usr/local/java/jdk1.7.0_80  #注意此处jdk目录与你解压目录相同</span><br><span class="line">export JRE_HOME=$JAVA_HOME/jre</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure>
<p>编辑完后终端输入<strong>source /etc/profile</strong>使环境变量生效。</p>
<h4 id="hadoop下载"><a href="#hadoop下载" class="headerlink" title="hadoop下载"></a>hadoop下载</h4><p>下载的hadoop2.6版本。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget --no-check-certificate -c --header "Cookie: oraclelicense=accept-securebackup-cookie" http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.7.0.tar.gz</span><br></pre></td></tr></table></figure>
<p>然后对hadoop进行解压放到与jdk同一个目录中：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf hadoop-2.7.1.tar.gz -C /usr/local</span><br></pre></td></tr></table></figure>
<p>配置hadoop全局环境变量并使其生效，在Java环境变量配置的下面:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">HADOOP VARIABLES</span></span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop-2.6.4</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line">export HADOOP_MAPRED_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_HDFS_HOME=$HADOOP_HOME</span><br><span class="line">export YARN_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</span><br><span class="line">export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib"</span><br></pre></td></tr></table></figure>
<p>编辑完后终端输入<strong>source /etc/profile</strong>使环境变量生效。</p>
<p>另外这里注意配置hadoop-env.sh文件的$JAVA_HOME，接着用<strong>sudo gedit hadoop-env.sh</strong>配置jdk绝对路径：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME=/usr/local/java/jdk1.7.0_80  #注意此处jdk目录与你解压目录相同</span><br></pre></td></tr></table></figure>
<h4 id="映射配置"><a href="#映射配置" class="headerlink" title="映射配置"></a>映射配置</h4><p>使用 vim 进入到 “/etc/hostname” 的这个文件进行修改，我修改了为“wangxue-para”，同时修改“/etc/hosts”文件，在里面追加 IP 地址与 wangxue-para 主机的映射。</p>
<p><img src="/Users/wangxue/Desktop/hostname.png" alt="hostname"></p>
<h4 id="配置免秘钥登录"><a href="#配置免秘钥登录" class="headerlink" title="配置免秘钥登录"></a>配置免秘钥登录</h4><p>整个hadoop的处理过程之中，都是利用ssh实现通讯的，就算是在本机，也一样使用ssh进行通讯处理，因此需要在电脑上配置ssh免登录处理。</p>
<p>在本主机上生成一个ssh key：使用<strong>sudo apt-get openssh-server</strong>安装openssh-server后，然后使用<strong>ssh-keygen -t rsa -P “”</strong>生成.ssh文件</p>
<p>保存公钥：这个时候的程序如果要想进行登录依然需要密码。需要将公钥信息保存在授权认证的文件之中 ： “authorized_key”文件里面。</p>
]]></content>
      <categories>
        <category>配置</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>配置</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据技术1hadoop</title>
    <url>/2020/04/05/20200405%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF1hadoop/</url>
    <content><![CDATA[<h3 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h3><h3 id="虚拟化技术"><a href="#虚拟化技术" class="headerlink" title="虚拟化技术"></a>虚拟化技术</h3><h3 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h3><p>hadoop是一个开源框架，允许使用简单的编程模型在跨计算机集群的分布式环境中存储和处理大数据。</p><h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><p>分布式文件系统，是一个高度容错性的系统（每个数据块都复制到多个节点），可以提供高吞吐量的数据访问（T级别，多个节点同时处理数据）。</p><p>文件分块存储，HDFS将一个完整的大文件平均分块存储到不同的计算器上，多主机读取比单主机读取效率更高。代码向数据迁移，尽量地将任务分配到离数据最近的机器上运行。</p><a id="more"></a>


<p>适用情况：大规模数据，流式数据（一次写入多次读写，不支持动态改变文件内容，不支持并发写，小文件不合适。），一般硬件，时间延迟有代价（低时延的访问需求HBase更合适）。</p>
<h4 id="关键元素"><a href="#关键元素" class="headerlink" title="关键元素"></a>关键元素</h4><p>Block：文件分块，一般大小是64MB or 128MB。配置大的块减少搜寻时间，减少管理块的数据开销，每个块都需要在NameNode上有对应的记录；对数据块进行读写减少建立网络的连接成本。每个块都会被复制到多台机器（可靠性）。</p>
<p>NameNode：保存整个文件系统的目录信息，文件信息及分块信息。存储文件的metadata，运行时所有数据都保存到内存，整个HDFS可存储的文件数受限于NameNode的内存大小。一个Block在NameNode中对应一条记录</p>
<p>DataNode：分布在廉价的计算机上，用于存储Block块文件。负责数据的读写操作和复制操作，DataNode启动时会向NameNode报告当前存储的数据块信息。DataNode之间会进行通信，复制数据块，虽然有冗余但是可靠。</p>
<p>结构如图：</p>
<p><img src="/images/20200405hadoop_namenode.jpg" alt="20200405hadoop_namenode"></p>
<p>名称节点（NameNode） 主节点（Master），数据节点 （DataNode） 从节点（Slave）</p>
<p>名称节点负责文件和目录的创建、删除和重命名等，同时管理数据节点与文件块的映射关系；数据节点负责数据的存储和读取。</p>
<h4 id="HDFS的数据流—读文件"><a href="#HDFS的数据流—读文件" class="headerlink" title="HDFS的数据流—读文件"></a>HDFS的数据流—读文件</h4><p><img src="/images/20200405HDFS_architecture.jpg" alt="20200405HDFS_architecture"></p>
<p>客户端client用FileSystem的open() 函数打开文件。</p>
<p>DistributedFileSystem用RPC调用元数据节点，得到文件的数据块信息。对于每一个数据块，元数据节点返回保存数据块的数据节点的地址。</p>
<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><p>是一套从海量数据中提取分析元素，最后返回结果集的编程模型。MapReduce的基本原理就是：将大的数据分析分成小块逐个分析，最后再将提取出来的数据汇总分析，最终获得我们想要的内容。</p>
<p>一种分布式的计算方式指定一个Map函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。</p>
<p><img src="/images/20200405MapReduce.jpg" alt="20200405MapReduce"></p>
<p>map: (K1, V1) → list(K2, V2) combine: (K2, list(V2)) → list(K2, V2) reduce: (K2, list(V2)) → list(K3, V3)</p>
<p><img src="/images/20200405MapReduce1.jpg" alt="20200405MapReduce1"></p>
<p>多节点下流程图：</p>
<p><img src="/images/20200405mapreduce2.png" alt="20200405mapreduce2"></p>
<p>Record reader：记录阅读器会翻译由输入格式生成的记录，记录阅读器用于将数据解析给记录，并不分析记录自身。记录读取器的目的是将数据解析成记录，但不分析记录本身。它将数据以键值对的形式传输给mapper。通常键是位置信息，值是构成记录的数据存储块.</p>
<p>Map：在映射器中用户提供的代码称为中间对。对于键值的具体定义是慎重的，因为定义对于分布式任务的完成具有重要意义.键决定了数据分类的依据，而值决定了处理器中的分析信息。</p>
<p>Shuffle and Sort：ruduce任务以随机和排序步骤开始。此步骤写入输出文件并下载到本地计算机。这些数据采用键进行排序以把等价密钥组合到一起。</p>
<p>Reduce：reducer采用分组数据作为输入。该功能传递键和此键相关值的迭代器。可以采用多种方式来汇总、过滤或者合并数据。当ruduce功能完成，就会发送0个或多个键值对。</p>
<p>输出格式：输出格式会转换最终的键值对并写入文件。默认情况下键和值以tab分割，各记录以换行符分割。因此可以自定义更多输出格式，最终数据会写入HDFS。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，《云计算课程》</p>
<p>2，W3Cschool： <a href="https://www.w3cschool.cn/hadoop/fgr61jyf.html" target="_blank" rel="noopener">https://www.w3cschool.cn/hadoop/fgr61jyf.html</a></p>
]]></content>
      <categories>
        <category>数据挖掘</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>分治递归思想</title>
    <url>/2020/03/31/20200330%E5%88%86%E6%B2%BB%E9%80%92%E5%BD%92%E6%80%9D%E6%83%B3/</url>
    <content><![CDATA[<h3 id="分治递归思想"><a href="#分治递归思想" class="headerlink" title="分治递归思想"></a>分治递归思想</h3><p>为了解决一个给定的问题，算法一次或多次递归的调用自身以解决若干子问题，这些就是典型的分治法的思想。我们将原问题分解为几个规模较小但类似于原问题的子问题，从而递归的调用自身，最后合并这些子问题的解来建立原问题的解。</p><p>关键：1，分解原问题为相同结构的子问题。2，解决这些子问题。3，合并子问题的解。</p><a id="more"></a>

<h3 id="经典案例"><a href="#经典案例" class="headerlink" title="经典案例"></a>经典案例</h3><h4 id="递归求和"><a href="#递归求和" class="headerlink" title="递归求和"></a>递归求和</h4><p>如果计算1 + 2 + … n ，可以用递归的方法来写。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">AddFrom1ToN_Recursive</span><span class="params">(<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">	<span class="keyword">return</span> n &lt;= <span class="number">0</span>?: <span class="number">0</span>:n + AddFrom1ToN_Recursive(n<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但这里递归比循环的时间复杂度更高，函数递归调用自身都要在内存栈中分配空间保存参数（如n到哪了），返回地址（函数的地址），临时变量（上一次计算得到的AddFrom1ToN_Recursive值）等等，因此空间和时间消耗较多。</p>
<p>更严重的话递归会带来调用栈溢出的问题，递归调用层级太多就有可能超出栈的容量。</p>
<h4 id="归并排序。"><a href="#归并排序。" class="headerlink" title="归并排序。"></a>归并排序。</h4><p><a href="[https://saruagithub.github.io/2020/03/10/20200309%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%A4%8D%E4%B9%A0/](https://saruagithub.github.io/2020/03/10/20200309排序算法复习/">排序—归并排序</a>)</p>
<p>归并排序的详细复杂度分析见 《算法导论》P21，通过递归树分析，总代价是$cnlgn + cn$ (c表示求解规模为1的问题所需要的时间以及在分解步骤与合并步骤处理每个数组元素所需要的时间。)</p>
<h3 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h3><h4 id="leecode84"><a href="#leecode84" class="headerlink" title="leecode84"></a>leecode84</h4><p>给定 <em>n</em> 个非负整数，用来表示柱状图中各个柱子的高度。每个柱子彼此相邻，且宽度为 1 。求在该柱状图中，能够勾勒出来的矩形的最大面积。</p>
<p>分析：最大面积是最矮柱子以后，矩形的宽尽可能往两边延伸；or 最矮柱子左边的最大面积矩形 or 最矮柱子右边的最大面积矩形。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">calculateArea</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; <span class="built_in">height</span>,<span class="keyword">int</span> start, <span class="keyword">int</span> <span class="built_in">end</span>)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (start &gt; <span class="built_in">end</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> minindex = start;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=start; i&lt;=<span class="built_in">end</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">height</span>[minindex] &gt; <span class="built_in">height</span>[i]) &#123;</span><br><span class="line">            minindex = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(<span class="built_in">height</span>[minindex]*(<span class="built_in">end</span>-start+<span class="number">1</span>) ,<span class="built_in">max</span>( calculateArea(<span class="built_in">height</span>,start,minindex<span class="number">-1</span>), calculateArea(<span class="built_in">height</span>,minindex+<span class="number">1</span>,<span class="built_in">end</span>)) );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">largestRectangleArea</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; <span class="built_in">height</span>)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> calculateArea(<span class="built_in">height</span>, <span class="number">0</span>, <span class="built_in">height</span>.<span class="built_in">size</span>()<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main_recursive</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; nums = &#123;<span class="number">2</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;largestRectangleArea(nums)&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1, 《算法导论》机械工业出版社 第三版（黑皮的，Thoms H Cormen…）</p>
<p>2，leecode网站</p>
<p>3，</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>递归</tag>
        <tag>分治</tag>
      </tags>
  </entry>
  <entry>
    <title>链表类算法</title>
    <url>/2020/03/29/20200329%E9%93%BE%E8%A1%A8%E7%B1%BB%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h3 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h3><p>用指针来实现线性表，链表是动态的。</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ListNode</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> val;</span><br><span class="line">    ListNode *next;</span><br><span class="line">    ListNode(<span class="keyword">int</span> x): val(x),next(<span class="literal">NULL</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>链表</tag>
        <tag>ListNode</tag>
      </tags>
  </entry>
  <entry>
    <title>数组实现堆</title>
    <url>/2020/03/28/20200328%E6%95%B0%E7%BB%84%E5%AE%9E%E7%8E%B0%E5%A0%86/</url>
    <content><![CDATA[<h3 id="完全二叉树"><a href="#完全二叉树" class="headerlink" title="完全二叉树"></a>完全二叉树</h3><p>完全二叉树，逐层而下，从左到右，结点的位置完全由其序号觉得，因此可以用数组来实现。</p><p>计算各结点下标的公式，其中$r$ 表示结点的下标，范围在0 ~ n-1 之间，n是二叉树结点的总数。</p><p>$Parent(r)= \lfloor (r-1)/2 \rfloor$ 向下取整，当$r≠0$时</p><p>$Leftchild(r)=2r+1$,当$2r+1&lt;n$时</p><a id="more"></a>



<p>$Rightchild(r)=2r+2$,当 $2r+2&lt;n$ 时</p>
<p>$Leftsibling()=r-1$,当r为偶数时</p>
<p>$Rightsibling()=r+1$ ,当r为奇数并且$r+1&lt;n$时</p>
<p><img src="/images/20200328Build_heap.jpg" alt="20200328Build_heap"></p>
<h3 id="C-实现"><a href="#C-实现" class="headerlink" title="C++实现"></a>C++实现</h3><p>完全二叉树的一个重要应用是最大堆和最小堆，最小堆就是儿子的值一定不小于父亲的值，树的节点从上到下，从左到右紧凑排列。这里给出最小堆的实现：</p>
<p>插入数值：在堆的末尾插入，然后不断向上提升，直到没有大小颠倒。</p>
<p>删除数值：首先把堆的最后一个节点的数值放到根上去，并且删除最后一个节点，然后不断向下交换直到没有大小颠倒为止。向下交换的时候如果2个儿子都比自己小，那么选择数值较小的儿子进行交换。</p>
<p>复杂度：建堆需要$\Theta(n)$ 的时间，但删除插入都和树深度成正比，时间复杂度是$\Theta(nlogn)$。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ------------------- min heap --------------------------</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MAX_N = <span class="number">100</span>;</span><br><span class="line"><span class="keyword">int</span> heap[MAX_N],sz=<span class="number">0</span>; <span class="comment">//sz is global variable, meaning the lengh of heap</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">heap_push</span><span class="params">(<span class="keyword">int</span> x)</span></span>&#123;</span><br><span class="line">    <span class="comment">//own node's num.</span></span><br><span class="line">    <span class="keyword">int</span> node_index = sz++;</span><br><span class="line">    <span class="keyword">while</span> (node_index &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> p = (node_index<span class="number">-1</span>)/<span class="number">2</span>; <span class="comment">//i's parent</span></span><br><span class="line">        <span class="keyword">if</span> (heap[p] &lt;= x) &#123;</span><br><span class="line">            <span class="keyword">break</span>; <span class="comment">// sequence is ok</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// parent's value put down, node value go up</span></span><br><span class="line">        heap[node_index] = heap[p];</span><br><span class="line">        node_index = p;</span><br><span class="line">    &#125;</span><br><span class="line">    heap[node_index] = x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">heap_pop</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// min (root)</span></span><br><span class="line">    <span class="keyword">int</span> rec = heap[<span class="number">0</span>];</span><br><span class="line">    <span class="comment">// the new temp root value, get it for compare and move it</span></span><br><span class="line">    <span class="keyword">int</span> x = heap[--sz];</span><br><span class="line">    <span class="comment">//replace from the root</span></span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (i*<span class="number">2</span>+<span class="number">1</span> &lt; sz) &#123;</span><br><span class="line">        <span class="comment">//compare the children value</span></span><br><span class="line">        <span class="keyword">int</span> a = i*<span class="number">2</span>+<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> b = i*<span class="number">2</span>+<span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (b &lt; sz &amp;&amp; heap[b] &lt; heap[a]) &#123;</span><br><span class="line">            a = b;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// sequence is right</span></span><br><span class="line">        <span class="keyword">if</span> (heap[a] &gt;= x) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// child's value go up</span></span><br><span class="line">        heap[i] = heap[a];</span><br><span class="line">        i=a;</span><br><span class="line">    &#125;</span><br><span class="line">    heap[i] = x;</span><br><span class="line">    <span class="keyword">return</span> rec;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">//push(3);</span></span><br><span class="line">    heap_push(<span class="number">9</span>);</span><br><span class="line">    heap_push(<span class="number">2</span>);</span><br><span class="line">    heap_push(<span class="number">6</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;sz; i++) &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;heap[i]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"pop:"</span>&lt;&lt;heap_pop()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"pop:"</span>&lt;&lt;heap_pop()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ------ standard package is the max queue ------</span></span><br><span class="line">    priority_queue&lt;<span class="keyword">int</span>&gt; qqueue;</span><br><span class="line">    qqueue.push(<span class="number">-9</span>);</span><br><span class="line">    qqueue.push(<span class="number">-2</span>);</span><br><span class="line">    qqueue.push(<span class="number">-6</span>);</span><br><span class="line">    <span class="comment">//loop until it is empty</span></span><br><span class="line">    <span class="keyword">while</span> (!qqueue.empty()) &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="number">-1</span> * qqueue.top()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        qqueue.pop();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，《数据结构与算法分析》 Clifford A. Shaffer 等</p>
<p>2，《挑战程序设计》</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>算法</tag>
        <tag>堆</tag>
        <tag>完全二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title>20200325word的xml无效而无法打开</title>
    <url>/2020/03/26/20200325word%E7%9A%84xml%E6%97%A0%E6%95%88%E8%80%8C%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80/</url>
    <content><![CDATA[<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>写论文生成word的时候出现了xml无效的问题。</p><p><img src="/images/20200325word_problem1.jpg" alt="20200325word_problem1"></p><p>将word文档原扩展名“docx”手动改为压缩文件扩展名“zip”，备份一个，然后用解压软件解压。用vscode编辑器或者其他的一些xml编辑器（如firstobject）打开解压文件夹下的word目录下的document.xml 文件。根据对xml错误提示进行更改。</p><a id="more"></a>


<p>我这里提示的错误是：起始标记“mc:Fallback”（偏移位置 1732371）在偏移位置 1733790缺少对应的结束标记。则将鼠标移动到 1733790个字节的位置，说明这里缺少了 ＜/mc:Fallback＞，注意英文输入。 </p>
<p>然后重复分析xml文档的缺失，直到没有任何问题。其中遇到了下图这个最后的问题，这个问题是直接缺了 ＜ /w:r＞这个标签，怎么分析的呢？是查找对比前面的几对Fallback的格式发现的缺失，这个就要好好对比一下了。</p>
<p><img src="/images/20200325word_problem2.jpg" alt="20200325word_problem2"></p>
<h3 id="重新打开"><a href="#重新打开" class="headerlink" title="重新打开"></a>重新打开</h3><p>最后将改完的xml替换原来的xml，再将“.zip”改回”.dcox“文档，再次打开word文件就可以打开了。</p>
]]></content>
      <categories>
        <category>配置</category>
      </categories>
      <tags>
        <tag>配置</tag>
        <tag>word</tag>
      </tags>
  </entry>
  <entry>
    <title>Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications (Donut model, Part Ⅱ)</title>
    <url>/2020/03/14/20200314paper-Unsupervised-Anomaly-Detection-via-Variational-AutoEncoder-for-Seasonal-KPIs-in-Web-Applications(Part2)/</url>
    <content><![CDATA[<h3 id="Evaluation实验"><a href="#Evaluation实验" class="headerlink" title="Evaluation实验"></a>Evaluation实验</h3><h4 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h4><p>我们从大型互联网上获得了18个维护良好的商业KPIs（时间跨度足以进行培训和评估），所有的KPIs间隔为1min。三个数据集 A B C 如图6的Table1。因此我们可以评估Donut在不同级别的噪声。 我们将每个数据集分为训练集 49%，验证集21%和测试集30%。</p><a id="more"></a>
<p><img src="/images/20200314Donut_Dataset.jpg" alt="20200314Donut_Dataset"></p>
<h4 id="Performance-Metric度量指标"><a href="#Performance-Metric度量指标" class="headerlink" title="Performance Metric度量指标"></a>Performance Metric度量指标</h4><p>评估中，完全忽略了所有算法在缺失点（“空”）的输出。本文所有评估的算法为每个点计算一个异常分数，选择一个阈值来进行决策：如果某个点的分数大于阈值，则应该触发警报。这样，异常检测就类似于分类问题，并且我们可以计算与每个阈值相对应的精度和召回率。给定所有可能的阈值，我们可以进一步计算AUC，即召回率的平均精度。或F分数，它是给定一个特定阈值的精度和召回率的谐平均值。我们还可能枚举所有阈值，获得所有F分数，并使用最佳F分数作为度量。给定最佳全局阈值，最好的F分数表示模型在特定测试集上的最佳性能。在实践中，最佳F分数与AUC基本一致，除了细微差异（见图8）。<strong>相比AUC我们更喜欢best F-score</strong>，因为在某个阈值上拥有出色的F分数比在大多数阈值上拥有高但不是那么出色的F分数更为重要。</p>
<p>简单评估策略：在实际应用中，操作员通常并不关心逐点度量。 如果延迟不太长，触发连续异常段中任何点的警报都是可接受的。 已经提出了一些用于异常检测的度量来适应这种偏好，例如，[22 NAB]，但是大多数度量没有被广泛接受，这可能是因为它们太复杂了。 相反，我们使用一种简单的策略：如果可以通过选定的阈值检测到真实异常段中的任何点，那么我们就说该段被正确检测了，并且将该段中的所有点都视为可以被此段检测到。 同时，异常段外的点将照常处理。 然后相应地计算精度，召回率，AUC，F-score和best F-score。 图7中说明了这种方法。alert delay = 警报分段中第一个点与第一个检测到的点之间的时间差。</p>
<p><img src="/images/20200314Metric.jpg" alt="20200314Metric"></p>
<h4 id="Experiment-启动"><a href="#Experiment-启动" class="headerlink" title="Experiment 启动"></a>Experiment 启动</h4><p>参数设置：我们设置窗口大小W = 120，即2h。W的选择受到两个因素的限制。 一方面，W太小将导致模型无法捕获模式，因为模型被期望识别出那些仅来自窗口的正常模式，（请参阅第5.1节）。 另一方面，W太大会增加过度拟合的风险，因为我们用没有权值共享的全连接层，因此模型参数的数量与W成正比。我们将B和C的潜在维度K设置为3，因为3维空间可以很容易地可视化以便分析。隐藏层的 $q_{\phi}(\mathbf{z} | \mathbf{x})$ 和 $p_{\theta}(\mathbf{x} | \mathbf{z})$ 都选择作两个ReLU层，每个ReLU层具有100个单位，这使得变分和生成网络具有相等的大小。我们没有对隐藏网络的结构进行详尽的搜索。</p>
<p>其他超参： std 层的 $\epsilon = 10^{-4}$ ，injection ratio = $\lambda$ ,  MCMC 迭代次数M = 10， 蒙特卡洛积分的采样数量$L = 1024$ ，训练的batch size = 256，运行250 Epochs，优化器是 Adam[15]，初始学习率是 $10^{-3}$ ，每过10Epochs就将学习率折0.75，对隐藏层采用L2正则化其系数coefficient = $10^{-3}$。 我们按标准裁剪clip梯度，限制为10.0。 </p>
<p>标签说明：为了评估没有标签的Donut，我们将忽略所有标签。 对于偶有的标签，我们对训练和验证集的异常标签进行下采样，以使其包含10％的标记异常。 请注意，缺失点不会被下采样。 我们一直随机丢弃异常片段，其概率与每个片段的长度成正比，直到达到所需的下采样率。 我们使用这种方法，而不是随机丢弃单个异常点，因为KPI是时间序列，并且每个异常点都可能泄漏有关其邻近点的信息，从而导致性能被高估。 这样的下采样完成了10次，这使我们能够进行10个独立的重复实验。 对于每个数据集，总体而言，我们有三个版本：0％标签，10％标签和100％标签。</p>
<h4 id="总体性能"><a href="#总体性能" class="headerlink" title="总体性能"></a>总体性能</h4><p>我们比较AUC，best F-score和平均alert delay，与三种算法相比，如图8：</p>
<p><img src="/images/20200314compare_metric.jpg" alt="20200314compare_metric"></p>
<p>比较的算法：Opprentice[25]，VAE baselin[2] 基于VAE的异常检测不处理时间序列，因此我们按以下方法设置VAE基模型。 首先，VAE基模型具有与Donut相同的网络结构，如图4所示。其次，在图3中的所有技术中，仅使用“数据准备”步骤中的那些技术。 第三，正如[2]所建议的，我们从训练数据中排除所有包含标记异常或缺失点的窗口。 Donut-Prior算法，给定一个生成模型自然学习 $p(x)$ ，而在VAE $p(x)$ 被定义为 $\mathbb{E}_{\boldsymbol{p}_{\theta}(\mathbf{z})}\left[p_{\theta}(\mathbf{x} | \mathbf{z})\right]$ ，我们还评估了重建概率的先前部分 $\mathbb{E}_{p_{\theta}(\mathbf{z})}\left[\log p_{\theta}(\mathbf{x} | \mathbf{z})\right]$。 我们只需要先验的基模型，因此我们可以通过简单的蒙特卡洛积分来计算先验期望，而无需使用先进的技术来改善结果。</p>
<p>The best F-score of Donut is quite satisfactory in totally unsu- pervised case, ranges from 0.75 to 0.9, </p>
<p>Donut，Opprentice和VAE Baseline的平均警报延迟在所有数据集中都是可接受的</p>
<h4 id="Donut技术的效果"><a href="#Donut技术的效果" class="headerlink" title="Donut技术的效果"></a>Donut技术的效果</h4><p>我们提出的三种技术的各自的作用(1) M-ELBO (Eqn (3)), (2) missing data injection, and (3) MCMC imputation。我们通过这些技术的四种可能的组合展示了Donut的最佳F分数：</p>
<p><img src="/images/202003154Tech-BestF-score.jpg" alt="202003154Tech-BestF-score"></p>
<p>仅M-ELBO就能在VAE基模型上做出大部分改进。 它通过训练Donut来适应x中可能出现的异常点并在这种情况下产生所需的输出而起作用。尽管对于生成模型来说很自然（第5.2节），但仅使用正常数据来训练VAE以进行异常检测不是一个好习惯。</p>
<p>丢失数据注入是为增强M-ELBO的效果而设计的，实际上可以看作是一种数据增强方法。我们仅注入遗漏的点。由于缺少数据注入而导致的最佳F分数的提高不是很明显。注射会给训练带来额外的随机性，因此需要更大的训练时间。</p>
<p>MCMC imputation还旨在帮助Donut处理异常点。 尽管Donut仅在某些情况下使用MCMC获得了最佳F评分的显着改善，但它从未损害性能。 根据[32]，这应该是预期的结果。 因此，我们建议在检测中始终采用MCMC。</p>
<h4 id="分析K的影响。"><a href="#分析K的影响。" class="headerlink" title="分析K的影响。"></a>分析K的影响。</h4><p>$z$ 的维度 K很重要。K太小可能会导致拟合不足或次优平衡（请参见第5.4节）。 另一方面，K太大可能会导致重建概率无法找到好的后验概率（请参阅第5.1节）。 在完全不受监督的情况下很难选择一个好的K，因此我们将其留作未来的工作。</p>
<h3 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h3><p>我们在此提出针对重建概率以及整个Donut算法的KDE（内核密度估计）解释。</p>
]]></content>
      <categories>
        <category>AIOps</category>
      </categories>
      <tags>
        <tag>AIOps</tag>
        <tag>论文</tag>
        <tag>AnomalyDetection</tag>
      </tags>
  </entry>
  <entry>
    <title>Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications (Donut model, Part I)</title>
    <url>/2020/03/13/20200314paper-Unsupervised-Anomaly-Detection-via-Variational-AutoEncoder-for-Seasonal-KPIs-in-Web-Applications(Part1)/</url>
    <content><![CDATA[<h3 id="ABS-amp-Intro"><a href="#ABS-amp-Intro" class="headerlink" title="ABS&amp;Intro"></a>ABS&amp;Intro</h3><h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><p>大的互联网公司一般会密切监控KPIs。然而这些有不同模式不同数据质量的季节性KPIs的异常检测很有挑战，特别是无标签。本文中，我们提出了Donut，基于VAE（Variational Auto-Encoder 变分自动编码器）的无监督异常检测算法，其最佳F-score达到0.75 ~ 0.9。我们为Donut的重构提出了一种新颖的KDE解释，使其成为第一种基于VAE的异常检测算法，并且具有扎实的理论解释。</p><a id="more"></a>
<h4 id="KPIs时间序列数据"><a href="#KPIs时间序列数据" class="headerlink" title="KPIs时间序列数据"></a>KPIs时间序列数据</h4><p>度量指标如页面浏览量，在线用户数量，订单数量等等。在所有的这些KPIs里，本文主要关心一些商业相关的KPIs，这些受用户行为计划所影响，因此大致表现出有规律的季节性模式（如按天，按周等）。</p>
<p>检测KPI异常的相关文献【1, 2, 5– 8, 17, 18, 21, 23–27, 29, 31, 35, 36, 40, 41】 很丰富。现有的异常检测算法遭受算法挑选/参数调整的麻烦，严重依赖标签，性能不令人满意和/或缺乏理论基础。</p>
<h4 id="本文"><a href="#本文" class="headerlink" title="本文"></a>本文</h4><p>本文提出的Donut，基于VAE（代表性的深层生成模型）的无监督异常检测算法，伴有理论解释，可以无标签或偶尔提供的标签下学习。</p>
<p>本文贡献：</p>
<p>1，Donut里的三项技术：改进的ELBO，缺失数据注入进行训练以及为了检测的MCMC (imputation)借补法。使它大大超越了最新的监督类和基于VAE的异常检测算法。 对于来自顶级全球互联网公司的研究KPI，无监督Donut的最佳F-score在0.75到0.9之间。</p>
<p>2，在文献中，我们首次发现采用VAE（或一般而言的生成模型）进行异常检测需要对正常数据和异常数据进行训练，这与通常的直觉相反。</p>
<p>3，我们为Donut在z空间中提出了一种新颖的KDE解释，使其成为第一个基于VAE的具有可靠理论解释的异常检测算法。这种解释可能有益于异常检测中其他深度生成模型的设计。 我们发现了潜在z空间中的时间梯度效应，很好地说明了Donut在检测季节性KPI异常方面的出色性能。</p>
<h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><h4 id="KPIs的异常检测"><a href="#KPIs的异常检测" class="headerlink" title="KPIs的异常检测"></a>KPIs的异常检测</h4><p>商业KPIs一般由季节性，另一方面在每个重复周期中，KPI曲线的形状并不完全相同，因为用户行为可能会随着天变化。这里我们命名KPIs为“具有局部变化的季节性KPIs” （如图1）</p>
<p><img src="/images/20200313Donut_Figure_KPIs.jpg" alt="20200313Donut_Figure1"></p>
<p>另一类局部变化是随着日数增加的趋势，可以通过Holt-Winters [41]和时间序列分解[6]来确定。 除非正确处理了这些局部变化，否则异常检测算法可能无法正常工作。</p>
<p>除了季节性，局部变化variation，这些KPIs也有噪声noise。我们假设噪声独立，在每个点服从0均值高斯分布。高斯噪声的精确值是没有意义的，因此，我们仅关注这些噪声的统计数据，即噪声的方差。</p>
<p>现在我们可以将季节性KPI的“正常模式”形式化为两个组成部分的组合：（1）具有局部变化的季节性模式（2）高斯噪声的统计数据。</p>
<p>我们使用Anomaly表示不遵循正常模式的（突然的尖峰和骤降）数据点，abnormal表示Anomaly和缺失点。本文主要检测Anomalies。</p>
<p>由于操作员需要处理异常以进行故障排除/缓解，因此有些异常会被标上标签。 请注意，此类偶然标签对异常的覆盖范围与典型的监督学习算法所需要的相去甚远。</p>
<p>异常检测算法一般对$x_{t-T+1}, \ldots, x_{t}$ 计算$p\left(y_{t}=1 | x_{t-T+1}, \ldots, x_{t}\right)$ ，操作员只需选择阈值判断异常。</p>
<h4 id="2-3的Problem-Statement"><a href="#2-3的Problem-Statement" class="headerlink" title="2.3的Problem Statement"></a>2.3的Problem Statement</h4><p>（挪到前面来了）在我们的上下文中，尽管远不完整，但偶尔还是可以使用标签，应该以某种方式加以利用。本文的问题陈述如下：</p>
<p>我们致力于<u>基于深度生成模型且具有可靠理论解释的无监督异常检测算法，该算法可以利用偶尔可用的标签</u>。</p>
<h3 id="Previous-Work"><a href="#Previous-Work" class="headerlink" title="Previous Work"></a>Previous Work</h3><h4 id="传统统计模型"><a href="#传统统计模型" class="headerlink" title="传统统计模型"></a>传统统计模型</h4><p>许多基于传统统计模型的异常检测器（大多是时间序列模型）[6, 17, 18, 24, 26, 27, 31, 40, 41] 已经被提出来计算异常分数。由于这些算法通常对适用的KPI有基本的假设，需要涉及专家的参考才能为给定的KPI选择合适的检测器，然后基于训练数据去微调检测器参数。这些检测器的简单集合（例如多数表决[8]和归一化[35]）不能很好地起作用。</p>
<h4 id="监督集成方法"><a href="#监督集成方法" class="headerlink" title="监督集成方法"></a>监督集成方法</h4><p>为了规避传统统计异常检测器算法/参数调整的麻烦，提出了有监督的集成方法<strong>EGADS [21]和Opprentice [25]</strong>。 他们使用用户反馈作为标签并使用传统检测器输出的异常评分作为特征来训练异常分类器。 EGADS和Opprentice均显示出令人鼓舞的结果，但它们严重依赖于<strong>良好的标签</strong>（远远超过我们所积累的轶事标签），这在大规模应用中通常不可行。 此外，运行多个传统检测器以在检测期间提取特征会引入大量的计算成本，这是一个实际问题。</p>
<h4 id="无监督方法与深度生成模型"><a href="#无监督方法与深度生成模型" class="headerlink" title="无监督方法与深度生成模型"></a>无监督方法与深度生成模型</h4><p>最近采用无监督机器学习方法是个趋势。, e.g., one-class SVM [1, 7], clustering based methods [9] like K-Means [28] and GMM [23], KDE [29], and VAE [2] and VRNN [36].  </p>
<p>其理念是关注正常模式而不是异常：由于KPIs通常主要由正常数据组成，因此即使没有标签也可以轻松地训练模型。 粗略地说，它们都首先识别原始或某些潜在特征空间中的“正常”区域，然后通过测量观测值与正常区域的“距离”来计算异常分数。</p>
<p>沿着此方向，1，学习正常模式可以看作是学习训练数据的分布，这是生成模型的主题。2，最近在利用深度学习技术训练生成模型方面取得了巨大进展（例如<strong>GAN [13]和深度贝叶斯网络[4，39]</strong>）。后者属于深度生成模型家族，它采用图形graphical[30]模型框架和变分技术[3]，以VAE [16，32]为代表。 3，尽管深度生成模型在异常检测方面具有广阔的前景，但现有的基于VAE的异常检测方法[2]并非为KPIs（时间序列）设计，在我们的设置中效果不佳（请参见§4），并且没有 为其用于异常检测的深度生成模型的设计提供支持的理论基础（请参阅§5）4，简单地采用基于VRNN的更复杂的模型[36]在我们的实验中显示出训练时间长且性能差。5，[2]假定仅对干净数据进行训练，这在我们的上下文中是不可行的。</p>
<h3 id="变分自动编码器Variational-Auto-Encoder"><a href="#变分自动编码器Variational-Auto-Encoder" class="headerlink" title="变分自动编码器Variational Auto-Encoder"></a>变分自动编码器Variational Auto-Encoder</h3><p>由于VAE是深度贝叶斯网络的基本构建块，因此我们选择开始使用VAE。</p>
<p><img src="/images/20200313Donut_Figure2_VAE.jpg" alt="20200313Donut_Figure2_VAE"></p>
<h4 id="VAE的背景"><a href="#VAE的背景" class="headerlink" title="VAE的背景"></a>VAE的背景</h4><p>深度贝叶斯网络使用神经网络来表达变量之间的关系，因此它们不再局限于简单的分布族，因此可以轻松地应用于复杂的数据。 在训练和预测中经常采用变分推理技术[12]，这是由神经网络延伸出的解决后验分布的有效方法。</p>
<p>VAE是深度贝叶斯网络，它对两个随机变量（潜变量$z$和可见变量$x$）之间的关系进行建模。 为 $z$ 选择一个先验分布，它通常是多元单位高斯分布 $\mathcal{N}(\mathbf{0}, \mathbf{I})$ 。之后，从由参数为 $\theta$ 的神经网络提取出的 $p_{\theta}(\mathbf{x} | \mathbf{z})$ 中采样得到 $x$ 。$p_{\theta}(\mathbf{z} | \mathbf{x})$ 的准确形式由任务需求进行选择。真实的后验 $p_{\theta}(\mathbf{z} | \mathbf{x})$ 是无解析解的，但对于训练是必不可少的，并且通常对预测有用，因此变分推理技术可用于fit另外的神经网络，作为近似后验 $q_{\phi}(\mathbf{z} | \mathbf{x})$。该后验通常被假定为 $\mathcal{N}\left(\boldsymbol{\mu}_{\phi}(\mathbf{x}), \boldsymbol{\sigma}_{\phi}^{2}(\mathbf{x})\right)$ , $\boldsymbol{\mu}_{\phi}(\mathbf{x})$ 与 $\boldsymbol{\sigma}_{\phi}(\mathbf{x})$ 是由神经网络导出。（如图FIgure2）</p>
<p>SGVB [16, 32] 是一个伴随VAE一起用的变分推断算法，其中通过最大化变分下界evidence lower bound (ELBO Eqn1 ) 来联合训练近似后验模型和生成模型。</p>
<p>Equation 1:</p>
<script type="math/tex; mode=display">\begin{aligned} \log p_{\theta}(\mathbf{x}) & \geq \log p_{\theta}(\mathbf{x})-\operatorname{KL}\left[q_{\phi}(\mathbf{z} | \mathbf{x}) \| p_{\theta}(\mathbf{z} | \mathbf{x})\right] \\ &=\mathcal{L}(\mathbf{x}) \\ &=\mathbb{E}_{\boldsymbol{q}_{\phi}(\mathbf{z} | \mathbf{x})}\left[\log p_{\theta}(\mathbf{x})+\log p_{\theta}(\mathbf{z} | \mathbf{x})-\log q_{\phi}(\mathbf{z} | \mathbf{x})\right] \\ &=\mathbb{E}_{\boldsymbol{q}_{\phi}(\mathbf{z} | \mathbf{x})}\left[\log p_{\theta}(\mathbf{x}, \mathbf{z})-\log q_{\phi}(\mathbf{z} | \mathbf{x})\right] \\ &=\mathbb{E}_{\boldsymbol{q}_{\phi}(\mathbf{z} | \mathbf{x})}\left[\log p_{\theta}(\mathbf{x} | \mathbf{z})+\log p_{\theta}(\mathbf{z})-\log q_{\phi}(\mathbf{z} | \mathbf{x})\right] \end{aligned}</script><p>蒙特卡洛积分常常被用于近似 Eqn 1 中的期望。如Eqn 2，$\mathbf{z}^{(l)}, l=1 \ldots L$ 是来自 $q_{\phi}(\mathbf{z} | \mathbf{x})$ 的样例samples。整个本文中，我们都坚持使用这种方法。</p>
<p>Equation 2：</p>
<script type="math/tex; mode=display">\mathbb{E}_{\boldsymbol{q}_{\phi}(\mathbf{z} | \mathbf{x})}[f(\mathbf{z})] \approx \frac{1}{L} \sum_{l=1}^{L} f\left(\mathbf{z}^{(l)}\right)</script><h3 id="Architecture结构"><a href="#Architecture结构" class="headerlink" title="Architecture结构"></a>Architecture结构</h3><p>Donut的总体架构如图Figure3，三个关键技术是Modified ELBO，训练时的Missing Data Injection， 检测时的MCMC Imputation。</p>
<p><img src="/images/20200314Arch_Donut.jpg" alt="20200314Arch_Donut"></p>
<p><img src="/images/20200314Network_Donut.jpg" alt="20200314Network_Donut"></p>
<h4 id="Network-Structure"><a href="#Network-Structure" class="headerlink" title="Network Structure"></a>Network Structure</h4><p>VAE不是一个序列模型，因此我们在KPI上应用长度为 $w$ 的<strong>滑动窗口</strong>[34]。 对于每一个 $x_t$ 使用 $x_{t-W+1}, …, x_{t}$ 作为VAE的 $X$  向量。该滑动窗口由于其简单性而首先被采用，实际上却带来了重要而有益的结果。</p>
<p>Donut的总体网络结构如图4，其中有双线轮廓的组件 (e.g., Sliding Window x, W Dimensional at bottom left) 是我们的新设计，其余组件来自标准VAEs。先验 $p_{\theta}(z)$ 被选择为 $\mathcal{N}(\mathrm{0}, \mathrm{I})$ 。 x和z后验均选择为对角高斯 diagonal Gaussian：</p>
<script type="math/tex; mode=display">p_{\theta}(\mathbf{x} | \mathbf{z})=\mathcal{N}\left(\boldsymbol{\mu}_{\mathbf{x}}, \boldsymbol{\sigma}_{\mathbf{x}}^{2} \mathbf{I}\right)</script><script type="math/tex; mode=display">q_{\phi}(\mathbf{z} | \mathbf{x})=\mathcal{N}\left(\boldsymbol{\mu}_{\mathbf{z}}, \boldsymbol{\sigma}_{\mathbf{z}}^{2} \mathbf{I}\right)</script><p>这里的$\mu_x,\mu_z,\sigma_x,\sigma_z$ 是每个独立高斯组件的均值和标准差。 $z$ 是 K 维的。通过分离的隐藏层$f_{\phi}(\mathbf{x}) , f_{\theta}(\mathbf{z})$ ，从 $x$ 和 $z$ 隐藏特征被提取出来。然后从隐藏特征中得出x和z的高斯参数。 </p>
<p>均值是从线性层导出：</p>
<script type="math/tex; mode=display">\boldsymbol{\mu}_{\mathbf{X}}=\mathbf{W}_{\boldsymbol{\mu}_{\mathbf{X}}}^{\top} f_{\theta}(\mathbf{z})+\mathbf{b}_{\boldsymbol{\mu}_{\mathbf{X}}}</script><script type="math/tex; mode=display">\boldsymbol\mu_{z}=\mathbf{W}_{\mu_{z}}^{\top} f_{\phi}(\mathbf{x})+\mathbf{b}_{\mu_{z}}</script><p>标准差是从soft-plus层导出，加上一个非负小数 $\epsilon$ ：</p>
<script type="math/tex; mode=display">\sigma_{\mathrm{x}} = \text{SoftPlus} \left[\mathbf{W}_{\sigma_{x}}^{\top} f_{\phi}(\mathbf{x})+\mathbf{b}_{\sigma_{x}}\right]+\epsilon</script><script type="math/tex; mode=display">\sigma_{\mathrm{z}}=\text{SoftPlus} \left[\mathbf{W}_{\boldsymbol{\sigma}_{\mathbf{z}}}^{\top} f_{\phi}(\mathbf{z})+\mathbf{b}_{\boldsymbol{\sigma}_{\mathbf{z}}}\right]+\boldsymbol{\epsilon}</script><p>这里的 $\text{SoftPlus}[a] = log[exp(a) + 1]$ ，这里介绍的所有W-s和b-s是相应层的参数。 注意，将标量函数 $f(x)$ 应用于向量 $x$ 时，意味着将其应用于每个部分component。</p>
<p>我们以此种方式导出 $\sigma_x, \sigma_z$ 而非像其他人一样用线性层导出 $log_{\sigma_x}$ 有以下几个原因：我们关注的 KPIs 的局部变化非常小，以至于 $\sigma_x$ 和 $\sigma_z$ 可能变得非常接近于零，从而使 $log_{\sigma_x}$ 和$\log_{\sigma_z}$无界。 在计算高斯变量的可能性时，这将导致严重的数值问题。 因此，我们使用soft-plus和 $\epsilon$ 技巧来防止此类问题。</p>
<p>我们有意选择全连接层作为隐藏层的结构，从而使整体体系结构相当简单。 这是因为我们的目标是开发具有扎实的理论解释的基于VAE的异常检测算法，并且简单的网络结构无疑将使在复杂的“变分自动编码器”中分析内部行为更加容易。</p>
<h4 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h4><p>训练直接用SGVB[16] 算法去优化 ELBO (Eqn 1) ，由于[16]报告，当使用SGVB算法训练VAE时，一个样本已经足以计算ELBO，因此在训练期间让采样数$L = 1$。我们还按照SGVB的要求应用了重新参数化技巧：没有采样 $\mathbf{z} \sim \mathcal{N}\left(\boldsymbol{\mu}_{\mathbf{z}}, \boldsymbol{\sigma}_{\mathbf{z}}^{2} \mathbf{I}\right)$ ，专门的随机变量 $\xi \sim \mathcal{N}(0, \mathrm{I})$ 被采样，如此我们重写 $z$ 为 $\mathbf{z}(\boldsymbol{\xi})=\boldsymbol{\mu}_{\mathbf{z}}+\boldsymbol{\xi} \cdot \boldsymbol{\sigma}_{\mathbf{z}}$。$\xi$ 上的采样与参数 $\phi$ 无关，像VAE是普通神经网络一样，这使我们能够应用<strong>随机梯度下降</strong>。$x$ 的窗口在每个epoch之前都会随机打乱，这有利于随机梯度下降。 在每个mini-batch中要获取足够多的 $x$，这对于稳定训练至关重要，因为采样会引入额外的随机性。</p>
<p>对于某些给定的KPIs这里没有labels，可能会想用合成的值替换训练数据中的标记异常（如果有）和缺失点（已知）。先前的一些工作已经提出了填补缺失数据的方法，例如[37]，但是很难产生足够好地遵循“正常模式”的数据。重要的是，用另一种算法生成的数据训练生成模型是很荒谬的，因为生成模型的一个主要应用就是生成数据。 使用由比VAE更弱的算法估算的数据可能会降低性能。 因此，我们不会在训练VAE之前采用缺失数据插值imputation，而是选择简单地将缺失点填充为零（在图3中的数据准备步骤中），然后修改ELBO（以下简称M-ELBO）以排除异常和缺失点的影响（如图所示）。 如图3中的“训练”步骤。</p>
<p>更具体地，我们<strong>修改标准的ELBO</strong> （Eqn 1中）为 Eqn 3：</p>
<script type="math/tex; mode=display">\widetilde{\mathcal{L}}(\mathbf{x})=\mathbb{E}_{\boldsymbol{q}_{\phi}(\mathbf{z} | \mathbf{x})}\left[\sum_{w=1}^{W} \alpha_{w} \log p_{\theta}\left(x_{w} | \mathbf{z}\right)+\beta \log p_{\theta}(\mathbf{z})-\log q_{\phi}(\mathbf{z} | \mathbf{x})\right]</script><p>其中 $\alpha_w$ 定义为指示值 indicator，当$\alpha_w = 1$ 指示 $x_w$ 不是异常值或缺失值。$\alpha_w = 0$ 反之。$\beta$ 被定义为 $\left(\sum_{w=1}^{W} \alpha_{w}\right) / W$ 。请注意，当训练数据中没有标记的异常时，方程（3）仍然成立。$\alpha_w$ 直接排除了来自标记的异常和缺失点的 $p_{\theta}\left(x_{w} | \mathbf{z}\right)$ 的贡献，而缩放因子 $\beta$ 根据 $x$ 中正常点的比例缩小了 $p_{\theta}(\mathbf{z})$ 的贡献。这种修改使Donut能够正确地重建 $x$ 内的正常点，即使 $x$ 内的某些点异常。我们并没有收缩 $q_{\phi}(\mathbf{z} | \mathbf{x})$ ，因为下面两个考虑：不像 $p_{\theta}(\mathbf{z})$ 是生成模型 （即“正常模式”的模型）中的一部分，$q_{\phi}(\mathbf{z} | \mathbf{x})$ 仅仅描述了从x到z的映射，并未考虑“正常模式”。因此，似乎没有必要去掉 $q_{\phi}(\mathbf{z} | \mathbf{x})$ 的贡献。另一个原因是 $\mathbb{E}_{\boldsymbol{q}_{\phi}(\mathbf{z} | \mathbf{x})}\left[-\log q_{\phi}(\mathbf{z} | \mathbf{x})\right]$ 是 $q_{\phi}(\mathbf{z} | \mathbf{x})$ 的熵。这个熵术语实际上在训练中还有其他作用（将在5.3节中讨论），因此最好保持不变。</p>
<p>进一步地，我们还在训练中引入了<strong>缺失数据注入</strong>：我们将 $λ$ 比例的正常点随机设置为零，就好像它们是缺失点一样。 缺失点更多，当给定异常 $x$ 时 ，会更频繁地训练Donut来重建正常点，从而增强了M-ELBO的效果。 该注入在每轮  epoch 之前完成，并且在Epoch 结束后恢复点。 图3中的Training步骤显示了这种丢失的数据注入。</p>
<h4 id="Detection"><a href="#Detection" class="headerlink" title="Detection"></a>Detection</h4><p>与仅为一个目的而设计的判别模型（例如，为仅计算分类概率 $p(y|x)$ 而设计的分类器）不同，像VAE这样的生成模型可以得出各种输出。 在异常检测的范围内，观察窗 $x$ 的可能性（即VAE中的 $p_{\theta}(\mathbf{x})$ ）是重要的输出，因为我们想知道给定的 $x$ 遵循正常模式的程度。可以采用蒙特卡洛方法来计算 $x$ 的概率密度 <script type="math/tex">p_{\theta}(\mathbf{x})=\mathbb{E}_{p_{\theta}(\mathbf{z})}\left[p_{\theta}(\mathbf{x} | \mathbf{z})\right]</script> 。尽管在理论上有很好的解释，但实际上，对先验样本进行采样实际上并不能很好地完成工作，如第4段所示</p>
<p>与其对先验进行采样，不如通过变分后验 $q_{\phi}(\mathbf{z} | \mathbf{x})$ 来推导有用的输出。一种选择是计算出 $\mathbb{E}_{\boldsymbol{q}_{\phi}(\mathbf{z} | \mathbf{x})}\left[p_{\theta}(\mathbf{x} | \mathbf{z})\right]$ 。尽管与 $p_{\theta}(\mathbf{x})$ 相似，它实际上不是一个定义很好的概率密度。另一种选择是计算在[2] 中采用的 $\mathbb{E}_{\boldsymbol{q}_{\phi}(\mathbf{z} | \mathbf{x})}\left[\log p_{\theta}(\mathbf{x} | \mathbf{z})\right]$ ，称为“重建概率”。由于在异常检测中只关注异常评分的顺序而不是确切值，因此我们遵循[2]并使用后者。或者另一个可选项，如[36]所示，ELBO（等式Eqn 1）也可用于近似 $\log p_{\theta}(\mathbf{x})$。然而，在ELBO的另外一项  $\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}\left[\log p_{\theta}(\mathbf{z})-\log q_{\phi}(\mathbf{z} | \mathbf{x})\right]$  使其内部机制难以理解。 由于[36]中的实验不支持该可选方法的优越性，因此我们选择不使用它。</p>
<p>在检测期间，测试窗口$x$中的异常点和缺失点可能给映射的 $z$ 带来偏差，并进一步使重建概率不准确，这将在5.2节中讨论。 由于缺失点始终是已知的（称为“null”），我们有机会消除缺失点所带来的偏差。 我们选择采用经过训练的VAE的基于MCMC的缺失数据插入imputation技术，该技术由[32]提出。 同时，我们在检测之前不知道异常点的确切位置，因此无法对异常采用MCMC。</p>
<p>更具体地，测试 $x$ 被划分为观察部分和缺失部分，即 $\left(\mathbf{x}_{o}, \mathbf{x}_{m}\right)$。一个 $z$ 样例从 $q_{\phi}\left(\mathbf{z} | \mathbf{x}_{o}, \mathbf{x}_{m}\right)$ 中获取，然后一个重建样例 $\left(\mathbf{x}_{\boldsymbol{o}}^{\prime}, \mathbf{x}_{m}^{\prime}\right)$ 从 $p_{\theta}\left(\mathbf{x}_{\boldsymbol{o}}, \mathbf{x}_{m} | \mathbf{z}\right)$ 中获取得到。$\left(\mathbf{x}_{o}, \mathbf{x}_{m}\right)$ then由 $\left(\mathbf{x}_{\boldsymbol{o}}, \mathbf{x}_{m}^{\prime}\right)$ 替换，即观察点是固定的，缺失点被设置为新值。  这个过程迭代 M次，然后最终的 $\left(\mathbf{x}_{o}, \mathbf{x}_{m}^{\prime}\right)$ 被用来计算重建概率。在整个过程中，中间值$\mathbf{x}_{m}^{\prime}$会越来越接近正常值。给定足够大的M，可以减少偏差，并且可以获得更准确的重构概率。 MCMC方法在图5中说明，并在图3的“检测”步骤中显示。</p>
<p><img src="/images/20200314Figure5_MCMC.jpg" alt="20200314Figure5_MCMC"></p>
<p>MCMC之后，我们取z的L个样本通过蒙特卡洛积分来计算重构概率。 值得一提的是，尽管我们可以计算x的每个窗口中每个点的重建概率，但我们仅使用最后一个点的分数（即$x_t$ 在 $x_{t-T+1}, \ldots, x_{t}$），因为我们想要将在检测过程中尽快归纳异常 。后续文章中我们仍将使用矢量符号，它们与VAE的体系结构相对应。 尽管可以通过延迟决策并在不同时间考虑同一点的更多分数来提高检测性能，但我们将其留作将来的工作。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，Xu H, Chen W, Zhao N, et al. Unsupervised anomaly detection via variational auto-encoder for seasonal kpis in web applications[C]//Proceedings of the 2018 World Wide Web Conference. 2018: 187-196.</p>
]]></content>
      <categories>
        <category>AIOps</category>
      </categories>
      <tags>
        <tag>AIOps</tag>
        <tag>论文</tag>
        <tag>AnomalyDetection</tag>
      </tags>
  </entry>
  <entry>
    <title>Computers&amp;Operations Research部分论文简读</title>
    <url>/2020/03/10/20200310Computers&amp;Operations%20Research%E9%83%A8%E5%88%86%E8%AE%BA%E6%96%87%E7%AE%80%E8%AF%BB/</url>
    <content><![CDATA[<h2 id="Exact-and-heuristic-approaches-to-detect-failures-in-failed-k-out-of-n-systems"><a href="#Exact-and-heuristic-approaches-to-detect-failures-in-failed-k-out-of-n-systems" class="headerlink" title="Exact and heuristic approaches to detect failures in failed k-out-of-n systems"></a>Exact and heuristic approaches to detect failures in failed k-out-of-n systems</h2><h3 id="ABS-amp-Intro"><a href="#ABS-amp-Intro" class="headerlink" title="ABS&amp;Intro"></a>ABS&amp;Intro</h3><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>本文考虑n个系统中k个故障了（表决系统），相应的测试每个组件是有成本的。另外，我们具有某些组件是故障的原因的先验概率信息。目标是以最小的预期成本去识别导致故障的那部分组件。</p><a id="more"></a>
<h4 id="本文工作"><a href="#本文工作" class="headerlink" title="本文工作"></a>本文工作</h4><p>提出了精确与近似的策略，在故障表决系统（k-out-of-n）中检测组件状态。我们提出两种整数规划编程公式，两种基于Markov决策过程（MDP）的新颖方法以及两种启发式算法。展示了精确式算法的限制以及启发式算法在随机产生的测试例子的有效性。尽管CPU时间更长，整数规划更灵活地整合更多约束 restriction，例如必要时进行测试优先级关系。数值结果表明，针对所提出的MDP模型进行动态编程是最有效的精确方法，在一小时内最多可解决12个组件。 针对小到中级测试实例，启发式算法的性能是对比精确式算法给的，并针对高级测试实例给出下限。</p>
<h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>系统越来越复杂，组件、感应器，子系统越来越多。为了系统更加可靠，系统中总会有冗余存在。当组件故障时，整个系统也可能fail，需要尽快恢复。两个主要问题：(1) 是否系统工作和失败（序列测试问题） (2) 故障原因（failure detection故障检测问题）。在这两种问题中，可行的解决方法可以被描述为二分决策树，目标是最小化期望成本。</p>
<p>difference区别：故障检测问题中测试结果的概率随着测试执行而变化。但在序列测试问题中则是不变的。另一个区别是，在故障检测问题中，输出是导致故障的一组组件，而在序列测试问题中，输出是系统正在运行或发生故障的信息以及该状态的证明。</p>
<h4 id="研究综述"><a href="#研究综述" class="headerlink" title="研究综述"></a>研究综述</h4><p>序列测试问题和故障检测问题：Chang 研究在序列测试的上下文中以最小的成本诊断电子晶体，并提供多项式时间的精确式算法。B K 提出了表决系统以在核反应堆子系统中提供冗余，以实现可靠的运行。W提出当测试不完美并且测试有优先限制时的启发式算法。Ba分析某些维护策略的长期平均成本。Gar蚁群优化算法用于计算机网络中的故障定位。</p>
<p>故障检测问题的灵异研究领域：离散搜索问题，旨在找到隐藏在N个盒子中的一个item，并且其预期成本最小。检查盒子会很昂贵，并且已知该item在盒子内的概率是先验的。K对搜索问题提出最优贪心算法，当仅可能出现假阳性结果时。W&amp;D考虑一个变体，当存在简单的优先级约束并且路径依赖关系由组活动定义时。</p>
<h4 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h4><p>1，我们引入和研究了k-out-of-n系统的故障检测问题，将文献中研究的n-out-of-n系统归纳了下来。</p>
<p>2，我们提供了四种精确的两种启发式方法来解决该问题，并提供了两种下限lower bound方案，用于在较大的情况下进行基准测试。</p>
<p>3，首次提出整数规划建模和马尔可夫决策过程来解决此类问题。</p>
<p>4，我们进行数值实验以评估不同方法的有效性。</p>
<p>（暂时了解背景和introduction，未读完）</p>
<h2 id="A-survey-of-models-and-algorithms-for-emergency-response-logistics-in-electric-distribution-systems-Part-I-Reliability-planning-with-fault-considerations"><a href="#A-survey-of-models-and-algorithms-for-emergency-response-logistics-in-electric-distribution-systems-Part-I-Reliability-planning-with-fault-considerations" class="headerlink" title="A survey of models and algorithms for emergency response logistics in electric distribution systems. Part I: Reliability planning with fault considerations"></a>A survey of models and algorithms for emergency response logistics in electric distribution systems. Part I: Reliability planning with fault considerations</h2><h3 id="ABS-amp-Intro-1"><a href="#ABS-amp-Intro-1" class="headerlink" title="ABS&amp;Intro"></a>ABS&amp;Intro</h3><p>配电系统的应急响应设计一系列在可靠性和应急计划级别的决策问题。这些操作包括故障诊断，故障定位，故障隔离，恢复和修复。本文回顾了针对与配电运行相关的故障考虑的可靠性规划问题的优化模型和解决方法。本文对确定配电变电站单故障容量，重新分配超负荷，配置配电系统，将地理区域划分为服务区域以及定位物料仓库和仓库的研究进行了调查。</p>
<p>规划应急响应的操作涉及许多决策问题，可以使用运筹学方法论来解决。 故障情况可能会导致配电系统服务中断的“极端”状态，从而降低服务质量并给电力公司造成经济损失。eg 2008年1月在中国中东部和南部地区的暴风雪使几个省的电线和电线杆倒塌，影响了中国近三分之二的土地，估计造成了100亿美元的直接经济损失。但应急分配响应研究少。</p>
<p>由于网络拓扑结构，操作能力和应用的操作设备等特性的差异，规划人员面临的问题非常复杂，并且因地而异。 在过去的二十年中，文献中已经出现了越来越多的运筹学应用程序用于应急分配响应。配电系统中涉及的大量组件，配电网络的复杂性以及公用事业运营这些网络的能力不断提高，所有这些都促使人们在配电公用事业的各个层面上使用优化技术。</p>
<h2 id="Application-of-Optimized-Machine-Learning-Techniques-for-Prediction-of-Occupational-Accidents"><a href="#Application-of-Optimized-Machine-Learning-Techniques-for-Prediction-of-Occupational-Accidents" class="headerlink" title="Application of Optimized Machine Learning Techniques for Prediction of Occupational Accidents"></a>Application of Optimized Machine Learning Techniques for Prediction of Occupational Accidents</h2><h3 id="ABS-amp-Intro-2"><a href="#ABS-amp-Intro-2" class="headerlink" title="ABS&amp;Intro"></a>ABS&amp;Intro</h3><p>机器学习在职业安全领域中预测事故的探索几乎是新的。但基于ML方法的算法在参数合理调整优化之前并不能得到最佳性能。更进一步，此外，仅选择高效的优化分类器可能无法满足总体决策目的，因为它无法解释事故发生背后的因素之间的相互关系。因此，除了预测之外，还需要从事故数据中提取决策规则。</p>
<p>考虑到上述问题，在这项研究中，使用职业事故数据occupational accident data，已优化的机器学习算法来已经被应用于预测事故后果，例如伤害，差错和财产损失。使用了两种流行的机器学习算法，即支持向量机（SVM）和人工神经网络（ANN），其参数通过两种强大的优化算法进行了优化，<strong>即遗传算法（GA）和粒子群优化（PSO）</strong>，以实现更高的准确性和鲁棒性。基于PSO的SVM具有最高的准确性和鲁棒性，优于其他算法。此外，<strong>通过将决策树C5.0算法与基于PSO的SVM模型相结合来提取规则</strong>。最后，提取了一组九个有用的规则，以识别造成伤害，near miss差错和财产损失案件的根本原因。提出了一个钢铁厂的案例研究case study，以揭示该方法的潜力和有效性。</p>
<p>简介：全球每年约有230万工人死于职业事故和疾病，其中包括约36万致命事故[1]。事故的根本原因是不安全的情况或不安全的行为，或两者兼有。造成事故的因素有很多。文献中有许多理论可以解释事故的因果关系。 Khanzode等 [5]解释了他们在事故背后的各种研究理论，例如事故倾向性理论[6]，多米诺骨牌理论[7]，伤害流行病学[8]，系统理论[9]，社会技术系统理论[10]和宏观人机工程学理论[11]。由于一系列事件或因果关系的存在，导致发生伤害事件。如果知道原因，则可以预测结果（即事故）。另外，预测模型将量化各种因果因素对事故发生的贡献。</p>
<p>ML用于预测模型很广泛。然而，ML技术用于职业事件分析还是有限的 limited biasis。至今，关于职业分析的研究展示了基于机器学习技术的预测能力[14]和解释能力[15]。这些方法基于事件报告中的历史数据或与员工进行的访谈，可确保它们在预测功能和影响事件结果的预测变量的重要性方面优于常规统计数据。</p>
<p>本文：</p>
<p>本研究的主要目标是使用机器学习技术（即SVM和ANN）开发预测模型，以预测职业事故的后果。 为了获得更好的精度，在分类器上采用了优化技术，即GA和PSO。 此外，基于PSO-SVM、结合决策树（C5.0）的分类器对伤害injury的发生提取规则。 次要目标包括使用卡方特征选择技术识别可归因于事件结果的相关变量。 分析结果显示了SVM分类器在预测以及规则提取目的方面的效用。</p>
<h3 id="文献综述"><a href="#文献综述" class="headerlink" title="文献综述"></a>文献综述</h3><p>在职业事件预测中，许多机器学习算法如SVM，ANN，Extreme Learning machine（极限学习机）与决策树等。在DT在事故分析中的应用中，通常使用C4.5，C5.0分类和回归树（CART）分析，卡方自动交互检测器（CHAID）等算法来预测职业事故。使用DT的主要目的是预测和解释数据中的定性和定量模式，从而对隐藏信息探索。 由于对属性分布或属性独立性假设的放宽，DTs已成功应用于医学[17]，社会科学[18]，业务管理[19]，建筑工程与管理[20]，过程等不同领域 工业[13]。</p>
<p>除了DTs，神经网络，贝叶斯分类器，自适应神经模糊推理系统（ANFIS），贝叶斯网络，支持向量机，extreme learning machine (ELM) 被用于不同的领域。eg：He等。试图通过使用ANN的后向算法（BA-ANN）和指数评估方法（EEM）的分类技术解决煤与瓦斯突发问题[24]。使用BAANN，针对响应变量（即煤和瓦斯突发）计算因子的权重。Yi等人他们收集了550份与工作，环境和个人有关的数据，并由ANN进行了分析，以预测建筑工地工人的感知劳累（RPE）等级。</p>
<p>以上机器学习方法都要调整参数。为了调整分类算法的参数，发现优化方法比其他技术（如手动调整或网格搜索）最有用。从其他领域的研究可以看出，为了提高SVM模型的准确性，可以考虑优化惩罚因子（c）和内核参数 r [27]。有许多优化技术用于这个目的像遗传算法（GA），粒子群优化（PSO），梯度下降法等[28]。其中，GA和PSO被认为是最优化分类器参数（例如SVM）以实现更高准确度的方法[29]。使用基于GA算法的反向传播神经网络（BPNN）的初始参数，网络拓扑，权重和阈值[30]。 </p>
<p>分类器不仅取决于参数，还取决于数据类型。数值属性比类别属性或纯文本属性有更多信息。事故领域中的大多数文献都使用数值数据或类别数据来分析事故场景。 对纯文本数据的分析仍未得到充分利用，因为从纯文本中提取模式是一项艰巨的任务。 叙事文本是预测事故的关键资源之一。 它提供了分析中有价值的附加信息以及其他类型的数据。如布朗所做的一个值得注意的贡献是使用与潜在狄利克雷分配（LDA）和随机森林[35]等其他技术相关的文本挖掘来分析铁路事故数据，以探索事故背后的主要因素。在道路事故分析中，Pereira等人进行了一项研究。使用交通事件报告的主题建模来实时提取信息以预测事件持续时间[40]。</p>
<p>从事故数据集中提取规则及其解释通常被认为是一种有效的方法。通常可以使用决策树（DT）或关联规则挖掘（ARM）方法获得规则。在一些职业事故研究中，DT已比ARM更多地用于规则提取和解释。当目标函数是离散值，属性值对可描述目标函数或对数据集进行噪声训练时，发现DT很有用。还尝试过带有SVM的DT算法，以将SVM决策的黑匣子变成透明且可理解的规则，这些规则可用作任何决策任务的第二意见。</p>
<h3 id="本文研究关键"><a href="#本文研究关键" class="headerlink" title="本文研究关键"></a>本文研究关键</h3><p>1，将文本数据与非文本数据用于事件预测</p>
<p>2，分类器的参数优化，以获得更好的预测准确率</p>
<p>3，少有基于SVM的规则提取用于事件发生的研究</p>
<h2 id="Application-of-SVM-and-ANN-for-intrusion-detection"><a href="#Application-of-SVM-and-ANN-for-intrusion-detection" class="headerlink" title="Application of SVM and ANN for intrusion detection"></a>Application of SVM and ANN for intrusion detection</h2><h3 id="ABS-amp-Intro-3"><a href="#ABS-amp-Intro-3" class="headerlink" title="ABS &amp; Intro"></a>ABS &amp; Intro</h3><p>两种数据挖掘技术，ANNs 人工神经网络和支持向量机。两种编码方式，，基于简单频率的方案和tf×idf方案，来检测潜在的系统入侵。我们的结果展示采用TF-IDF方案的SVM性能最佳，而基于简单频率方案的ANN表现最差。实验中使用的数据是麻省理工学院林肯实验室的DARPA 1998入侵检测评估计划的BSM审核数据。</p>
<p>简介：电子商务和最近的在线消费者热潮迫使对共享网络上的系统的基本计算机安全设计进行更改。 现在设计的系统具有更高的灵活性和更少的屏障安全性。 此外，随着计算机在金融上越来越普及给大众，它们也越来越以消费者为导向。 用户友好性和公共可访问性的结合，尽管对普通人有利，但不可避免地使交换的信息容易受到犯罪分子的攻击。 存储在内部数据仓库中的消费者信息，员工数据或知识产权受到外部攻击者和不满员工的威胁，他们可能会滥用访问权限谋取私利。由于软件应用程序中隐藏的弱点和错误bug，安全策略或防火墙很难阻止此类攻击。 此外，黑客不断发明新的攻击并通过Internet进行传播。</p>
<p> 入侵检测系统可以检测，识别并响应未经授权的或异常的活动，具有缓解或防止此类攻击的潜力。 因此，security breech是Internet社区日益关注的一个领域[2]。</p>
<p>大多数研究人员（请参见表1）使用简短的系统调用序列来表征程序行为。少部分使用系统调用的频率分布。与基于序列的编码技术相比，基于频率的编码技术所需的开销更少，基于序列的编码技术需要为每个程序构建一个文件（例如，必须为sendmail或lpr 1构建一个文件），并在每个时间帧检查攻击 。 基于频率的编码技术仅为每个进程而不是每个程序（一个进程可能包含多个程序）建立一个配置文件，并在该过程结束时检查攻击实例。 </p>
<p>在这项研究中，我们探索了应用人工神经网络（ANN）和支持向量机（SVM）预测基于基于频率的编码技术的攻击的可行性。使用ANN和SVM进行攻击检测的目的是从有限的训练数据中发展泛化能力。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，Yavuz T, Kundakcioglu O E, Ünlüyurt T. Exact and heuristic approaches to detect failures in failed k-out-of-n systems[J]. Computers &amp; Operations Research, 2019, 112: 104752.</p>
<p>2，A survey of models and algorithms for emergency response logistics in electric distribution systems. Part I: Reliability planning with fault considerations</p>
<p>3，Application of Optimized Machine Learning Techniques for Prediction of Occupational Accidents</p>
<p>4，Application of SVM and ANN for intrusion detection （Wun-Hwa Chen, Sheng-Hsun Hsu∗, Hwang-Pin Shen）</p>
]]></content>
      <categories>
        <category>AIOps</category>
      </categories>
      <tags>
        <tag>AIOps</tag>
        <tag>故障检测</tag>
        <tag>Operation Research</tag>
      </tags>
  </entry>
  <entry>
    <title>排序算法复习</title>
    <url>/2020/03/10/20200309%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%A4%8D%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="排序算法"><a href="#排序算法" class="headerlink" title="排序算法"></a>排序算法</h3><p>排序算法在搜索中常用，因此非常重要。排序算法里包含了重要的分治的思想，就是在划分子问题上。归并排序将数据折半划分，快速排序将数据分成大数和小数部分，基数排序则每次都会按照关键码中的一个数字划分数据。</p><p>什么是稳定的排序：如果一种排序算法不会改变关键码值相同的记录的相对顺序，则称为稳定的。</p><h4 id="三种基本的排序算法"><a href="#三种基本的排序算法" class="headerlink" title="三种基本的排序算法"></a>三种基本的排序算法</h4><a id="more"></a>

<h5 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h5><p>例子：每处理一次数据就把它和前面已经排序的子序列进行比较，再将它插入到前面的正确位置。算法里的Comp类要自己写，实现关键码比较大小，如int就直接比较大小，其他类别比较大小等等。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// C++</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> E, <span class="keyword">typename</span> Comp&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">inssort</span><span class="params">(E A[], <span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;n;i++)</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> j=i; (j&gt;<span class="number">0</span>)&amp;&amp;(Comp::prior(A[j],A[j<span class="number">-1</span>])); j--)</span><br><span class="line">			swap(A, j, j<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># python</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_sort</span><span class="params">(array)</span>:</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(array)):</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> range(i,<span class="number">0</span>,<span class="number">-1</span>):</span><br><span class="line">			<span class="keyword">if</span> j&gt;<span class="number">0</span> <span class="keyword">and</span> array[j] &lt; array[j<span class="number">-1</span>]:</span><br><span class="line">				array[j],array[j<span class="number">-1</span>] = array[j<span class="number">-1</span>],array[j] <span class="comment"># change the elem</span></span><br></pre></td></tr></table></figure>
<p>这里最差的情况是每条记录都必须移动到最前面（如 array = [3,2,1,0])，空间复杂度由于并没有用其他临时数组，所以还是 $O(1)$，此时时间复杂度：</p>
<script type="math/tex; mode=display">\sum_{i=2}^n i \approx n^2/2 = \Theta(n^2)</script><p>最佳情况就是每条记录都已经是有序的了，进入内部for循环就退出，于是此时的时间代价是 $\Theta(n)$</p>
<p>平均情况根据逆置来判断，逆置的数值（即数组中位于一个给定值之前的比它大的值的数目）决定比较与交换的次数。平均情况下，在数组的前i-1条记录中有一半关键码值比第i条记录的关键码值大。平均情况下，时间代价是最差情况的一半 $\Theta(n^2/4)$， 是稳定排序。</p>
<h5 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h5><p>例子：气泡冒上来的过程。从最后开始，比较相邻的，如果前面的比它大则交换。就像气泡逐渐被推到数组的顶部。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//C++</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> E,<span class="keyword">typename</span> Comp&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bubsort</span><span class="params">(E A[], <span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n<span class="number">-1</span>;i++)</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j=n<span class="number">-1</span>; j&gt;i; j--)</span><br><span class="line">      <span class="keyword">if</span>(Comp::prior(A[j],A[j<span class="number">-1</span>]))</span><br><span class="line">        swap(A,j,j<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># python</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sort</span><span class="params">(array)</span>:</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(array)<span class="number">-1</span>):</span><br><span class="line">		flag = <span class="number">0</span>  <span class="comment"># trace the exchange times</span></span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> range(len(array)<span class="number">-1</span>,i,<span class="number">-1</span>):</span><br><span class="line">			<span class="keyword">if</span> array[j] &lt; array[j<span class="number">-1</span>]:</span><br><span class="line">				array[j], array[j - <span class="number">1</span>] = array[j - <span class="number">1</span>], array[j]</span><br><span class="line">				flag = <span class="number">1</span></span><br><span class="line">		<span class="keyword">if</span>(flag==<span class="number">0</span>):</span><br><span class="line">			<span class="keyword">return</span></span><br></pre></td></tr></table></figure>
<p>内层的for循环比较次数总会是 i，因此最差时间代价是：$\sum_{i=1}^n i \approx n^2/2 = \Theta(n^2)$ ，平均也是类似插入排序$\Theta(n^2)$，它是稳定的排序。</p>
<p>修改冒泡排序以跟踪其执行的交换次数。 如果数组已经按排序顺序排列，并且冒泡排序不进行交换，则算法可以在经过一遍后终止。在最佳情况下复杂度是 $\Theta(n)$ 。</p>
<p>冒泡排序相对于大多数其他算法（甚至是快速排序，但不是插入排序）具有的唯一显着优势是，该算法内置了检测列表是否被有效排序的功能。</p>
<h5 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h5><p>选择排序就是选择数组中第i小的记录，并把该记录放到数组的第i个位置上，只需一次交换。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> E,<span class="keyword">typename</span> Comp&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">selsort</span><span class="params">(E A[], <span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n<span class="number">-1</span>; i++)&#123;</span><br><span class="line">    <span class="keyword">int</span> lowindex = i;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j=n<span class="number">-1</span>; j&gt;i ; j--)</span><br><span class="line">      <span class="keyword">if</span>(Comp::prior(A[j], A[lowindex]))</span><br><span class="line">        lowindex = j;</span><br><span class="line">    swap(A,i,lowindex);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># python</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">select_sort</span><span class="params">(array)</span>:</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(array)<span class="number">-1</span>):</span><br><span class="line">		lowindex = i</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> range(len(array)<span class="number">-1</span>, i, <span class="number">-1</span>):</span><br><span class="line">			<span class="keyword">if</span> array[j] &lt; array[lowindex]:</span><br><span class="line">				lowindex = j</span><br><span class="line">			array[i], array[lowindex] = array[lowindex], array[i]</span><br></pre></td></tr></table></figure>
<p>比较的次数是 $\Theta(n^2)$ ，但交换的次数比冒泡排序少很多，对于那些做交换花费时间多的问题是更好的。</p>
<h3 id="改进的排序"><a href="#改进的排序" class="headerlink" title="改进的排序"></a>改进的排序</h3><h4 id="shellsort"><a href="#shellsort" class="headerlink" title="shellsort"></a>shellsort</h4><p>它在不相邻的记录之间进行比较与交换。shell排序利用了插入排序的最佳时间代价特性。他将序列分成多个子序列，然后分别对子序列进行排序，最后将子序列组合起来。由于实现了元素的跳跃式移动，使排序效率提高。如下图：图中的增量序列就是8，4，2，1。最后一轮将是一次“正常的”插入排序，因为此时序列整体基本上有序，故用插入排序的复杂度相对较小。</p>
<p>shellsort增量选择3的时候，效果较好，平均运行时间复杂度是$\Theta(n^{1.5})$ 。 </p>
<p>相同的元素可能在各自的插入排序中移动， 是不稳定排序。在中等大小规模的数据上表现良好。</p>
<p><img src="/images/20200310shellsort.jpg" alt="20200310shellsort"></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//shellsort</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span>  E&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insort</span><span class="params">(E A[],<span class="keyword">int</span> n, <span class="keyword">int</span> increment)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=increment; i&lt;n; i+=increment) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=i; (j&gt;=increment)&amp;&amp;(A[j]&lt;A[j-increment]); j-=increment) &#123;</span><br><span class="line">            E temp = A[j];</span><br><span class="line">            A[j] = A[j-increment];</span><br><span class="line">            A[j-increment] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span>  E&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">shellsort</span><span class="params">(E A[],<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=n/<span class="number">2</span>; i&gt;<span class="number">2</span>; i/=<span class="number">2</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;i; j++) &#123;</span><br><span class="line">            insort&lt;E&gt;(&amp;A[j], n-j, i);<span class="comment">//A[j] is the start address  偏移，巧妙</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    insort&lt;E&gt;(A, n, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> num[<span class="number">16</span>] = &#123;<span class="number">59</span>,<span class="number">20</span>,<span class="number">17</span>,<span class="number">13</span>,<span class="number">28</span>,<span class="number">14</span>,<span class="number">23</span>,<span class="number">83</span>,<span class="number">36</span>,<span class="number">98</span>,<span class="number">11</span>,<span class="number">70</span>,<span class="number">65</span>,<span class="number">41</span>,<span class="number">42</span>,<span class="number">15</span>&#125;;</span><br><span class="line">    shellsort&lt;<span class="keyword">int</span>&gt;(num, <span class="number">16</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> n:num) &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;n&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Python：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">def shell_sort(array):</span><br><span class="line">	n = len(<span class="built_in">array</span>)</span><br><span class="line">	gap = n <span class="comment">// 2</span></span><br><span class="line">	<span class="keyword">while</span> gap &gt; <span class="number">0</span>:</span><br><span class="line">		<span class="keyword">for</span> i in range(gap,n):</span><br><span class="line">			temp = <span class="built_in">array</span>[i]</span><br><span class="line">			j = i</span><br><span class="line">			<span class="keyword">while</span> j &gt;= gap <span class="keyword">and</span> <span class="built_in">array</span>[j-gap] &gt; temp:</span><br><span class="line">				<span class="built_in">array</span>[j] = <span class="built_in">array</span>[j-gap]</span><br><span class="line">				j-=gap</span><br><span class="line">			<span class="built_in">array</span>[j] = temp</span><br><span class="line">		gap <span class="comment">//= 2</span></span><br></pre></td></tr></table></figure>
<h4 id="mergesort"><a href="#mergesort" class="headerlink" title="mergesort"></a>mergesort</h4><p>来源于分治的思想，在排序问题上分治的思想体现在把待排序的列表分成片段，先处理片段，然后将片段重组。</p>
<p>伪代码的提现其思想：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">List mergesort(List inlist)&#123;</span><br><span class="line">	if(inlist.length() &lt;= 1) return inlist;</span><br><span class="line">	List L1 = half of the list;</span><br><span class="line">	List L2 = other half of the list;</span><br><span class="line">	return mergesort(mergesort(L1),mergesort(L2));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/images/20200310Merge-Sort.png" alt="20200310Merge-Sort"></p>
<p>当输入的待排序数据存储在链表中时，归并排序是一个很好的选择。</p>
<p>两个指针，最初分别为两个已经排序序列的起始位置。比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置。重复直到某一指针达到序列尾，剩下的元素直接放入到合并的片段里。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> E&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mergesort</span><span class="params">(E A[],E temp[], <span class="keyword">int</span> left, <span class="keyword">int</span> right)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (left == right) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> mid = left + (right-left)/<span class="number">2</span>;</span><br><span class="line">    mergesort&lt;E&gt;(A, temp, left, mid);</span><br><span class="line">    mergesort&lt;E&gt;(A, temp, mid+<span class="number">1</span>, right);</span><br><span class="line">    <span class="comment">//then merge, temp[] is the auxiliary array</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=left; i&lt;=right; i++) &#123;</span><br><span class="line">        temp[i] = A[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> i1 = left;</span><br><span class="line">    <span class="keyword">int</span> i2 = mid+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> curr=left; curr&lt;=right; curr++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (i1 == mid+<span class="number">1</span>) A[curr] = temp[i2++]; <span class="comment">//left all &lt; right</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(i2 &gt; right) A[curr] = temp[i1++]; <span class="comment">//right all &lt; left</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (temp[i1] &lt; temp[i2]) A[curr] = temp[i1++];<span class="comment">// smaller one is put into A</span></span><br><span class="line">        <span class="keyword">else</span> A[curr] = temp[i2++];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> num[<span class="number">16</span>] = &#123;<span class="number">59</span>,<span class="number">20</span>,<span class="number">17</span>,<span class="number">13</span>,<span class="number">28</span>,<span class="number">14</span>,<span class="number">23</span>,<span class="number">83</span>,<span class="number">36</span>,<span class="number">98</span>,<span class="number">11</span>,<span class="number">70</span>,<span class="number">65</span>,<span class="number">41</span>,<span class="number">42</span>,<span class="number">15</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> temp[<span class="number">16</span>] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">    mergesort&lt;<span class="keyword">int</span>&gt;(num, temp, <span class="number">0</span>, <span class="number">15</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> n:num) &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;n&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当被排序元素的数目是n时，递归的深度是$logn$ ，第一层递归是对长度为n的数组排序，下一层是对2个长度为n/2的子数组排序……，在所有$logn$ 层递归中，每一层都需要$\Theta(n)$ 时间代价，因此总时间代价都是$n log(n)$。由于需要temp数组做临时存储，空间复杂度是$\Theta(n)$.</p>
<p>python版本代码可以参考<a href="https://www.geeksforgeeks.org/python-program-for-merge-sort/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/python-program-for-merge-sort/</a></p>
<h4 id="quicksort"><a href="#quicksort" class="headerlink" title="quicksort"></a>quicksort</h4><p>快速排序不需要额外的空间，典型应用是Unix系统调用库里的qsort函数。快速排序选定一个轴值，数组在小于轴值的放在左边，大于的放在右边。这被称为数组的一个划分 partition。快速排序最差情况是当轴值每次都不能把数组划分得很好，下一次处理子问题规模只比原来的问题规模减少1，时间代价是$\Theta(n^2)$ ，最佳和平均复杂度是$\Theta(n logn)$ 。2，由于递归调用，空间复杂度是$\Theta(logn)$</p>
<p>快排为什么这么快？</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> A[], <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> temp = A[i];</span><br><span class="line">    A[i] = A[j];</span><br><span class="line">    A[j] = temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">partition</span><span class="params">(<span class="keyword">int</span> A[],<span class="keyword">int</span> l, <span class="keyword">int</span> r, <span class="keyword">int</span>&amp; pivot)</span></span>&#123;</span><br><span class="line">    <span class="keyword">do</span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(A[++l] &gt; pivot); <span class="comment">//move the index</span></span><br><span class="line">        <span class="keyword">while</span>((l&lt;r) &amp;&amp; (A[--r] &lt; pivot));</span><br><span class="line">        swap(A,l,r);</span><br><span class="line">    &#125;<span class="keyword">while</span>(l&lt;r);</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">myqsort</span><span class="params">(<span class="keyword">int</span> A[],<span class="keyword">int</span> i,<span class="keyword">int</span> j)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (i &gt;= j) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">int</span> pivotIndex = (i+j)/<span class="number">2</span>; <span class="comment">//这里可以写一个findpivot函数，三者取中（三个随机值的中间）</span></span><br><span class="line">    swap(A,pivotIndex,j);</span><br><span class="line">    <span class="keyword">int</span> k = partition(A,i<span class="number">-1</span>,j,A[j]); <span class="comment">//k is the start of the left half</span></span><br><span class="line">    swap(A,k,j);<span class="comment">// 轴值就在k位置，就是最终排序好的数组中的位置</span></span><br><span class="line">    myqsort(A,i,k<span class="number">-1</span>);</span><br><span class="line">    myqsort(A,k+<span class="number">1</span>,j);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里面的改进可以从pivotIndex的设置，以及递归到一个较小的数组的时候采用插入排序（基本有序的小数组很适合）等。</p>
<p>Python版本：更清晰一点，把轴值设置为左边第一个。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span><span class="params">(array, left, right)</span>:</span></span><br><span class="line">	<span class="keyword">if</span> left &gt;= right:</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	low = left</span><br><span class="line">	high = right</span><br><span class="line">	key = array[low]</span><br><span class="line">	<span class="keyword">while</span> left &lt; right:</span><br><span class="line">		<span class="keyword">while</span> left &lt; right <span class="keyword">and</span> array[right] &gt; key:</span><br><span class="line">			right -= <span class="number">1</span></span><br><span class="line">		array[left] = array[right]</span><br><span class="line">		<span class="keyword">while</span> left &lt; right <span class="keyword">and</span> array[left] &lt;= key:</span><br><span class="line">			left += <span class="number">1</span></span><br><span class="line">		array[right] = array[left]</span><br><span class="line">	array[right] = key</span><br><span class="line"></span><br><span class="line">	quick_sort(array, low, left - <span class="number">1</span>)</span><br><span class="line">	quick_sort(array, left + <span class="number">1</span>, high)</span><br></pre></td></tr></table></figure>
<h4 id="heapsort"><a href="#heapsort" class="headerlink" title="heapsort"></a>heapsort</h4><p>堆是一棵完全二叉树，可以用数组来实现。参考 <a href="[https://saruagithub.github.io/2020/03/28/20200328%E6%95%B0%E7%BB%84%E5%AE%9E%E7%8E%B0%E5%A0%86/](https://saruagithub.github.io/2020/03/28/20200328数组实现堆/">数组实现堆</a>)</p>
<p>堆可以用来排序，适合于那些数据集太大而不适合在内存中排序的例子。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> E&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">heapsort</span><span class="params">(E A[], <span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">	E maxval;</span><br><span class="line">	heap&lt;E&gt; Heap(A,n,n); <span class="comment">//build the heap</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n ; i++)</span><br><span class="line">    maxval = Heap.removefirst();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>建堆需要$\Theta(n)$，且n次取堆的最大元素要用$\Theta(logn)$ 时间，因此时间代价是$nlogn$。但堆排序一般情况下比快排在常熟因子上慢。</p>
<p>为什么堆排比快排慢？堆排序将最大值取走后要调整结构，用堆底元素替换堆顶元素，然后那最后一个元素从顶上往下滑到恰当的位置（重新使堆最大化）。其实这里堆底的元素肯定很小，将它拿到堆顶和原本属于最大元素的两个子节点比较，比他们都大的可能性是很小的。这一次比较的结果就是概率不均等的，这次比较就很有可能是无效的，堆顶元素很有可能继续下移比较。</p>
<p>Python实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># To heapify subtree rooted at index i , n is size of heap</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heapify</span><span class="params">(array,n,i)</span>:</span></span><br><span class="line">	largest = i <span class="comment"># init largest as root</span></span><br><span class="line">	l = <span class="number">2</span> * i + <span class="number">1</span></span><br><span class="line">	r = <span class="number">2</span> * i + <span class="number">2</span></span><br><span class="line">  </span><br><span class="line">	<span class="comment"># See if left child of root exists and is greater than root</span></span><br><span class="line">	<span class="keyword">if</span> l &lt; n <span class="keyword">and</span> array[i] &lt; array[l]:</span><br><span class="line">		largest = l</span><br><span class="line">	<span class="comment"># See if right child of root exists and is greater than root</span></span><br><span class="line">	<span class="keyword">if</span> r &lt; n <span class="keyword">and</span> array[largest] &lt; array[r]:</span><br><span class="line">		largest = r</span><br><span class="line"></span><br><span class="line">	<span class="comment"># Change root, if needed</span></span><br><span class="line">	<span class="keyword">if</span> largest != i:</span><br><span class="line">		array[i], array[largest] = array[largest], array[i]  <span class="comment"># swap</span></span><br><span class="line">		<span class="comment"># Heapify the root</span></span><br><span class="line">		heapify(array, n, largest)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># The main function to sort an array of given size</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heapSort</span><span class="params">(arr)</span>:</span></span><br><span class="line">	n = len(arr)</span><br><span class="line">	<span class="comment"># Build a maxheap.</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(n, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">		heapify(arr, n, i)</span><br><span class="line">	<span class="comment"># One by one extract elements</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(n - <span class="number">1</span>, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">		arr[i], arr[<span class="number">0</span>] = arr[<span class="number">0</span>], arr[i]  <span class="comment"># swap</span></span><br><span class="line">		heapify(arr, i, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h4 id="计数排序-分配排序Binsort"><a href="#计数排序-分配排序Binsort" class="headerlink" title="计数排序 / 分配排序Binsort"></a>计数排序 / 分配排序Binsort</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">	B[A[i]] = A[i];</span><br></pre></td></tr></table></figure>
<p>这里的关键码用来确定一个记录在排序中的最后的位置，关键码将记录放到盒子里，是分配排序的一个基本例子。比如数组[0,3,4,2,1] 经过一遍之后，B array 就直接把值放到了该放的地方了。</p>
<p>但这里它只能用于对一个从0到n-1的序列进行排序，而且还有重复的问题待处理。如果数组B变成一个链表数组，将所有的关键码i的值放到B[i] 盒子里，这就解决了重复的问题。另一个扩展是允许关键码大于n。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;list&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MaxKeyValue = <span class="number">100</span>; <span class="comment">// 0&lt;=A[i]&lt;=50</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Binsort</span><span class="params">(<span class="keyword">int</span> A[],<span class="keyword">int</span> n)</span></span>&#123; <span class="comment">// n is the A.length</span></span><br><span class="line">    <span class="keyword">if</span>(n&lt;=<span class="number">0</span>) <span class="keyword">return</span>;</span><br><span class="line">    <span class="built_in">list</span>&lt;<span class="keyword">int</span>&gt; B[MaxKeyValue];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++) &#123;</span><br><span class="line">        B[A[i]].push_back(A[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;MaxKeyValue; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (B[i].<span class="built_in">size</span>() != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="built_in">list</span>&lt;<span class="keyword">int</span>&gt;::iterator it=B[i].<span class="built_in">begin</span>(); it!=B[i].<span class="built_in">end</span>(); ++it) &#123;</span><br><span class="line">                <span class="built_in">cout</span>&lt;&lt;*it&lt;&lt;<span class="string">','</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> num[<span class="number">16</span>] = &#123;<span class="number">59</span>,<span class="number">20</span>,<span class="number">17</span>,<span class="number">13</span>,<span class="number">28</span>,<span class="number">14</span>,<span class="number">23</span>,<span class="number">83</span>,<span class="number">36</span>,<span class="number">98</span>,<span class="number">11</span>,<span class="number">70</span>,<span class="number">65</span>,<span class="number">41</span>,<span class="number">42</span>,<span class="number">15</span>&#125;;</span><br><span class="line">  Binsort(num,<span class="number">16</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里也可以优化一些，计数排序：B[A[i]] 存储 A[i] 值出现的次数。这样最好遍历一遍B，再根据次数，输出下标值，即排序后的A[i]。但以上设计的缺陷是MaxKeyValue太大了，如果是$n^2$ ， 那么时间代价就是 $\Theta(n^2)$ ，而且所用空间也更大了。</p>
<h4 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序"></a>桶排序</h4><p>进一步改进前面的Binsort为桶式排序Bucketsort，每一个盒子并非与一个关键码值联系，而是与一组关键码有关。记录放到“桶”中后，再借用其他排序对桶里的记录排序。</p>
<p>eg：有10个盒子，首先可以把记录的关键码对10取模的结果赋值到盒子里，这样每个关键码都以其个位为标准放到10个不同的盒子里。然后按顺序再收集这些记录，按照最高位（十位）对他们进行排序。如图：</p>
<p><img src="/images/20200310BucketSort.jpg" alt="20200310BucketSort"></p>
<p>对于n长的序列，假设基数是r，这个算法需要k轮，每一轮分配的时间是$\Theta(n+r)$ </p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">radix</span><span class="params">(<span class="keyword">int</span> A[], <span class="keyword">int</span> Bin[],<span class="keyword">int</span> n,<span class="keyword">int</span> k,<span class="keyword">int</span> r,<span class="keyword">int</span> cnt[])</span></span>&#123;</span><br><span class="line">    <span class="comment">//n is the size of A,k is the digit of A[max], r is Cardinality 10 (make r from 1 to 10 to 100)</span></span><br><span class="line">    <span class="comment">//cnt[i] stores number of records in bin[i]</span></span><br><span class="line">    <span class="keyword">int</span> j;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>,rtoi=<span class="number">1</span>; i&lt;k; i++,rtoi*=r) &#123;</span><br><span class="line">        <span class="keyword">for</span> (j=<span class="number">0</span>; j&lt;r; j++) cnt[j] = <span class="number">0</span>; <span class="comment">//init cnt,roti save the r^i</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">//count the number of records for each bin on this pass</span></span><br><span class="line">        <span class="keyword">for</span> (j=<span class="number">0</span>; j&lt;n; j++) cnt[(A[j] / rtoi) % r]++;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//index of B: cnt[j] will be index for last slot of bin j</span></span><br><span class="line">        <span class="keyword">for</span> (j=<span class="number">1</span>; j&lt;r; j++) cnt[j] = cnt[j<span class="number">-1</span>] + cnt[j];</span><br><span class="line"></span><br><span class="line">        <span class="comment">//put records into bins, work from bottom of each bin</span></span><br><span class="line">        <span class="comment">//since bins fill from bottom, j counts downwards</span></span><br><span class="line">        <span class="keyword">for</span> (j=n<span class="number">-1</span>; j&gt;=<span class="number">0</span>; j--) &#123;</span><br><span class="line">            Bin[--cnt[(A[j] / rtoi) % r]] = A[j]; <span class="comment">//wait for debug.....</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//copy B back to A</span></span><br><span class="line">        <span class="keyword">for</span> (j=<span class="number">0</span>; j&lt;n; j++) &#123;</span><br><span class="line">            A[j] = Bin[j];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">      <span class="keyword">int</span> n = <span class="number">12</span>;</span><br><span class="line">    <span class="keyword">int</span> k=<span class="number">2</span>;</span><br><span class="line">    <span class="keyword">int</span> r=<span class="number">10</span>;</span><br><span class="line">    <span class="keyword">int</span> A[<span class="number">12</span>] = &#123;<span class="number">27</span>,<span class="number">91</span>,<span class="number">1</span>,<span class="number">97</span>,<span class="number">17</span>,<span class="number">23</span>,<span class="number">84</span>,<span class="number">28</span>,<span class="number">72</span>,<span class="number">5</span>,<span class="number">67</span>,<span class="number">25</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> B[<span class="number">12</span>] = &#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> cnt[] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">    radix(A,B,n,k,r,cnt);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++) &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;A[i]&lt;&lt;<span class="string">" "</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="基数排序"><a href="#基数排序" class="headerlink" title="基数排序"></a>基数排序</h4><h3 id="其他内嵌算法"><a href="#其他内嵌算法" class="headerlink" title="其他内嵌算法"></a>其他内嵌算法</h3><h4 id="timsort"><a href="#timsort" class="headerlink" title="timsort"></a>timsort</h4><p>这是Python的内嵌排序算法。</p>
<p><img src="/Users/wangxue/gitpro/20191105MyBlog/saruagithub/source/images/20200310Allsort.jpg" alt="20200310Allsort"></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，《数据结构与算法分析》 Clifford A. Shaffer 等</p>
<p>2，<a href="[https://baike.baidu.com/item/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F](https://baike.baidu.com/item/希尔排序">百度百科</a>)</p>
<p>3， <a href="https://www.jiqizhixin.com/articles/2018-11-20-3" target="_blank" rel="noopener">机器之心 Timsort</a></p>
<p>4，<a href="https://www.geeksforgeeks.org/python-program-for-merge-sort/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/python-program-for-merge-sort/</a></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title>DFS与BFS算法</title>
    <url>/2020/02/28/20200228DFS%E4%B8%8EBFS%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h3><p>深度优先搜索从某个状态开始，不断的转移状态直到无法转移，然后回退到前一步的状态。执行的过程其实是跟栈有关，因为暂时没有执行的部分会被存放到堆栈里。直白点就是一条道走到黑，然后再逐步掉头，继续走到头。</p><p>一般要注意算法停止条件。迭代过程分析。</p><h3 id="2-DFS类题目"><a href="#2-DFS类题目" class="headerlink" title="2 DFS类题目"></a>2 DFS类题目</h3><h4 id="部分和问题"><a href="#部分和问题" class="headerlink" title="部分和问题"></a>部分和问题</h4><p>给定整数$a_{1}, a_{2}, \cdots, a_{n}$ ，判断能否可以从中选出若干数，使他们的和恰好为$k$</p><a id="more"></a>


<p>例如：输入 n = 4, a = {1,2,4,7} , k=13</p>
<p>Yes (13 = 2 + 4 + 7)</p>
<p>分析：首先要考虑所有数字的组合情况，判断组合的加和是否等于k，典型的搜索过程，用DFS。转移过程就是先一直往左到底，然后在倒回去一步走 dfs(i+1, sum+a[i])  加上a[i] 。</p>
<p>如下图，整个DFS的展开如黑色，红色是执行过程：</p>
<p><img src="/images/20200228Dfs1.jpg" alt="20200228_dfs1"></p>
<p>深度优先搜索就是从最开始的状态出发，遍历所有可以达到的状态。由此可以对所有的状态进行操作或者列举出所有的状态。DFS在设计的时候要考虑停止条件（i==n），搜索的结果变量 sum等。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> max_N = <span class="number">100</span>;</span><br><span class="line"><span class="keyword">int</span> n,k,a[max_N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> i,<span class="keyword">int</span> sum)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(i == n)</span><br><span class="line">        <span class="keyword">return</span> sum==k; <span class="comment">// all nums have been used</span></span><br><span class="line">    <span class="keyword">if</span>(dfs(i+<span class="number">1</span>, sum))  <span class="comment">//not add a[i]</span></span><br><span class="line">        <span class="keyword">return</span>  <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">if</span>(dfs(i+<span class="number">1</span>, sum+a[i])) <span class="comment">// add a[i]</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"input n:"</span>;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;n;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;a[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;k;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(dfs(<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Yes!\n"</span>);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"No!\n"</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="延伸-leecode39题"><a href="#延伸-leecode39题" class="headerlink" title="延伸 leecode39题"></a>延伸 leecode39题</h5><p>给定一个无重复元素的数组 <code>candidates</code> 和一个目标数 <code>target</code> ，找出 <code>candidates</code> 中所有可以使数字和为 <code>target</code> 的组合。<code>candidates</code> 中的数字可以无限制重复被选取。（这里与上一题的不同在于数字可以重复选取，并且要存所有组合的结果）</p>
<p>分析：组合、搜索问题首先需要画出树形图，代码根据树形图写出来。</p>
<p>如输入: <code>candidates = [2, 3, 6, 7]</code>，<code>target = 7</code>，所求解集为: <code>[[7], [2, 2, 3]]</code>。</p>
<p>我自己的思路：首先k控制DFS的深度，sum判断每次加和结果，last存上一个candidate的值，从而在每次下一层的时候避免重复选择之前选过的小的值。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 注意last控制去重</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dfs_addSum1</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp;candidates,<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; res,<span class="keyword">int</span> target, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; v, <span class="keyword">int</span> k, <span class="keyword">int</span> sum, <span class="keyword">int</span> last)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (sum == target) &#123;</span><br><span class="line">        res.push_back(v);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (sum &gt; target) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i&lt;candidates.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (candidates[i] &lt; last) <span class="keyword">break</span>;</span><br><span class="line">        v.push_back(candidates[i]);</span><br><span class="line">        dfs_addSum1(candidates,res,target,v,k+<span class="number">1</span>,sum+candidates[i],candidates[i]);</span><br><span class="line">        v.pop_back();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; combinationSum1(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; candidates, <span class="keyword">int</span> target) &#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; v;</span><br><span class="line">    sort(candidates.<span class="built_in">begin</span>(), candidates.<span class="built_in">end</span>());</span><br><span class="line">    dfs_addSum1(candidates,res,target,v, <span class="number">0</span>, <span class="number">0</span> ,<span class="number">0</span> ); <span class="comment">// 0 means level, 0 is temp_sum, 0 is the last val</span></span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>另一种答案的思路是根据remain 从最开始的target减去candidate里的剩余数字。last变量这里很巧，这样每次就从比之前的数字更大的数字去选择。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dfs_addSum</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp;candidates,<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; res,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; v,<span class="keyword">int</span> remain, <span class="keyword">int</span> last)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(remain == <span class="number">0</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    res.push_back(v);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span>(remain &lt; <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = last; i &lt; candidates.<span class="built_in">size</span>(); i++)</span><br><span class="line">  &#123;</span><br><span class="line"></span><br><span class="line">    v.push_back(candidates[i]);</span><br><span class="line">    dfs_addSum(candidates,res,v, remain - candidates[i], i);</span><br><span class="line">    v.pop_back();</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; combinationSum(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; candidates, <span class="keyword">int</span> target) &#123;</span><br><span class="line">  <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">  <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; v;</span><br><span class="line">  sort(candidates.<span class="built_in">begin</span>(), candidates.<span class="built_in">end</span>());</span><br><span class="line">  dfs_addSum(candidates,res,v,target, <span class="number">0</span>);</span><br><span class="line">  <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="电话号码的字母组合"><a href="#电话号码的字母组合" class="headerlink" title="电话号码的字母组合"></a>电话号码的字母组合</h4><p>leecode17题：给定一个仅包含数字 <code>2-9</code> 的字符串，返回所有它能表示的字母组合。</p>
<p>对应关系如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">unordered_map</span>&lt;<span class="keyword">char</span>, <span class="built_in">string</span>&gt; table&#123;</span><br><span class="line">    &#123;<span class="string">'0'</span>, <span class="string">" "</span>&#125;, &#123;<span class="string">'1'</span>,<span class="string">"*"</span>&#125;, &#123;<span class="string">'2'</span>, <span class="string">"abc"</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'3'</span>,<span class="string">"def"</span>&#125;, &#123;<span class="string">'4'</span>,<span class="string">"ghi"</span>&#125;, &#123;<span class="string">'5'</span>,<span class="string">"jkl"</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'6'</span>,<span class="string">"mno"</span>&#125;, &#123;<span class="string">'7'</span>,<span class="string">"pqrs"</span>&#125;,&#123;<span class="string">'8'</span>,<span class="string">"tuv"</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'9'</span>,<span class="string">"wxyz"</span>&#125;&#125;;</span><br></pre></td></tr></table></figure>
<p>如，给定输入”23”，输出是[“ad”, “ae”, “af”, “bd”, “be”, “bf”, “cd”, “ce”, “cf”]。</p>
<p>分析：根据数字，组合数字的字母，也是一个全部搜索的过程。停止条件是当字符串不断拼接直到长度与输入的数字个数一致。 变量有res （即最后输出），str变量用来存拼接字符，k控制深度。（另外两个参数digits与hash其实是相当于默认参数）</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; res,<span class="built_in">string</span> str,<span class="built_in">string</span>&amp; digits,<span class="built_in">unordered_map</span>&lt;<span class="keyword">char</span>, <span class="built_in">string</span>&gt;&amp;hash, <span class="keyword">int</span> k)</span></span>&#123;</span><br><span class="line">    <span class="comment">// stop condition, str 不断拼接，直到与给的数字长度相同</span></span><br><span class="line">    <span class="keyword">if</span>(str.<span class="built_in">size</span>() == digits.<span class="built_in">size</span>())&#123;</span><br><span class="line">        res.push_back(str);<span class="comment">//添加到结果里</span></span><br><span class="line">        <span class="keyword">return</span>;<span class="comment">//递归深入完毕，退出</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">string</span> temp = hash[digits[k]];<span class="comment">//k代表每层</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">char</span> w:temp)&#123;</span><br><span class="line">        str += w; <span class="comment">// 添加一个字符</span></span><br><span class="line">        dfs(res, str, digits, hash, k+<span class="number">1</span>); <span class="comment">//继续向下搜索</span></span><br><span class="line">        str.pop_back();<span class="comment">//去掉末尾字符向上走（回溯）</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; letterCombinations(<span class="built_in">string</span> digits)&#123;</span><br><span class="line">    <span class="built_in">unordered_map</span>&lt;<span class="keyword">char</span>, <span class="built_in">string</span>&gt; table&#123;</span><br><span class="line">    &#123;<span class="string">'0'</span>, <span class="string">" "</span>&#125;, &#123;<span class="string">'1'</span>,<span class="string">"*"</span>&#125;, &#123;<span class="string">'2'</span>, <span class="string">"abc"</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'3'</span>,<span class="string">"def"</span>&#125;, &#123;<span class="string">'4'</span>,<span class="string">"ghi"</span>&#125;, &#123;<span class="string">'5'</span>,<span class="string">"jkl"</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'6'</span>,<span class="string">"mno"</span>&#125;, &#123;<span class="string">'7'</span>,<span class="string">"pqrs"</span>&#125;,&#123;<span class="string">'8'</span>,<span class="string">"tuv"</span>&#125;,</span><br><span class="line">    &#123;<span class="string">'9'</span>,<span class="string">"wxyz"</span>&#125;&#125;;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; result;</span><br><span class="line">    <span class="keyword">if</span> (digits == <span class="string">""</span>) <span class="keyword">return</span> result;</span><br><span class="line">    dfs(result,<span class="string">""</span>,digits,table,<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="括号生成"><a href="#括号生成" class="headerlink" title="括号生成"></a>括号生成</h4><p>leecode 22：给出 <em>n</em> 代表生成括号的对数，请你写出一个函数，使其能够生成所有可能的并且<strong>有效的</strong>括号组合。如n=3时，输出：[  “((()))”,  “(()())”,  “(())()”,  “()(())”,  “()()()”]</p>
<p>分析：全部组合的过程中，注意简单的条件剪枝。停止条件左括号个数 = n且右括号个数 = n。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 剪枝的条件为：左括号的数目一旦小于右括号的数目，以及，左括号的数目和右括号数目均小于n。</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; res, <span class="built_in">string</span> str,<span class="keyword">int</span> l, <span class="keyword">int</span> r, <span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (l &gt; n || r &gt; n || r &gt; l) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">if</span> (l == n &amp;&amp; r==n) &#123; <span class="comment">//stop condition</span></span><br><span class="line">        res.push_back(str);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    dfs(res, str + <span class="string">'('</span>, l+<span class="number">1</span>, r, n);</span><br><span class="line">    dfs(res, str + <span class="string">')'</span>, l, r+<span class="number">1</span>, n);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; generateParenthesis(<span class="keyword">int</span> n)&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; res;</span><br><span class="line">    dfs(res, <span class="string">""</span>, <span class="number">0</span>, <span class="number">0</span>, n);</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">    <span class="comment">// thanks a lot</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="数组的所有子集"><a href="#数组的所有子集" class="headerlink" title="数组的所有子集"></a>数组的所有子集</h4><p>leecode 78给定一组<strong>不含重复元素</strong>的整数数组 <em>nums</em>，返回该数组所有可能的子集（幂集）。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dfs_subsets</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; res_temp, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; res,<span class="keyword">int</span> k)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (k == nums.<span class="built_in">size</span>())  &#123;</span><br><span class="line">        res.push_back(res_temp);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//不选</span></span><br><span class="line">    dfs_subsets(nums,res_temp,res,k+<span class="number">1</span>);</span><br><span class="line">    res_temp.push_back(nums[k]); <span class="comment">//选nums[k]</span></span><br><span class="line">    dfs_subsets(nums,res_temp,res,k+<span class="number">1</span>);</span><br><span class="line">    res_temp.pop_back();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; subsets(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; res_temp;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">    dfs_subsets(nums,res_temp,res,<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="图遍历的DFS"><a href="#图遍历的DFS" class="headerlink" title="图遍历的DFS"></a>图遍历的DFS</h3><p> 在图的遍历过程中，常用两种遍历算法。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">graphTraverse</span><span class="params">(Graph* G)</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> v;</span><br><span class="line">	<span class="keyword">for</span>(v=<span class="number">0</span>;v&lt;G-&gt;n();v++) G-&gt;setMark(v, UNVISITED); <span class="comment">// n - nodes num</span></span><br><span class="line">	<span class="keyword">for</span>(v=<span class="number">0</span>;v&lt;G-&gt;n();v++)&#123;</span><br><span class="line">		<span class="keyword">if</span>(G-&gt;getMark(v) == UNVISITED)</span><br><span class="line">			doTraverse(G,v);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在搜索过程中，每当访问某个顶点V时，DFS会递归的访问它的所有未被访问的相邻节点。DFS将所有从顶点V出去的边存入栈中，从栈顶弹出一条边，根据这个边找到顶点V的一个相邻节点，这个顶点就是下一个要访问的顶点。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">DFS</span><span class="params">(Graph* G, <span class="keyword">int</span> v)</span></span>&#123;</span><br><span class="line">	PreVisit(G,v); <span class="comment">//take appropriate action</span></span><br><span class="line">	G-&gt;setMark(v, VISITED);</span><br><span class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> w = G-&gt;first(v); w&lt;G-&gt;n(); w=G-&gt;next(v,w))</span><br><span class="line">		<span class="keyword">if</span>(G-&gt;getMark(w) == UNVISITED)</span><br><span class="line">			DFS(G,w); <span class="comment">// go deep to traverse</span></span><br><span class="line">		PostVisit(G,v);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="图遍历的BFS"><a href="#图遍历的BFS" class="headerlink" title="图遍历的BFS"></a>图遍历的BFS</h3><p>BFS  在进一步深入访问其他顶点之前，检查起点的所有相邻节点。用队列代替递归栈，BFS将逐层对各个节点进行访问。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">BFS</span><span class="params">(Graph* G, <span class="keyword">int</span> start, Queue&lt;<span class="keyword">int</span>&gt;* Q)</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> v,w;</span><br><span class="line">	Q-&gt;enqueue(start); <span class="comment">// initial node</span></span><br><span class="line">	G-&gt;setMark(start,VISITED);</span><br><span class="line">	<span class="keyword">while</span>(Q-&gt;length() != <span class="number">0</span>)&#123; <span class="comment">//process all vertices</span></span><br><span class="line">    v = Q-&gt;dequeue();</span><br><span class="line">    PreVisit(G,v);</span><br><span class="line">    <span class="keyword">for</span>(w=G-&gt;first(v); w&lt;G-&gt;n(); w = G-&gt;next(v,w))&#123;</span><br><span class="line">      <span class="keyword">if</span>(G-&gt;getMark(w) == UNVISITED)&#123;</span><br><span class="line">        G-&gt;getMark(w) == VISITED;</span><br><span class="line">        Q-&gt;enqueue(w);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，leecode100经典 17,22题。</p>
<p>2，《挑战程序设计》</p>
<p>3,  《数据结构与算法分析 》 Clifford A. Shaffer</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>DFS与BFS</tag>
      </tags>
  </entry>
  <entry>
    <title>字节算法岗面试记录</title>
    <url>/2020/02/10/20200210%E5%AD%97%E8%8A%82%E7%AE%97%E6%B3%95%E5%B2%97%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h3 id="一面"><a href="#一面" class="headerlink" title="一面"></a>一面</h3><p>面试官真的是很直接了，就出了道算法题。但整体来说这个面试官真的是超级好了啊，特别会引导，我觉得字节就是这点细节很好。</p><p>最大连续序列和。</p><p>如给一个Array： 1，-2，3，1，-1，5 。则是8 (3, 1, -1 , 5)</p><p>分析：设DP[k] 是表示以k结尾的最大的和。则递推公式为 DP[k] = max{DP[k-1] + A[k] ，A[k] }，要么是前一个连续和加上数组值（当前数组值为正），要么就是数组本身。这样最后只需要一遍遍历过去，找出以某个k结尾的最大和的那个DP值即为答案。</p><a id="more"></a>



<p>代入看：初始化DP[0] = 0 , DP[1] = max{1, 0} = 1 , DP[2] = max{-1, -2} = -1; ….</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">maxSequenceSum</span><span class="params">(<span class="keyword">int</span>* matrix, <span class="keyword">int</span> length)</span></span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(length &lt; <span class="number">0</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">  <span class="keyword">int</span> dp[length];</span><br><span class="line">  dp[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;length;i++)&#123;</span><br><span class="line">    dp[i] = <span class="built_in">max</span>(dp[i<span class="number">-1</span>]+matrix[i], matrix[i]);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// get the max</span></span><br><span class="line">  <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;length;i++)&#123;</span><br><span class="line">    <span class="keyword">if</span>(dp[i] &gt; res) res = dp[i];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里的时间复杂度是O (n)，空间复杂度也是O(n)，面试官引导进行优化空间。</p>
<p>思路就是用变量存上一个dp[i-1] 与最大的 dp值，直接返回即可。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">maxSequenceSum</span><span class="params">(<span class="keyword">int</span>* matrix, <span class="keyword">int</span> length)</span></span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(length &lt; <span class="number">0</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">  <span class="keyword">int</span> dp[length];</span><br><span class="line">  <span class="keyword">int</span> dp_max = matrix[<span class="number">0</span>]; <span class="comment">// store the max</span></span><br><span class="line">  <span class="keyword">int</span> dp_last = matrix[<span class="number">0</span>]; <span class="comment">// store the dp[i-1]</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;length;i++)&#123;</span><br><span class="line">    dp_last = <span class="built_in">max</span>(dp_last + matrx[i], matrix[i]);</span><br><span class="line">    <span class="keyword">if</span>(dp_last &gt; dp_max) dp_max = dp_last;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> dp_max;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>真的是有意思，我也没有刷完所有题，感觉自己思路还是有些慢，得再练哦。</p>
<h3 id="二面"><a href="#二面" class="headerlink" title="二面"></a>二面</h3><p>二面的技术leader有点像个稍严厉的大父亲，而且涉及很广居然包括博弈论，我虽然是学了很多博弈论的数学模型（还记得当时的考试，复习得可费劲了，得理解所有的啥完美，完全博弈啥概念，还得计算的）。在此记录一些问题吧。</p>
<h4 id="1，优化问题"><a href="#1，优化问题" class="headerlink" title="1，优化问题"></a>1，优化问题</h4><p>出了个问题是在给定的CTR和CVR之下，让用户尽量久的停留（停留时间长）。考虑最优化，写优化和约束和拉格朗日法。</p>
<p>max: t</p>
<p>s.t. CTR+r CVR &gt; n</p>
<p>CTR和CVR的计算应该也是跟用户停留时间t有关的（现象上来看，用户停留时间越长，点击率和转化率可能越高），用最优化里的有约束的凸二次规划来看的话。</p>
<p>构建拉格朗日函数，对不等式约束引入拉格朗日乘子, $\alpha_i \geq 0$。</p>
<script type="math/tex; mode=display">L(t) = t - \alpha_i (CTR+r CVR - n)</script><p>当然这里根据CTR和CVR的计算公式展开。根据拉格朗日对偶像，原始问题的对偶问题是极小极大问题。对所有实数域上的优化问题都有其对偶问题。</p>
<script type="math/tex; mode=display">min_{\alpha_i} max_t  L(t)</script><p>这里应该是对偶可以求一个 upper bound的。我一开始莽撞写错了不等式约束，然后后面联想SVM才改。在复习一下（图中f ,g 不要求是凸的）：</p>
<p><img src="/images/20200211Dual.jpg" alt="20200211Dual"></p>
<h4 id="2，广告拍卖模型"><a href="#2，广告拍卖模型" class="headerlink" title="2，广告拍卖模型"></a>2，广告拍卖模型</h4><p>明拍（谁出的高就收谁的）和暗拍（相互不知道对方出价），各自的影响。</p>
<p>为什么拍卖？揭示信息并减少代理成本。当一个物品对买者的价值比卖者更清楚时，卖者一般不愿意首先提出价格，而采用拍卖方式获得可能的最高价格。</p>
<p>明拍：从最低价开始举牌逐渐升高。这里面可能涉及作弊问题，拍卖客户之间串通，以低价甚至是起拍底价成交的人，其他竞买人都不举牌与之竞争，再私下得到一些好处。</p>
<p>暗拍，是以出价最高的投标者获得拍卖品。并支付出价给卖者。（有一级密封拍卖，出价最高；二级密封拍卖，报价中的次高价）</p>
<h5 id="2-1-一级拍卖"><a href="#2-1-一级拍卖" class="headerlink" title="2.1 一级拍卖"></a>2.1 一级拍卖</h5><p>两个投标人，假设$b_i \geq 0$ 是投标人i的出价，$v_i$ 是拍卖品对投标人i的价值，可见$v_i$只有i自己知道（自己根据估计的真实价值进行出价，这个函数只与自己相关）。$v_i$ 独立地取自定义在区间$[0,1]$ 上的均匀分布函数。投标人i的效用（可以理解为我的收益）是：</p>
<script type="math/tex; mode=display">u_{i}\left(b_{i}, b_{j} ; v_{i}\right)=\left\{\begin{array}{cl}{v_{i}-b_{i},} & {\text { 如果 } b_{i}>b_{j}} \\ {\frac{1}{2}\left(v_{i}-b_{i}\right),} & {\text { 如果 } b_{i}=b_{j}} \\ {0,} & {\text { 如果 } b_{i}<b_{j}}\end{array}\right.</script><p>假设投标人i的出价 $b_i(v_i)$ 是其价值 $v_i$ 的严格递增可微函数，肯定不会$b_i ＞1 &gt; v_i$ 因为没人付比物品价值更高的出价。考虑对称的情况下出价策略 $b = b^{\star}(v)$ ，投标人i的预期支付是：</p>
<script type="math/tex; mode=display">u_{i}=(v-b) \operatorname{Pr} o b\left\{b_{j}<b\right\}</script><script type="math/tex; mode=display">\operatorname{Pr} o b\left\{b_{j}<b\right\}=\operatorname{Pr} o b\left\{b^{*}\left(v_{j}\right)<b\right\} = \operatorname{Pr} o b\left\{v_{j}<b^{*-1}(b) \equiv \Phi(b)\right\}=\Phi(b)</script><p>根据均匀分布有$k \in[0,1], \quad \operatorname{Pr} o b(\theta \leq k)=k$，即这里的$\Phi(b) = b^{*-1}(b)$ </p>
<p>投标人面对的问题就是：</p>
<script type="math/tex; mode=display">\max _{b} u_{i}=(v-b) \operatorname{Pr} o b\left\{b_{j}<b\right\}=(v-b) \Phi(b)</script><p>上面这个max最优化问题的一阶条件是：$-\Phi(b)+(v-b) \Phi^{\prime}(b)=0$</p>
<p>如果$b^{*}(\cdot)$ 是投标者i的最优策略，$\Phi(b)=v, then, v=(v-b) \frac{\mathrm{d} v}{\mathrm{d} b}$</p>
<script type="math/tex; mode=display">v \mathrm{d} b+b \mathrm{d} v=v \mathrm{d} v , \frac{\mathrm{d}(v b)}{\mathrm{d} v}=v</script><p>积分$vb = \frac{1}{2}v^2$ 求得 $b^{\star}=v / 2$，即是这个博弈的贝叶斯均衡。</p>
<p>当有n个投标人时，每个投标人的价值$v_i$ 定义在【0，1】区间上且独立同分布。投标人i的预期支付函数是：</p>
<script type="math/tex; mode=display">u_{i}=(v-b) \prod_{j \neq i} \operatorname{Pr} o b\left\{b_{j}<b\right\}=(v-b) \Phi^{n-1}(b)</script><script type="math/tex; mode=display">b^{\star}(v)=\frac{n-1}{n} v</script><p><strong>投标人越多，卖者能得到的价格就越高；当投标人数趋于无穷时，卖者几乎得到拍卖品价值的全部。因此，卖者希望更多的人加入竞标 。</strong></p>
<h5 id="2-2-二级拍卖"><a href="#2-2-二级拍卖" class="headerlink" title="2.2 二级拍卖"></a>2.2 二级拍卖</h5><p>如果投标者想赢得投标，则他的效用是：</p>
<script type="math/tex; mode=display">u_{i}=v_{i}-\max _{j \neq i} b_{j}</script><script type="math/tex; mode=display">b_{i}>\max _{j \neq i} b_{j}</script><p>对每个参与人来说，自己只需要比其他人好一点点就行。即以他的估价进行投标的策略$\left(b_{i}=v_{i}\right)$ 弱优于其他策略。记$r_{i} \equiv \max _{j \neq i} b_{j}$ 即第二大出价。</p>
<p>$when: r_i \leq v_i $，以$v_i$投标则投标者获得效用是： $v_i - r_i$ （理解为其他所有人的出价都稍微小于自己心中对物品的估价，这样才可能获得正效用。）</p>
<p>当$r_i \geq b_i$ ，投标者i获得效用是0。当 <script type="math/tex">v_i < r_i < b_i</script> 则投标者i具有效用是 $v_i - r_i &lt; 0$，若此时投标$v_i$ 则效用是0。</p>
<p>因此<strong>在二级密封价格拍卖中，投标者会以他们的估价进行投标</strong> 。</p>
<p>类比到互联网的广告拍卖里，其实也有广义第一价格GFP（实收价等于出价）和广义第二价格GSP（实收价等于第二出价），还有VGG竞价机制。</p>
<p>广义第一价格GFP（实收价等于出价）的影响，受广告主的出价影响，可能不稳定，可能高也坑可能低。GSP更能凸显出广告的真实价格。</p>
<h5 id="2-3，概率生成器。"><a href="#2-3，概率生成器。" class="headerlink" title="2.3，概率生成器。"></a>2.3，概率生成器。</h5><p>给一个不均分的硬币，投的正面概率是P（不是0.5），怎么用它来得到均匀（0.5）的结果。两次正面的概率是p，两次反面概率是（1-p）^2，一正一反的概率是 2p(1-p)，这里01、10的生成概率是相同的，基于此代表0，1来生成。</p>
<p>2020年1月23好不容易面完了二面，技术岗说后面HR联系，然后然后就没有然后了通知说岗位不匹配，就这样记录记录吧，每次面试都是一次学习总结的机会。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，肖条军 《决策与博弈论》</p>
<p>2，<a href="[https://wiki.mbalib.com/wiki/%E5%B0%81%E9%97%AD%E5%BC%8F%E6%8B%8D%E5%8D%96](https://wiki.mbalib.com/wiki/封闭式拍卖">封闭式拍卖</a>)</p>
]]></content>
      <categories>
        <category>经历</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>异常检测方法</title>
    <url>/2020/02/10/20191210%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h3 id="异常检测方法综述"><a href="#异常检测方法综述" class="headerlink" title="异常检测方法综述"></a>异常检测方法综述</h3><h4 id="统计方法"><a href="#统计方法" class="headerlink" title="统计方法"></a>统计方法</h4><p>有基于阈值的，还有对数据的分布做出假设，并找出假设下所定义的“异常”，因此往往会使用极值分析或者假设检验，概率密度函数值小于某个阈值的点判定为异常。 还有些多元模型，如计算多个事件指标之间期望的相关性等等。</p><h5 id="看图"><a href="#看图" class="headerlink" title="看图"></a>看图</h5><p>频率直方图， 点分布图</p><h5 id="高斯分布的-k-sigma"><a href="#高斯分布的-k-sigma" class="headerlink" title="高斯分布的 k-sigma"></a>高斯分布的 k-sigma</h5><p>概率密度函数为 $f(x)=\frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}$</p><a id="more"></a>


<p>当点$X \notin ( { \mu } - 3 { \sigma } ,  { \mu } + 3  { \sigma } ) $ 则为异常，因为这个点出现的概率小于 1 - 99.74%。</p>
<p>延伸出滑动窗高斯模型，后续s表示为异常分数score：</p>
<script type="math/tex; mode=display">s =1-Q\left(\frac{\left|x_-\mu \right|}{\sigma}\right)</script><p>Q函数是标准正态分布的右尾函数：$Q(x)=\int_{x}^{\infty} \frac{1}{\sqrt{2 \pi}} e^{-\frac{t^{2}}{2}} d t$，Q函数又叫（标准正态分布的）互补累计分布函数，Q ( x )是正常(高斯)随机变量获得大于x标准差的值的概率。</p>
<h5 id="箱型图"><a href="#箱型图" class="headerlink" title="箱型图"></a>箱型图</h5><p><img src="/images/20191211BoxPlot.jpg" alt="20191211BoxPlot"></p>
<p>IQR (inter quartile range) = Q3 - Q1 ； 占据中心值周围50%数量的范围</p>
<p>LQR (lower quartile range) = median - Q1 ； IQR的下半部分</p>
<p>UQR (upper quartile range) = Q3 - median ； IQR的上半部分</p>
<p>若按3 σ来判断异常， 3 σ = 2.1 IQR，则异常在median的2.1 IQR之外，因此在Q1或者Q3再延伸1.5 IQR (3σ 之外)的点就很可能是outlier点了。</p>
<p>即$P &gt; Q3+1.5IQR$ or $P&lt; Q1 - 1.5IQR$</p>
<h5 id="假设检验类型"><a href="#假设检验类型" class="headerlink" title="假设检验类型"></a>假设检验类型</h5><p>如extreme studentized deviate（Grubb’s Test ）</p>
<p>提出假设H0:没有异常点，H1：至少有一个异常点。</p>
<p>根据样本的均值和标准差来计算最大 bias / standard deviation 比值。</p>
<script type="math/tex; mode=display">G=\frac{\max _{i=1, \ldots, N}\left|X_{i}-\bar{X}\right|}{s}</script><p>基于t-student分布定检出水平$\alpha$（置信概率$P=1- \alpha$）与检测次数$n$查找表格获得临界值$G_0$。当计算的$G&gt;G_0$则判断为异常点。</p>
<p>其他还有卡方检验（chi-square theory），Q_test等</p>
<h5 id="Skyline用到的几种统计方法（单时间序列的异常检测）"><a href="#Skyline用到的几种统计方法（单时间序列的异常检测）" class="headerlink" title="Skyline用到的几种统计方法（单时间序列的异常检测）"></a>Skyline用到的几种统计方法（单时间序列的异常检测）</h5><p><strong>median absolute deviation （MAD）</strong></p>
<p>计算数据的中位数，偏差 = 每个值-中位数，得到偏差中位数</p>
<script type="math/tex; mode=display">\mathrm{MAD}=\operatorname{median}\left(\left|X_{i}-\operatorname{median}(X)\right|\right)</script><p>MAD对数据集中的异常值比标准偏差更具弹性。在标准偏差中，与均值的距离的平方，较大的异常值会影响更大。可以通过判断一个点的偏差是否过于偏离MAD来判断异常。</p>
<p><strong>stddev_from_average</strong></p>
<p>时间序列最后三个点的 $(t - series.mean) &gt; 3 * series.std$</p>
<p>最新的三个数据点的平均值的绝对值减去移动平均值，大于三个平均值的标准偏差。</p>
<p><strong>least_squares</strong></p>
<p>根据最小二乘模型上，将最后三个数据点的平均值投影，大于三个sigma，则时间序列是异常的。</p>
<p><strong>Histogram-based</strong></p>
<p>如果最后三个数据点的平均值落入了带有少于n个其他数据点的直方图bin中。</p>
<p>统计学方法是可以用在时间序列上的，取最近的一时间段来进行统计计算。</p>
<h4 id="基于距离distanced-based"><a href="#基于距离distanced-based" class="headerlink" title="基于距离distanced-based"></a>基于距离distanced-based</h4><h5 id="直接定义距离"><a href="#直接定义距离" class="headerlink" title="直接定义距离"></a>直接定义距离</h5><p>假设：若一个数据点和大多数数据点距离很远，则这个对象就是异常。但这个方法不太适合稀疏数据集。</p>
<h5 id="KNN等基于邻居"><a href="#KNN等基于邻居" class="headerlink" title="KNN等基于邻居"></a>KNN等基于邻居</h5><p>简单的定义可以是：用数据对象与最近的K个点的距离之和。很明显，与K个最近点的距离之和越小，异常分越低；与K个最近点的距离之和越大，异常分越大。</p>
<script type="math/tex; mode=display">N C M(o, M)=\sum_{h \in k N N(o)} d i s t(o, h)</script><h5 id="聚类clustering"><a href="#聚类clustering" class="headerlink" title="聚类clustering"></a>聚类clustering</h5><h5 id="基于密度density"><a href="#基于密度density" class="headerlink" title="基于密度density"></a>基于密度density</h5><p>LOF方法：通过局部的数据密度来检测异常。显然，异常点所在空间的数据点少，密度低。</p>
<p>K邻近距离，在距离数据点 p 最近的几个点中，第 k 个最近的点跟点 p 之间的距离称为点 p 的 K-邻近距离，记为 k-distance (p) 。</p>
<p>可达距离：可达距离的定义跟K-邻近距离是相关的，给定参数k时， 数据点 p 到 数据点 o 的可达距离 reach-dist（p, o）为数据点 o 的K-邻近距离 和 数据点p与点o之间的直接距离的最大值。</p>
<script type="math/tex; mode=display">reachdist_k ( p , o ) =\max \{k-\text {distance}(o), d(p, o)\}</script><p>局部可达密度：基于可达距离的，对于数据点 p，那些跟点p的距离小于等于 k-distance（p）的数据点称为它的 k-nearest-neighbor，记为$N_{k}(p)$数据点 p 的局部可达密度为它与邻近的数据点的平均可达距离的倒数：</p>
<script type="math/tex; mode=display">lrd_{k}(p)=\frac{1}{\frac{\sum_{o \in N_{k}(p)} reachdist_{k} ( p , o ) }{\left|N_{k}(p)\right|}}</script><p>局部异常因子：用局部相对密度来定义的。数据点 p 的局部相对密度（局部异常因子）为点p的邻居们的平均局部可达密度跟数据点p的局部可达密度的比值。</p>
<script type="math/tex; mode=display">L O F_{k}(p)=\frac{\sum_{o \in N_{k}(p)} \frac{l r d(o)}{l r d(p)}}{\left|N_{k}(p)\right|}=\frac{\sum_{o \in N_{k}(p)} lrd(o)}{\left|N_{k}(p)\right|} / \operatorname{lr} d(p)</script><p>如果一个数据点跟其他点比较疏远的话，那么显然它的局部可达密度就小。判断异常点就是看它跟周围邻近的数据点的相对密度。如果数据点 p 的 LOF 得分在1附近，表明数据点p的局部密度跟它的邻居们差不多；如果数据点 p 的 LOF 得分小于1，表明数据点p处在一个相对密集的区域，不像是一个异常点；如果数据点 p 的 LOF 得分远大于1，表明数据点p跟其他点比较疏远，很有可能是一个异常点。</p>
<h5 id="ABOD基于角度"><a href="#ABOD基于角度" class="headerlink" title="ABOD基于角度"></a>ABOD基于角度</h5><h5 id="IsolationForest"><a href="#IsolationForest" class="headerlink" title="IsolationForest"></a>IsolationForest</h5><p>划分超平面来计算“孤立”一个样本所需的超平面数量。异常点所在空间中，所需要的划分次数更少。</p>
<p><strong>构造itree随机二叉树</strong>：</p>
<p>从全量数据中抽取一批样本，然后随机选择一个特征作为起始节点（bagging），并在该特征的最大值和最小值之间随机选择一个值，将样本中小于该取值的数据划到左分支，大于等于该取值的划到右分支。异常点一般都是非常稀有的，在iTree中会很快被划分到叶子节点。</p>
<p>x —— 要预测的样本</p>
<p>T.size —— iTree 的训练样本中同样落在 x 所在叶子节点的样本数。</p>
<p>e —— 数据 x 从 iTree 的根节点到叶节点过程中经过的边的数目</p>
<p>C(T.size) —— 修正值，二叉树的平均路径长度。</p>
<p>h(x) —— x在 iTree 中的路径长度：</p>
<script type="math/tex; mode=display">h ( x ) = e + C ( T . s i z e ) , C ( n ) = 2 H ( n - 1 ) - \left( \frac { 2 ( n - 1 ) } { n } \right), H ( k ) = \ln ( k ) + \xi</script><p>ψ —— 训练一棵itree的样本数</p>
<p>E(h(x))—— 数据x在多棵树上的路径长度均值</p>
<p>x在这棵树的异常指数是：</p>
<script type="math/tex; mode=display">s ( x , \psi ) = 2 ^ { \left( - \frac { E( h ( x ) ) } { c ( \psi ) } \right) }%</script><p>如果h(x)越小，则s(x,ψ)越接近1；越大，则s(x,ψ)越接近0.5。</p>
<p><strong>构造iforest</strong>：</p>
<p>随机采样一部分数据集去构造每一棵树，保证不同树之间的差异性，采样数据量ψ不需要等于n，可以远远小于n。</p>
<p><img src="/images/20200226iForest.jpg" alt="20200226iForest"></p>
<p>其他树方法变形：random cut forest、iForest、SCiForest、RRCF、改进的iForestASD方法，流数据异常检测帧等等。</p>
<h4 id="回归模型"><a href="#回归模型" class="headerlink" title="回归模型"></a>回归模型</h4><p>1，自回归AR</p>
<script type="math/tex; mode=display">X_t = c + \sum_{i=1}^P \theta_{i}X_{t-i} + \varepsilon_t</script><p>其中$c$是常数项，$\theta_i$是自相关系数，$ \varepsilon_t$是随机误差项（平均数为0，标准差为$\sigma$的随机误差值，也称白噪声）。$X_t$的当前值是前几期的线性组合。$\theta_i$的变化将使得时间序列拥有不同的特征。</p>
<p>对于AR(1)而言：</p>
<p>当$\theta_1=0$, $X_t$相当于白噪声。</p>
<p>当$\theta_1=1, c=0$时，$X_t$相当于随机游走模型。</p>
<p>当$\theta_1=1, c\neq0$时，$X_t$相当于带漂移的随机游走模型。</p>
<p>当$\theta_1&lt;0$, $X_t$在正负值之间上下浮动。</p>
<p>P阶自回归模型的要求是时序数据具有平稳性，必须有自相关性（即自相关系数大于0.5），自回归只能适用于预测与自身前期相关的经济现象。</p>
<p>2，移动平均模型 MA</p>
<script type="math/tex; mode=display">X_{t}=c+\varepsilon_{t}+\sum_{i=1}^q \theta_i\varepsilon_{t-i}</script><p>移动平均模型MA(q)更关注自回归模型中的误差项的累加。每一个值都可以被认为是一个历史预测误差的加权移动平均值。</p>
<p>AR(1)可以用MA($\infty$) 表示：$y_{t}=\varepsilon_{t}+\phi_{1} \varepsilon_{t-1}+\phi_{1}^{2} \varepsilon_{t-2}+\phi_{1}^{3} \varepsilon_{t-3}+\cdots$</p>
<p>2.1 注意移动平均法和移动模型不同</p>
<p>移动平均法适用于即期预测。当产品需求既不快速增长也不快速下降，且不存在季节性因素时，移动平均法能有效地消除预测中的随机波动，非常有用的。移动平均法包括简单移动平均和加权移动平均。</p>
<p>简单移动平均：$X_t = \frac{\sum_{i=1}^n X_{t-i}}{n}$</p>
<p>加权移动平均：$X_t = \sum_{i=1}^n \theta_i X_{t-i}$ , 其中$\theta_i$是权重值，对近期的趋势反映较敏感，但不适合有季节性的数据。</p>
<p>根据同一个移动段内不同时间的数据对预测值的影响程度，分别给予不同的权数，然后再进行平均移动以预测未来值。</p>
<p>指数加权移动平均EWMA，指数移动平均EMA。</p>
<p>3，ARIMA模型</p>
<script type="math/tex; mode=display">y_{t}=\mu+\sum_{i=1}^{p} \gamma_{i} y_{t-i}+\epsilon_{t}+\sum_{i=1}^{q} \theta_{i} \epsilon_{t-i}</script><p>适合有季节性的数据</p>
<p>4，时间序列分解</p>
<p>STL季节性分解</p>
<p>论文：Online Conditional Outlier Detection in Nonstationary Time Series</p>
<p>STL分解（非参数分解方法）为三个要素：季节性、趋势、残差。 分析残差的偏差，然后引入残差阈值，这样就能得到一种异常检测得算法。</p>
<p>移动平均、指数平滑、ARMA、ARIMA</p>
<h4 id="2-4-线性模型（基于子空间subspace）"><a href="#2-4-线性模型（基于子空间subspace）" class="headerlink" title="2.4 线性模型（基于子空间subspace）"></a>2.4 线性模型（基于子空间subspace）</h4><p>主成分分析PCA</p>
<p>因子分析Factor Analysis</p>
<h4 id="2-3-机器学习"><a href="#2-3-机器学习" class="headerlink" title="2.3 机器学习"></a>2.3 机器学习</h4><p>分类模型（类别不平衡问题）</p>
<p>决策树</p>
<p>支持向量SVM </p>
<p>延伸出来的还有OneClass SVM，Support Vector Machine (SVM) with ant colony network[4]</p>
<p>随机森林等</p>
<p>Isolation Forest方法</p>
<p>GBDT方法 / XgBoost / Bagging等</p>
<p>Bayesiannetwork </p>
<h4 id="2-4-神经网络"><a href="#2-4-神经网络" class="headerlink" title="2.4 神经网络"></a>2.4 神经网络</h4><p>RNN、LSTM方法</p>
<p>论文：Anomaly detection in ECG time signals via deep long short-term memory networks</p>
<p>AutoEncoder</p>
<p>深度信念网络等</p>
<p>SOM自组织地图</p>
<p>HTM方法</p>
<p>频谱残差</p>
<h4 id="2-5-实时序列异常检测"><a href="#2-5-实时序列异常检测" class="headerlink" title="2.5 实时序列异常检测"></a>2.5 实时序列异常检测</h4><h5 id="2-5-1-NAB库有的"><a href="#2-5-1-NAB库有的" class="headerlink" title="2.5.1 NAB库有的"></a>2.5.1 NAB库有的</h5><p>期望相似性估计</p>
<h5 id="2-5-2-其他"><a href="#2-5-2-其他" class="headerlink" title="2.5.2 其他"></a>2.5.2 其他</h5><p>[4]里的Support Vector Machine (SVM) with ant colony network ，pcStream algorithm（stream clustering），random cut forest, </p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1, “Everything you need to know about AIOps”, from <a href="https://www.moogsoft.com/resources/aiops/guide/everything-aiops/" target="_blank" rel="noopener">https://www.moogsoft.com/resources/aiops/guide/everything-aiops/</a> (retrieved as of Feb. 12, 2019)</p>
<p>2，<a href="https://github.com/yzhao062/pyod#gopalan2019pidforest" target="_blank" rel="noopener">https://github.com/yzhao062/pyod#gopalan2019pidforest</a> pyod异常检测库</p>
<p>3，<a href="https://github.com/etsy/skyline" target="_blank" rel="noopener">https://github.com/etsy/skyline</a> Skyline，一些统计方法</p>
<p>4，Habeeb R A A, Nasaruddin F, Gani A, et al. Real-time big data processing for anomaly detection: A Survey[J]. International Journal of Information Management, 2019, 45: 289-307.</p>
<p>5，<a href="https://otexts.com/fppcn/MA.html" target="_blank" rel="noopener">https://otexts.com/fppcn/MA.html</a> 预测方法与实践</p>
]]></content>
      <categories>
        <category>AIOps</category>
      </categories>
      <tags>
        <tag>异常检测</tag>
        <tag>机器学习</tag>
        <tag>AIOps</tag>
      </tags>
  </entry>
  <entry>
    <title>DP算法</title>
    <url>/2020/02/10/20200210DP%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h3 id="1-经典的背包问题"><a href="#1-经典的背包问题" class="headerlink" title="1 经典的背包问题"></a>1 经典的背包问题</h3><p>有n个重量和价值分别为$w_i,v_i$ 的物品，从这些物品中挑选出总重量不超过W的物品。求所有挑选方案中价值总和的最大值。</p><p>限制条件：</p><script type="math/tex; mode=display">1 \leqslant n \leqslant 100</script><script type="math/tex; mode=display">1 \leqslant w_{i}, v_{i} \leqslant 100</script><script type="math/tex; mode=display">1 \leqslant W \leqslant 10000</script><a id="more"></a>

<p>样例输入： n = 4, (w,v) = {(2,3) , (1,2), (3,4) , (2,2)} ,  w = 5 则输出是 7 （选 0、1、3号物品）</p>
<p>分析：</p>
<p>记 $dp[i+1][j]$ 是从前i个物品中挑选总重不超过j 的物品时总价值的最大值。于是有如下的递推式：</p>
<script type="math/tex; mode=display">dp[0]\lfloor j]=0</script><script type="math/tex; mode=display">dp[i+1] [j]=\left\{\begin{array}{ll}{d p[i][j]} & {(j<w[i])} \\ {\max (d p[i][j], d p[i][j-w[i]]+v[i])} & {(其他)}\end{array}\right.</script><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">solve</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;=W; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (j&lt;w[i]) &#123;</span><br><span class="line">                dp[i+<span class="number">1</span>][j] = dp[i][j];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                dp[i+<span class="number">1</span>][j] = <span class="built_in">max</span>(dp[i][j],dp[i+<span class="number">1</span>][j-w[i]] + v[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;dp[n][W]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-最长公共子序列"><a href="#2-最长公共子序列" class="headerlink" title="2 最长公共子序列"></a>2 最长公共子序列</h3><p>LCS问题是经典问题。给定两个字符串 $s_1s_2s_3…s_n$ 和 $t_1t_2…t_n$ 。求出这两个字符串的最长公共子序列的长度。</p>
<p>输入：n=4, m=4, s=”abcd”, t=”becd”</p>
<p>输出：3 （“bcd”）</p>
<p>定义 $d p[i][j]:= s_1…s_i和t_1…t_j$ 对应的LCS的长度。</p>
<p>由此$s_1…s_{i+1}和t_1…t_{j+1}$ 对应的公共子序列可能是几种情况：</p>
<p>第一，当$s_{i+1} = t_{j+1}$ 的时候，在$s_1…s_i和t_1…t_j$ 的公共子序列末尾追加上$s_{i+1}$</p>
<p>不等的时候，要么是$s_1…s_i和t_1…t_{j+1}$ 的序列的公共子序列，要么就是$s_1…s_{i+1}和t_1…t_j$</p>
<p>故递推公式是：</p>
<script type="math/tex; mode=display">d p[i+1][j+1]=\left\{\begin{array}{ll}{d p[i][j]+1} & {\left(s_{i+1}=t_{j+1}\right)} \\ {\max (d p[i][j+1], d p[i+1][j])} & {其他}\end{array}\right.</script><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// input n,m</span></span><br><span class="line"><span class="keyword">char</span> s[MAX_N],t[MAX_N];</span><br><span class="line"><span class="keyword">int</span> dp[MAX_N+<span class="number">1</span>][MAX_N+<span class="number">1</span>];</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">solve</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;m; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (s[i] == t[j]) &#123;</span><br><span class="line">                dp[i+<span class="number">1</span>][j+<span class="number">1</span>] = dp[i][j]+<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                dp[i+<span class="number">1</span>][j+<span class="number">1</span>] = <span class="built_in">max</span>(dp[i][j+<span class="number">1</span>],dp[i+<span class="number">1</span>][j]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;dp[n][m]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/images/20200211LCS_DP.jpg" alt="20200211LCS_DP"></p>
<h3 id="多重部分和"><a href="#多重部分和" class="headerlink" title="多重部分和"></a>多重部分和</h3><p>leecode39里这里暂时先不考虑将所有的可以加和的结果都存起来。我们先简单考虑能够通过给定的数组里的数，将和得到。下面的代码说明了能否通过这几个数字加和为target，是返回1，不是返回0。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//DP[i+1][j] 表示用前i种数字加和成j， 需要前i-1种数字加和成 j，j-a[i], j - k *a[i]</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">combinationSum</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; candidates, <span class="keyword">int</span> target)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> dp[candidates.<span class="built_in">size</span>()+<span class="number">1</span>][target+<span class="number">1</span>]; <span class="comment">// 注意声明大小</span></span><br><span class="line">    <span class="comment">//init</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i &lt; candidates.<span class="built_in">size</span>()+<span class="number">1</span>; i++) dp[<span class="number">0</span>][i] = <span class="number">0</span>;</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt; candidates.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;= target; j++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> k=<span class="number">0</span>; k * candidates[i] &lt;= j; k++) &#123;</span><br><span class="line">                dp[i+<span class="number">1</span>][j] = dp[i][j - k*candidates[i]];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (dp[candidates.<span class="built_in">size</span>()][target]) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// test:  vector&lt;int&gt; candidates = &#123;2,3,6,7&#125;;</span></span><br><span class="line"><span class="comment">// cout&lt;&lt;combinationSum(candidates,11)&lt;&lt;endl; 是-1</span></span><br></pre></td></tr></table></figure>
<h3 id="4-leecode100-10-正则表达式匹配"><a href="#4-leecode100-10-正则表达式匹配" class="headerlink" title="4 leecode100-10 正则表达式匹配"></a>4 leecode100-10 正则表达式匹配</h3><p>给你一个字符串s 和一个字符规律 p，请你来实现一个支持 <code>&#39;.&#39;</code> 和 <code>&#39;*&#39;</code> 的正则表达式匹配。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&apos;.&apos; 匹配任意单个字符</span><br><span class="line">&apos;*&apos; 匹配零个或多个前面的那一个元素</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入:</span><br><span class="line">s = &quot;aa&quot;</span><br><span class="line">p = &quot;a&quot;</span><br><span class="line">输出: false</span><br><span class="line">解释: &quot;a&quot; 无法匹配 &quot;aa&quot; 整个字符串。</span><br><span class="line"></span><br><span class="line">输入:</span><br><span class="line">s = &quot;aab&quot;</span><br><span class="line">p = &quot;c*a*b&quot;</span><br><span class="line">输出: true</span><br><span class="line">解释: 因为 &apos;*&apos; 表示零个或多个，这里 &apos;c&apos; 为 0 个, &apos;a&apos; 被重复一次。因此可以匹配字符串 &quot;aab&quot;。</span><br></pre></td></tr></table></figure>
<p>这里主要是考虑到星的匹配条件。$\operatorname{dp}[i][j]$ 是表示s的前i个能否被p的前j个匹配。</p>
<p>当$\mathrm{p}[\mathrm{j}]=\mathrm{s}[\mathrm{i}] 或 p[j] = “.”: \mathrm{dp}[\mathrm{i}][\mathrm{j}]=\operatorname{dp}[\mathrm{i}-1][\mathrm{j}-1]$</p>
<p>当$p[j] = “*”$ 时考虑两种情况：</p>
<script type="math/tex; mode=display">p[j-1] \quad !=s[i]: \operatorname{dp}[i][j]=\operatorname{dp}[i][j-2]</script><p>如 （ab, abc*）</p>
<script type="math/tex; mode=display">p[j-1]=s[i] \text { or } p[j-1]="."</script><script type="math/tex; mode=display">\operatorname{dp}[i-1][j] , \operatorname{dp}[i][j-1], \operatorname{dp}[i][j-2]</script><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isMatch</span><span class="params">(<span class="built_in">string</span> s,<span class="built_in">string</span> p)</span></span>&#123;</span><br><span class="line">    <span class="comment">// dp[i][j] means that s 的前i个能否被p的前j个匹配</span></span><br><span class="line">    <span class="keyword">int</span> sl = s.length();</span><br><span class="line">    <span class="keyword">int</span> pl = p.length();</span><br><span class="line">    <span class="keyword">if</span>(p.empty()) <span class="keyword">return</span> s.empty();</span><br><span class="line">    <span class="comment">// init</span></span><br><span class="line">    <span class="keyword">int</span> dp[sl+<span class="number">1</span>][pl+<span class="number">1</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;=sl; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;=pl; j++) &#123;</span><br><span class="line">            dp[i][j] = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">1</span>;<span class="comment">//dp[i][j] 表示 s 的前 i 个是否能被 p 的前 j 个匹配</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">1</span>; j&lt;=pl; j++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (p[j] == <span class="string">'*'</span> &amp;&amp; dp[<span class="number">0</span>][j - <span class="number">1</span>]) &#123;</span><br><span class="line">            dp[<span class="number">0</span>][j + <span class="number">1</span>] = <span class="number">1</span>; <span class="comment">// here's y axis should be i+1</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;sl; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;pl; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (s[i] == p[j] || p[j] == <span class="string">'.'</span>) &#123;</span><br><span class="line">                dp[i+<span class="number">1</span>][j+<span class="number">1</span>] = dp[i][j];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(p[j]==<span class="string">'*'</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(p[j<span class="number">-1</span>]!=s[i] &amp;&amp; p[j - <span class="number">1</span>] != <span class="string">'.'</span>) dp[i+<span class="number">1</span>][j+<span class="number">1</span>] = dp[i+<span class="number">1</span>][j<span class="number">-1</span>]; <span class="comment">//如果前一个元素不匹配且不为任意元素</span></span><br><span class="line">                <span class="keyword">else</span> dp[i + <span class="number">1</span>][j + <span class="number">1</span>] = (dp[i + <span class="number">1</span>][j] || dp[i][j + <span class="number">1</span>] || dp[i + <span class="number">1</span>][j - <span class="number">1</span>]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[sl][pl];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">string</span> s = <span class="string">"mississippi"</span>;</span><br><span class="line">    <span class="built_in">string</span> p = <span class="string">"mis*is*p*."</span>;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;isMatch(s,p)&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="5-最长有效括号"><a href="#5-最长有效括号" class="headerlink" title="5 最长有效括号"></a>5 最长有效括号</h3><p>leecode100题的32题，给定一个只包含 <code>&#39;(&#39;</code> 和 <code>&#39;)&#39;</code> 的字符串，找出最长的包含有效括号的子串的长度。其实一看子序列长度就很像是DP题，那DP怎么定义的呢？一直觉得DP的定义找准真有点难。因为有时候定义不同，解法甚至就会不同。</p>
<p>DP[i] 以下标为i的字符结尾的最长有效子串长度。为什么这么定义，是因为i+1的字符是不是反括号 ) 决定了能否添加在最长子串的后面，要以i+1结尾的最长有效字符串则i+1一定是 )。以 ( 结尾的子字符串对应的 dp 数组位置上的值必定为 0 。所以说我们只需要更新 ) 在 dp 数组中对应位置的值。</p>
<p>1，$s[i] = ) 且 s[i-1]= ($  ，可以判断字符串类似”……()” ，那么dp[i] = dp[i-2] + 2; 这里dp[i-2] 是因为后两个字符一起判断的，加2，是因为（）的字符长度是2。</p>
<script type="math/tex; mode=display">\mathrm{dp}[i]=\mathrm{dp}[i-2]+2</script><p>2，$s[i] = ) 且 s[i-1] = )$ , 此时字符串类似 “…. ))” ，如果 $\mathrm{s}[i-\mathrm{dp}[i-1]-1]= ($ ，则：</p>
<script type="math/tex; mode=display">\mathrm{dp}[i]=\mathrm{dp}[i-1]+\mathrm{dp}[i-\mathrm{dp}[i-1]-2]+2</script><p>因为这个时候要考虑到如果倒数第二个 ) 是dp[i-1] 的最长子串的一部分。对于最后个 ) ，要匹配 dp[i-1] 最长子串的前面一个 ( 才是子串增加。而dp[i-1] 最长子串的前一个 ( 跟此时 dp[i] 的 ）匹配上了的话，就还得看 dp[i-1] 的前面是否还有以前的最长子串，就是$\mathrm{dp}[i-\mathrm{dp}[i-1]-2]$。减去2 则位置就在 $here(dp[i-1]的sub)$</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">longestValidParentheses</span><span class="params">(<span class="built_in">string</span> s)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (s == <span class="string">""</span> || s==<span class="string">"("</span> || s==<span class="string">")"</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">//init</span></span><br><span class="line">    <span class="keyword">int</span> *dp = <span class="keyword">new</span> <span class="keyword">int</span>[s.<span class="built_in">size</span>()];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;s.<span class="built_in">size</span>();i++) dp[i] = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">//begin 注意边界</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;s.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">        <span class="keyword">if</span>(s[i] == <span class="string">')'</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(s[i<span class="number">-1</span>] == <span class="string">'('</span> )&#123;</span><br><span class="line">                dp[i] = (i&gt;=<span class="number">2</span>? dp[i<span class="number">-2</span>]:<span class="number">0</span>) + <span class="number">2</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(i-dp[i<span class="number">-1</span>]&gt;<span class="number">0</span> &amp;&amp; s[i-dp[i<span class="number">-1</span>]<span class="number">-1</span>] == <span class="string">'('</span>)&#123;</span><br><span class="line">                dp[i] = dp[i<span class="number">-1</span>] + ((i - dp[i - <span class="number">1</span>]) &gt;= <span class="number">2</span> ? dp[i - dp[i - <span class="number">1</span>] - <span class="number">2</span>] : <span class="number">0</span>) + <span class="number">2</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//update the max</span></span><br><span class="line">            <span class="keyword">if</span> (dp[i] &gt; res) &#123;</span><br><span class="line">               res = dp[i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// s[i] == '(', dp[i] = 0</span></span><br><span class="line">        <span class="keyword">else</span> dp[i] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="最大连续序列和与接雨水"><a href="#最大连续序列和与接雨水" class="headerlink" title="最大连续序列和与接雨水"></a>最大连续序列和与接雨水</h3><p>如给一个 Array： 1，-2，3，1，-1，5 。则是 8 (3, 1, -1 , 5)</p>
<p>分析：设 DP [k] 是表示以 k 结尾的最大的和。则递推公式为 DP [k] = max {DP [k-1] + A [k] ，A [k] }，要么是前一个连续和加上数组值（当前数组值为正），要么就是数组本身。这样最后只需要一遍遍历过去，找出以某个 k 结尾的最大和的那个 DP 值即为答案。</p>
<p>leecode100-42题接雨水：给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。</p>
<p>第一个for循环找每个点的左侧最大高度 left[i] = max(left[i - 1], height[i - 1]);，</p>
<p>第二个for循环找每个点右侧的最大高度 right[i] = max(right[i + 1], height[i + 1]);</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">  <span class="keyword">int</span> level = <span class="built_in">min</span>(left[i], right[i]);</span><br><span class="line">  water += <span class="built_in">max</span>(<span class="number">0</span>, level - <span class="built_in">height</span>[i]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，《挑战程序设计》 2.3 动态规划章节</p>
<p>2，leecode经典100题10题，32题，39题</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>技术思考（常更）</title>
    <url>/2020/02/07/00000000%E6%8A%80%E6%9C%AF%E6%80%9D%E8%80%83%EF%BC%88%E5%B8%B8%E6%9B%B4%EF%BC%89/</url>
    <content><![CDATA[<p>2020-02-07</p><p>0，计算机科学。计算机可以是一个计算工具，代码只是为了实现一个计算。计算机本身也是一个机器设计的科学，里面有许多的机制与策略，为了让机器更快更有效率，更稳定，更易用，更易于扩展，更简洁易懂，更开放等等，这些是一种设计的科学和精神。</p><p>1，其实机器学习目前来看绝大多数基于概率统计，比如说贝叶斯分类，根据数据类别的分布去推测出新数据更可能属于哪个类别。深度学习则更多的时候是拟合非线性函数，在数学上看都是模型，建模建模是要根据实际问题和实际数据情况来的，所以才有了奥卡姆剃刀规则。其实我觉得底层其实是数学，看了越多论文越觉得一切皆数学，包括目前跨院接触的运筹经管。</p><a id="more"></a>


<p>2，运筹优化领域：其实在管科里这个应用十分广泛，毕竟本质是数学。始于线性规划（减少物料使用，减少费用这是目标，各种限制是约束条件），发展于各种决策甚至统计学习（线性回归SVM等优化函数）与深度学习（优化损失函数），更深的数学还有组合优化，多目标优化等等。我在想是否可以考虑一些运筹启发式的策略用于学习呢？比如说模拟退火？考虑一定的概率跳出当前解，重新搜索进行梯度优化？</p>
<p>3，在推荐领域，推荐的根本思想在于销售，销售除了考虑产品的性质，marketing，还有环境等等，联系起来其实数据特征、特征工程还有规则策略其实不就是为了解决这样的问题吗。</p>
<p>4，“最好的问题”就是那些能够均分所有可能性的问题，不论如何排除掉k-1/k种可能性。在搜索排序中，如何划分更小的问题的思路。</p>
]]></content>
      <categories>
        <category>经历</category>
      </categories>
      <tags>
        <tag>计算机</tag>
        <tag>IT行业</tag>
      </tags>
  </entry>
  <entry>
    <title>20200205腾讯广告算法大赛——鱼佬方案</title>
    <url>/2020/02/05/20200205%E8%85%BE%E8%AE%AF%E5%B9%BF%E5%91%8A%E7%AE%97%E6%B3%95%E5%A4%A7%E8%B5%9B/</url>
    <content><![CDATA[<h3 id="1-方案学习"><a href="#1-方案学习" class="headerlink" title="1 方案学习"></a>1 方案学习</h3><h4 id="1-1-赛题简介"><a href="#1-1-赛题简介" class="headerlink" title="1.1 赛题简介"></a>1.1 赛题简介</h4><p>题目：腾讯效果广告采用的是GSP（Generalized Second-Price）竞价机制，<strong>广告的实际曝光取决于广告的流量覆盖大小和在竞争广告中的相对竞争力水平</strong>。</p><p>其中广告的流量覆盖取决于广告的人群定向（匹配对应特征的用户数量）、广告素材尺寸（匹配的广告位）以及投放时段、预算等设置项。而影响广告竞争力的主要有出价、广告质量等因素（如pctr/pcvr等）， 以及对用户体验的控制策略。</p><a id="more"></a>

<p>通常来说， 基本竞争力可以用ecpm = 1000 <em> cpc_bid </em> pctr = 1000 <em> cpa_bid </em> pctr * pcvr (cpc, cpa分别代表按点击付费模式和按转化付费模式)。综上，前者决定广告能参与竞争的次数以及竞争对象，后者决定在每次竞争中的胜出概率。二者最终决定广告每天的曝光量。</p>
<p>本次竞赛将提供历史n天的曝光广告的数据（特定流量上采样）， 包括对应每次曝光的流量特征（用户属性和广告位等时空信息）以及曝光广告的设置和竞争力分数；测试集是新的一批广告设置（有完全新的广告id， 也有老的广告id修改了设置）。 </p>
<p>目标：预估测试集里这批广告的日曝光量。</p>
<h4 id="1-2-数据分析与清洗"><a href="#1-2-数据分析与清洗" class="headerlink" title="1.2 数据分析与清洗"></a>1.2 数据分析与清洗</h4><h5 id="查看数据与预处理："><a href="#查看数据与预处理：" class="headerlink" title="查看数据与预处理："></a>查看数据与预处理：</h5><p>数据集大小，数据类型，数据是否干净，标签类型，去重，离群点（散点图，删除），缺失情况（背后的意义，业务含义考虑填充），错误值（删除样本，均值或中位数替换等，标签里的错误值 剔除or 标签log化），各类别分布（均值情况，方差情况），大概可以构造的特征，特征之间是否冗余，时间信息。</p>
<h5 id="构造数据"><a href="#构造数据" class="headerlink" title="构造数据"></a>构造数据</h5><ol>
<li><p>将广告操作表中出价、定向人群、投放时段信息与广告静态表merge。</p>
</li>
<li><p>对日志数据中的广告id构造日曝光量得到新的数据集。</p>
</li>
<li><p>将data与广告静态表进行merge，并给缺失的投放时段填充-999</p>
</li>
</ol>
<h5 id="训练原始特征："><a href="#训练原始特征：" class="headerlink" title="训练原始特征："></a>训练原始特征：</h5><p>这些特征比较稳定：广告id，素材大小，广告行业id，商品类型，商品id，广告账户id；</p>
<p>广告账户id，出价 定点人群投放时间。</p>
<p>测试集也包含这些特征，然后构造好的广告id和标签数据与广告静态数据经行合并。</p>
<h4 id="1-3-特征工程"><a href="#1-3-特征工程" class="headerlink" title="1.3 特征工程"></a>1.3 特征工程</h4><h5 id="类别特征"><a href="#类别特征" class="headerlink" title="类别特征"></a>类别特征</h5><p>先处理可以转为自然编码，onehot编码</p>
<p>1，计数count统计（热度啥的，注意特殊值；计数排序 异常值不敏感；label占比的比例（过拟合问题，交叉验证处理）；</p>
<p>2，目标编码：出价的均值，点击率均值，或ecpm均值构造（新的广告ID的话，中位数填充）</p>
<p>3，交叉组合（类别与类别组合，粒度更细；类别和数值特征组合，这个类别出价的均价，平均点击率之类的）），可以nunique统计。</p>
<p>4，时序特征：前一两天的曝光值，出价情况等。时间序列考虑历史平均（d-1天的信息作为d天的特征）。</p>
<p>存在一个不存在的类别，缺失值的话用中位数或均值填充。</p>
<p>5，数值特征可以均值统计，最大最小，中位数等。</p>
<p>6，其他注意</p>
<p>细粒度的特征增强模型的刻画能力，粗粒度的特征保证模型的泛化能力。细粒度的特征对活跃用户比较好，可以更精细地刻画他的喜好，提供更个性化的商品排序；而粗粒度的特征是为了服务不活跃用户甚至是新用户，用大数据中总结出的一般规律来提供商品的排序。</p>
<p>为了避免过拟合，注意<strong>（5折）交叉统计</strong>构造特征。</p>
<p>CountVectorizer是属于常见的特征数值计算类，是一个文本特征提取方法。对于每一个训练文本，它只考虑每种词汇在该训练文本中出现的频率。对于多值特征，最方便的展开方式就是使用CountVectorizer。</p>
<h5 id="数值特征"><a href="#数值特征" class="headerlink" title="数值特征"></a>数值特征</h5><p>1，分桶：转为离散特征，就可以交叉组合。数值特征可以均值统计，最大最小，中位数等。</p>
<p>2，特征交叉：加减乘除等。根据业务出价 × 点击率 = ecpm 值。还可以类别与数值交叉。</p>
<h5 id="时间特征"><a href="#时间特征" class="headerlink" title="时间特征"></a>时间特征</h5><p>1，日期变量：年、月、周、日、小时、分钟等</p>
<p>2，时序相关特征：历史平均，历史曝光率，历史PCTR，滑动窗统计。d-1天的信息作为d天的特征，这种相近日期的数据相关性是非常大的。</p>
<p><img src="https://pic4.zhimg.com/80/v2-13ed138d221b38e7948060114a450907_720w.jpg" alt="img"></p>
<h5 id="特征筛选"><a href="#特征筛选" class="headerlink" title="特征筛选"></a>特征筛选</h5><p>1，过滤法：卡方检验 衡量x、y的相关性，相关系数来衡量特征间的相关性</p>
<p>2，封装法：逐个添加特征来判断效果好不好（前向，后向搜索），变好就选它，不适合特征太多的情况</p>
<p>3，嵌入法：基于学习模型的特征排序。如 树模型LightGBM可以返回特征的重要性，反映特征在训练过程中的分裂次数（越多，重要性越高），信息增益情况，按高低排序，阈值排序。</p>
<h5 id="一些trick"><a href="#一些trick" class="headerlink" title="一些trick"></a>一些trick</h5><p>1，模型与规则：比如历史平均来填充旧广告id的曝光量，新广告id曝光量用广告size、商品id等特征对应历史平均来填充。调整单调性。</p>
<p>2，目标编码防过拟合：进行目标编码的时候没有防过拟合处理，导致数据泄露。有效的办法是采用交叉验证的方式，比如我们将将样本划分为5份，对于其中每一份数据，我们都用另外4份数据来构造。</p>
<p><img src="https://pic4.zhimg.com/80/v2-3e624280c6761bda895810e3b9d9c3af_720w.jpg" alt="目标编码"></p>
<h4 id="1-4-模型训练与验证"><a href="#1-4-模型训练与验证" class="headerlink" title="1.4 模型训练与验证"></a>1.4 模型训练与验证</h4><p>Baseline：XGboost或LIghtGBM，对特征处理要求低，对类别和连续特征友好，缺失值不需要填充。</p>
<p>交叉验证：时序问题，为了避免数据泄露，常选择训练集最后一天进行线下验证，或者K-folds交叉验证。</p>
<p>模型融合：特征差异，样本差异（交叉验证中选择的样本是不一样的），模型差异（树模型，深度模型等）</p>
<p>训练过程融合：Bagging与Boosting</p>
<p>训练结果融合：投票法（类别），平均法（回归），Stacking</p>
<p>要不断尝试新idea，向优秀选手提问，赛后总结看优秀方案。</p>
<h3 id="2-源码阅读"><a href="#2-源码阅读" class="headerlink" title="2 源码阅读"></a>2 源码阅读</h3><p>数据处理</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.read_csv().sort_values() // 排序</span><br><span class="line">df[[<span class="string">'col'</span>]].astype(int) // 类型转换</span><br><span class="line">df.to_pickle() //pkl 存储更快</span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------</span></span><br><span class="line"></span><br><span class="line">log=train_df</span><br><span class="line">tmp = pd.DataFrame(train_df.groupby([<span class="string">'aid'</span>,<span class="string">'request_day'</span>]).size()).reset_index()</span><br><span class="line">tmp.columns=[<span class="string">'aid'</span>,<span class="string">'request_day'</span>,<span class="string">'imp'</span>] <span class="comment"># 统计广告每天的出现次数，曝光量</span></span><br><span class="line">log=log.merge(tmp,on=[<span class="string">'aid'</span>,<span class="string">'request_day'</span>],how=<span class="string">'left'</span>)</span><br><span class="line">log[log[<span class="string">'request_day'</span>]&lt;<span class="number">17973</span>].to_pickle(<span class="string">'../data/user_log_dev.pkl'</span>) <span class="comment"># 构造验证集</span></span><br><span class="line">log.to_pickle(<span class="string">'../data/user_log_test.pkl'</span>) <span class="comment"># 构造的测试集</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#-----------------------构造训练集</span></span><br></pre></td></tr></table></figure>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，<a href="https://algo.qq.com/application/home/rankinglist/rankingList.html" target="_blank" rel="noopener">https://algo.qq.com/application/home/rankinglist/rankingList.html</a> 腾讯算法大赛</p>
<p>2，<a href="https://zhuanlan.zhihu.com/p/63718151" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/63718151</a> 鱼佬知乎 <a href="https://zhuanlan.zhihu.com/p/73062485" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/73062485</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>推荐算法</tag>
      </tags>
  </entry>
  <entry>
    <title>20200204统计学之辛普森悖论</title>
    <url>/2020/02/04/20200204%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%8B%E8%BE%9B%E6%99%AE%E6%A3%AE%E6%82%96%E8%AE%BA/</url>
    <content><![CDATA[<h3 id="1-例子引入"><a href="#1-例子引入" class="headerlink" title="1 例子引入"></a>1 例子引入</h3><p>医院A和医院B哪个更好？</p><p>医院A最近接收的1000个病人里，有900个活着，100个死了。</p><p>医院B最近接收的1000个病人里，有800个活着，200个死了。</p><p>粗略的看起来A的存活率更高，也许A更好。但是如果考虑更细致的重症病例存活情况呢？</p><div class="table-container">
<table>
<thead>
<tr>
<th>病情</th>
<th>死亡</th>
<th>存活</th>
<th>总数</th>
<th>存活率</th>
</tr>
</thead>
<tbody>
<tr>
<td>严重</td>
<td>70</td>
<td>30</td>
<td>100</td>
<td>30%</td>
</tr>
<tr>
<td>不严重</td>
<td>30</td>
<td>870</td>
<td>900</td>
<td>96.7%</td>
</tr>
<tr>
<td>合计</td>
<td>100</td>
<td>900</td>
<td>1000</td>
<td>90%</td>
</tr>
</tbody>
</table>
</div><a id="more"></a>




<center> 医院A </center>



<div class="table-container">
<table>
<thead>
<tr>
<th>病情</th>
<th>死亡</th>
<th>存活</th>
<th>总数</th>
<th>存活率</th>
</tr>
</thead>
<tbody>
<tr>
<td>严重</td>
<td>190</td>
<td>210</td>
<td>400</td>
<td>52.5%</td>
</tr>
<tr>
<td>不严重</td>
<td>10</td>
<td>590</td>
<td>600</td>
<td>98.3%</td>
</tr>
<tr>
<td>合计</td>
<td>200</td>
<td>800</td>
<td>1000</td>
<td>80%</td>
</tr>
</tbody>
</table>
</div>
<center> 医院B </center>

<p>这样来看是否B更好呢。</p>
<h3 id="2-统计学之辛普森悖论"><a href="#2-统计学之辛普森悖论" class="headerlink" title="2 统计学之辛普森悖论"></a>2 统计学之辛普森悖论</h3><p>这个例子就体现了统计学里的辛普森悖论（Simpson’s paradox）辛普森悖论最初是英国数学家爱德华·H·辛普森（Edward H. Simpson）在1951年发现的。</p>
<p><strong>辛普森悖论的不同解释：1，当你把数据拆开细看的时候，细节和整体趋势完全不同的现象。2，分组的数据点各自表现出某一个方向的相关性，在聚集时却表现出相反方向的相关性。</strong>说明数据不是绝对客观的。</p>
<p><img src="/images/20200204Data_SimpsonParadox.jpg" alt="20200204Data_SimpsonParadox"></p>
<p>从统计学家的观点来看，出现辛普森悖论的原因是因为这些数据中潜藏着一个魔鬼——潜在变量。比如在上面这个例子里，潜在变量就是病情严重程度不同的病人的占比。</p>
<p>我们能做的，就是仔细地研究分析各种影响因素。需要选择将数据分组或将它们聚合在一起。这似乎很简单，但我们如何决定做哪个？答案是<strong>学会思考因果关系</strong>：数据如何生成，基于此，哪些因素会影响我们未展示的结果？</p>
<p>仅有数据还不够。数据绝不是纯粹客观的，特别是当我们只看到最终的图表时，我们必须考虑是否明白整个事件。</p>
<p>为了避免辛普森悖论出现，就需要斟酌个别分组的权重，以一定的系数去消除以分组资料基数差异所造成的影响，同时必需了解该情境是否存在其他潜在要因而综合考虑。</p>
<h3 id="3-思考"><a href="#3-思考" class="headerlink" title="3 思考"></a>3 思考</h3><p>这个跟推荐系统里的隐变量很相似啊。直接数据只是用户表现（浏览数据，点击结果），而内在的隐变量则代表了同一类用户的行为习惯，其中不也是有因果关系的存在嘛。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1， <a href="https://zhuanlan.zhihu.com/p/47867414" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/47867414</a> 机器之心 辛普森悖论</p>
<p>2，公众号“把科学带回家”</p>
<p>3， <a href="[https://wiki.mbalib.com/wiki/%E8%BE%9B%E6%99%AE%E6%A3%AE%E6%82%96%E8%AE%BA](https://wiki.mbalib.com/wiki/辛普森悖论">MBA智库 辛普森悖论</a>)</p>
]]></content>
      <categories>
        <category>统计学</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>AIOps</tag>
        <tag>统计学</tag>
      </tags>
  </entry>
  <entry>
    <title>点云的三种可视化方法</title>
    <url>/2020/01/16/20200116%E7%82%B9%E4%BA%91%E7%9A%84%E4%B8%89%E7%A7%8D%E5%8F%AF%E8%A7%86%E5%8C%96%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h3 id="1-点云介绍"><a href="#1-点云介绍" class="headerlink" title="1 点云介绍"></a>1 点云介绍</h3><p>点云数据是来自斯坦福大学的HDF5格式数据。HDF5 格式是用于存储和分发科学数据的一种多对象文件格式。可以用 HDFView 打开文件，查看数据。 </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">www = &apos;https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip</span><br></pre></td></tr></table></figure><a id="more"></a>

<p>点云还有PLY格式：PLY 文件格式是 Stanford 大学开发的一套三维 mesh 模型数据格式，图形学领域最初很多模型都是基于此格式，我使用了此格式的点云物体文件进行了部分物体的参考和对比。</p>
<p>点云还有PCD格式：一种新的 3D 点云数据文件格式，是当初为了解决某些不支持 PCL 为 3D点云处理进行的文件扩展。他的文件头部具有固定格式，必须用 ASCII 编码，包含标题、对点云数据的某些属性的声明。PCD 文件可以使用 PCL 库里的 PCL_Viewer 打开，从而直接查看到点云的三维图像。</p>
<p>MAC上的PCL_Viewer需要装PCL库，当时配置的一些问题记录在博客里了。<a href="[https://saruagithub.github.io/2019/03/27/PCL%E5%9C%A8Mac%E4%B8%8A%E7%8E%AF%E5%A2%83%E9%97%AE%E9%A2%98/](https://saruagithub.github.io/2019/03/27/PCL在Mac上环境问题/">PCL 在 Mac 上环境问题</a></p>
<h3 id="2-可视化方法"><a href="#2-可视化方法" class="headerlink" title="2 可视化方法"></a>2 可视化方法</h3><h4 id="2-1-Matplotlib方法"><a href="#2-1-Matplotlib方法" class="headerlink" title="2.1 Matplotlib方法"></a>2.1 Matplotlib方法</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">'3d'</span>)</span><br><span class="line"><span class="comment"># point_range = range(0, points.shape[0], skip) # skip points to prevent crash</span></span><br><span class="line">point_range = range(<span class="number">0</span>, points.shape[<span class="number">0</span>])</span><br><span class="line">ax.scatter(points[point_range, <span class="number">0</span>],   <span class="comment"># x</span></span><br><span class="line">           points[point_range, <span class="number">1</span>],   <span class="comment"># y</span></span><br><span class="line">           points[point_range, <span class="number">2</span>],   <span class="comment"># z</span></span><br><span class="line">           c=points[point_range, <span class="number">2</span>], <span class="comment"># height data for color</span></span><br><span class="line">           cmap=<span class="string">'spectral'</span>,</span><br><span class="line">           marker=<span class="string">"x"</span>)</span><br><span class="line">ax.axis(<span class="string">'scaled'</span>)  <span class="comment"># &#123;equal, scaled&#125;</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<p><img src="/images/20200116MatPlotLib_PointCloud.jpg" alt="20200116MatPlotLib_PointCloud"></p>
<h4 id="2-2-PCD格式转化用PCL-Viewer可视化"><a href="#2-2-PCD格式转化用PCL-Viewer可视化" class="headerlink" title="2.2 PCD格式转化用PCL_Viewer可视化"></a>2.2 PCD格式转化用PCL_Viewer可视化</h4><p>对 HDF5 格式的数据进行了重写为 PCD 文件格式，主要 就是将数据写入的时候需要满足 PCD 文件顶头部分的特定格式。 PCL_viewer 是可视化点云文件的 PCL 工具，它需要用到 PCL 库里的 vtk 库进 行可视化。 </p>
<p>详情见我的github项目里 <a href="https://github.com/saruagithub/PointCloudClassification_keras" target="_blank" rel="noopener">点云分类</a> 的H5toPcd.py。</p>
<h4 id="2-3-Three-js-网页可视化"><a href="#2-3-Three-js-网页可视化" class="headerlink" title="2.3 Three.js 网页可视化"></a>2.3 Three.js 网页可视化</h4><p>首先构建一个场景，遍历添加 3D 点云的所有 点到场景里，并给点赋值颜色 RGB 值和材质，其实场景就是物体的一个容器。然后设置好相机，相机的角度决定了场景中某一角度的 3D 点云物体的图像。相机对 旋转的点云拍照，从而渲染显示在页面上即可看到可视化的点云物体了。最后设置 好渲染器。使用渲染器的 render(scene, camera)函数，设置渲染器的像素和页面元 素大小，渲染器将相机拍到的图形渲染显示在页面的元素内，从而在页面中可以看到图像。 </p>
<p>详情见github项目 <a href="https://github.com/saruagithub/PointCloudUpload" target="_blank" rel="noopener">点云分类网页展示</a> 的draw2.html</p>
<p><img src="/images/20200116Three_PointCloud.jpg" alt="20200116Three_PointCloud"></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol>
<li><p>普林斯顿大学 Modelnet 官网，<a href="http://modelnet.cs.princeton.edu/" target="_blank" rel="noopener">http://modelnet.cs.princeton.edu/</a> 2018 Princeton Vision &amp; </p>
<p>Robotics Labs ‒ Department of Computer Science </p>
</li>
<li><p>PCL 官网，<a href="http://www.pointclouds.org/about/#open" target="_blank" rel="noopener">http://www.pointclouds.org/about/#open</a> 2018/5/23 </p>
</li>
<li><p>Three.js 官网 <a href="https://threejs.org/" target="_blank" rel="noopener">https://threejs.org/</a> 2018/5/23 </p>
</li>
</ol>
]]></content>
      <categories>
        <category>可视化</category>
      </categories>
      <tags>
        <tag>三维点云</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title>二分查找算法</title>
    <url>/2020/01/13/20200113%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h3 id="基本二分查找"><a href="#基本二分查找" class="headerlink" title="基本二分查找"></a>基本二分查找</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// return index of target</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">binarySearch</span><span class="params">(<span class="keyword">int</span> numbers[],<span class="keyword">int</span> length, <span class="keyword">int</span> target)</span></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> low = <span class="number">0</span>, high = length<span class="number">-1</span>, middle = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span>(low &lt;= high)&#123;</span><br><span class="line">    middle = (low + high) / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span>(target == numbers[middle]) <span class="keyword">return</span> middle;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(target &lt; numbers[middle]) high = middle - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> low = middle + <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><a id="more"></a>
<p>二分查找的时间复杂度是 $O(logn)$</p>
<p>二分查找里的边界条件有不同的写法，当 while 循环的条件中是 &lt;=时，在[low, high] 的闭区间上查找。</p>
<p>基于二分查找的题目很多，但基本很多情况都是给排序好的数组之类的进行查找。</p>
<h3 id="翻转排序数组"><a href="#翻转排序数组" class="headerlink" title="翻转排序数组"></a>翻转排序数组</h3><p>leecode100-33：假设按照升序排序的数组在预先未知的某个点上进行了旋转。搜索一个给定的目标值，如果数组中存在这个目标值，则返回它的索引。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">search</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(nums.<span class="built_in">size</span>() &lt;= <span class="number">0</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">int</span> start = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> <span class="built_in">end</span> = nums.<span class="built_in">size</span>() - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>(start &lt;= <span class="built_in">end</span>)&#123;</span><br><span class="line">        <span class="keyword">int</span> mid = start + (<span class="built_in">end</span>-start)/<span class="number">2</span>;</span><br><span class="line">        <span class="comment">// find it</span></span><br><span class="line">        <span class="keyword">if</span>(nums[mid] == target) <span class="keyword">return</span> mid;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// left side is ASE</span></span><br><span class="line">        <span class="keyword">if</span> (nums[start] &lt;= nums[mid])&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[start] &lt;= target &amp;&amp; nums[mid] &gt; target) <span class="built_in">end</span> = mid;</span><br><span class="line">            <span class="keyword">else</span> start = mid+<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="comment">// right ride is ASE</span></span><br><span class="line">            <span class="keyword">if</span>(nums[mid] &lt; target &amp;&amp; target&lt; nums[start]) start = mid+<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span>    <span class="built_in">end</span> = mid;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="leecode34-二分查找第一与最后位置"><a href="#leecode34-二分查找第一与最后位置" class="headerlink" title="leecode34 二分查找第一与最后位置"></a>leecode34 二分查找第一与最后位置</h3><p>在排序数组中查找元素的第一个和最后一个位置。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">searchRange_left_bound</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (nums.<span class="built_in">size</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> start=<span class="number">0</span>, <span class="built_in">end</span>=nums.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">while</span> (start &lt; <span class="built_in">end</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> mid = start + (<span class="built_in">end</span> - start) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (nums[mid] == target) <span class="built_in">end</span> = mid;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &lt; target) start = mid + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="built_in">end</span> = mid;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> start;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>左侧边界start的含义，nums中小于target的元素有几个。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">searchRange_left_bound</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (nums.<span class="built_in">size</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> start=<span class="number">0</span>, <span class="built_in">end</span>=nums.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">while</span> (start &lt; <span class="built_in">end</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> mid = start + (<span class="built_in">end</span> - start) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (nums[mid] == target) <span class="built_in">end</span> = mid;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &lt; target) start = mid + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="built_in">end</span> = mid;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (start == nums.<span class="built_in">size</span>()) <span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">// target 比所有数都大</span></span><br><span class="line">    <span class="keyword">return</span> nums[start] == target ? start : <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">searchRange_right_bound</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (nums.<span class="built_in">size</span>() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">int</span> start = <span class="number">0</span>, <span class="built_in">end</span> = nums.<span class="built_in">size</span>();</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (start &lt; <span class="built_in">end</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> mid = start + (<span class="built_in">end</span> - start) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (nums[mid] == target) &#123;</span><br><span class="line">            start = mid + <span class="number">1</span>; <span class="comment">// 注意</span></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &lt; target) &#123;</span><br><span class="line">            start = mid + <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &gt; target) &#123;</span><br><span class="line">            <span class="built_in">end</span> = mid;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 注意</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">end</span> == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> nums[<span class="built_in">end</span><span class="number">-1</span>] == target ? (<span class="built_in">end</span><span class="number">-1</span>) : <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="SwordToOffer-二维数组的查找"><a href="#SwordToOffer-二维数组的查找" class="headerlink" title="SwordToOffer 二维数组的查找"></a>SwordToOffer 二维数组的查找</h3><p>书P47，每次选取数组的右上角元素，如果目标值较小，就逐渐往左下走。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// P47 题目s4，二维数组查找数字</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">find_num</span><span class="params">(<span class="keyword">int</span>* matrix, <span class="keyword">int</span> rows, <span class="keyword">int</span> columns, <span class="keyword">int</span> number)</span></span>&#123;</span><br><span class="line">    <span class="keyword">bool</span> found = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (matrix != <span class="literal">nullptr</span> &amp;&amp; rows&gt;<span class="number">0</span> &amp;&amp; columns&gt;<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> row = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> col = columns - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (row &lt; rows &amp;&amp; col &gt;=<span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (matrix[row * columns + col] == number) &#123;</span><br><span class="line">                found = <span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (matrix[row * columns + col] &gt; number) --col;</span><br><span class="line">            <span class="keyword">else</span> ++row;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> found;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>SwordToOffer</tag>
      </tags>
  </entry>
  <entry>
    <title>剑指OfferP41与哈希散列</title>
    <url>/2020/01/12/20200112%E5%89%91%E6%8C%87OfferP41/</url>
    <content><![CDATA[<h3 id="数组中重复的数字"><a href="#数组中重复的数字" class="headerlink" title="数组中重复的数字"></a>数组中重复的数字</h3><p>思路1：排序，然后比较当前个与下一个是否相同，相同则为重复元素。</p><p>思路2：一遍遍历，hash表将数组元素存起来，每次判断是否在hash里出现过。t:O(n)，space: O(n)</p><p>思路3：题目限制得比较死，数字在0~n-1的范围。所以可以采取书中的特殊交换解法。交换有限次即可找到，因此time O(n)。</p><a id="more"></a>


<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unordered_map&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// solution2</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; duplicate2(<span class="keyword">int</span> numbers[],<span class="keyword">int</span> length)&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; duplication;</span><br><span class="line">    <span class="built_in">unordered_map</span>&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; mmap;</span><br><span class="line">    <span class="keyword">if</span> (numbers==<span class="literal">nullptr</span> || length&lt;=<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> duplication;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;length; i++) &#123;</span><br><span class="line">        <span class="comment">// 可以去除这个限制了</span></span><br><span class="line">        <span class="keyword">if</span> (numbers[i] &lt; <span class="number">0</span> || numbers[i] &gt; length+<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> duplication;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (mmap.<span class="built_in">find</span>(numbers[i]) != mmap.<span class="built_in">end</span>() ) &#123;</span><br><span class="line">            duplication.push_back(numbers[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            mmap[i] = numbers[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> duplication;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// solution 3</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; duplicate(<span class="keyword">int</span> numbers[],<span class="keyword">int</span> length)&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; duplication;</span><br><span class="line">    <span class="comment">// Boundary conditions</span></span><br><span class="line">    <span class="keyword">if</span> (numbers==<span class="literal">nullptr</span> || length &lt;=<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> duplication;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (numbers[i] &lt; <span class="number">0</span> || numbers[i] &gt; length<span class="number">-1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> duplication;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;length; i++) &#123;</span><br><span class="line">        <span class="keyword">while</span> (numbers[i] != i) &#123;</span><br><span class="line">            <span class="keyword">if</span> (numbers[i] == numbers[numbers[i]]) &#123;</span><br><span class="line">                duplication.push_back(numbers[i]);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//swap num[i] and num[num[i]]</span></span><br><span class="line">            swap(numbers[i], numbers[numbers[i]]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> duplication;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// 测试输出重复的数字 the duplicate num</span></span><br><span class="line">    <span class="keyword">int</span> num[<span class="number">7</span>] = &#123;<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">3</span>&#125;;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; duplication;</span><br><span class="line">    duplication = duplicate(num, <span class="keyword">sizeof</span>(num)/<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> item:duplication) <span class="built_in">cout</span>&lt;&lt;item&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我修改了下，直接返回vector重复的数字。</p>
<h3 id="hash原理"><a href="#hash原理" class="headerlink" title="hash原理"></a>hash原理</h3><h4 id="hash原理-1"><a href="#hash原理-1" class="headerlink" title="hash原理"></a>hash原理</h4><p>根据关键码值直接访问表。如可以把关键码值映射到数组中的位置来访问记录，这个就是散列。把关键码值映射到位置的函数称为散列函数，用h表示。存放记录的数组称为散列表 HT。散列表中的第一个位置称为槽 slot，HT中槽的数目用M表示。$i = h(K)$ 是表中满足 $0 \leq h(K) &lt; M$ 的一个槽，记录在HT[i] 的关键码值与K相等。</p>
<p>散列方法不适合多条记录有相同关键码的应用程序。散列方法一般不适合范围检索。适合的是精确查找。有吗？那条记录是关键码值K呢？应用：主存的检索，磁盘的检索，组织存储在磁盘上的大型数据库。</p>
<p>适用情况，记录关键码值的范围很大，并且把记录存储在一个槽数目相对较少的表中。</p>
<p>散列函数：一般来说希望选择的散列函数能把记录以相同的概率分布到散列表的所有槽中。但是在一般情况下，根据关键码值的分布来选择散列 函数。</p>
<p>一些常见的散列函数：取余、平方取中法，字符串散列函数，折叠方法——ASCII码累加起来 % M（散列表长）</p>
<h4 id="开散列方法——单链方法"><a href="#开散列方法——单链方法" class="headerlink" title="开散列方法——单链方法"></a>开散列方法——单链方法</h4><p>冲突解决方法之开散列方法。</p>
<p>《数据结构与算法分析》P212，最简单的形式是：把散列表中的每个槽定义为一个链表的表头，散列到一个槽的所有记录都放到这个槽的链表内。链表中的记录可以按照插入次序排列，按照关键码值次序排列，按照访问频率次序排列等等。</p>
<p>适用于主存中。</p>
<h4 id="闭散列方法——开地址方法"><a href="#闭散列方法——开地址方法" class="headerlink" title="闭散列方法——开地址方法"></a>闭散列方法——开地址方法</h4><p>把所有记录直接存储到散列表中。每条关键码值标记为$k_R$ ，记录R有一个基槽，就是$h(k_R)$ ，即由散列函数计算出来的槽。如果要插入一条记录R，另一条记录占据了R的基槽，就把R存储在表的其他槽内。</p>
<p>桶式散列。把散列表中的槽分成多个桶。先进入桶中的槽，再进入溢出槽里。散列函数把记录在各个桶之间平均分布，使得进入溢出桶的记录尽可能少。</p>
<p>适用于磁盘的散列表。可以把桶的大小设置为磁盘块的大小。</p>
<h6 id="线性探查"><a href="#线性探查" class="headerlink" title="线性探查"></a>线性探查</h6><p>当基槽被占用时，在散列表中找到一个空槽，冲突策略就到达这个组中的下一个槽。如果这个槽也被占用了，就找下一个空槽。探测序列由探测函数P生成。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">typename</span> E&gt;</span><br><span class="line"><span class="keyword">void</span> hashdict&lt;Key,E&gt;::hashInsert(<span class="keyword">const</span> Key&amp;k, <span class="keyword">const</span> E&amp;e)&#123;</span><br><span class="line">  <span class="keyword">int</span> <span class="built_in">home</span>; <span class="comment">// home position for k</span></span><br><span class="line">  <span class="keyword">int</span> pos = <span class="built_in">home</span> = h(k); <span class="comment">//Init proble sequence</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; EMPTYKEY!=(HT[pos]).key(); i++)&#123;</span><br><span class="line">    pos = (<span class="built_in">home</span> + p(k,i) % M); <span class="comment">// probe</span></span><br><span class="line">    Assert(k != (HT[pos]).key(), <span class="string">"Duplication not allowed!"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  KVpair&lt;Key,E&gt; temp(k,e);</span><br><span class="line">  HT[pos] = temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>第i次对P调用，返回第i次要用到的偏移量。</p>
<p>探测函数：线性探测，避免聚集可P(k,i) = ci</p>
<p>好的探测序列是在回到基槽之前，把散列表的所有槽都走一遍。理想的探测函数应该在探查序列中随机的从未走过的槽中选择下一个位置，即探查序列应当是散列表位置的随机排列。如伪随机探查。$( h(K) + r_i ) mod M$, $r_i$ 是1到M-1之间的数的随机排列。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>SwordToOffer</tag>
      </tags>
  </entry>
  <entry>
    <title>20180915pointnet论文3——TensorFlow源码阅读</title>
    <url>/2020/01/11/20180915pointnet%E8%AE%BA%E6%96%873%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</url>
    <content><![CDATA[<h3 id="目录说明"><a href="#目录说明" class="headerlink" title="目录说明"></a>目录说明</h3><p>根目录下：</p><p>train.py用于点云分类训练</p><p>provider.py 用于点云的数据预处理（旋转，抖动等）</p><p>evaluate用于评估训练结果。</p><p>其他目录：<strong>data</strong>目录下存放用于训练的样例文件h5，test_files与train_files中列举的用于训练及测试的文件路径。<strong>log</strong> 存放的是训练结果，默认情况下只存放最近一次训练结果。<strong>models</strong>存放的是模型文件，pointnet_cls.py（POINTNET）和pointnet_cls_basic.py（baseline模型）中的MLP是分类模型结构。pointnet_seg.py是点云分割模型网络；transform_nets.py为原始点云对称变换以及特征变换，即论文中的T-net网络。</p><a id="more"></a>




<h3 id="1，数据预处理provider"><a href="#1，数据预处理provider" class="headerlink" title="1，数据预处理provider"></a>1，数据预处理provider</h3><p>前面下载数据以及后面的hdf5格式加载数据就略过了。说一说数据预处理部分干了些什么。</p>
<p>1，shuffle_data函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shuffle_data</span><span class="params">(data, labels)</span>:</span></span><br><span class="line">    idx = np.arange(len(labels))</span><br><span class="line">    np.random.shuffle(idx)</span><br><span class="line">    <span class="keyword">return</span> data[idx, ...], labels[idx], idx</span><br></pre></td></tr></table></figure>
<p>根据labels的长度创建idx下标集合，对下标集合随机打乱，返回打乱的数据data[idx,…] 和labels[idx]。</p>
<p>2，随机旋转点云rotate_point_cloud（参数batch_data）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rotate_point_cloud</span><span class="params">(batch_data)</span>:</span></span><br><span class="line">    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(batch_data.shape[<span class="number">0</span>]):</span><br><span class="line">        rotation_angle = np.random.uniform() * <span class="number">2</span> * np.pi</span><br><span class="line">        cosval = np.cos(rotation_angle)</span><br><span class="line">        sinval = np.sin(rotation_angle)</span><br><span class="line">        rotation_matrix = np.array([[cosval, <span class="number">0</span>, sinval],</span><br><span class="line">                                    [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                                    [-sinval, <span class="number">0</span>, cosval]])</span><br><span class="line">        shape_pc = batch_data[k, ...]</span><br><span class="line">        rotated_data[k, ...] = np.dot(shape_pc.reshape((<span class="number">-1</span>, <span class="number">3</span>)), rotation_matrix)</span><br><span class="line">    <span class="keyword">return</span> rotated_data</span><br></pre></td></tr></table></figure>
<p>遍历这批点云物体batch_data.shape[0] 即B的大小。</p>
<p>旋转角度是随机生成的，乘以2$\pi$ ，即使角度多大都没关系，反正按角度算。</p>
<p>计算cos和sin值。</p>
<p>注意此处的旋转矩阵。原一个点云物体k的大小的n*3与旋转矩阵做点积。其实就是物体逆时针旋转那么多角度。对这一批点云物体都做这一个随机旋转角度值。</p>
<script type="math/tex; mode=display">\left[\begin{array}{lll}{cosval} & {0} & {sinval} \\ {0} & {1} & {0} \\ {-sinval} & {0} & {cosval}\end{array}\right]</script><p>rotate_point_cloud_by_angle旋转也是同理，不过是指定角度旋转。角度作为参赛输入函数。</p>
<p>3，jitter_point_cloud随机抖动点云</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">jitter_point_cloud</span><span class="params">(batch_data, sigma=<span class="number">0.01</span>, clip=<span class="number">0.05</span>)</span>:</span></span><br><span class="line">    B, N, C = batch_data.shape</span><br><span class="line">    <span class="keyword">assert</span>(clip &gt; <span class="number">0</span>)</span><br><span class="line">    jittered_data = np.clip(sigma * np.random.randn(B, N, C), <span class="number">-1</span>*clip, clip)</span><br><span class="line">    jittered_data += batch_data</span><br><span class="line">    <span class="keyword">return</span> jittered_data</span><br></pre></td></tr></table></figure>
<p>sigma = 0.01， clip = 0.05</p>
<p>sigma <em> sigma </em> np.random.randn(B, N, C) 是均值为sigma的正态分布数据，大小是$B\times N \times C$</p>
<p>将这些数值切割到-0.05到0.05之间，并与原始点云的坐标数据相加。</p>
<p>相当于给点云数据加微小的噪声，增强数据有助于模型的泛化性。</p>
<h3 id="2，基础模型baseline"><a href="#2，基础模型baseline" class="headerlink" title="2，基础模型baseline"></a>2，基础模型baseline</h3><p>pointnet_cla_basic.py 函数。就是不看T-net的网络部分。</p>
<p><img src="/images/20180914pointnet.jpg" alt="20180914pointnet"></p>
<p>placeholder_inputs() 根据点云物体一批大小，以及每个点云物体的点的数目声明变量占位。</p>
<p>get_model() 输入大小BxNx3, 输出Bx40 （这个是40个类别分类向量</p>
<p>其中input_image的shape是$B \times N \times 3 \times 1$ ， 而输出大小是$B \times 40$ 因为物体是40个类别。</p>
<p>然后就是点云的卷积网络多层感知层MLP，卷积层的卷积核个数为64，大小是$1 \times 3$ ，步长是 $1 \times 1$，padding = valid 不补0，激活函数是Relu。 这几个参数，其中卷积核个数为64表示卷积中输出滤波器filter的数量，$1 \times 3$  的卷积核大小是因为坐标为xyz。卷积核就会在训练过程中逐步得到一些与点云物体的特殊的特征点。</p>
<p><img src="/images/20200114POINTNET_CNN.png" alt="20200114POINTNET_CNN"></p>
<p><center>卷积图，输入是2048 × 3，输出其实有64个特征地图，其实就是论文图中的 n × 64</center><br>同理，后续的卷积核大小都是(1,1)，步长也是(1,1) 都是为了挑选这些特征点（信息点，有趣点），即局部感知，可以想这个网络只是把每个点连接起来而已。</p>
<p>然后经过5个卷积层之后，采用了最大池化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">MaxPooling2D(pool_size=(NUM_POINT,<span class="number">1</span>),strides=[<span class="number">2</span>,<span class="number">2</span>],padding=<span class="string">'valid'</span>)</span><br></pre></td></tr></table></figure>
<p>最大池化采用大小为(2,2) 将特征地图缩小一半，并提取关键信息点。同时这里的最大池化将特征点起了对称作用，最后将全局的特征进行聚合。</p>
<script type="math/tex; mode=display">f\left(\left\{x_{1}, \ldots, x_{n}\right\}\right) \approx g\left(h\left(x_{1}\right), \ldots, h\left(x_{n}\right)\right)</script><script type="math/tex; mode=display">f: 2^{\mathrm{R}^{N}} \rightarrow \mathbb{R}, h \quad: \mathbb{R}^{N} \rightarrow \mathbb{R}^{K}</script><p>g是一个对称函数，即maxpool；h是卷积网络；下图中的$\gamma$ 是拟合分类函数（即全连接层逼近复杂函数）。</p>
<p><img src="/images/20200114POINTNET_pic.jpg" alt="20200114POINTNET_pic"></p>
<p>最后的三个全连接网络，大小分别是512，256，40。最后的40输出类别。激活函数为softmax输出概率，哪个概率大则输出就是哪个类别的物体。全连接网络好理解，就是对特征点汇总为全局描述符，最后用于分类。</p>
<h3 id="3，POINTNET网络"><a href="#3，POINTNET网络" class="headerlink" title="3，POINTNET网络"></a>3，POINTNET网络</h3><p>T-Net的作用：我们期望通过网络学习到的表征（特征）对于这些仿射变换是不变的。</p>
<h4 id="3-1-Input-Transform网络"><a href="#3-1-Input-Transform网络" class="headerlink" title="3.1 Input Transform网络"></a>3.1 Input Transform网络</h4><h5 id="3-1-1-论文原理"><a href="#3-1-1-论文原理" class="headerlink" title="3.1.1 论文原理"></a>3.1.1 论文原理</h5><p>我们通过<strong>微型网络（图2中的T-net）预测仿射变换矩阵</strong>，将该变换直接应用于输入点的坐标。</p>
<h5 id="3-1-2-源码"><a href="#3-1-2-源码" class="headerlink" title="3.1.2 源码"></a>3.1.2 源码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">transform = input_transform_net(point_cloud, is_training, bn_decay, K=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>这个T-net网络也是一个类似前面的baseline模型。这里point_cloud的输入大小是(B = 32, N = 2048, 3) 。然后分别由三个卷积层，大小是64（卷积核大小1×3），128（1×1），1024（1×1），一个最大池化层，两个全连接网络组成。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'transform_XYZ'</span>) <span class="keyword">as</span> sc:</span><br><span class="line">    <span class="keyword">assert</span>(K==<span class="number">3</span>)</span><br><span class="line">    weights = tf.get_variable(<span class="string">'weights'</span>, [<span class="number">256</span>, <span class="number">3</span>*K],</span><br><span class="line">                              initializer=tf.constant_initializer(<span class="number">0.0</span>),</span><br><span class="line">                              dtype=tf.float32)</span><br><span class="line">    biases = tf.get_variable(<span class="string">'biases'</span>, [<span class="number">3</span>*K],</span><br><span class="line">                             initializer=tf.constant_initializer(<span class="number">0.0</span>),</span><br><span class="line">                             dtype=tf.float32)</span><br><span class="line">    biases += tf.constant([<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>], dtype=tf.float32)</span><br><span class="line">    transform = tf.matmul(net, weights)</span><br><span class="line">    transform = tf.nn.bias_add(transform, biases)</span><br><span class="line"></span><br><span class="line">transform = tf.reshape(transform, [batch_size, <span class="number">3</span>, K])</span><br><span class="line"><span class="keyword">return</span> transform</span><br></pre></td></tr></table></figure>
<p>初始化weights是(256, 9) 大小，biases大小是(9,)，biases初始化加常量。transform将net网络即卷积网络（大小是 n × 256，n是个点）于权重（大小是 256 × 9）相乘。</p>
<p>input transform是对空间中点云进行调整，直观上理解是旋转出一个更有利于分类或分割的角度，比如把物体转到正面。</p>
<h4 id="3-2-Feature-Transform网络"><a href="#3-2-Feature-Transform网络" class="headerlink" title="3.2 Feature Transform网络"></a>3.2 Feature Transform网络</h4><h5 id="3-2-1-论文原理"><a href="#3-2-1-论文原理" class="headerlink" title="3.2.1 论文原理"></a>3.2.1 论文原理</h5><p>可以在点特征（point features）上插入另一个对齐网络，并预测一个特征转换矩阵以对齐来自不同输入点云（point clouds）的特征。由于特征空间中的变换矩阵具有比空间变换矩阵高（much higher）的维数，这大大增加了优化的难度。 因此，我们在softmax训练损失中添加了一个正则化项。</p>
<p> 我们约束特征变换矩阵使其接近正交矩阵：</p>
<script type="math/tex; mode=display">L_{r e g}=\left\|I-A A^{T}\right\|_{F}^{2}</script><p>$A$ 是特征对齐矩阵（由a mini-network T-net预测的），正交变换将不会丢失输入中的信息，因此是需要的。 我们发现通过添加正则项，优化变得更加稳定，并且我们的模型获得了更好的性能。</p>
<p>正交变换是线性变换的一种，它从实内积空间V映射到V自身，且保证变换前后内积不变。对一个由空间投射到同一空间的线性转换，如果转换后的向量长度与转换前的长度相同，则为正交变换。这里正交变换矩阵其实就是用于点云做仿射变换的。</p>
<h5 id="3-1-3-源码"><a href="#3-1-3-源码" class="headerlink" title="3.1.3 源码"></a>3.1.3 源码</h5><p>1，网络部分</p>
<p>第二次feature transform是对提取出的64维特征进行对齐，即在特征层面对点云进行变换。</p>
<p>2，损失函数部分</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_loss</span><span class="params">(pred, label, end_points, reg_weight=<span class="number">0.001</span>)</span>:</span></span><br><span class="line">    <span class="string">""" pred: B*NUM_CLASSES,</span></span><br><span class="line"><span class="string">        label: B, """</span></span><br><span class="line">    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=label)</span><br><span class="line">    classify_loss = tf.reduce_mean(loss)</span><br><span class="line">    tf.summary.scalar(<span class="string">'classify loss'</span>, classify_loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Enforce the transformation as orthogonal matrix</span></span><br><span class="line">    transform = end_points[<span class="string">'transform'</span>] <span class="comment"># BxKxK</span></span><br><span class="line">    K = transform.get_shape()[<span class="number">1</span>].value</span><br><span class="line">    mat_diff = tf.matmul(transform, tf.transpose(transform, perm=[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>]))</span><br><span class="line">    mat_diff -= tf.constant(np.eye(K), dtype=tf.float32)</span><br><span class="line">    mat_diff_loss = tf.nn.l2_loss(mat_diff) </span><br><span class="line">    tf.summary.scalar(<span class="string">'mat loss'</span>, mat_diff_loss)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> classify_loss + mat_diff_loss * reg_weight</span><br></pre></td></tr></table></figure>
<p>损失函数部分由两部分构成，一部分是交叉熵损失，一部分就是正则化项。</p>
<p>这里Transform的大小是（32,64,64）就是特征转换矩阵，把它与它的转置矩阵相乘$AA^T$。然后与对角矩阵相减 $AA^T - I$ 使这个损失变小。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1, 开源代码 <a href="https://github.com/charlesq34/pointnet" target="_blank" rel="noopener">https://github.com/charlesq34/pointnet</a></p>
<p>2，1*1 的卷积核 <a href="https://zhuanlan.zhihu.com/p/40050371" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/40050371</a></p>
<p>3，卷积神经网络 <a href="https://zhuanlan.zhihu.com/p/47184529" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/47184529</a></p>
<p>4，点云POINTNET解读 <a href="https://blog.csdn.net/tumi678/article/details/80499998" target="_blank" rel="noopener">https://blog.csdn.net/tumi678/article/details/80499998</a></p>
<p>5，损失函数 <a href="https://blog.csdn.net/mao_xiao_feng/article/details/53382790" target="_blank" rel="noopener">https://blog.csdn.net/mao_xiao_feng/article/details/53382790</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>三维点云</tag>
      </tags>
  </entry>
  <entry>
    <title>20180915pointnet论文2——实验部分</title>
    <url>/2020/01/11/20180915pointnet%E8%AE%BA%E6%96%872/</url>
    <content><![CDATA[<h3 id="1-论文中实验"><a href="#1-论文中实验" class="headerlink" title="1 论文中实验"></a>1 论文中实验</h3><h4 id="1-1-点云分类classification"><a href="#1-1-点云分类classification" class="headerlink" title="1.1 点云分类classification"></a>1.1 点云分类classification</h4><p>数据集：ModelNet40，12311CAD模型，40个类别，9843个训练，2468测试。</p><p>我们根据网格区域对网格表面上的1024个点进行统一采样，并将其标准化为单位球体。</p><p>数据增强：1，沿上轴随机旋转对象（随机旋转 or 旋转某一角度）。2，通过具有零均值和0.02标准偏差的高斯噪声使每个点的位置抖动来动态地增加点云。</p><a id="more"></a>


<p>对比实验，table1中SPH[11]，3DShapeNets[28]，VoxNet[17]，Subvolume[18]，LFD[28]，MVCNN[23]（这个的平均每个类别的准确率达到了90.1%，很好诶）与我们的基模型（卷积+最大池化+全连接），PointNet（总体分类准确率89.2 %）的分类准确率比较。</p>
<p>比MVCNN的效果差可能原因是：认为这是由于可以通过渲染图像捕获的精细几何细节的丢失。</p>
<h4 id="1-2-点云零件分割"><a href="#1-2-点云零件分割" class="headerlink" title="1.2 点云零件分割"></a>1.2 点云零件分割</h4><p>3D对象零件分割零件分割是一项具有挑战性的细粒度3D识别任务。</p>
<p>数据集：对来自[29]的ShapeNet零件数据集进行评估，该数据集包含16个类别的16,881个形状，总共标注了50个零件。</p>
<p>我们将零件分割公式化为每个点的分类问题。 评估指标是按点计算。 对于类别C（如杯子）的每个形状S（杯柄与内杯），要计算形状S的mIoU：<strong>如果groundtruth（真实标记）和预测点的并集为空，则将零件IoU计为1</strong>。然后，我们对类别C中所有零件类型的IoU进行平均，以得到该形状的mIoU。 要计算类别的mIoU，我们对该类别中所有形状的mIoU取平均值。</p>
<p>Table2，我们报告每个类别，并表示IoU（％）得分。 我们观察到平均IoU改善了2.3％，我们的网络在大多数类别中都超过了基本方法。</p>
<h4 id="1-3-场景语义分割"><a href="#1-3-场景语义分割" class="headerlink" title="1.3 场景语义分割"></a>1.3 场景语义分割</h4><p>零件分割网络扩展到场景语义分割。其中点标签成为语义对象类（semantic object class），而不是对象零件标签（object part label）。</p>
<p>数据集：斯坦福3D语义分割数据集上进行了实验[1]。 数据集包含来自6个区域（包括271个房间）的Matterport扫描仪的3D扫描。 扫描中来自13个类别（椅子，桌子，地板，墙壁等，加上混乱）的每个点都有语义标签进行标注。</p>
<p>为了准备训练数据，首先按房间来划分points，然后将房间采样为面积为1m x 1m的块。我们训练PointNet的分割segmentation版本以预测每个块中的每个点类。</p>
<p>在训练时，我们会在每个飞行块中随机抽取4096个点。在测试时，我们对所有方面进行测试。我们将我们的方法与使用手工制作的点特征的基线进行比较。基线提取相同的9-dim局部特征和三个附加特征：局部点密度，局部曲率和法线。我们使用标准的MLP作为分类器。结果显示在表3中，其中我们的PointNet方法明显优于基线方法。</p>
<h3 id="2-我的理解"><a href="#2-我的理解" class="headerlink" title="2 我的理解"></a>2 我的理解</h3><p>1，卷积的过程</p>
<p>如何对点进行卷积，提取关键点（信息点）</p>
<p>在卷积的时候，把点云看做是（2048,3,1）的一张灰度图来进行卷积计算。但第一步的卷积核大小是(1,3)  是对点进行计算，提取他的特征点。后续的卷积卷积核也是(1,1)的，也是提取一些关键点。</p>
<p><img src="/images/20200114POINTNET_CNN.png" alt="20200114POINTNET_CNN"></p>
<p>2，对称函数 max pool的作用</p>
<p>解决无序性问题（为什么可以解决无序性）</p>
<p>原生的PointNet就是这样一种g函数。使用multi-layer perceptron (MLP) 和 max pooling 来建模g函数。</p>
<p>3，相邻点的交互信息必须考虑进去（通过共享的MLP或者2D卷积解决）：解决相邻点之间的关联信息问题？</p>
<p>4，网络结构中的T-net作用</p>
<p>论文中指的是将输入点和特征进行对齐、适用于刚性or仿射变换。</p>
<p>通过<strong>微型网络（图2中的T-net）预测仿射变换矩阵</strong>（仿射变换前是直线，仿射变换后还是直线，直线比例保持不变。），并将该变换直接应用于输入点的坐标。why？</p>
<p>其中的正则化项？ 我们约束特征变换矩阵使其接近正交矩阵？</p>
<p>避免n! 排列</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>三维点云</tag>
      </tags>
  </entry>
  <entry>
    <title>20180914pointnet论文1——论文部分</title>
    <url>/2020/01/08/20180914pointnet%E8%AE%BA%E6%96%871/</url>
    <content><![CDATA[<h3 id="1-Abs-amp-Intro"><a href="#1-Abs-amp-Intro" class="headerlink" title="1 Abs &amp; Intro"></a>1 Abs &amp; Intro</h3><p>点云是一种重要的几何数据结构（自动驾驶的数据），由于不规则性许多研究者之前用3D体素网络 voxel grids（体积CNN：[28、17、18]是在体素化形状上应用3D卷积神经网络的先驱。由于数据稀疏性和3D卷积的计算成本，体积表示受到其分辨率的限制。）或图片集合（将点云数据投影到二维平面，扩展性以及提取特征的表示能力的限制。）来进行识别，但这使得数据变庞大，引入了量化伪像，这些伪像会掩盖数据的自然不变性。</p><a id="more"></a>
<p>本文设计了一种新颖的神经网络，直接输入点云，该网络很好地考虑了输入中点的排列不变性（点云是无序向量集。）。POINTNET可以用于分类，零件分割，场景语义分割等。典型的卷积体系结构需要高度规则的输入数据格式，例如图像网格或3D体素，以执行权重共享和其他内核优化。点云是简单统一的结构，避免了网格的组合不规则性和复杂性，因此更易于学习。但是，PointNet仍然必须尊重这样一个事实，即点云只是一组点，因此其成员的排列是不变的，因此在网络计算中必须具有一定的对称性。</p>
<p><strong>（核心原理）我们方法的关键是使用一个简单的对称函数，即最大池化max pool。 网络有效地学习了一组最优标准，它选择了点云的有趣点或信息点，并对选择它们的原因进行了编码。</strong> 网络的最终全连接层将这些学习的最优值汇总到整个描述符的全局描述符中（如上所述）（形状分类），或用于预测每个点云的类别标签（形状分割）。我们的网络<strong>学会了通过稀疏的一组关键点来总结输入点云，根据可视化，这些关键点大致对应于对象的骨架。</strong></p>
<p>我们的输入格式易应用于刚性或仿射变换，因为每个点都是独立变换的。 因此，我们可以添加一个依赖数据的空间转换器网络，该网络尝试在PointNet处理数据之前对数据进行规范化，以进一步改善结果。</p>
<p>文章主要贡献：</p>
<p>1，我们设计了可以直接对3D无序点云处理的深度网络架构。</p>
<p>2，这个网络如何被训练执行3D形状分类，零件分割和场景分割。</p>
<p>3，经验与理论分析其稳定性与有效性。</p>
<p>4，说明选定的神经元在网络中计算出的3D特征，并对其性能进行直观的解释。</p>
<h3 id="2-Problem-Statement"><a href="#2-Problem-Statement" class="headerlink" title="2 Problem Statement"></a>2 Problem Statement</h3><p>深度学习架构，直接将无序点云输入。一个点云表示为3D点的集合$\left\{P_{i} | i=1, \dots, n\right\}$，其中每个点$P_i$ 是其坐标(x,y,z) 的坐标（也可以加上另外的特征，如颜色，法向量等）。</p>
<p>对于对象分类任务，可以直接从形状中采样输入点云，也可以从场景点云中预先分割输入点云。 我们建议的深度网络针对所有k个候选类输出k个分数。</p>
<p> 对于语义分割，输入可以是用于部分零件区域分割的单个对象，也可以是3D场景中的用于对象区域分割。 我们的模型输出n×m分数，即输出每个点（一共n个）的每一个m个语义子类别。</p>
<h3 id="3-点集上的深度学习"><a href="#3-点集上的深度学习" class="headerlink" title="3 点集上的深度学习"></a>3 点集上的深度学习</h3><h4 id="3-1-点集属性"><a href="#3-1-点集属性" class="headerlink" title="3.1 点集属性"></a>3.1 点集属性</h4><p>1，无序性。 与图像中的像素阵列或体积网格中的体素阵列不同，点云是一组没有特定顺序的点。换句话说，消耗N个3D点集的网络需要对于输入集的N个排列按数据馈送顺序保持不变。（无论点如何顺序输入，都要能够识别）</p>
<p>2，点之间的相互作用。 这些点来自具有距离度量的空间。 这意味着这些点不是孤立的，相邻点形成一个有意义的子集。 因此，模型需要能够从附近的点捕获局部结构，以及局部结构之间的组合相互作用。</p>
<p>3，变换下的不变性。 作为几何对象，学习到的点集表示应不变于某些变换。 例如，一起旋转和平移点都不应修改全局点云类别或点的分割。</p>
<h4 id="3-2-点云架构"><a href="#3-2-点云架构" class="headerlink" title="3.2 点云架构"></a>3.2 点云架构</h4><p><img src="/images/20180914pointnet.jpg" alt="20180914pointnet"></p>
<p>我们的网络具有<strong>三个关键模块：最大池层（作为对称函数，用于汇总来自所有点的信息），一个局部和全局信息组合结构，以及两个对齐输入点集和点特征的联合对齐网络。</strong></p>
<h5 id="3-2-1-无序输入的对称函数！！！"><a href="#3-2-1-无序输入的对称函数！！！" class="headerlink" title="3.2.1 无序输入的对称函数！！！"></a>3.2.1 无序输入的对称函数！！！</h5><p>为了使模型对输入排列不变，存在以下三种策略：</p>
<p>1）按规范顺序对输入进行排序； </p>
<p>尽管排序听起来很简单，但实际上在高维空间中不存在稳定的排序，关于一般意义上的点扰动。 矛盾很容易说明。 如果存在这种排序策略，它将在高维空间和1d实线之间定义一个双射映射（输入的点不论顺序，通过一一对应的函数映射到高维空间）。 不难发现，关于点扰动要求顺序是稳定的，就等同于要求此映射随着维度减小而保留空间邻近性，这是一般情况下无法实现的任务。</p>
<p>因此，排序无法完全解决ordering问题，并且随着ordering问题的持续存在，网络很难学习从输入到输出的一致映射。 如实验所示（图5），我们发现直接在排序点集上应用MLP效果较差，尽管比直接处理未排序的输入要好一些。</p>
<p>2）将输入作为训练RNN的序列，但通过各种排列来增强训练数据； </p>
<p>使用RNN的想法将点集视为序列信号，并希望通过用随机排列的序列训练RNN，RNN将对输入顺序不变。 但是，在“ OrderMatters” [25]中，作者表明顺序确实很重要，不能完全省略。 尽管RNN对长度较短（数十个）的序列的输入排序具有相对较好的鲁棒性，但很难扩展到数千个输入元素，这是点集的常见大小。 根据经验，我们还表明，基于RNN的模型的性能不如我们提出的方法。</p>
<p>3）使用简单的<strong>对称函数</strong>汇总每个点的信息。 在此，对称函数将n个向量作为输入，并输出一个与输入顺序不变的新向量。 例如，+和∗运算符是对称二进制函数。</p>
<script type="math/tex; mode=display">f\left(\left\{x_{1}, \ldots, x_{n}\right\}\right) \approx g\left(h\left(x_{1}\right), \ldots, h\left(x_{n}\right)\right)</script><script type="math/tex; mode=display">f: 2^{\mathrm{R}^{N}} \rightarrow \mathbb{R}, h \quad: \mathbb{R}^{N} \rightarrow \mathbb{R}^{K}</script><p>g是一个对称函数。</p>
<p><strong>基本思想</strong>：从经验上讲，我们的基本模块非常简单，我们通过多层感知器网络近似模拟h函数，通过单个变量函数和最大池函数的组合来近似g。 通过实验发现这种方法效果很好。 通过收集h，我们可以学习多个f来捕获集合的不同属性。</p>
<h5 id="3-2-2-分类、分割"><a href="#3-2-2-分类、分割" class="headerlink" title="3.2.2 分类、分割"></a>3.2.2 分类、分割</h5><p><strong>点云的分类</strong>：轻松地在形状全局特征向量上训练SVM或多层感知器分类器以进行分类。</p>
<p><strong>点云的分割</strong>：需要结合局部信息和全局信息。将全局特征向量与每一个点的特征联合起来再送回每个点特征（feed it back to per point features）。再基于此提取每个新点的特征，这样每个点特征既了解本地信息又了解全局信息。（个人理解：由于需要对逐点的语义分割，所以将<em>global feature</em> 与每一点的feature向量连接，作用是使每一个点都同时具有自身点的feature和global feature，更有利于进行逐点的分类。）</p>
<p>（附录）分割网络是分类网络的扩展。局部特征（第二个feature transform T-net 网络输出）和全局特征（最大池化的输出）联合到一起 for each point。分割网络没有Dropout，训练参数与分类网络一样。输出是每n个点的每一个m个语义子类别。</p>
<p>对比实验：3D CNN Segmentation Network 模型：对于给定的点云，我们首先将其转换为具有32×32×32分辨率的占用网格的体积表示形式。然后，依次应用五个3D卷积运算，每个具有32个输出通道，步幅为1。 每个体素的感受野为19。 最后，将内核大小为1×1×1的3D卷积层序列附加到计算的特征图中，以预测每个体素的分割标签。</p>
<p><img src="/images/20200111_3DCNN.jpg" alt="20200111_3DCNN"></p>
<p>（附录）<strong>零件part分割</strong>。我们添加了一个ont-hot向量表明输入的类别，并将它和最大池化层的输出拼接。我们还在某些层layer增加神经元并添加了跳过链接以收集不同层中的局部点特征，并将它们连接起来以形成点特征输入到分割网络中。</p>
<p><img src="/images/20200111PartSegmentation.jpg" alt="20200111PartSegmentation"></p>
<p>通过这种修改，我们的网络能够预测依赖于局部几何和全局语义的每点数量。 例如，我们可以准确地预测每个点的法线（补充图），从而验证网络能够汇总该点的局部邻域的信息？。 </p>
<h5 id="3-2-3-对齐网络-Joint-Alignment-Network"><a href="#3-2-3-对齐网络-Joint-Alignment-Network" class="headerlink" title="3.2.3 对齐网络 Joint Alignment Network"></a>3.2.3 对齐网络 Joint Alignment Network</h5><p>如果点云经过某些几何变换（例如刚性变换），则该点云的语义标记必须不变。因此，我们期望通过网络学习到的表征（特征）对于这些变换是不变的。</p>
<p>我们通过<strong>微型网络（图2中的T-net）预测仿射变换矩阵</strong>（仿射变换前是直线，仿射变换后还是直线，直线比例保持不变。如平移，翻转，拉伸变换等），并将该变换直接应用于输入点的坐标。 T-net网络本身类似于大型网络，由点独立特征提取（point independent feature extraction），最大池化和完全连接层的基本模块组成。 </p>
<p>这个想法也可以进一步扩展到特征空间的对齐。 我们可以在点特征（point features）上插入另一个对齐网络，并预测一个特征转换矩阵以对齐来自不同输入点云（point clouds）的特征（理解：对齐特征有利于分类）。 然而，特征空间中的变换矩阵具有比空间变换矩阵高（much higher）的维数，这大大增加了优化的难度。 因此，我们在softmax训练损失中添加了一个正则化项。 我们约束特征变换矩阵使其接近正交矩阵</p>
<script type="math/tex; mode=display">L_{r e g}=\left\|I-A A^{T}\right\|_{F}^{2}</script><p>$A$ 是特征对齐矩阵（由a mini-network T-net预测的），正交变换将不会丢失输入中的信息，因此是需要的。 我们发现通过添加正则项，优化变得更加稳定，并且我们的模型获得了更好的性能。</p>
<h6 id="3-2-3-1-附录部分解释Network-Architecture-and-Training-Details"><a href="#3-2-3-1-附录部分解释Network-Architecture-and-Training-Details" class="headerlink" title="3.2.3.1 附录部分解释Network Architecture and Training Details"></a>3.2.3.1 附录部分解释Network Architecture and Training Details</h6><p>1，第一个 input transform T-net微型网络是一个minit-PointNet，输入是原始点集并回归到3 * 3大小的矩阵。他是由在每个点上的共享MLP（64，128，1024即CNN）组成，一个最大池化层，两个大小为512，256的全连接网络组成。输出矩阵被初始化为单位矩阵。除最后一层外，所有层均包括ReLU和批处理规范化（batch normalization）。</p>
<p>2，第二层feature transform T-net微型网络与第一个有相同的结构。除了输出是64*64大小的矩阵。矩阵也是被初始化为单位矩阵。将正则化损失（权重为0.001）添加到softmax分类损失中，以使矩阵接近正交。</p>
<h3 id="4-理论分析"><a href="#4-理论分析" class="headerlink" title="4 理论分析"></a>4 理论分析</h3><h4 id="4-1-函数逼近"><a href="#4-1-函数逼近" class="headerlink" title="4.1 函数逼近"></a>4.1 函数逼近</h4><p>令$\mathcal{X}=\left\{S: S \subseteq[0,1]^{m} \text { and }|S|=n\right\}$，$f: \mathcal{X} \rightarrow \mathbb{R}$ 是一个在$\mathcal{X}$ 上关于豪斯多夫距离的连续集合函数（set function），即$\forall \epsilon&gt;0, \exists \delta&gt;0, \text { for any } S, S^{\prime} \in \mathcal{X}$，如果$d_{H}\left(S, S^{\prime}\right)&lt;\delta$ ，则$\left|f(S)-f\left(S^{\prime}\right)\right|&lt;\epsilon$。我们的定理说，在最大池化层有足够的神经元的情况下，我们的网络可以任意近似f。PointNet模型的表征能力和maxpooling操作输出的数据维度(K)相关，K值越大，模型的表征能力越强。</p>
<p>Theorem 1：假设$f: \mathcal{X} \rightarrow \mathbb{R}$ 是一个关于豪斯多夫距离 $d_{H}(\cdot, \cdot)$ 的连续集合函数，对$\forall \epsilon&gt;0, \exists$ 一个连续函数 $h$ 和一个对称函数 $g\left(x_{1}, \ldots, x_{n}\right)=\gamma \circ M A X$，对任何$S \in \mathcal{X}$ ，</p>
<script type="math/tex; mode=display">\left|f(S)-\gamma\left(\underset{x_{i} \in S}{\operatorname{MAX}}\left\{h\left(x_{i}\right)\right\}\right)\right|<\epsilon</script><p>此处 $x_1, \dots,x_n$ 是任意顺序的S的全部元素。$\gamma$ 是一个连续函数，MAX是一个向量最大操作。</p>
<p>定理证明看论文补充材料（ supplementary material. ）</p>
<p>个人理解：表达式的意思是可以找出一个函数r，向量元素$x_i$经过$h$，足够多的神经元的MAX操作和r函数后任意近似原函数 $f(S)$，而$h$  在文章里值的是许多的卷积函数，MAX是最大池化函数，r是全连接分类映射网络。原函数$f(S)$ 可以想成是S是原所有点的特征空间，f是对原特征空间映射为点云物体的函数。</p>
<h4 id="4-2-瓶颈与稳定性"><a href="#4-2-瓶颈与稳定性" class="headerlink" title="4.2 瓶颈与稳定性"></a>4.2 瓶颈与稳定性</h4><p>理论上和实验上，我们发现网络的表现力受到最大池化层的尺寸（即（1）中的K）的强烈影响。</p>
<p>定义：$\mathbf{u}=\underset{x_{i} \in S}{\operatorname{MAX}}\left\{h\left(x_{i}\right)\right\}$ 是f的子网络，它映射 a point set in $[0,1]^m$ 为K维的向量。输入集中的小损坏或额外的噪声点不太可能改变网络的输出：</p>
<p>Theorem 2：假设$\mathbf{u}: \mathcal{X} \rightarrow \mathbb{R}^{K}$ ，$\mathbf{u} = {MAX}_{x_{i} \in S}\left\{h\left(x_{i}\right)\right\}$ 且 $f=\gamma \circ \mathbf{u}$ ，则：</p>
<script type="math/tex; mode=display">\text { (a) } \forall S, \exists \mathcal{C}_{S}, \mathcal{N}_{S} \subseteq \mathcal{X}, f(T)=f(S) \text { if } \mathcal{C}_{S} \subseteq T \subseteq \mathcal{N}_{S}</script><script type="math/tex; mode=display">(b)\left|\mathcal{C}_{S}\right| \leq K</script><p>a说明对于任何输入数据集S，可以找到最小集Cs和一个最大集Ns，使得对Cs和Ns之间的任何集合T，其网络输出都和S一样。模型对输入数据在有噪声(引入额外的数据点，趋于Ns)和有数据损坏(缺少数据点，趋于Cs)的情况都是<strong>鲁棒</strong>的。定理2(b)说明了最小集Cs的数据多少由maxpooling操作输出数据的维度K给出上界。</p>
<p>直观地，我们的网络学习通过稀疏的关键点来总结形状。在实验部分，我们看到关键点形成了对象的骨架。（实验部分请参考下一篇博客）</p>
<h3 id="5-PointNet-改进部分"><a href="#5-PointNet-改进部分" class="headerlink" title="5 PointNet++改进部分"></a>5 PointNet++改进部分</h3><p>简单说一下POINTNET的缺点是没有考虑点之间的局部关系。POINTNET++ 进行了改进。</p>
<p>提取一个点的局部特征。一个图片像素点的局部是其周围一定曼哈顿距离下的像素点，通常由卷积层的卷积核大小确定。同理，点云数据中的一个点的局部由其周围给定半径划出的球形空间内的其他点构成。组合层的作用就是找出通过采样层后的每一个点的所有构成其局部的点，以方便后续对每个局部提取特征。</p>
<p>特征提取层（feature learning）：因为PointNet给出了一个基于点云数据的特征提取网络，因此可以用PointNet对组合层给出的各个局部进行特征提取来得到局部特征。</p>
<p>分组层，在上一层提取出的中心点的某个范围内寻找最近个k近邻点组成patch；特征提取层是将这k个点通过小型pointnet网络进行卷积和pooling得到的特征作为此中心点的特征，再送入下一个分层继续。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，知乎PointNet解读 <a href="https://zhuanlan.zhihu.com/p/44809266" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/44809266</a></p>
<p>2，Point perception <a href="http://mech.fsv.cvut.cz/~dr/papers/CC05/node6.html" target="_blank" rel="noopener">http://mech.fsv.cvut.cz/~dr/papers/CC05/node6.html</a></p>
<p>3，仿射变换概念：<a href="https://www.zhihu.com/question/20666664" target="_blank" rel="noopener">https://www.zhihu.com/question/20666664</a></p>
<p>4，豪斯多夫距离 <a href="https://www.cnblogs.com/icmzn/p/8531719.html" target="_blank" rel="noopener">https://www.cnblogs.com/icmzn/p/8531719.html</a> （即 A集合中的任一点ai 到集合B中的任意点的最短的距离di，然后在这些距离di中选择距离<strong>最长（远）</strong>的，即作为两个集合A与B之间的Hausdoff Distance。豪斯多夫距离量度度量空间中紧子集之间的距离。）</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>三维点云</tag>
      </tags>
  </entry>
  <entry>
    <title>LightGBM_paper</title>
    <url>/2020/01/03/20200103LightGBM-paper/</url>
    <content><![CDATA[<h3 id="1-摘要简介"><a href="#1-摘要简介" class="headerlink" title="1 摘要简介"></a>1 摘要简介</h3><h4 id="1-1-简介"><a href="#1-1-简介" class="headerlink" title="1.1 简介"></a>1.1 简介</h4><p>GBDT的实现有XGBoost，pGBRT等。但当特征维度高，数据集size大的时候有效性还不够。主要原因在于对每一个特征，都要扫描所有实例并估计所有可能的划分节点的信息增益。</p><p>LightGBM提出的方法是：Gradient-based one-side sampling (GOSS) ，Exclusive feature bundling (EFB)。</p><a id="more"></a>

<h4 id="1-2-GOSS"><a href="#1-2-GOSS" class="headerlink" title="1.2 GOSS"></a>1.2 GOSS</h4><p>GOSS的作用排除相当一部分小的梯度的数据实例（instance），只使用剩下的来估计信息增益。<strong>更大的梯度的数据实例在计算信息增益上起到更重要的作用</strong>。</p>
<p>GBDT中没有数据实例权重。但具有不同梯度的数据实例在信息增益的计算中起着不同的作用。根据信息增益的定义，<u>那些具有较大梯度的实例（即训练不足的实例）将为信息增益做出更大的贡献</u>。下采样那些梯度大的实例（阈值or百分比），并随机丢弃那些小的梯度的实例。</p>
<h4 id="1-3-EFB的作用"><a href="#1-3-EFB的作用" class="headerlink" title="1.3 EFB的作用"></a>1.3 EFB的作用</h4><p>EFB的作用：捆绑互斥特征（即，他们很少同时采用非零值）贪心策略来找最优互斥特征。</p>
<p>现实中，特征空间稀疏。这为我们提供了一种设计几乎无损方法以减少有效特征数量的可能性。在稀疏特征空间中，许多特征几乎是互斥的，即他们很少同时采用非零值（文本挖掘里one hot词表征）。我们可以很安全的捆绑这些互斥特征。</p>
<p>设计了一个以恒定近似比率的贪心算法将最优特征捆绑问题转换为图着色问题。通过将特征作为顶点并为每两个特征（如果它们之间不是互斥的话）添加边。</p>
<p><strong>而Hitogram算法的主要作用是减少候选分裂点数量，GOSS算法的作用是减少样本的数量，EFB算法的作用是减少特征的数量。</strong></p>
<h3 id="2-GBDT回顾"><a href="#2-GBDT回顾" class="headerlink" title="2 GBDT回顾"></a>2 GBDT回顾</h3><p>GBDT是决策树的集成模型。每次迭代GBDT通过拟合负梯度（残差）学习决策树。他的主要成本是在于学习决策树。划分节点的选择是非常耗时的，之前有预排序算法，它每次枚举所有可能的划分点，基于预排序的特征值，从而找到最优划分节点。</p>
<p>另一种是基于直方图的算法。他将连续特征值分桶为离散的bins，利用bins来构建特征直方图。（内存消耗更少，训练速度更快）。直方图建立是 O(#data <em> #feature)，划分节点是 O(#bin </em> #feature)。</p>
<p>实际应用中使用的大规模数据集通常很少。 带有预排序算法的GBDT可以通过忽略零值的特征来降低训练成本[13]。 但是，具有基于直方图的算法的GBDT没有有效的稀疏优化解决方案。 原因是，无论特征值是否为零，基于直方图的算法都需要为每个数据实例检索特征仓值（请参阅算法1）。</p>
<p><img src="/images/20200104GBDT_Algo.jpg" alt="20200104GBDT_Algo"></p>
<p><center>图1</center></p>
<h4 id="2-1-直方图算法"><a href="#2-1-直方图算法" class="headerlink" title="2.1 直方图算法"></a>2.1 直方图算法</h4><p><img src="/images/20200105Histogram.jpg" alt="20200105Histogram"></p>
<p><center>图2</center><br>for node in nodeSet (for all leaf p in Tc-1(x)) 这里是对当前层的叶子节点遍历。（需要遍历所有的特征，来找到增益最大的特征及其划分值，以此来分裂该叶子节点。）</p>
<p>for k=1 to m (for all f in X.Features) 这里是对所有特征进行遍历。<strong>对于每个特征，为其创建一个直方图</strong>。</p>
<p>for j in usedRows do ( for i in (0, num_of_row)) 这里是对此节点的样本row进行统计计算。这个直方图存储了两类信息，分别是每个bin中样本的梯度之和 $H[f \cdot b i n s[i]] \cdot g$, 还有就是每个bin中样本数量$H[f . \text { bins }[i]] . n$ 。下面图2的循环 for i in (0, len(H)) 是遍历所有bin，分别以当前bin作为分割点，累加其左边的bin至当前bin的梯度和$S_L$以及样本数量$n_L$，与父节点的梯度和$S_p,n_p$ 相减得到右边的。</p>
<p>然后计算增益，在遍历过程中取最大的增益，以此时的特征和bin的特征值作为分裂节点的特征和分裂特征取值。</p>
<p>连续特征的分桶和离散特征的分桶是不一样的。先把连续的浮点特征值离散化成k个整数（其实又是分桶的思想，而这些桶称为bin，比如[0,0.1)→0, [0.1,0.3)→1），同时构造一个宽度为k的直方图。离散特征直接对特征的每个取值进行计数。即LightGBM可以直接将<strong>每个类别取值和一个bin关联</strong>，从而自动地处理它们，而无需预处理成onehot编码多此一举。</p>
<p>对比Xgboost的预排序算法：预排序算法首先将样本按照特征取值排序，然后从全部特征取值中找到最优的分裂点位，该算法的候选分裂点数量与样本数量成正比。</p>
<h3 id="3-Gradient-based-One-side-Sampling"><a href="#3-Gradient-based-One-side-Sampling" class="headerlink" title="3 Gradient-based One-side Sampling"></a>3 Gradient-based One-side Sampling</h3><p>在AdaBoost中，样本权重可以很好地表明数据实例的重要性。但GBDT里面就没有这个权重，但我们注意到GBDT中每个数据实例的梯度为我们提供了有用的数据采样信息。如果实例与较小的坡度关联，则该实例的训练误差很小，并且已经过良好训练。 一个简单的主意是丢弃那些梯度小的数据实例。 但是，这样做会改变数据分布，这会损害学习模型的准确性。 为避免此问题，我们提出基于梯度的单边采样（GOSS）。</p>
<p>GOSS保留所有具有大梯度的实例，并对具有小梯度的实例执行随机采样。为了补偿对数据分布的影响，在计算信息增益时，GOSS为具有较小梯度的数据实例引入了一个常数乘法器（constant multiplier）。</p>
<p>GOSS首先根据数据实例的梯度绝对值进行排序，选出最高的a%的实例。随机从剩余的数据实例中采样出 b% 的数据。GOSS放大采样的梯度较小的数据实例，乘常量因子$\frac{1-a}{b}$。</p>
<h4 id="3-1-理论分析"><a href="#3-1-理论分析" class="headerlink" title="3.1 理论分析"></a>3.1 理论分析</h4><p>$\mathcal{X}$ 输入空间</p>
<p>$\mathcal{G}$ 是梯度空间</p>
<p>$n$ 是样本实例个数。</p>
<p>$\{g_1,g_2…g_n\}$ 是损失函数关于模型输出（即$f_{m-1}的预测值$）的负梯度。</p>
<p>对于GBDT，信息增益经常是由划分后的方差度量的。</p>
<p>定义：令$O$ 是在决策树的一个固定节点的训练数据集training dataset，划分特征 $j$ 在点 $d$ （我的理解是特征取值d）的方差增益定义是（理解一下就是划分的两边的平均负梯度的平方的平均）：</p>
<script type="math/tex; mode=display">V_{j | O}(d)=\frac{1}{n_{O}}\left(\frac{\left(\sum_{\left\{x_{i} \in O: x_{i j} \leq d\right\}} g_{i}\right)^{2}}{n_{l | O}^{j}(d)}+\frac{\left(\sum_{\left\{x_{i} \in O: x_{i j}>d\right\}} g_{i}\right)^{2}}{n_{r | O}^{j}(d)}\right)</script><script type="math/tex; mode=display">n_{O}=\sum I\left[x_{i} \in O\right], n_{l | O}^{j}(d)=\sum I\left[x_{i} \in O: x_{i j} \leq d\right] \text { and } n_{r | O}^{j}(d)=\sum I\left[x_{i} \in O: x_{i j}>d\right]</script><p>对于特征 $j$ ，决策树算法选择：</p>
<script type="math/tex; mode=display">d_{j}^{*}=\operatorname{argmax}_{d} V_{j}(d)</script><p>并计算最大增益：$V_{j}\left(d_{j}^{*}\right)$</p>
<p>然后数据由特征 $j^{\star}$ 在划分点 $d_{j^{\star}}$ 为左右子节点。</p>
<p>在我们提出的GOSS方法中，首先，我们将训练实例根据其梯度的绝对值按降序排列。然后保存前 $a * 100%$ 的数据实例子集 $A$ ，剩下的数据 $A^c$ 是随机采样大小为 $b \times\left|A^{c}\right|$子集$B$。 最后通过在数据 $A \cup B$对估计的方差增益 $\tilde{V}_{j}(d)$ 划分数据实例</p>
<script type="math/tex; mode=display">\tilde{V}_{j}(d)=\frac{1}{n}\left(\frac{\left(\sum_{x_{i} \in A_{l}} g_{i}+\frac{1-a}{b} \sum_{x_{i} \in B_{l}} g_{i}\right)^{2}}{n_{l}^{j}(d)}+\frac{\left(\sum_{x_{i} \in A_{r}} g_{i}+\frac{1-a}{b} \sum_{x_{i} \in B_{r}} g_{i}\right)^{2}}{n_{r}^{j}(d)}\right)</script><script type="math/tex; mode=display">A_{l}=\left\{x_{i} \in A: x_{i j} \leq d\right\}, A_{r}=\left\{x_{i} \in A: x_{i j}>d\right\}, B_{l}=\left\{x_{i} \in B: x_{i j} \leq d\right\}, B_{r}=\left\{x_{i} \in B: x_{ij} > d \}\right.</script><p>该系数$\frac{1-a}{b}$用于将B上的梯度总和归一化为A的大小，GOSS放大采样的梯度较小的数据实例。</p>
<h3 id="4-Exclusive-feature-Bundling"><a href="#4-Exclusive-feature-Bundling" class="headerlink" title="4 Exclusive feature Bundling"></a>4 Exclusive feature Bundling</h3><p>目的：减少特征数量。</p>
<p>高维数据经常是稀疏的，特征空间的稀疏性为我们提供了一种设计几乎无损方法以减少特征数量的可能性。在稀疏的特征空间中，许多特征是互斥的，即它们永远不会同时采用非零值（意思是所有样本在这两特征的取值不是同时采用非零值，这个很像我之前看的HTM里的SDR），因此可以绑定这俩特征为一个单特征。</p>
<p>可以有趣的是，对于类别特征，如果转换成onehot编码，则这些onehot编码后的多个特征相互之间是互斥的，从而可以被捆绑成为一个特征。we can build the same feature histograms from the feature bundles as those from individual features. </p>
<h4 id="4-1-绑哪些feature"><a href="#4-1-绑哪些feature" class="headerlink" title="4.1 绑哪些feature"></a>4.1 绑哪些feature</h4><p>背景图着色问题：给顶点着色，相连的顶点颜色都不同，最少需要多少颜色，这是NP难问题。</p>
<p>给定$G = (V,E)$。$V$ 是特征数，通过将特征作为顶点并为每两个特征（如果它们之间不是互斥的话）添加边。则互斥特征是有着相同颜色的节点。最后采用贪心策略来产生bundle。</p>
<p><img src="/images/20200105EFB.jpg" alt="20200105EFB"></p>
<p>算法过程：</p>
<p>1,首先，我们构造一个具有加权边的图，其权重对应于特征之间的总冲突（特征并不是100%的互斥，只要很少很少的同时为非零值也可 allow a small fraction of conflicts）。 </p>
<p>2, 其次，我们按特征在图中的度（degrees ）降序对特征进行排序。 </p>
<p>3, 最后，我们依次检查排序列表中的每个feature，要么将其分配给冲突很小（由γ控制）的现有bundle，或创建一个新包bundle。 Alg.3 的时间复杂度是$O(feature^2)$，在训练之前仅处理一次使得操作之后的总体冲突最小。</p>
<p>​    当特征数量不是很大时，这种复杂性是可以接受的，但如果有数百万个特征，则可能仍然会受到影响。 为了进一步提高效率，我们提出了一种更有效的排序策略，而无需构建图表：通过非零值的计数进行排序，这类似于按度排序，因为更多的非零值通常会导致发生冲突的可能性更高（类似于根据度degree排序）。</p>
<h4 id="4-2-如何捆绑bundle"><a href="#4-2-如何捆绑bundle" class="headerlink" title="4.2 如何捆绑bundle"></a>4.2 如何捆绑bundle</h4><p>对于第二个问题，我们需要一种很好的方法来合并同一捆绑bundle中的特征，以减少相应的训练复杂性。 关键是要确保可以从feature bundles中识别原始feature的值。</p>
<p>由于基于直方图的算法存储的是离散的bins而不是特征feature的连续值，因此我们可以通过让互斥特征驻留在不同的bins中来构造feature bundle。 这可以通过向特征原始值添加偏移量来完成。 例如，假设我们在feature bundle中有两个特征。 最初，特征A取值[0，10），特征B取值[0，20）。 然后，我们向特征B的值添加10的偏移量，以使经过改进的特征采用[10，30）中的值。 之后，可以安全地合并特征A和B，并使用范围为[0，30]的feature bundle替换原始特征A和B。详细算法在Alg 4。</p>
<p>EFB算法可以将许多互斥特征捆绑到少得多的密集特征上，从而可以<strong>有效避免零特征值</strong>的不必要计算。</p>
<p>实际上，我们还可以优化基本的基于直方图的算法，通过为每个特征使用一个表table 记录具有非零值的数据来忽略零特征值。 通过扫描此表中的数据，构建功能的直方图的成本将从$O(data)$变为$O(non-zero-data)$。 但是，此方法需要额外的内存和计算成本才能在整个树生长过程中维护这些per-feature tables。 我们在LightGBM中将这种优化实现为基本功能。 请注意，此优化不会与EFB冲突，因为当bundle稀疏时我们仍然可以使用它。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>LightGBM的优化点总结</p>
<ul>
<li>基于Histogram的决策树算法。直方图做差加速。</li>
<li>带深度限制的Leaf-wise的叶子生长策略：level-wise 过一次数据可以同时分裂同一层的叶子，容易进行多线程优化，不容易过拟合。但实际上level-wise是一种低效的算法，因为它不加区分的对待同一层的叶子，带来了很多没必要的开销。因为实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。leaf-wise则是一种更为高效的策略，每次从当前所有叶子中，找到分裂增益最大(一般也是数据量最大)的一个叶子，然后分裂，如此循环。因此同 level-wise 相比，在分裂次数相同的情况下，leaf-wise 可以降低更多的误差，得到更好的精度。leaf-wise 的缺点是可能会长出比较深的决策树，产生过拟合。因此 LightGBM 在leaf-wise 之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合。</li>
<li>直接支持类别特征(Categorical Feature)：类别特征最优分割</li>
<li>基于梯度的单边采样算法</li>
<li>特征捆绑策略</li>
</ul>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，论文 LightGBM: A highly efficient gradient boosting decision tree.</p>
<p>2，<a href="https://blog.csdn.net/anshuai_aw1/article/details/83040541" target="_blank" rel="noopener">LightGBM直方图优化算法</a></p>
<p>3，<a href="https://juejin.im/post/5d25e1d0e51d4556da53d151" target="_blank" rel="noopener">一些面试问题</a></p>
<p>4，<a href="https://zhuanlan.zhihu.com/p/91167170" target="_blank" rel="noopener">LightGBM</a></p>
<p>5， <a href="https://zhuanlan.zhihu.com/p/87885678" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/87885678</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>20191231面试2</title>
    <url>/2020/01/02/20191231%E9%9D%A2%E8%AF%952_%E7%9F%A5%E4%B9%8E%E7%BD%91%E6%98%93/</url>
    <content><![CDATA[<h3 id="1，项目介绍"><a href="#1，项目介绍" class="headerlink" title="1，项目介绍"></a>1，项目介绍</h3><p>首先自我介绍。再介绍异常检测项目。在介绍广告CTR项目。</p><p>1，对每个项目的细节梳理清楚：</p><p>如lightGBM如何对类别特征进行节点分裂的？（<a href="http://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradi" target="_blank" rel="noopener">lightGBM论文</a>）</p><p>2，然后就是要仔细思考进一步的优化的地方在哪。</p><p>如何进一步提高点云的识别率呢？当时做了实验加多卷积层并没有明显的提升效果了，物体结构的特征点已经提取充分，所以并没用更深的网络。另一方面继续优化的点可以考虑点与点之间的领域结构，就像图像主要是考虑了相对位置关系，才可以用一些高反差核之类的卷积核提取图像的局部信息。</p><a id="more"></a>




<h3 id="2-基础知识"><a href="#2-基础知识" class="headerlink" title="2 基础知识"></a>2 基础知识</h3><p>中间问了机器学习的一些算法。</p>
<p>1，随机森林的采样体现在哪些地方？</p>
<p>（1）随机森林主要是Bagging和特征采用。Bagging是有放回的抽样，每次约63.2%的数据样本作为训练集。</p>
<p>随机森林每次没有用的样本数据有用吗？做包外预测$H^{oob}(x)$：</p>
<script type="math/tex; mode=display">H^{o o b}(\boldsymbol{x})=\underset{y \in \mathcal{Y}}{\arg \max } \sum_{t=1}^{T} \mathbb{I}\left(h_{t}(\boldsymbol{x})=y\right) \cdot \mathbb{I}\left(\boldsymbol{x} \notin D_{t}\right)</script><p>Bagging的泛化误差包外估计是：</p>
<script type="math/tex; mode=display">\epsilon^{o o b}=\frac{1}{|D|} \sum_{(\boldsymbol{x}, y) \in D} \mathbb{I}\left(H^{o o b}(\boldsymbol{x}) \neq y\right)</script><p>包外估计可以辅助剪枝。</p>
<p>Bagging可以降低方差。</p>
<p>（2）另外RF引入了随机特征选择。就是每个结点都会随机选择一些特征来构建树。如下图的算法流程。第5行，先选取了部分特征用来构建树（森林中每棵树都只随机的选择特征集中的一部分特征进行训练，因而森林中的每棵树都不会全都关注某些有很强预测性的特征上面），然后每个结点都有选择特征子集（line 5）来计算Gini impurity或均方误差，以此挑选最优划分特征（line 6），计算最优划分点（line7）。</p>
<p>（额额额，后面我居然给直接忘了，还有后面算法题短路得不行，捂脸）</p>
<p>每个结点的特征子集的好处：如果特征A1,A2彼此相关。树根据信息增益选择了A1后，A2的信息增益一定会变得很小，因为A1和A2所引起的不确定度是同一个不确定度，确定了A1后那么这个不确定度就没有了，确定A2后数据集的不确定性不会再减小了，因而造成的结果就是虽然说A1和A2同等重要，但是所有的树每次选择A1后就不会选择A2了。</p>
<p><img src="/images/20200102RandomForest.jpg" alt="20200102RandomForest"></p>
<p>（3）其他</p>
<p>随机森林的结合策略有：平均法（简单平均、加权平均），投票法，stacking（先从初始数据集训练出初始学习器，然后生成一个新数据集用于训练次级学习器，交叉验证）</p>
<p><img src="/images/20200102Stacking.jpg" alt="20200102Stacking"></p>
<p>2，梯度下降算法在GBDT有吗？动量法可以用到里面吗？</p>
<p>GBDT本身就是梯度提升法。在构建树的时候，是根据上一次的预测值和真实值的预测残差来构建的，其实就是拟合的损失函数的负梯度。</p>
<h3 id="3-算法题"><a href="#3-算法题" class="headerlink" title="3 算法题"></a>3 算法题</h3><p>海量数据，找出最大的k个数。紧张得面红耳赤，下来了总结学习下咯。</p>
<p>思路1，将数据qsort从大道小排序，取前k-1个数。回顾下qsort，复杂度O(nlogn)。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> A[], <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> temp = A[i];</span><br><span class="line">    A[i] = A[j];</span><br><span class="line">    A[j] = temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">partition</span><span class="params">(<span class="keyword">int</span> A[],<span class="keyword">int</span> l, <span class="keyword">int</span> r, <span class="keyword">int</span>&amp; pivot)</span></span>&#123;</span><br><span class="line">    <span class="keyword">do</span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(A[++l] &gt; pivot);</span><br><span class="line">        <span class="keyword">while</span>((l&lt;r) &amp;&amp; (A[--r] &lt; pivot));</span><br><span class="line">        swap(A,l,r);</span><br><span class="line">    &#125;<span class="keyword">while</span>(l&lt;r);</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">myqsort</span><span class="params">(<span class="keyword">int</span> A[],<span class="keyword">int</span> i,<span class="keyword">int</span> j)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (j &lt;= i) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">int</span> pivotIndex = (i+j)/<span class="number">2</span>;</span><br><span class="line">    swap(A,pivotIndex,j);</span><br><span class="line">    <span class="keyword">int</span> k = partition(A,i<span class="number">-1</span>,j,A[j]);</span><br><span class="line">    swap(A,k,j);</span><br><span class="line">    myqsort(A,i,k<span class="number">-1</span>);</span><br><span class="line">    myqsort(A,k+<span class="number">1</span>,j);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// function call: myqsort(num, 0, N-1);</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">  	<span class="keyword">int</span> k;</span><br><span class="line">    <span class="keyword">int</span> num[<span class="number">3</span>] = &#123;<span class="number">1</span>,<span class="number">-2</span>,<span class="number">0</span>&#125;;</span><br><span class="line">    myqsort(num, <span class="number">0</span>, N<span class="number">-1</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;k; i++) &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;num[i]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>思路2，用partition函数每次划分，两边排好序来做。当中间pivot下标正好是k-1则左边部分就是前k大个数。左边大的数的个数大于k，则最大的k个数在左边。否则在右边，个数为k-count个，复杂度是O(nlog2K)。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">KthBig</span><span class="params">(<span class="keyword">int</span> A[],<span class="keyword">int</span> i,<span class="keyword">int</span> j,<span class="keyword">int</span> kBig)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (j &lt;= i || A == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">int</span> pivotIndex = (i+j)/<span class="number">2</span>;</span><br><span class="line">    swap(A,pivotIndex,j);</span><br><span class="line">    <span class="keyword">int</span> index = partition0(A,i<span class="number">-1</span>,j,A[j]); <span class="comment">// k is index</span></span><br><span class="line">    swap(A,index,j);</span><br><span class="line">    count = index - i + <span class="number">1</span>; <span class="comment">// count the k big data</span></span><br><span class="line">    <span class="keyword">if</span> (kBig == count) &#123;</span><br><span class="line">        <span class="keyword">return</span> index;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(count &gt; kBig)&#123;</span><br><span class="line">        <span class="keyword">return</span> KthBig(A, i, index, kBig);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> KthBig(A, index, j, kBig-count);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>思路3，k个的最大堆。然后后面的数一遍遍历过去，每次有比堆当前最小值小的即替换，调整堆结构。</p>
<p>首先堆的思想：完全二叉树，局部有序，O(logn)。简单基于数组的实现如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MAX_N = <span class="number">100</span>;</span><br><span class="line"><span class="keyword">int</span> heap[MAX_N],sz=<span class="number">0</span>; <span class="comment">//sz is global variable, meaning the lengh of heap</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">heap_push</span><span class="params">(<span class="keyword">int</span> x)</span></span>&#123;</span><br><span class="line">    <span class="comment">//own node's num.</span></span><br><span class="line">    <span class="keyword">int</span> node_index = sz++;</span><br><span class="line">    <span class="keyword">while</span> (node_index &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> p = (node_index<span class="number">-1</span>)/<span class="number">2</span>; <span class="comment">//i's parent</span></span><br><span class="line">        <span class="keyword">if</span> (heap[p] &gt;= x) &#123;</span><br><span class="line">            <span class="keyword">break</span>; <span class="comment">// sequence is ok</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// parent's value put down, node value go up</span></span><br><span class="line">        heap[node_index] = heap[p];</span><br><span class="line">        node_index = p;</span><br><span class="line">    &#125;</span><br><span class="line">    heap[node_index] = x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">heap_pop</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// max (root)</span></span><br><span class="line">    <span class="keyword">int</span> rec = heap[<span class="number">0</span>];</span><br><span class="line">    <span class="comment">// The value to put in the root</span></span><br><span class="line">    <span class="keyword">int</span> x = heap[--sz];</span><br><span class="line">    <span class="comment">//Swap from root</span></span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (i*<span class="number">2</span>+<span class="number">1</span> &lt; sz) &#123;</span><br><span class="line">        <span class="comment">//compare the children value</span></span><br><span class="line">        <span class="keyword">int</span> a = i*<span class="number">2</span>+<span class="number">1</span>; <span class="comment">// left child</span></span><br><span class="line">        <span class="keyword">int</span> b = i*<span class="number">2</span>+<span class="number">2</span>; <span class="comment">// right child</span></span><br><span class="line">        <span class="keyword">if</span> (b &lt; sz &amp;&amp; heap[b] &gt; heap[a]) &#123;</span><br><span class="line">            a = b;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// sequence is right</span></span><br><span class="line">        <span class="keyword">if</span> (heap[a] &lt;= x) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// child's value go up</span></span><br><span class="line">        heap[i] = heap[a];</span><br><span class="line">        i=a;</span><br><span class="line">    &#125;</span><br><span class="line">    heap[i] = x;</span><br><span class="line">    <span class="keyword">return</span> rec;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">//push(3);</span></span><br><span class="line">    heap_push(<span class="number">9</span>);</span><br><span class="line">    heap_push(<span class="number">2</span>);</span><br><span class="line">    heap_push(<span class="number">6</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;sz; i++) &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;heap[i]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"pop:"</span>&lt;&lt;heap_pop()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">  	</span><br><span class="line">  	<span class="comment">// also we can use library</span></span><br><span class="line">    priority_queue&lt;<span class="keyword">int</span>&gt; qqueue;</span><br><span class="line">    qqueue.push(<span class="number">9</span>);</span><br><span class="line">    qqueue.push(<span class="number">2</span>);</span><br><span class="line">    qqueue.push(<span class="number">6</span>);</span><br><span class="line">    <span class="comment">//loop until it is empty</span></span><br><span class="line">    <span class="keyword">while</span> (!qqueue.empty()) &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;qqueue.top()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        qqueue.pop();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最近面了三次，也见识了，知道哪该查漏补缺了。</p>
<p>1，项目的总结博客（启发式算法、三维点云、异常检测部分）</p>
<p>2，深度模型CTR（DeepCTR入手）</p>
<p>3，leecode刷题系列</p>
<p>4，其他（印象笔记搬迁到博客，kaggle比赛开源代码读读）</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://blog.csdn.net/weixin_37688445/article/details/79272319" target="_blank" rel="noopener">https://blog.csdn.net/weixin_37688445/article/details/79272319</a></p>
]]></content>
      <tags>
        <tag>面试</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络CNN</title>
    <url>/2019/12/25/20200225%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN/</url>
    <content><![CDATA[<h3 id="1-图像基础"><a href="#1-图像基础" class="headerlink" title="1 图像基础"></a>1 图像基础</h3><h4 id="1-1-位图与矢量图"><a href="#1-1-位图与矢量图" class="headerlink" title="1.1 位图与矢量图"></a>1.1 位图与矢量图</h4><p><strong>位图</strong>称为点阵图像、像素图或栅格图像，是由称作像素（图片元素）的单个点组成。他的单位是像素。位图有个缺点是放大后看到边缘是有些模糊的，这就是因为像素点组成的缘故。</p><p>位图的参数有：</p><p>像素：像素大小决定图像大小。</p><p>深度：色彩位数，每个像素使用的信息位数越多，可用的颜色就越多</p><p>通道：通常把RGB三种颜色信息称为红通道、绿通道和蓝通道，相应的把透明度称为Alpha通道，alpha通道存储图片的明暗信息等</p><a id="more"></a>




<p><strong>矢量图</strong>的图形元素（点和线段）称为对象，每个对象都是一个单独的个体，它具有大小、方向、轮廓、颜色和屏幕位置等属性。矢量图形软件就是用数学的方法来绘制矩形等基本形状，因此它放大后不会模糊。</p>
<h4 id="1-2-图像特征"><a href="#1-2-图像特征" class="headerlink" title="1.2 图像特征"></a>1.2 图像特征</h4><p>图像具有视觉特征，即颜色、纹理、形状等。还具有空间关系特征，即物体与物体之间的空间关系等等（目前的研究热点 目标检测 yolo网络等）。</p>
<p>目前的卷积网络就是基于位图的，基于像素值、深度、通道等数值进行的计算。</p>
<h3 id="2-卷积核"><a href="#2-卷积核" class="headerlink" title="2 卷积核"></a>2 卷积核</h3><h4 id="2-1-卷积介绍"><a href="#2-1-卷积介绍" class="headerlink" title="2.1 卷积介绍"></a>2.1 卷积介绍</h4><p>卷积核其实是一个小的方阵。训练过程中的参数。</p>
<script type="math/tex; mode=display">\left(\begin{array}{ccc}{1} & {0} & {1} \\ {0} & {1} & {0} \\ {1} & {0} & {1}\end{array}\right)</script><p>卷积的意义？</p>
<p>卷积运算就是在数据矩阵上做滑动的内积（向量内积是向量模长×cos夹角）。他的直观意义就是卷积核和图像的相似程度（余弦距离），可以发现局部的特征在什么位置明显，输出的feature map则提现了图片局部与卷积核的相似程度。</p>
<p><img src="/images/20200225CNN_kernel.jpg" alt="20200225CNN_kernel"></p>
<p>为什么做卷积？</p>
<p>可以减少参数数量，如果采用DNN全连接网络的方式，这样导致每一个像素点都有权重等参数，参数量太大了。另一方面，卷积可以提取图像特征，将图像局部看做是一个输入，卷积核看做是一个权重。</p>
<p>卷积可以提取哪些特征？</p>
<p>局部特征：卷积核提取。</p>
<p>整体特征：多个卷积核提取汇总可以提取整体特征。</p>
<h4 id="2-2-常见卷积核"><a href="#2-2-常见卷积核" class="headerlink" title="2.2 常见卷积核"></a>2.2 常见卷积核</h4><p>垂直、水平边缘检测核。</p>
<script type="math/tex; mode=display">\left(\begin{array}{ccc}{1} & {0} & {-1} \\ {1} & {0} & {-1} \\ {1} & {0} & {-1}\end{array}\right) \quad\left(\begin{array}{ccc}{1} & {1} & {1} \\ {0} & {0} & {0} \\ {-1} & {-1} & {-1}\end{array}\right)</script><p>Laplacian 高反差检测核</p>
<script type="math/tex; mode=display">\left(\begin{array}{ccc}{0} & {-1} & {0} \\ {-1} & {4} & {-1} \\ {0} & {-1} & {0}\end{array}\right) \quad\left(\begin{array}{ccc}{-1} & {-1} & {-1} \\ {-1} & {8} & {-1} \\ {-1} & {-1} & {-1}\end{array}\right)</script><p>eg: 发丝，高反差，加色之后，发丝更明显.</p>
<h4 id="2-3-卷积过程"><a href="#2-3-卷积过程" class="headerlink" title="2.3 卷积过程"></a>2.3 卷积过程</h4><p><img src="/images/20200225CNN_process.jpg" alt="20200225CNN_process"></p>
<p>假设输入图像为矩阵A，大小4×4，卷积核为3×3的下图。</p>
<script type="math/tex; mode=display">\left|\begin{array}{lll}{k 11} & {k 12} & {k 13} \\ {k 21} & {k 22} & {k 23} \\ {k 31} & {k 32} & {k 33}\end{array}\right|</script><p>卷积的过程（注意是做内积）：</p>
<script type="math/tex; mode=display">\left[\begin{array}{ll}{u_{11}} & {u_{12}} \\ {u_{21}} & {u_{22}}\end{array}\right]=\left[\begin{array}{cccc}{x_{11}} & {x_{12}} & {x_{13}} & {x_{14}} \\ {x_{21}} & {x_{22}} & {x_{23}} & {x_{24}} \\ {x_{31}} & {x_{32}} & {x_{33}} & {x_{34}} \\ {x_{41}} & {x_{42}} & {x_{43}} & {x_{44}}\end{array}\right] \times \left[\begin{array}{ccc}{k_{11}} & {k_{12}} & {k_{13}} \\ {k_{21}} & {k_{22}} & {k_{23}} \\ {k_{31}} & {k_{32}} & {k_{33}}\end{array}\right]+\left[\begin{array}{cc}{b} & {b} \\ {b} & {b}\end{array}\right]</script><script type="math/tex; mode=display">=\left[\begin{array}{ll}{x_{11} k_{11}+x_{12} k_{12}+x_{13} k_{13}+} & {x_{12} k_{11}+x_{13} k_{12}+x_{14} k_{13}+} \\ {x_{21} k_{21}+x_{22} k_{22}+x_{23} k_{23}+} & {x_{22} k_{21}+x_{23} k_{22}+x_{24} k_{23}+} \\ {x_{31} k_{31}+x_{32} k_{32}+x_{33} k_{33}+b} & {x_{32} k_{31}+x_{33} k_{32}+x_{34} k_{33}+b} \\ {x_{21} k_{11}+x_{22} k_{12}+x_{23} k_{13}+} & {x_{22} k_{11}+x_{23} k_{12}+x_{24} k_{13}+} \\ {x_{31} k_{21}+x_{32} k_{22}+x_{33} k_{23}+} & {x_{32} k_{21}+x_{33} k_{22}+x_{34} k_{23}+} \\ {x_{41} k_{31}+x_{42} k_{32}+x_{43} k_{33}+b} & {x_{42} k_{31}+x_{43} k_{32}+x_{44} k_{33}+b}\end{array}\right]</script><p>中间L-1层到L层的正向传播表达式（加上激活函数）：</p>
<script type="math/tex; mode=display">\mathrm{x}_{i j}^{L}=\mathrm{f}\left(\mathrm{u}_{i j}^{L}\right)=\mathrm{f}\left(\Sigma_{p=1}^{3} \Sigma_{q=1}^{3} x_{i+p-1, j+q-1}^{L-1} * k_{p q}^{L}+b^{L}\right)</script><p>若最后一场将特征地图进行全连接输出为$y$ （概率输出） ，真实是 $\hat{y}$</p>
<script type="math/tex; mode=display">y=\operatorname{sigmoid}\left(\sum_{i} \sum_{j} u_{ij}\right), \operatorname{loss}=\frac{1}{2}(y-\hat{y})^{2}</script><p>根据链式求导得最后一层全连接的权重 $w$：</p>
<script type="math/tex; mode=display">\Delta w_{i j}=\eta \frac{d_{loss}}{d_{y}} \frac{d y}{d u_{ij}}=\eta(y-\hat{y})({y} *(1-{y}))</script><p>中间卷积核（主要是看哪些对 $\delta$ 误差有贡献，反向传播乘以其相应权重，与DNN的思想类似）：</p>
<script type="math/tex; mode=display">\Delta k_{p q}=\eta \Sigma_{i} \Sigma_{j}(\frac{d_{Loss}}{d x_{i j}^{(l)}} \frac{d x_{i j}^{(l)}}{d u_{i j}^{(l)}} \frac{d u_{i j}^{(l)}}{d k_{p q}^{(l)}})=\eta \sum_{i} \sum_{j}\left(\frac{d_{loss}}{d_{x_{ij}}^{(l)}} \mathrm{f}^{\prime}\left(\mathrm{u}_{i j}^{l}\right) x_{i+p-1, j+q-1}^{l-1}\right)</script><p>上式由于激活函数中间：</p>
<script type="math/tex; mode=display">\frac{\partial x_{i j}^{(l)}}{\partial u_{i j}^{(l)}}=f^{\prime}\left(u_{i j}^{(l)}\right)</script><script type="math/tex; mode=display">\frac{\partial u_{j}^{(l)}}{\partial k_{p q}^{(l)}}=\frac{\partial\left(\sum_{p=1}^{s} \sum_{q=1}^{s} x_{i+p-1, j+q-1}^{(l-1)} \times k_{p q}^{(l)}+b^{(l)}\right)}{\partial k_{p q}^{(l)}}=x_{i+p-1, j+q-1}^{(l-1)}</script><p>反向传播将 $\delta \times \Delta w_{i j}$ 将误差传递回来，即$\frac{\partial L}{\partial x_{i j}^{(l)}}$，代入上述公式就可以求出 $\Delta k_{p q}$。</p>
<script type="math/tex; mode=display">\Delta b_{p q}=\eta \sum_{i} \sum_{j}\left(\frac{d \operatorname{loss}}{d x \mathrm{ij}} \frac{d x_{ij}}{d u_{ij}}\right)=\eta \sum_{i} \sum_{j}\left(\frac{d \operatorname{loss}}{d x_{ij}} \mathrm{f}^{\prime}\left(\mathrm{u}_{i j}^{L}\right)\right)</script><p>其实将卷积核作为一个整体来看，这个传播过程就跟DNN很类似了。CNN里损失函数对临时变量的偏导数，和DNN的全连接不同的是这是一个矩阵：</p>
<script type="math/tex; mode=display">\left[\begin{array}{ccc}\delta_{11}^{(l)} & \dots & \delta_{1 m}^{(l)} \\ \dots & \dots & \dots \\ \delta_{n 1}^{(l)} & \dots & \delta_{m n}^{(l)}\end{array}\right]</script><p>损失函数对卷积核的偏导数实际上就是输入图像矩阵与误差矩阵的卷积：</p>
<script type="math/tex; mode=display">\left[\begin{array}{llll}x_{11} & x_{12} & x_{13} & x_{14} \\ x_{21} & x_{22} & x_{23} & x_{24} \\ x_{31} & x_{32} & x_{33} & x_{34} \\ x_{41} & x_{42} & x_{43} & x_{44}\end{array}\right] *\left[\begin{array}{ll}\delta_{11} & \delta_{12} \\ \delta_{21} & \delta_{22}\end{array}\right]</script><p>（后续看reference1的详细介绍）</p>
<h4 id="2-4-池化"><a href="#2-4-池化" class="headerlink" title="2.4 池化"></a>2.4 池化</h4><p>池化可以压缩特征（压缩信息）：有最大池化，平均池化，加权池化等。</p>
<p><img src="/images/20200225CNN_maxpool.jpg" alt="20200225CNN_maxpool"></p>
<p>池化层没有参数，没有激活函数，故池化的反向传播直接将$\delta$ 传回来即可。如果是平均池化，则粉色 6 反向到 1，1，5，6那里，这四个数的误差项就是 $\frac{\delta}{4}$ , 最大池化的话就是 6 的误差是 $\delta$。</p>
<h3 id="3-对比"><a href="#3-对比" class="headerlink" title="3 对比"></a>3 对比</h3><div class="table-container">
<table>
<thead>
<tr>
<th>DNN</th>
<th>CNN</th>
</tr>
</thead>
<tbody>
<tr>
<td>参数多</td>
<td>使用卷积核，全局共享，参数较少</td>
</tr>
<tr>
<td>不适用与图片处理，没有考虑局部结构信息</td>
<td>卷积核存储图片特征，本例中不断检测一些边缘</td>
</tr>
<tr>
<td>DNN可能陷入局部最优</td>
<td>池化层也可以减小图片</td>
</tr>
<tr>
<td></td>
<td>卷积神经网络更独立于数据输入维度</td>
</tr>
<tr>
<td>保留了原始输入数据的信息</td>
<td>但CNN可能损失原始数据细节信息</td>
</tr>
</tbody>
</table>
</div>
<h3 id="4-典型的CNN结构"><a href="#4-典型的CNN结构" class="headerlink" title="4 典型的CNN结构"></a>4 典型的CNN结构</h3><p>LeNet 商用级别的手写数字识别系统，邮政编码等。</p>
<p>AlexNet</p>
<p>VGGNet</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，<a href="https://zhuanlan.zhihu.com/p/41392664" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/41392664</a> CNN的反向传播</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>神经网络</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>DNN概述</title>
    <url>/2019/12/24/20200223DNN%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>从最开始的神经元开始，1943年MP单个神经元诞生。$y = f\left(\sum_{i=1}^{n} w_{i} x_{i}-\theta\right)$</p><p><img src="/images/20200223MP_nerual.jpg" alt="20200223MP_nerual"></p><p>1958年，感知机perception提出。感知机能很好的实现逻辑与、或、非运算。与、或、非本来也是线性可分问题。若两类模式是线性可分的，即存在一个线性超平面将它们分开。</p><a id="more"></a>


<p>若要解决非线性可分问题，要使用多层功能神经元（1982-1986年，1995提出SVM）。两层感知机可以解决异或问题了。一个神经网络足够多的两层网络 + 适当的激活函数能够逼近任意连续的函数。</p>
<p>2012年，DNN，CNN由于计算能力的提高再次兴起。</p>
<p><img src="/images/20200223DNN.jpg" alt="20200223DNN"></p>
<h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>正向传播就是将输入与权重相乘，逐层向前，直到最后输出。然后计算输出层的误差，反向传播则是将误差逆向传播至隐层神经元。根据隐层神经元的误差对权值和阈值进行更新。</p>
<p><img src="/images/20200223DNN_BP.jpg" alt="20200223DNN_BP"></p>
<p>$z$ 是样本真实值，$y = f (e), e= wx + b$ 是DNN预测值，激活函数 $f$ 采用 sigmoid，采用均方误差 $\frac{1}{2}(y-z)^2$。</p>
<p>机器学习书上推导是根据链式求导：</p>
<script type="math/tex; mode=display">\delta_{6}=(y-z) \frac{d f_6(e)}{d e}=(y-z) f_6(e)(1-f_6(e))</script><script type="math/tex; mode=display">\delta_{4}=\mathrm{w}_{46} \delta_{6} \frac{\mathrm{df}_{4}(\mathrm{e})}{d e}, \delta_{5}=\mathrm{W}_{56} \mathrm{\delta}_{6} \frac{\mathrm{df_4}(\mathrm{e})}{d e}</script><script type="math/tex; mode=display">\delta_{1}=\left(\mathrm{w}_{14} \mathrm{\delta}_{4}+\mathrm{w}_{15} \mathrm{\delta}_{5}\right) \frac{\mathrm{df}_{1}(\mathrm{e})}{d e}, \quad \delta_{2}=\left(\mathrm{w}_{24} \delta_{4}+\mathrm{w}_{25} \delta_{5}\right) \frac{\mathrm{d} f_{2}(\mathrm{e})}{d e}, \delta_{3}=\left(\mathrm{W}_{34} \mathrm{\delta}_{4}+\mathrm{W}_{35} \mathrm{\delta}_{5}\right) \frac{\mathrm{d} \mathrm{f}_3(\mathrm{e})}{d e}</script><p>同理……</p>
<h3 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h3><p>1，目前网络层次越深能够抽象出来的特征越多，但随着神经网络层数的加深，计算量越大，优化函数越来越容易陷入局部最优解。</p>
<p>2，随着网络层数增加，“梯度消失”现象更加严重。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，智能技术基础，罗晓鹏</p>
<p>2，机器学习，周志华</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Stochastic Gradient Descent</title>
    <url>/2019/12/23/20181015StochasticGradientDescent/</url>
    <content><![CDATA[<h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1 概述"></a>1 概述</h3><h4 id="1-1-梯度下降"><a href="#1-1-梯度下降" class="headerlink" title="1.1 梯度下降"></a>1.1 梯度下降</h4><p>梯度下降是经典的局部优化算法。在2000年L Bottou使得随机梯度下降再次被提出。</p><p>对于数据$\left\{\left(X_{j}, Y_{j}\right)\right\}_{j=1}^{M}$ 需要求解：</p><script type="math/tex; mode=display">\min _{\theta \in \mathbb{R}^{n}} J(\theta), \quad J(\theta)=\frac{1}{M} \sum_{j=1}^{M} L\left(\theta ; X_{j}, Y_{j}\right)</script><a id="more"></a>

<p>梯度下降迭代格式：</p>
<script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-\alpha_{i} \nabla J\left(\theta_{i}\right), \quad \alpha_{i} \in \mathbb{R}^{+}</script><p>直接针对损失函数的梯度下降存在的问题是容易陷入局部极小，计算量大（每一次都要计算$\nabla_{\theta} L\left(\theta_{i} ; X_{j}, Y_{j}\right)$）, 鞍点终止问题（鞍点梯度为0）。</p>
<h4 id="1-2-随机梯度下降"><a href="#1-2-随机梯度下降" class="headerlink" title="1.2 随机梯度下降"></a>1.2 随机梯度下降</h4><p>因此提出随机梯度下降。每次仅仅随机取一个数据$\left(X_{R_{i}}, Y_{R_{i}}\right)$来近似均值的损失$\frac{1}{M} \sum_{j=1}^{M} \nabla_{\theta} L\left(\theta_{i} ; X_{j}, Y_{j}\right)$。</p>
<script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-\alpha_{i} \nabla_{\theta} L\left(\theta_{i} ; X_{R_{i}}, Y_{R_{i}}\right)</script><h4 id="1-3-三种梯度下降"><a href="#1-3-三种梯度下降" class="headerlink" title="1.3 三种梯度下降"></a>1.3 三种梯度下降</h4><p>梯度下降：全部数据迭代计算梯度。</p>
<script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-\alpha_{i} \frac{1}{M} \sum_{j=1}^{M} \nabla_{\theta} L\left(\theta_{i} ; X_{j}, Y_{j}\right)</script><p>随机梯度：随机取一个数据来更新梯度。</p>
<script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-\alpha_{i} \nabla_{\theta} L\left(\theta_{i} ; X_{R_{i}}, Y_{R_{i}}\right)</script><p>小批量梯度：随机取$m(\in[50,300])$ 个数据来计算梯度。</p>
<script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-\alpha_{i} \frac{1}{m} \sum_{j=1}^{m} \nabla_{\theta} L\left(\theta_{i} ; X_{R_{i, j}}, Y_{R_{i, j}}\right)</script><p>下批量梯度下降的好处。加噪，避免梯度法终止于鞍点，存在一定概率跳出局部极小，小批量计算量可接受。</p>
<p>如果$J_M(\theta)$满足强凸条件，对于批量梯度法，线性收敛。对于随机梯度下降法，次线性收敛。</p>
<h4 id="1-4-Github代码"><a href="#1-4-Github代码" class="headerlink" title="1.4 Github代码"></a>1.4 Github代码</h4><p><a href="https://github.com/saruagithub/AIcourse_gradientDescent" target="_blank" rel="noopener">https://github.com/saruagithub/AIcourse_gradientDescent</a></p>
<h3 id="2-SGD技巧"><a href="#2-SGD技巧" class="headerlink" title="2 SGD技巧"></a>2 SGD技巧</h3><p>1，SGD缺点：梯度方向不一定好，固定的学习率太小收敛慢太大则阻碍收敛，如何快速穿过山谷（狭窄山谷的震荡）平原呢。</p>
<script type="math/tex; mode=display">v_i = \alpha \nabla_{\theta} J\left(\theta_{i}\right)</script><script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-v_{i}</script><p>2，动量法：梯度的加权平均，递归的添加方向的历史信息（即$v_{i-1}$）。但转弯会慢。</p>
<script type="math/tex; mode=display">v_{i}=\gamma v_{i-1}+\alpha \nabla_{\theta} J\left(\theta_{i}\right)</script><p>其中$\gamma$ 是阻力因子。</p>
<script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-v_{i}</script><p>3，Nesterov：加速梯度法，更早的注意到梯度的变化。在动量法梯度更新前减去动量项。</p>
<script type="math/tex; mode=display">v_{i}=\gamma v_{i-1}+\alpha \nabla_{\theta} J\left(\theta_{i}-\gamma v_{i-1}\right)</script><script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-v_{i}</script><p>就是使用上一步的$v_{i-1}$先走一步再计算合并梯度。这里的$- \gamma v_{i-1}$就是下图B-C这段。</p>
<p>优点：前瞻性，在原方向虚拟走了一步后的梯度。收敛速度明显加快。波动也小了很多。</p>
<p><img src="/images/20181015Nesterov.jpg" alt="20181015Nesterov"></p>
<p>4，Adagrad：自适应梯度，弱化频繁变化的参数。$G_i$指的是历史与当前梯度的平方的累加。</p>
<script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-\frac{\alpha}{\sqrt{G_{i}+\epsilon}} \nabla_{\theta} J\left(\theta_{i}\right)</script><script type="math/tex; mode=display">G_{i}=G_{i-1} + (\nabla_{\theta} J\left(\theta_{i}\right))^{2}</script><p>$\epsilon$ 平滑项，避免除数为0。</p>
<p>5，RMSProp，对AdaGrad的一种改进，使用加权平均于梯度平方项。当前梯度平方项加上上一时刻的平均值。</p>
<script type="math/tex; mode=display">G_{i}=\gamma G_{i-1}+(1-\gamma)(\nabla_{\theta} J\left(\theta_{i}\right))^{2}</script><script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-\frac{\alpha}{\sqrt{G_{i}+\epsilon}} \nabla_{\theta} J\left(\theta_{i}\right)</script><p>另一个改进是定义指数衰减均值，AdaDelta2使用Delta平方的exponential moving average替代learning rate。</p>
<script type="math/tex; mode=display">\theta_{i+1} = \theta_i -\frac{\sqrt{D_{i-1}+\epsilon}}{\sqrt{G_{i}+\epsilon}} \nabla_{\theta} J(\theta_{i})</script><script type="math/tex; mode=display">D_{i}=\gamma D_{i-1}+(1-\gamma)\left[\Delta \theta_{t}\right]^{2}</script><script type="math/tex; mode=display">G_{i}=\gamma G_{i-1}+(1-\gamma)(\nabla_{\theta} J\left(\theta_{i}\right))^{2}</script><script type="math/tex; mode=display">\Delta \theta_{t}=\theta_{t}-\theta_{t-1}</script><p>6，Adam:Adam是对Momentum和RMPprop的一个结合。像 Adadelta 和 RMSprop 一样存储了过去梯度的平方 vt 的指数衰减平均值 ，也像 momentum 一样保持了过去梯度 mt 的指数衰减平均值。</p>
<p>首先令：</p>
<script type="math/tex; mode=display">v_{i}=\gamma_{1} v_{i-1}+\left(1-\gamma_{1}\right) \nabla_{\theta} J\left(\theta_{i}\right)</script><script type="math/tex; mode=display">u_{i}=\gamma_{2} u_{i-1}+\left(1-\gamma_{2}\right) (\nabla_{\theta} J\left(\theta_{i}\right))^{2}</script><p>则：</p>
<script type="math/tex; mode=display">\hat{v}_{i}=\frac{v_{i}}{1-\gamma_{1}^{i}}, \quad \hat{u}_{i}=\frac{u_{i}}{1-\gamma_{2}^{i}}</script><p>最终得：</p>
<script type="math/tex; mode=display">\theta_{i+1} = \theta_i - \frac{\alpha}{\sqrt{\hat{u}_{i}+\epsilon}} \hat{v}_{i}</script><p>梯度部分像Momentum里一样使用V即梯度的exponential moving average来替代当前梯度来更新权重。学习率部分像RMSprop里一样用学习率除以S(即梯度的exponential moving average)来进行学习。V和S都初始化为0。一般$\alpha=0.001, \quad \gamma_{1}=0.9, \quad \gamma_{2}=0.999, \quad \epsilon=10^{-8}$</p>
<p>7, 推荐技巧：</p>
<script type="math/tex; mode=display">v_{i}=\gamma v_{i-1}+(1-\gamma) \nabla_{\theta} J\left(\theta_{i}-\gamma v_{i-1}\right)</script><script type="math/tex; mode=display">u_{i}=\gamma u_{i-1}+(1-\gamma)\left(\nabla_{\theta} J\left(\theta_{i}-\gamma v_{i-1}\right)\right)^{2}</script><script type="math/tex; mode=display">w_{i}=\gamma w_{i-1}+(1-\gamma) \Delta \theta_{i}^{2}</script><p>可得：</p>
<script type="math/tex; mode=display">\theta_{i+1}=\theta_{i} -\frac{\sqrt{w_{i-1}+\epsilon}}{\sqrt{u_{i}+\epsilon}} v_{i}</script><p>所有技巧的目的都是为了根据历史梯度和当前梯度来更新梯度。学习率迭代则是为了能适应梯度，梯度太大则更新小，将学习率learning rate除以当前的梯度，就能得到一个“适应”好的学习率的值。</p>
<p>数学回顾：一元函数的导数与泰勒级数</p>
<p>函数f(x)在x0上的导数定义为：</p>
<script type="math/tex; mode=display">f^{\prime}\left(x_{0}\right)=\lim _{x \rightarrow x_{0}} \frac{f(x)-f\left(x_{0}\right)}{x-x_{0}}</script><p>f(x)在x0附近的Taylor级数是：</p>
<script type="math/tex; mode=display">f(x)=f\left(x_{0}\right)+f^{\prime}\left(x_{0}\right)\left(x-x_{0}\right)+\frac{f^{\prime \prime}\left(x_{0}\right)}{2}\left(x-x_{0}\right)^{2}+O\left(\left|x-x_{0}\right|^{3}\right)</script><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，智能技术基础课PPT &amp; 印象笔记，智能技术基础课2，3</p>
<p>2，<a href="https://blog.csdn.net/tsyccnh/article/details/76673073" target="_blank" rel="noopener">https://blog.csdn.net/tsyccnh/article/details/76673073</a></p>
<p>3, <a href="https://www.zhihu.com/question/305638940/answer/770984541" target="_blank" rel="noopener">https://www.zhihu.com/question/305638940/answer/770984541</a> 梯度下降法</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>leecode168周赛</title>
    <url>/2019/12/22/20191222leecode168%E5%91%A8%E8%B5%9B/</url>
    <content><![CDATA[<h3 id="leecode5291统计位数为偶数的数字"><a href="#leecode5291统计位数为偶数的数字" class="headerlink" title="leecode5291统计位数为偶数的数字"></a>leecode5291统计位数为偶数的数字</h3><p>给你一个整数数组 <code>nums</code>，请你返回其中位数为 <strong>偶数</strong> 的数字的个数。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">输入：nums = [12,345,2,6,7896]</span><br><span class="line">输出：2</span><br><span class="line">解释：</span><br><span class="line">12 是 2 位数字（位数为偶数） </span><br><span class="line">345 是 3 位数字（位数为奇数）  </span><br><span class="line">2 是 1 位数字（位数为奇数） </span><br><span class="line">6 是 1 位数字 位数为奇数） </span><br><span class="line">7896 是 4 位数字（位数为偶数）  </span><br><span class="line">因此只有 12 和 7896 是位数为偶数的数字</span><br><span class="line"></span><br><span class="line">输入：nums = [555,901,482,1771]</span><br><span class="line">输出：1 </span><br><span class="line">解释： </span><br><span class="line">只有 1771 是位数为偶数的数字。</span><br><span class="line"></span><br><span class="line">1 &lt;= nums.length &lt;= 500</span><br><span class="line">1 &lt;= nums[i] &lt;= 10^5</span><br></pre></td></tr></table></figure><a id="more"></a>

<p>思路1：c++，位数是除以10，而判断是否偶数是对2取余判断是否为0。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">findNumbers</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> res=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> num: nums)&#123;</span><br><span class="line">        <span class="keyword">int</span> weishu=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(num / <span class="number">10</span> &gt; <span class="number">0</span>)&#123;</span><br><span class="line">            weishu ++;</span><br><span class="line">            num /= <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;weishu&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">if</span>(weishu % <span class="number">2</span> == <span class="number">0</span>)&#123;</span><br><span class="line">            res ++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; test1 = &#123;<span class="number">12</span>,<span class="number">345</span>,<span class="number">2</span>,<span class="number">6</span>,<span class="number">7896</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> res = findNumbers(test1);</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;res&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>思路2：Python，遍历nums里的数字。将数字转换为string。判断string的长度对2取余是否为0，是0则取1，否则取0（表示位数不是偶数）。再将是偶数的数字求和 sum。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">findNumbers</span><span class="params">(nums: List[int])</span> -&gt; int:</span></span><br><span class="line">        <span class="keyword">return</span> sum(<span class="number">1</span> <span class="keyword">if</span> len(str(x)) % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> nums)</span><br></pre></td></tr></table></figure>
<h3 id="leecode5292划分数组为连续数字的集合"><a href="#leecode5292划分数组为连续数字的集合" class="headerlink" title="leecode5292划分数组为连续数字的集合"></a>leecode5292划分数组为连续数字的集合</h3><p>给你一个整数数组 nums 和一个正整数 k，请你判断是否可以把这个数组划分成一些由 k 个连续数字组成的集合。<br>如果可以，请返回 True；否则，返回 False。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">实例1</span><br><span class="line">输入：nums = [1,2,3,3,4,4,5,6], k = 4</span><br><span class="line">输出：true</span><br><span class="line">解释：数组可以分成 [1,2,3,4] 和 [3,4,5,6]。</span><br><span class="line"></span><br><span class="line">示例2</span><br><span class="line">输入：nums = [3,2,1,2,3,4,3,4,5,9,10,11], k = 3</span><br><span class="line">输出：true</span><br><span class="line">解释：数组可以分成 [1,2,3] , [2,3,4] , [3,4,5] 和 [9,10,11]。</span><br><span class="line"></span><br><span class="line">示例3 </span><br><span class="line">输入：nums = [3,3,2,2,1,1], k = 3</span><br><span class="line">输出：true</span><br><span class="line"></span><br><span class="line">示例4</span><br><span class="line">输入：nums = [1,2,3,4], k = 3</span><br><span class="line">输出：false</span><br><span class="line">解释：数组不能分成几个大小为 3 的子数组。</span><br><span class="line"></span><br><span class="line">1 &lt;= nums.length &lt;= 10^5</span><br><span class="line">1 &lt;= nums[i] &lt;= 10^9</span><br><span class="line">1 &lt;= k &lt;= nums.length</span><br></pre></td></tr></table></figure>
<p>思路1：简单基本思路，将nums里的最小取出来，然后每次取[min,min+k]的值，不断从原nums里去除掉。如果可以这样去空原nums则返回true，否则只要有值不在nums里，则返回false。（但这个方法的时间复杂度太高$O(kn^2)$）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isPossibleDivide</span><span class="params">(nums, k)</span>:</span></span><br><span class="line">	<span class="string">"""</span></span><br><span class="line"><span class="string">	:type nums: List[int]</span></span><br><span class="line"><span class="string">	:type k: int</span></span><br><span class="line"><span class="string">	:rtype: bool</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">	<span class="keyword">if</span> (len(nums) % k != <span class="number">0</span>):</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">while</span> (len(nums) != <span class="number">0</span>):</span><br><span class="line">		<span class="comment"># each list</span></span><br><span class="line">		<span class="keyword">for</span> x <span class="keyword">in</span> range(min(nums), min(nums)+k):</span><br><span class="line">			<span class="keyword">if</span> x <span class="keyword">in</span> nums:</span><br><span class="line">				nums.remove(x)</span><br><span class="line">			<span class="keyword">else</span>:</span><br><span class="line">				<span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">	nums = [<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>]</span><br><span class="line">	k = <span class="number">3</span></span><br><span class="line">	res = isPossibleDivide(nums,k)</span><br><span class="line">	print(res)</span><br></pre></td></tr></table></figure>
<p>进一步，用hash优化查找x in nums。(c++中的map是平衡二叉树)，排序时间复杂度$O(nlogn)$，</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isPossibleDivide</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (nums.<span class="built_in">size</span>() % k != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    sort(nums.<span class="built_in">begin</span>(), nums.<span class="built_in">end</span>());</span><br><span class="line">    <span class="built_in">map</span>&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; hash;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> num:nums) hash[num]++;</span><br><span class="line">    <span class="keyword">int</span> groups = nums.<span class="built_in">size</span>() / k;</span><br><span class="line">    <span class="comment">//group nums</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;groups; i++) &#123;</span><br><span class="line">        <span class="keyword">int</span> min_index = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (hash[nums[min_index]] == <span class="number">0</span>) &#123;</span><br><span class="line">            min_index++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//if min~min+k is not in nums, false</span></span><br><span class="line">        <span class="keyword">int</span> start = nums[min_index];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=start; j&lt;start+k; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (hash[j] == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> hash[j]--;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; test2 = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> res2 = isPossibleDivide(test2,<span class="number">3</span>);</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;res2&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>思路3。新学习了multiset。避免了while这一段找min_index（见上），直接在multiset里查找并去掉，时间要短一点点，但空间用的要更多（因为multiset允许存储重复元素）</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isPossibleDivide2</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (nums.<span class="built_in">size</span>() % k != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">multiset</span>&lt;<span class="keyword">int</span>&gt; s;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> num:nums) s.insert(num);</span><br><span class="line">  	<span class="comment">//multiset&lt;int&gt; s(a.begin(), a.end());</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;nums.<span class="built_in">size</span>() / k; i++) &#123;</span><br><span class="line">        <span class="keyword">int</span> <span class="built_in">min</span> = *s.<span class="built_in">begin</span>();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="built_in">min</span>; j&lt;<span class="built_in">min</span>+k; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (s.<span class="built_in">find</span>(j) == s.<span class="built_in">end</span>()) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            s.erase(s.<span class="built_in">find</span>(j));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1, <a href="https://leetcode-cn.com/problems/find-numbers-with-even-number-of-digits" target="_blank" rel="noopener">https://leetcode-cn.com/problems/find-numbers-with-even-number-of-digits</a></p>
<p>2, <a href="https://leetcode-cn.com/problems/divide-array-in-sets-of-k-consecutive-numbers" target="_blank" rel="noopener">https://leetcode-cn.com/problems/divide-array-in-sets-of-k-consecutive-numbers</a></p>
<p>3，<a href="https://leetcode-cn.com/contest/weekly-contest-168/" target="_blank" rel="noopener">https://leetcode-cn.com/contest/weekly-contest-168/</a></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>leecode</tag>
      </tags>
  </entry>
  <entry>
    <title>20191219leecode142快慢指针学习</title>
    <url>/2019/12/19/20191219leecode142%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="1-题目"><a href="#1-题目" class="headerlink" title="1 题目"></a>1 题目</h3><p>leecode142，给定一个链表，返回链表开始入环的第一个节点。 如果链表无环，则返回NULL。</p><h3 id="2-hash法与快慢指针法"><a href="#2-hash法与快慢指针法" class="headerlink" title="2 hash法与快慢指针法"></a>2 hash法与快慢指针法</h3><p>快慢指针法有意思的推导：</p><p>x：link起点到入环点距离</p><p>y: 入环点到相遇点距离</p><p>c：circle的长度</p><p>相遇时候，慢指针走了x+n1 c  + y （n1假设走了n1圈），快指针走了2倍(x+ n1c+y)</p><a id="more"></a>





<p>快指针比慢指针多走的路程一定是环长度的整数倍，有2(x+ n1c+y) - (x+ n1c+y) = n2 c </p>
<p>所以又x + y = (n2 - n1) c</p>
<p>可以相遇时快指针从起点再走（1倍速），慢指针也走，则相遇点就是入环点。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  leecode 142 circle link detection</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;set&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ListNode</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> val;</span><br><span class="line">    ListNode *next;</span><br><span class="line">    ListNode(<span class="keyword">int</span> x) : val(x), next(<span class="literal">NULL</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// save elem to set, time O(n) space O(n)</span></span><br><span class="line"><span class="function">ListNode *<span class="title">detectCycle</span><span class="params">(ListNode *head)</span> </span>&#123;</span><br><span class="line">    ListNode* p = head;</span><br><span class="line">    <span class="built_in">set</span>&lt;ListNode*&gt; elem_set;</span><br><span class="line">    <span class="keyword">while</span>(p)&#123;</span><br><span class="line">        <span class="keyword">if</span> (elem_set.<span class="built_in">find</span>(p) != elem_set.<span class="built_in">end</span>()) &#123;</span><br><span class="line">            <span class="keyword">return</span> p;</span><br><span class="line">        &#125;</span><br><span class="line">        elem_set.insert(p);<span class="comment">//O(logN)</span></span><br><span class="line">        p = p-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//fast and slow pointer</span></span><br><span class="line"><span class="function">ListNode *<span class="title">detectCycle1</span><span class="params">(ListNode *head)</span></span>&#123;</span><br><span class="line">    ListNode *slow,*fast;</span><br><span class="line">    slow = head;</span><br><span class="line">    fast = head;</span><br><span class="line">    <span class="keyword">while</span> (slow!=<span class="literal">NULL</span> &amp;&amp; fast-&gt;next!=<span class="literal">NULL</span>) &#123;</span><br><span class="line">        slow = slow-&gt;next;</span><br><span class="line">        fast = fast-&gt;next-&gt;next;</span><br><span class="line">        <span class="keyword">if</span> (slow == fast) &#123;</span><br><span class="line">            <span class="comment">//fast pointer go from and start of the link</span></span><br><span class="line">            fast = head;</span><br><span class="line">            <span class="keyword">while</span> (fast != slow) &#123;</span><br><span class="line">                fast = fast-&gt;next;</span><br><span class="line">                slow = slow-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> fast;<span class="comment">//now both pointer is in the start of the citcle</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">//input</span></span><br><span class="line">    ListNode* res;</span><br><span class="line">    ListNode *dummyhead,*head,*temp0,*temp1;</span><br><span class="line">    dummyhead = <span class="keyword">new</span> ListNode(<span class="number">-1</span>);</span><br><span class="line">    head = <span class="keyword">new</span> ListNode(<span class="number">1</span>);</span><br><span class="line">    dummyhead -&gt;next = head;</span><br><span class="line">    temp0 = <span class="keyword">new</span> ListNode(<span class="number">2</span>);</span><br><span class="line">    head-&gt;next = temp0;</span><br><span class="line">    temp1 = <span class="keyword">new</span> ListNode(<span class="number">4</span>);</span><br><span class="line">    temp0-&gt;next = temp1;</span><br><span class="line">    temp1-&gt;next = temp0;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//algorithm</span></span><br><span class="line">    <span class="comment">//res = detectCycle(head);</span></span><br><span class="line">    res = detectCycle1(head);</span><br><span class="line">    <span class="keyword">if</span> (res == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">"no circle"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="built_in">cout</span>&lt;&lt;res-&gt;val&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>leecode</tag>
      </tags>
  </entry>
  <entry>
    <title>20191216面试1&amp;图论问题回顾</title>
    <url>/2019/12/17/20191216%E5%AD%97%E8%8A%82%E9%9D%A2%E8%AF%95%E4%B8%8E%E5%8D%8E%E4%B8%BA%E5%9B%BE%E8%AE%BA%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="1，一面"><a href="#1，一面" class="headerlink" title="1，一面"></a>1，一面</h3><p>第一次面试，居然去面了目前北京最火的一家公司，虽然不是我想去的算法岗。emmm，真的是胆大。不过一面的面试官超级可爱，很温和，我也太幸运了吧。先让自我介绍，然后问项目，然后出了一个很简单的算法题。</p><h4 id="1-1-图论问题"><a href="#1-1-图论问题" class="headerlink" title="1.1 图论问题"></a>1.1 图论问题</h4><p>项目是我大三做的一个图论赛题，回顾总结一下。</p><p>问题：“服务器选址问题”，从图中选出一些节点安放服务器（图中绿色节点 表示为$S_i$），服务器输出流量供给消费节点（图中红色节点，表示为$C_i$）</p><a id="more"></a>


<p>目标：第一要满足每个消费节点的流量需求，第二费用最小。</p>
<p>约束：每个路径有流量限制$flow_{constrain}$，但上下行都可以。也有流量单位费用$UnitCost$。举例子比如图右上角从1到15节点，留出流量13，则费用是13 * 2 = 26，此条路后面只能再流过16 - 13 = 3的流量了。另外其他限制是90秒内必须输出结果，否则没有成绩，使用内存不超过2GB。</p>
<p>输出：每条路径，及流过的流量。</p>
<p><img src="/images/20170305HuaWeiFlow.png" alt="20170305HuaWeiFlow"></p>
<h4 id="1-2-我的算法"><a href="#1-2-我的算法" class="headerlink" title="1.2 我的算法"></a>1.2 我的算法</h4><h5 id="策略1：选择前n个可以流出带宽最大的节点"><a href="#策略1：选择前n个可以流出带宽最大的节点" class="headerlink" title="策略1：选择前n个可以流出带宽最大的节点"></a>策略1：选择前n个可以流出带宽最大的节点</h5><p>1，选择n个可以流出带宽最大的节点</p>
<p>step1 计算每个结点可以输出的带宽之和</p>
<p>step2 排序</p>
<p>step3 选择前n个，放置服务器</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getServerlocation</span><span class="params">(Graph&amp; g,<span class="keyword">int</span>* server)</span><span class="comment">//bigest bandwith Id</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> location=<span class="number">0</span>,i,bandwidth=<span class="number">0</span>,SecondBandWidth=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;g.numV();i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(g.Bandwidth[i] &gt; bandwidth)&#123;</span><br><span class="line">            SecondBandWidth = bandwidth;</span><br><span class="line">            location = i;</span><br><span class="line">            bandwidth = g.Bandwidth[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;g.numC();i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(location == server[i])&#123;</span><br><span class="line">            <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;g.numV();i++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(g.Bandwidth[i] == SecondBandWidth)</span><br><span class="line">                    location = i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> location;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>step4 用Dijkstra计算服务器到消费节点的最短路径（只根据$flow_{constrain}$来计算），计算这条路径的可以流过的最大流量，分配流量，计算费用。</p>
<p>Dijkstra算法：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(w=<span class="number">0</span>;w&lt;g.CountsOfConnectNode[v];w++)&#123;</span><br><span class="line">	<span class="keyword">if</span> (D[w] &gt; D[v] + g.getUnitConsumeCost(v, w))  计算server到各个点的距离，判断并更新</span><br><span class="line">		D[w] = D[v] + g.getUnitConsumeCost(v, w);</span><br></pre></td></tr></table></figure>
<p>获取本条路径可以流过的最大流量</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getflow</span><span class="params">(Graph* G,<span class="keyword">int</span> path[maxN][maxN],<span class="keyword">int</span> cn)</span><span class="comment">//get cn-consumenode minflow</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> flow = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> Cnode  = G-&gt;Con_Nodes[cn];</span><br><span class="line">    <span class="keyword">int</span> minflow = INFINITY,i;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;maxN;i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(minflow &gt; G-&gt;getWeight(path[Cnode][i], path[Cnode][i+<span class="number">1</span>]))&#123;</span><br><span class="line">            minflow = G-&gt;getWeight(path[Cnode][i], path[Cnode][i+<span class="number">1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(path[Cnode][i+<span class="number">2</span>] == <span class="number">-1</span>)&#123;</span><br><span class="line">            flow = minflow;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(flow &gt; G-&gt;Demand[cn])</span><br><span class="line">        flow = G-&gt;Demand[cn];</span><br><span class="line">    <span class="keyword">return</span> flow;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>更新图和消费节点的流量需求。</p>
<p>反过来消费点去找离他最近的服务器节点，分配流量。</p>
<h5 id="策略2：实在不行选择与消费点的直连点放服务器。"><a href="#策略2：实在不行选择与消费点的直连点放服务器。" class="headerlink" title="策略2：实在不行选择与消费点的直连点放服务器。"></a>策略2：实在不行选择与消费点的直连点放服务器。</h5><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* server is in the consumenode */</span></span><br><span class="line">   <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;graph.numC();i++)&#123;</span><br><span class="line">       <span class="keyword">if</span>(server[ser<span class="number">-1</span>] == graph.Con_Nodes[i])&#123;</span><br><span class="line">           pathpath[pathi][<span class="number">0</span>] = server[ser<span class="number">-1</span>];  <span class="comment">//add to the answer</span></span><br><span class="line">           pathpath[pathi][<span class="number">1</span>] = i;</span><br><span class="line">           pathpath[pathi][<span class="number">2</span>] = graph.Demand[i];</span><br><span class="line">           pathi++;</span><br><span class="line">           graph.Demand[i] = <span class="number">0</span>;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<h4 id="1-3-其他方法"><a href="#1-3-其他方法" class="headerlink" title="1.3 其他方法"></a>1.3 其他方法</h4><p>整数规划模型</p>
<p>启发式算法（模拟退火，遗传算法，去网上找了资料学了点基础）</p>
<h4 id="当年的反思"><a href="#当年的反思" class="headerlink" title="当年的反思"></a>当年的反思</h4><p><img src="/images/20191218HuaWeiRes.jpg" alt="20191218HuaWeiRes"></p>
<p>1、一个类里面空间是有限的，如果开了几个1000*1000的二维数组是不行的，要么static，要么设置全局。</p>
<p>2、在Dijkstra 里CountsOfConnectNode不能因为单边减少而减一，因为单边减少就减一的话会造成无法访问一些边，因为我是先遍历的在判断的周边路径是否存在，即weight &gt; 0。</p>
<p>3、一些存DotId的数组我初始化为了-1，其实-1是很容易造成下标越界的，但本来dot的范围是0~maxN，所以造成后面很多的判断 ！= -1 ，希望大家引以为戒。（因为-1 ，我的graph里的成员变量servercost竟然从100变成了-1，就是因为-1下标的范围导致内存访问异常，数据被修改，当时真是急哭我了）</p>
<p>4、记住所有变量定义的时候一定初始化，否则为任意值的话会造成不可知的错误，只能一直debug一步步找变量的变化，真是心累。</p>
<p>5、如果你的数据很多，请注释每个的含义，包括下标，否则你的队友会看不懂你的代码，自己写一写的就会弄混。</p>
<p>6、算法上的缺陷</p>
<p>没有反馈：一直计算的出来的结果，没有经过比较选择这是缺乏了优化的过程的。应该要一直迭代，随机取、放一些服务器后就算一遍最短路径和成本进行比较取优。其实我的代码跑完整个用的时间是ms级的，那么其实还要很多时间可以进行计算。因为最后来不及了也就没有做，自然成本高。</p>
<p>7、团队分工：队友要充分合作（一个人再强大真的比不上三个臭皮匠）、分工写任务，一定要充分相信对方。队长要想好整体，再把模块分开写，把需求明确，免得最后代码合并要哭。</p>
<p>8、编程基本功：编程基本功要多写多练才扎实，不然写这样的复杂稍大的程序就很容易出现一些低级错误</p>
<p>9、多去学习大佬怎么做的，站在前人大佬的基础上才不会自己太犯傻，至少基本的方向不会错！</p>
<h3 id="2，算法题"><a href="#2，算法题" class="headerlink" title="2，算法题"></a>2，算法题</h3><p>1，写出二叉树的最短路径长度。长度 = 路径上节点的值的和。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int MaxPath(TreeNode* root)&#123;</span><br><span class="line">	if (root -&gt; NULL) return 0;</span><br><span class="line">	else return root-&gt;val + max(MaxPath(root-&gt;left),MaxPath(root-&gt;right));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2，给出一个数组[1 3 2 6 5 7 10]，找出后面的比他大的第一个值，返回下标，答案 [1 3 3 5 5 6 -1]。</p>
<p>思路：倒过来遍历，取一个最小的stack</p>
<p>倒着遍历，维护一个递减的stack(top保持最小）。先10和其index绑定入stack，然后轮到7，判断stack top，若大于7就把stack top的数的index返回，否则弹出stack top，直到找到大于7或者stack弹空，若弹空则返回-1.然后把7绑定index压到stack里。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ListNode</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> value;</span><br><span class="line">    <span class="keyword">int</span> index;</span><br><span class="line">    ListNode(<span class="keyword">int</span> a,<span class="keyword">int</span> b)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;value=a;</span><br><span class="line">        <span class="keyword">this</span>-&gt;index=b;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">stack</span>&lt;ListNode&gt; stk;</span><br><span class="line">    <span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; res;</span><br><span class="line">    <span class="keyword">int</span> N; <span class="comment">//N &gt; 0</span></span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;N;</span><br><span class="line">    <span class="keyword">int</span> arr[N];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;N; i++) &#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;arr[i];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//algotithm</span></span><br><span class="line">    res.push(<span class="number">-1</span>);</span><br><span class="line">    <span class="function">ListNode <span class="title">temp</span><span class="params">(arr[N<span class="number">-1</span>],N<span class="number">-1</span>)</span></span>;</span><br><span class="line">    stk.push(temp);<span class="comment">//put last value,arr[N-1]</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=N<span class="number">-1</span>; i&gt;=<span class="number">0</span>; i--) &#123;</span><br><span class="line">        <span class="keyword">while</span> ( !stk.empty()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (arr[i] &lt; stk.top().value) &#123;<span class="comment">//compare with stack top value</span></span><br><span class="line">                res.push(stk.top().index);<span class="comment">//remember the result</span></span><br><span class="line">                <span class="function">ListNode <span class="title">temp</span><span class="params">(arr[i],i)</span></span>;</span><br><span class="line">                stk.push(temp);<span class="comment">//put current arr[i]</span></span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                stk.pop();</span><br><span class="line">                <span class="keyword">if</span> (stk.empty()) &#123;</span><br><span class="line">                    res.push(<span class="number">-1</span>); <span class="comment">//no bigger data, so res is -1</span></span><br><span class="line">                    <span class="function">ListNode <span class="title">temp</span><span class="params">(arr[i],i)</span></span>; <span class="comment">//put this value in it</span></span><br><span class="line">                    stk.push(temp);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;N; i++) &#123;<span class="comment">//print the result</span></span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;res.top()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        res.pop();</span><br><span class="line">    &#125;</span><br><span class="line">  	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-第二次zj开发岗"><a href="#3-第二次zj开发岗" class="headerlink" title="3 第二次zj开发岗"></a>3 第二次zj开发岗</h3><p>其实实习面试都是很基础的，本科学过的东西。问的主要是关于计算机网络，操作系统和数据库的。</p>
<p>操作系统。虽然目前开发岗</p>
<p><strong>操作系统</strong></p>
<p>1，线程和进程的区别：进程是运行中的程序，允许将多个程序调入内存并发执行，包含文本段、程序计数器、寄存器等。进程是CPU使用的基本单位，由线程ID、程序计数器、寄存器、栈等组合，与属于同一进程的其他线程共享代码段。</p>
<p>2，进程调度算法：先来先服务算法。短进程优先调度算法，优先权算法（非抢占、抢占式），高响应比优先调度算法。基于时间片的轮转法。多级反馈队列调度算法。</p>
<p><strong>计算机网络</strong></p>
<p>1，拥塞控制：发送方维护一个拥塞窗口，网络没有出现拥塞则拥塞窗口增大些，以便将更多的分组发送出去。但只要网络出现拥塞，就减小点。最开始cwnd窗口大小加倍，每收到一个对新的报文段确认后，将拥塞窗口加1。当cwnd &lt; ssthresh 时，使用慢开始算法。&gt; 则改用拥塞避免方法。当发送方判断网络出现拥塞，就把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半，然后cwnd重新设置为1，执行慢开始。</p>
<p><img src="/images/20191217Network-controlCongestion.jpg" alt="20170305HuaWeiFlow"></p>
<p><strong>数据库</strong></p>
<p>1，数据库的三范式：1NF是不可分的基本数据项（即列不能够再分成其他几列，每列保持原子性） 。2NF不存在非主属性部分依赖于码。非主键列必须直接依赖于主键，不能存在传递依赖。每列都和主键相关。3NF非主键列是直接依赖于主键。</p>
<p>2，创建表：表名，字段名，类型，大小，完整性约束（主键 not null）</p>
<p><strong>算法设计</strong></p>
<p>给一批int数，要求实现一个数据结构，使得以下操作平均时间复杂度都为O(1)，增加、删除指定的数、随机获取一个数。（想了想其实数组的增加，查找是直接根据下标的很快。加上hash的删除指定数就可以了）</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>20191210Skyline源码阅读</title>
    <url>/2019/12/10/20191210Skyline%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</url>
    <content><![CDATA[<h3 id="1-基类结构"><a href="#1-基类结构" class="headerlink" title="1 基类结构"></a>1 基类结构</h3><p>首先看异常检测基类base.py，所有检测器都是由它继承而来：</p><p>1，init() ：初始化dataSet，probationaryPercent 数据的最初一部分数据不做测试。inputMin, inputMax初始化最大最小值。</p><p>2，initialize()：多进程问题。进程池pool（它默认调用的是CPU的核数）</p><a id="more"></a>


<p>3，handleRecord(): 返回每一个时间点的异常分数值，Returns a list [anomalyScore, *]。这个函数子类必须继承。</p>
<p>4，getAdditionalHeaders()：如HTM检测器里会添加’anomalyscore’ , ‘rawscore’。添加并返回列名的，run函数中调用它拼接最后返回的dataframe。</p>
<p>5，detectDataSet(): 在运行给定检测器的每个检测器进程中调用的函数。参数 (i, detectorInstance, detectorName, labels, outputDir, relativePath) = args，主要是创建保存文件的路径，调用detectorInstance.initialize()，results = detectorInstance.run() </p>
<p>6，run()：为整个dataSet打分并返回结果（dataframe格式）</p>
<h3 id="2-Etsy的Skyline算法"><a href="#2-Etsy的Skyline算法" class="headerlink" title="2 Etsy的Skyline算法"></a>2 Etsy的Skyline算法</h3><p>继承异常检测器基类。另外它的算法是根据几个小算法各自的评分进行平均投票得到。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">self.algorithms =   [median_absolute_deviation,</span><br><span class="line">                     first_hour_average,</span><br><span class="line">                     stddev_from_average,</span><br><span class="line">                     stddev_from_moving_average,</span><br><span class="line">                     mean_subtraction_cumulation,</span><br><span class="line">                     least_squares,</span><br><span class="line">                     histogram_bins]</span><br></pre></td></tr></table></figure>
<h5 id="median-absolute-deviation"><a href="#median-absolute-deviation" class="headerlink" title="median_absolute_deviation"></a>median_absolute_deviation</h5><p>计算数据的中位数，偏差 = 每个值-中位数，得到偏差中位数</p>
<script type="math/tex; mode=display">\mathrm{MAD}=\operatorname{median}\left(\left|X_{i}-\operatorname{median}(X)\right|\right)</script><p>MAD对数据集中的异常值比标准偏差更具弹性。在标准偏差中，与均值的距离的平方，较大的异常值会影响更大。可以通过判断一个点的偏差是否过于偏离MAD来判断异常，此处是如果偏差6倍大于中位数，则判断为异常。</p>
<h5 id="first-hour-average"><a href="#first-hour-average" class="headerlink" title="first_hour_average"></a>first_hour_average</h5><p>上一天的这个时间段1h的均值是$mean$，标准差是$std$，如果$|X_t - mean| &gt; 3 * std$ 则是异常。</p>
<h5 id="stddev-from-average"><a href="#stddev-from-average" class="headerlink" title="stddev_from_average"></a>stddev_from_average</h5><p>值减去移动平均值大于平均值的三个标准偏差则为异常。</p>
<script type="math/tex; mode=display">|X_t - mean| > 3 * std</script><h5 id="stddev-from-moving-average"><a href="#stddev-from-moving-average" class="headerlink" title="stddev_from_moving_average"></a>stddev_from_moving_average</h5><p>值减去指数加权移动平均值大于平均值的三个标准偏差则为异常。</p>
<p>expAvg = series.ewm().mean()</p>
<p>stdDev = series.ewm().std()</p>
<script type="math/tex; mode=display">| X_t - expAvg | > 3 * stdDev</script><h5 id="mean-subtraction-cumulation"><a href="#mean-subtraction-cumulation" class="headerlink" title="mean_subtraction_cumulation"></a>mean_subtraction_cumulation</h5><p>从每个数据源点减去过去历史平均值之后，如果该序列中下一个数据点的值比累积项中的三个标准差远，则该时间序列是异常的。</p>
<h5 id="least-squares"><a href="#least-squares" class="headerlink" title="least_squares"></a>least_squares</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#X——代表时间 timestamp，Y——代表 value</span><br><span class="line">results = np.linalg.lstsq(A, Y)</span><br><span class="line">residual = results[1] #残差</span><br><span class="line">m, c = np.linalg.lstsq(A, Y)[0] #斜率与截距</span><br><span class="line">  for i, value in enumerate(y):</span><br><span class="line">    projected = m * X[i] + c</span><br><span class="line">    error = value - projected</span><br><span class="line">    errors.append(error)</span><br></pre></td></tr></table></figure>
<p>最后点投影到最小二乘上误差大于所有误差的std的3sigma时，判断为异常。</p>
<script type="math/tex; mode=display">Error_t > ErrorsStd</script><h5 id="histogram-bins"><a href="#histogram-bins" class="headerlink" title="histogram_bins"></a>histogram_bins</h5><p>最后时间点的值落入带有少于threshold个其他数据点的直方图bin中，则时间序列是异常的。</p>
]]></content>
      <categories>
        <category>AIOps</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>AIOps</tag>
      </tags>
  </entry>
  <entry>
    <title>mac上hexo的mathjax配置</title>
    <url>/2019/11/26/20191126mac%E4%B8%8Ahexo%E7%9A%84mathjax%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>博文中要写公式是难免的，因为配置hexo支持数学公式是必要的。 Next 主题提供了两个渲染引擎，分别是 mathjax 和 katex，后者相对前者来说渲染速度更快，而且支持更丰富的公式。我这里hexo是4.0版本了，因此又折腾了下。</p><h6 id="1，更改next下的config"><a href="#1，更改next下的config" class="headerlink" title="1，更改next下的config"></a>1，更改next下的config</h6><p>配置next主题里的_config如下，只需要改一个地方就是mathjax的enable为true。</p><a id="more"></a>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Math Formulas Render Support</span><br><span class="line">math:</span><br><span class="line">  # Default (true) will load mathjax / katex script on demand.</span><br><span class="line">  # That is it only render those page which has `mathjax: true` in Front-matter.</span><br><span class="line">  # If you set it to false, it will load mathjax / katex srcipt EVERY PAGE.</span><br><span class="line">  per_page: true</span><br><span class="line"></span><br><span class="line">  # hexo-renderer-pandoc (or hexo-renderer-kramed) required for full MathJax support.</span><br><span class="line">  mathjax:</span><br><span class="line">    enable: true</span><br><span class="line">    # See: https://mhchem.github.io/MathJax-mhchem/</span><br><span class="line">    mhchem: false</span><br></pre></td></tr></table></figure>
<h6 id="2-去掉hexo自带的数学渲染"><a href="#2-去掉hexo自带的数学渲染" class="headerlink" title="2, 去掉hexo自带的数学渲染"></a>2, 去掉hexo自带的数学渲染</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure>
<p>在修改下源文件。打开<code>node_modules/hexo-renderer-kramed/lib/renderer.js</code>，将</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Change inline math rule</span><br><span class="line">function formatText(text) &#123;</span><br><span class="line">    // Fit kramed&apos;s rule: $$ + \1 + $$</span><br><span class="line">    return text.replace(/`\$(.*?)\$`/g, &apos;$$$$$1$$$$&apos;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>改为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Change inline math rule</span><br><span class="line">function formatText(text) &#123;</span><br><span class="line">    return text;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>卸载hexo-math，安装新的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm uninstall hexo-math --save</span><br><span class="line">npm install hexo-renderer-mathjax --save</span><br></pre></td></tr></table></figure>
<p>在修改源文件，打开<code>node_modules/hexo-renderer-mathjax/mathjax.html</code>，将最后一句script改为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure>
<p>打开<code>node_modules/kramed/lib/rules/inline.js</code> : </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,  注释掉改为下面一句</span><br><span class="line">escape: /^\\([`*\[\]()# +\-.!_&gt;])/,</span><br></pre></td></tr></table></figure>
<p>下面的em渲染也改了:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 注释掉改为下面一句</span><br><span class="line">em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br></pre></td></tr></table></figure>
<h6 id="3，开启bolg下的config支持"><a href="#3，开启bolg下的config支持" class="headerlink" title="3，开启bolg下的config支持"></a>3，开启bolg下的config支持</h6><p>在末尾添加内容。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mathjax:</span><br><span class="line">    enable: true</span><br></pre></td></tr></table></figure>
<p>就可以了，鉴于之前的博客可能有些老了，配置了半天就记录下。</p>
<h6 id="4，最后自己在写bolg的时候头部加上mathjax-true，表示本文要数学公式渲染。"><a href="#4，最后自己在写bolg的时候头部加上mathjax-true，表示本文要数学公式渲染。" class="headerlink" title="4，最后自己在写bolg的时候头部加上mathjax: true，表示本文要数学公式渲染。"></a>4，最后自己在写bolg的时候头部加上mathjax: true，表示本文要数学公式渲染。</h6>]]></content>
      <categories>
        <category>配置</category>
      </categories>
      <tags>
        <tag>配置</tag>
      </tags>
  </entry>
  <entry>
    <title>Numenta的HTM简介</title>
    <url>/2019/11/25/20191125Numenta%E7%9A%84HTM%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<h4 id="1-Numenta的HTM简介"><a href="#1-Numenta的HTM简介" class="headerlink" title="1, Numenta的HTM简介"></a>1, Numenta的HTM简介</h4><p>Hierarchical Temporal Memeory(HTM,层级时间记忆，皮质学习) 是一种基于脑神经科学来模拟大脑进行学习和信息处理的神经网络。新皮质就是大脑里褶皱的皮层部分（图1），这只有哺乳动物有。将皮层纵向切开，不论是视觉还是听觉部分，切开后的结构是相似的（图2），很有可能大脑处理不同信息的方法是类似的。</p><a id="more"></a>
<p><img src="/images/20191125head.jpg" width="250"><br><img src="/images/20191125cells.png" width="200"> </p>
<p><center>图1 大脑皮层，图2 细胞图</center><br>新皮质分化为很多个区域（region，图3），这些区域通过神经纤维连接。这些区域以层次结构的方式连接在一起。低层级信息收集基础信号，经过不同层级逐渐加工，提取并理解更抽象信息，更高级的话或许可以关联到想法、事物活动等信息。这个有点类似卷积神经网络，低层级的网络提取图像边界等信息，高层级的网络识别物体类型等等。</p>
<p><img src="/images/20191125HierarchicalMode1.png" width="400"></p>
<p><center> 图 3 HTM分层示意图</center><br>目前，<strong>Numenta的HTM设计介绍讲解主要针对一个区域，即一层（图3，如黄色层），说明其数据输入方式，数据表征方式，神经元激活，以及时间记忆表示方式</strong>。HTM大概的原理是，首先将输入的数据编码为0、1稀疏数组，将这些稀疏数组经过空间池化转换为稀疏分布表征（SDR），然后时序记忆，建立突触，存储信息，进行预测等。</p>
<h4 id="2-数据输入"><a href="#2-数据输入" class="headerlink" title="2, 数据输入"></a>2, 数据输入</h4><p>数据输入一般有数字，日期，温度等，将这些数据编码为01稀疏数组（bit数组）。这在计算机领域十分常见，如一个字符的ASCⅡ表示，使用8bit表示的。n个bit可以表示$2^n$容量（capacity）的信息，bit数组可以有许多运算，与或非与异或等等。</p>
<p><img src="/images/20191125featureRepresentation1.png" width="400"></p>
<p>在HTM里，稀疏的每一个1可能表示了一个信息。在通过稀疏bit数组的压缩存储（只存1的下标位置），可以表示非常多的数据信息了。</p>
<h4 id="3-空间池化Spatial-Pooler"><a href="#3-空间池化Spatial-Pooler" class="headerlink" title="3, 空间池化Spatial Pooler"></a>3, 空间池化Spatial Pooler</h4><h5 id="3-1-稀疏分布表征-SDR"><a href="#3-1-稀疏分布表征-SDR" class="headerlink" title="3.1 稀疏分布表征 SDR"></a>3.1 稀疏分布表征 SDR</h5><p>稀疏分布表征（SDR）是空间池化的结果，通俗来看有点像大脑的数据结构，我们先看看SDR的一些特性，如图。计算SDR的容量:</p>
<script type="math/tex; mode=display">
capacity = \left( \begin{array} { c } { n } \\ { w } \end{array} \right) = \frac { n! } { w! ( n - w )! } = C_n^w （组合数）</script><p>也就是说可以表示这么多的信息量。</p>
<p><img src="/images/20191125SDR_Define.png" width="400"></p>
<p>1，SDR的一些基本运算。overlap交集，两个SDR交起来，相同的激活的bit越多，表明这俩SDR越相似。判断俩SDR是否匹配，可以设置一定的阈值。当俩SDR overlap之后，交集bit  $&gt;=\theta$ (阈值)，则俩SDR匹配。</p>
<p>2，SDR的噪声容忍度（noise tolerant）强。在下图中，选取29%的比例翻转bit的值，对比两个SDR，重叠分数为30。当30大于等于$\theta=30$ 则匹配。意思是说如果俩SDR是原本一致，就算其中一个SDR不完全准确有噪声，则还是会匹配上的。当然也有可能确实两SDR不一致，但又因为噪声导致其匹配上了，这样的误报可能有，但是概率很低 $FP = 交集的基数 / 原始SDR的n w的组合数 $ </p>
<p><img src="/images/20191125NoiseTolerant.jpg" width="400"></p>
<h5 id="3-2-SDR的重叠集"><a href="#3-2-SDR的重叠集" class="headerlink" title="3.2 SDR的重叠集"></a>3.2 SDR的重叠集</h5><p>如果俩同样大小的SDR（即$n,w$ 分别相等），所有bit匹配，则匹配的SDR必然跟原SDR一模一样，就只有一个。那如果降低匹配阈值 $\theta$ ，当相同激活的bit数目为$\theta$时，可以有多少个SDR与原SDR相匹配呢？ 这是个排列组合问题。</p>
<script type="math/tex; mode=display">\left|\Omega(n, w, \theta)\right|=\left(\begin{array}{c}{w} \\ {\theta}\end{array}\right) \times\left(\begin{array}{l}{n-w} \\ {w-\theta}\end{array}\right)</script><p>相匹配的SDR，左边从原SDR里$w$里选出$\theta$个bit来激活，这是俩SDR相同激活的bit。右边从原SDR里没有激活的$n-w$ 个bit里选出 $w-\theta$ 来激活即可。若 $n=600, w=40, \theta = 39$，算一算可以有 $40 * 560$个不同的SDR与原SDR匹配，是不是很多呀。</p>
<p>这有个好处就是，SDR可以表示很多相似的信息，而且可以直接通过俩SDR的交集来判断是否相似，误报率也很低。</p>
<h5 id="3-3-SDR栈"><a href="#3-3-SDR栈" class="headerlink" title="3.3 SDR栈"></a>3.3 SDR栈</h5><p>随着时间序列值逐步产生，即SDR也逐步产生。我们模拟看到SDR进行匹配的过程。new SDR与栈里的SDRs匹配，看看之前是不是见到过。匹配的SDR会有很多重叠的bit。</p>
<p><img src="/images/20191204SDR_Stack.jpg" width="400"></p>
<p>为了加快计算，之前的所有SDR采用Union合并到一起进行匹配。其实由于$n$很大，错误匹配的概率还是很小的。</p>
<h4 id="5-时序记忆-Temporal-Memory"><a href="#5-时序记忆-Temporal-Memory" class="headerlink" title="5, 时序记忆 Temporal Memory"></a>5, 时序记忆 Temporal Memory</h4><h4 id="6-总结"><a href="#6-总结" class="headerlink" title="6, 总结"></a>6, 总结</h4><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p>1，<a href="https://www.bilibili.com/video/av35735228?from=search&amp;seid=7001690129614399170" target="_blank" rel="noopener">bilibili的翻译HTM school</a></p>
<p>2，<a href="https://numenta.org/htm-school/" target="_blank" rel="noopener">numenta的YouTube视频</a></p>
<p>3， Ahmad S, Lavin A, Purdy S, et al. Unsupervised real-time anomaly detection for streaming data[J]. Neurocomputing, 2017, 262: 134-147.</p>
]]></content>
      <categories>
        <category>AIOps</category>
      </categories>
      <tags>
        <tag>AIOps</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>[paper]2019/11/06AIOps: Real-World Challenges and Research Innovations</title>
    <url>/2019/11/06/paper-2019-11-06AIOps-Real-World-Challenges-and-Research-Innovations/</url>
    <content><![CDATA[<h3 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h3><p>论文名字：AIOps: Real-World Challenges and Research Innovations<br>引用：Dang Y, Lin Q, Huang P. AIOps: real-world challenges and research innovations[C]//Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings. IEEE Press, 2019: 4-5.</p><a id="more"></a>
<h3 id="AIOps定义"><a href="#AIOps定义" class="headerlink" title="AIOps定义"></a>AIOps定义</h3><p>智能运维的定义：通过AI与ML有效构建运维应用 AIOps is about empowering software and service engineers (e.g., developers, program managers, support engineers, site reliability engineers) to efficiently and effectively build and operate online services and applications at scale with artificial intelligence (AI) and machine learning (ML) techniques. </p>
<p>DevOps 连续开发部署应用（来源于 G. Kim, P. Debois, et al, “The DevOps Handbook: How to Create World- Class Agility, Reliability, and Security in Technology Organizations”, IT Revolution Press, Oct. 2016）</p>
<h3 id="AIOps的三个目标"><a href="#AIOps的三个目标" class="headerlink" title="AIOps的三个目标"></a>AIOps的三个目标</h3><p>1，服务智能化<br>及时观察多方面变化，质量下降，成本增加，工作量增加等，基于AIOps的服务还可以根据其历史行为，工作量模式和基础来预测其未来状态。根据状态自我调整，trigger self-adaption or auto-healing behaviors of a service, with low human intervention.</p>
<p>思考：要监控性能，监控反应时间，问题调整策略（自动化调整）</p>
<p>2，较高的客户满意度<br>具有内置智能的服务可以了解客户的使用行为，并采取积极的行动来提高客户满意度。 例如，服务可以自动向客户推荐调整建议，以使其获得最佳性能（例如，调整配置，冗余级别，资源分配）</p>
<p>思考：网络不好的话如何自动调整？</p>
<p>3，高工程生产率<br> 工程师和操作员免于繁琐的工作，例如（1）从各种来源手动收集信息以调查问题； （2）解决重复出现的问题。 工程师和操作人员还可以使用AI / ML技术来学习系统行为的模式，预测服务行为和客户活动的未来，以进行必要的体系结构更改和服务适应策略更改等。</p>
<h3 id="challenges"><a href="#challenges" class="headerlink" title="challenges"></a>challenges</h3><p>整体思考，充足理解系统<br>工程架构转变 the AIOps engineering principles should include data/label quality monitoring and assurances, continuous model-quality validation, and actionability of insights.<br>缺乏label，极端失衡，数量太少，噪声程度高等，监督或半监督模型<br>组件服务之间的复杂依存关系</p>
<p>思考：还有服务变更带来的问题，新学习吗？<br>实时数据大量产生，怎么利用?</p>
]]></content>
      <categories>
        <category>AIOps</category>
      </categories>
      <tags>
        <tag>AIOps</tag>
        <tag>论文综述</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu16配置GPU深度学习环境、CUDA、cuNDD等</title>
    <url>/2019/11/06/20181106ubuntu16%E9%85%8D%E7%BD%AEGPU%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E3%80%81CUDA%E3%80%81cuNDD%E7%AD%89/</url>
    <content><![CDATA[<h3 id="1、准备"><a href="#1、准备" class="headerlink" title="1、准备"></a>1、准备</h3><ol>
<li>请先看好各种软件的版本对应要求，这仨一定要对应好。<pre><code>  [Tensorflow不同版本要求与CUDA及CUDNN版本对应关系](https://blog.csdn.net/omodao1/article/details/83241074)
</code></pre></li>
<li><p>知道要下哪些版本了，就预先做好各种软件下载工作。<br> 首先下载好英伟达的驱动 <a href="https://www.nvidia.cn/Download/index.aspx?lang=cn" target="_blank" rel="noopener">NVIDIA驱动下载</a><br> 注意！！！下载好跟自己显卡对应的驱动。显卡的产品类型、系列那些如果之前已经装好了驱动，则可以通过命令 nvidia-smi查询到。没有装刚买来就自己查。<br><img src="https://img-blog.csdnimg.cn/20190519153242367.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="我的显卡驱动"><br>即使你的机器之前已经装过驱动，那也最好重新装一遍驱动，因为那个CUDA一定要对应起来。不然后面有坑！</p>
<p>下载CUDA，链接 <a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">cuda-toolkit-archive</a><br><img src="https://img-blog.csdnimg.cn/20190519154540803.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="下载CUDA9.0版本"><br>请注意这里一定要选择下载runfilw文件，不是deb！，不然会覆盖之前的显卡驱动带来问题。<br><img src="https://img-blog.csdnimg.cn/20190519154709423.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="对应操作系统下载CUDA"><br>最后下载cuDNN，<a href="https://developer.nvidia.com/rdp/cudnn-archive" target="_blank" rel="noopener">cuDNN下载地址</a>，我下的7.0.5版本<br><img src="https://img-blog.csdnimg.cn/20190519160003336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="cuDNN下载"></p>
<h3 id="2、安装驱动"><a href="#2、安装驱动" class="headerlink" title="2、安装驱动"></a>2、安装驱动</h3><h4 id="2-1、正常装驱动。"><a href="#2-1、正常装驱动。" class="headerlink" title="2.1、正常装驱动。"></a>2.1、正常装驱动。</h4><p>按ctrl+alt+f2（有的是f1）进入字符界面命令行，先删除以前的驱动：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get purge nvidia*</span><br><span class="line">sudo apt-get autoremove</span><br></pre></td></tr></table></figure>
<p>禁止自带的nouveau nvidia驱动：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 打开配置文件</span><br><span class="line">sudo vim /etc/modprobe.d/blacklist-nouveau.conf</span><br></pre></td></tr></table></figure>
<p>添加以下内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">blacklist nouveau</span><br><span class="line">options nouveau modeset=0</span><br></pre></td></tr></table></figure>
<p>再更新一下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo update-initramfs -u</span><br></pre></td></tr></table></figure>
<p>最后需要进行重启。查看下Nouveau是否已经禁止，无输出则为成功：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lsmod | grep nouveau</span><br></pre></td></tr></table></figure>
<p>按ctrl+alt+f2，接着关闭图形化界面：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo service lightdm stop</span><br></pre></td></tr></table></figure>
<p>然后准备开始装驱动了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo sh NVIDIA-Linux-x86_64-XXX.run  –-no-opengl-files</span><br></pre></td></tr></table></figure>
<p>然后重新打开图形界面：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo service lightdm start</span><br></pre></td></tr></table></figure>
<p>再ctrl+alt+f7进入图形界面，再测试下驱动是否装好：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>
<p>安装完成后，重启:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo reboot</span><br></pre></td></tr></table></figure>
<p>在命令行通过nvidia-smi还可以查看到驱动的话就没有问题了，以上皆为顺利的过程。</p>
</li>
</ol><a id="more"></a>
<h4 id="2-2、意外情况"><a href="#2-2、意外情况" class="headerlink" title="2.2、意外情况"></a>2.2、意外情况</h4><p>当然我装的时候是遇到了个大坑的。我看到之前机器上装好了驱动就没管，然后开始装后面的CUDA，结果下的CUDA又是deb的包，导致安装中覆盖了之前的驱动，然后ubuntu打开正确输入密码也无法进入桌面了。</p>
<h5 id="2-2-1-安装libelf-dev"><a href="#2-2-1-安装libelf-dev" class="headerlink" title="2.2.1 安装libelf-dev"></a>2.2.1 安装libelf-dev</h5><p>于是我又修复，倒回到2.1开始，清理驱动，重装。中间在执行sudo sh NVIDIA-Linux-x86_64-XXX.run  –-no-opengl-files的时候还遇到了build出错，如图：<br><img src="https://img-blog.csdnimg.cn/20190519162933827.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="驱动编译出错"><br>打开他提示的nvidia-installer.log看，里面提示了很多<br><img src="https://img-blog.csdnimg.cn/20190519163249938.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="问题提示"><br>这里还挺好的提示了请安装libelf-dev这种信息，于是我又去下载 <a href="https://pkgs.org/download/libelf-dev" target="_blank" rel="noopener">libelf-dex安装包</a>。本来我只下了1那个，然后输入命令安装：<br><img src="https://img-blog.csdnimg.cn/20190519163856594.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="libelf的版本"><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo dpkg -i libelf-dev_0.165-3ubuntu1_amd64.deb</span><br></pre></td></tr></table></figure><br>很无情的又报了个错，提示amd64 system is ….ubuntu1.1，于是我又下了2那个更新包，再dpkg安装。<br><img src="https://img-blog.csdnimg.cn/20190519164151594.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>终于顺利给装上了，没有报错了。</p>
<h5 id="2-2-2-gcc和g-版本问题"><a href="#2-2-2-gcc和g-版本问题" class="headerlink" title="2.2.2 gcc和g++版本问题"></a>2.2.2 gcc和g++版本问题</h5><p>前面的装好了，我又准备执行sudo sh NVIDIA-Linux-x86_64-XXX.run  –-no-opengl-files 来着，然而还有问题，又通过命令查看log信息，sudo vim nvidia-installer.log。<br><img src="https://img-blog.csdnimg.cn/20190519164725139.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="不识别Command line"><br>这个问题就是由于gcc和g++版本太低编译不过导致的，因为我看之前有个教程是将这个版本降低了方便CUDA编译来着。但其实我这是CUDA9.0，CUDA9要求GCC版本是5.x或者6.x，其他版本不可以，需要自己进行配置。我之前就是5.5的版本，就不该降级。好的现在再根据那篇博文给换回来。<br><a href="https://blog.csdn.net/u011784994/article/details/80080938" target="_blank" rel="noopener">ubuntu 16.04 LTS 降级安装gcc 4.8
</a></p>
<h5 id="2-2-3-装好驱动"><a href="#2-2-3-装好驱动" class="headerlink" title="2.2.3 装好驱动"></a>2.2.3 装好驱动</h5><p>在sh NVIDIA-Linux-x86_64-XXX.run安装就可以了，哎哟喂真是不容易啊。。。<br>然后我再重启，输入密码，终于可以进入桌面了呀，感动到哭。。。</p>
<h3 id="3、安装CUDA"><a href="#3、安装CUDA" class="headerlink" title="3、安装CUDA"></a>3、安装CUDA</h3><ol>
<li>安装CUDA<br>打开终端，执行命令，运行run文件：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo sh cuda_9.0.176_384.81_linux.run</span><br></pre></td></tr></table></figure>
注意提示，前面是一些法律信息啥的，enter过去就好。到后面提示是否安装图像驱动的时候，一定选择no ！！！<br><img src="https://img-blog.csdnimg.cn/20190519165519471.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_4,color_FFFFFF,t_70" alt="no Driver"><br>后面的一些提示选择y就行。出现下图，就表示安装完成。<br><img src="https://img-blog.csdnimg.cn/20190519165702507.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="CUDA安装"><br>如果出现其他问题，可能是某些依赖库没装好，反正我是没遇到。可以试试安装依赖，然后重启再试试。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler</span><br><span class="line">sudo apt-get install --no-install-recommends libboost-all-dev</span><br><span class="line">sudo apt-get install libopenblas-dev liblapack-dev libatlas-base-dev</span><br><span class="line">sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>配置环境变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo gedit ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>打开文件后在最后写入：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export PATH=/usr/local/cuda-9.0/bin$&#123;PATH:+:$&#123;PATH&#125;&#125;  </span><br><span class="line">export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>然后点save后关闭在source一下生效：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试一下CUDA是否安装成功</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 第一步，进入例子文件</span><br><span class="line">cd /usr/local/cuda-8.0/samples/1_Utilities/deviceQuery</span><br><span class="line"># 第二步，执行make命令</span><br><span class="line">sudo make</span><br><span class="line"># 第三步</span><br><span class="line">./deviceQuery</span><br></pre></td></tr></table></figure>
<p>有提示GPU信息，就表示可以了。</p>
</li>
</ol>
<h3 id="4、安装cuDNN"><a href="#4、安装cuDNN" class="headerlink" title="4、安装cuDNN"></a>4、安装cuDNN</h3><p>安装命令：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo dpkg -i libcudnn7_7.0.5.15-1+cuda9.0_amd64.deb</span><br><span class="line">sudo dpkg -i libcudnn7-dev_7.0.5.11-1+cuda9.0_amd64.deb</span><br><span class="line">sudo dpkg -i libcudnn7-doc_7.0.5.11-1+cuda9.0_amd64.deb</span><br></pre></td></tr></table></figure><br>安装完以后需要进行测试是否安装成功，出现了“Test passed! ”，这几步我都没啥问题：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp -r /usr/src/cudnn_samples_v7/ $HOME</span><br><span class="line">cd $HOME/cudnn_samples_v7/mnistCUDNN</span><br><span class="line">make clean &amp;&amp; make</span><br><span class="line">./mnistCUDNN</span><br></pre></td></tr></table></figure></p>
<h3 id="5、安装TensorFlow-gpu"><a href="#5、安装TensorFlow-gpu" class="headerlink" title="5、安装TensorFlow-gpu"></a>5、安装TensorFlow-gpu</h3><p>卸载以前的TensorFlow，我的python环境是3.6<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip3 uninstall tensorflow</span><br></pre></td></tr></table></figure><br>然后重新装gpu版本就可以，注意我要用的是TensorFlow-gpu1.7版本，这个跟前面的都是对应的！</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip3 -i https://pypi.tuna.tsinghua.edu.cn/simple/ install tensorflow-gpu==1.7.0</span><br></pre></td></tr></table></figure>
<p>跑程序的时候，自动就调用了gpu进行计算，学习起来快了6、7倍，真的是开心啊~</p>
<h3 id="6、总结"><a href="#6、总结" class="headerlink" title="6、总结"></a>6、总结</h3><ol>
<li>最关键的问题就是软件各个版本要对应好</li>
<li>注意先装驱动再CUDA再cuDNN，总之就是驱动要先搞好，不然就会有我那种意外。</li>
<li>CUDA一定下载runfile文件。</li>
</ol>
<h3 id="7、reference"><a href="#7、reference" class="headerlink" title="7、reference"></a>7、reference</h3><p><a href="https://blog.csdn.net/weixin_41863685/article/details/80303963" target="_blank" rel="noopener">Ubuntu18.04深度学习GPU环境配置</a><br>我进不了桌面，也连不了网，所以都是自己拿另外的电脑下了U盘弄过去的。<br><a href="https://blog.csdn.net/hhhhh89/article/details/54311161" target="_blank" rel="noopener">ubuntu中使用终端查看U盘里的内容</a><br><a href="https://blog.csdn.net/u011784994/article/details/80080938" target="_blank" rel="noopener">ubuntu 16.04 LTS 降级安装gcc 4.8</a><br><a href="https://blog.csdn.net/omodao1/article/details/83241074" target="_blank" rel="noopener">Tensorflow不同版本要求与CUDA及CUDNN版本对应关系</a><br>最后感谢各个外援~</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>配置</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>2019HUAWEI_DiGiX_CTR</title>
    <url>/2019/07/20/20190810HUAWEI-DiGiX-CTR/</url>
    <content><![CDATA[<h3 id="1-赛题介绍"><a href="#1-赛题介绍" class="headerlink" title="1 赛题介绍"></a>1 赛题介绍</h3><p>7月HUAWEI-DIGIX比赛是广告CTR预估问题。 数据如下：</p><div class="table-container">
<table>
<thead>
<tr>
<th>train.zip</th>
<th>zip（2.62GB）</th>
<th>2019-05-18 00:00:00</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>test.zip</td>
<td>zip（15MB）</td>
<td>2019-05-18 00:00:00</td>
<td></td>
</tr>
<tr>
<td>user_info.zip</td>
<td>zip（291MB）</td>
<td>2019-05-18 00:00:00</td>
<td></td>
</tr>
<tr>
<td>ad_info.zip</td>
<td>zip（17.9KB）</td>
<td>2019-05-18 00:00:00</td>
<td></td>
</tr>
<tr>
<td>content_info.zip</td>
<td>zip（8.16KB）</td>
<td>2019-05-18 00:00:00</td>
</tr>
</tbody>
</table>
</div><a id="more"></a>

<p> 时间范围是某连续6天的行为数据。总体而言，数据集包含： 训练集数据文件、测试集数据文件、用户特征文件、广告任务特征文件、素材信息数据文件。train表和test表里的字段：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>label</th>
<th>是否点击，1表示点击，0表示未点击</th>
</tr>
</thead>
<tbody>
<tr>
<td>uId</td>
<td>匿名化处理后的用户唯一标识(示例：u100000001)</td>
</tr>
<tr>
<td>adId</td>
<td>广告任务唯一标识</td>
</tr>
<tr>
<td>operTime</td>
<td>操作时间(精确到毫秒，示例: “2019-04-01 10:45:20:257”)</td>
</tr>
<tr>
<td>siteId</td>
<td>媒体Id</td>
</tr>
<tr>
<td>slotId</td>
<td>广告位Id</td>
</tr>
<tr>
<td>contentId</td>
<td>素材Id</td>
</tr>
<tr>
<td>netType</td>
<td>网络连接类型(示例：1, 2, 3, 4, 5, 6)</td>
</tr>
</tbody>
</table>
</div>
<p>user_info表</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>uId</th>
<th>匿名化处理后的用户唯一标识(示例：u100000001)</th>
</tr>
</thead>
<tbody>
<tr>
<td>age</td>
<td>年龄段(示例：1, 2, 3, 4, 5, 6)</td>
</tr>
<tr>
<td>gender</td>
<td>性别(示例：1, 2, 3)</td>
</tr>
<tr>
<td>city</td>
<td>常住城市编码(示例：1, 2, 3…)</td>
</tr>
<tr>
<td>province</td>
<td>常驻省份编码(示例：1, 2, 3…)</td>
</tr>
<tr>
<td>phoneType</td>
<td>设备型号(示例：1, 2, 3…)</td>
</tr>
<tr>
<td>carrier</td>
<td>运营商编号</td>
</tr>
</tbody>
</table>
</div>
<p> 广告任务特征文件ad_info.csv：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>adId</th>
<th>广告任务唯一标识(示例：2556)</th>
</tr>
</thead>
<tbody>
<tr>
<td>billId</td>
<td>计费类型(示例：cpc, cpm, cpd)</td>
</tr>
<tr>
<td>primId</td>
<td>广告主唯一编号Id</td>
</tr>
<tr>
<td>creativeType</td>
<td>创意类型(示例：1. 文字广告，2. 图片广告，3. 图文广告，4. gif广告，5. 无具体创意类型)</td>
</tr>
<tr>
<td>intertype</td>
<td>交互类型(示例：0. 无交互，点击无响应，1. 点击后打开网，2. 点击下载应用，3. 点击后打开App)</td>
</tr>
<tr>
<td>spreadAppId</td>
<td>广告对应的appId</td>
</tr>
</tbody>
</table>
</div>
<p> 素材信息数据文件content_info.csv:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>contentId</th>
<th>素材唯一标识Id</th>
</tr>
</thead>
<tbody>
<tr>
<td>firstClass</td>
<td>素材内容文本的一级分类(示例：电商)</td>
</tr>
<tr>
<td>secondClass</td>
<td>素材内容文本的二级分类，多值使用‘#’分割</td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2 数据预处理"></a>2 数据预处理</h3><h4 id="2-1-分析数据"><a href="#2-1-分析数据" class="headerlink" title="2.1 分析数据"></a>2.1 分析数据</h4><h5 id="2-2-1-分布情况"><a href="#2-2-1-分布情况" class="headerlink" title="2.2.1 分布情况"></a>2.2.1 分布情况</h5><p>首先查看每个表里数据的分布情况。尤其注意训练集与测试集的分布情况。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pd.describe() # 查看计数，平均值、标准差，min max等值。</span><br></pre></td></tr></table></figure>
<p>有些特征取值频次低的考虑合并为其他类。</p>
<h5 id="2-2-2-可视化分析"><a href="#2-2-2-可视化分析" class="headerlink" title="2.2.2 可视化分析"></a>2.2.2 可视化分析</h5><p>对 Numerical Variable，可以用 Box Plot / 小提琴 来直观地查看它的分布。Categories Variable 用直方图。对于坐标类数据，可以用 Scatter Plot 来查看它们的分布趋势和是否有离群点的存在。（seaborn画图）</p>
<p>绘制变量之间两两的分布和相关度图表等，发现一些高相关和共线性的特征。</p>
<p>这些分析都有利于后续构造特征。</p>
<h4 id="2-2-数据处理"><a href="#2-2-数据处理" class="headerlink" title="2.2 数据处理"></a>2.2 数据处理</h4><p>1，缺失值处理</p>
<p>可以填补，丢弃等。</p>
<p>我在比赛中对content的firstclass和secondcalss根据spreadApp进行补全，因为广告类型可能会跟广告出现在哪类app有关系。 取出spreadApp相同的firstClass众数替换了少量缺失值。</p>
<p>2，异常值处理</p>
<p>比赛中，遇到了那种机器人用户，连续不停点击。这种数据应该在训练时过滤掉，在最后的提交结果也应该用规则处理下。</p>
<p>另外可以考虑分箱、均值、中位数、众数处理异常值缺失值等。</p>
<p>3，归一化和one hot的问题</p>
<p>SVM、LR模型等常常需要考虑归一化和one hot（dummy）的问题。</p>
<p>4，划分数据集</p>
<p>然后采用k折交叉验证。当线下的验证集和线上的测试集有同步的效果时最好，此时可以通过线下的验证集变化来验证线上情况。</p>
<p>比赛中我没有做到。但是后面问了大佬，做法是把训练集里的有点击广告行为的用户数据抽取出来作为的训练集。</p>
<h3 id="3-特征工程"><a href="#3-特征工程" class="headerlink" title="3 特征工程"></a>3 特征工程</h3><p>1，特征工程是最重要的。我们其实尝试用过自动特征工程，有一个featuretools，但这个做的所有统计特征都比较偏向数值类型的特征。做类别特征不太强。所以后面还是自己做特征。总的来说，我们应该生成尽量多的 Feature，相信 Model 能够挑出最有用的 Feature。</p>
<p>交叉特征：把俩取值连接起来，然后将str转换为数值。</p>
<p>俩俩特征之间的统计特征：比如用户看那些类别的广告数目，用户看广告主的次数等等。还有三个特征之间的统计特征。</p>
<p>还有就是word2ve的用户id和广告id序列特征（但这个效果不太好）。</p>
<p>2，筛选特征：</p>
<p>Random Forest 训练完以后得到的 Feature Importance。</p>
<p>也可以进行一些统计检验，卡方检验等。</p>
<p>直接观察CTR。比如特征对应的CTR数目。</p>
<h3 id="4-模型"><a href="#4-模型" class="headerlink" title="4 模型"></a>4 模型</h3><p>采用了lightGBM树模型。优点：基于直方图的树结点划分，内存消耗更少速度更快。lightGBM的论文阅读见博客。</p>
<p>注意一些模型选择：</p>
<ul>
<li><p>对于稀疏型特征（如文本特征，One-hot的ID类特征），我们一般使用线性模型，比如 Linear Regression 或者 Logistic Regression。Random Forest 和 GBDT 等树模型不太适用于稀疏的特征，但可以先对特征进行降维（如PCA，SVD/LSA等），再使用这些特征。稀疏特征直接输入 DNN 会导致网络 weight 较多，不利于优化，也可以考虑先降维，或者对 ID 类特征使用 Embedding 的方式；</p>
</li>
<li><p>对于稠密型特征，推荐使用 XGBoost 进行建模，简单易用效果好；</p>
</li>
<li>数据中既有稀疏特征，又有稠密特征，可以考虑使用线性模型对稀疏特征进行建模，将其输出与稠密特征一起再输入 XGBoost/DNN 建模。</li>
</ul>
<p>最后理论是要用“好而不同”的模型进行集成的，不过作为基模型lightGBM初期就够用了。</p>
<h3 id="5-学习"><a href="#5-学习" class="headerlink" title="5 学习"></a>5 学习</h3><p>大佬们的特征工程：</p>
<p>统计特征：当天广告曝光次数，当天用户曝光次数，当天广告主ID相对用户出现的次数，当天广告位相对用户出现的次数。</p>
<p>unique特征，用户相对广告的唯一ID，广告相对用户的唯一ID。</p>
<p>Ratio点击率特征：一维二维的点击率特征。</p>
<p>低频数据：置None，lightGBM对NULL数据处理友好。</p>
<p>序列数据：deepwalk或word2vec方法（Uid和广告id）</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，seaborn 可视化 <a href="http://seaborn.pydata.org/tutorial.html" target="_blank" rel="noopener">http://seaborn.pydata.org/tutorial.html</a></p>
<p>2，个人印象笔记《复赛答辩学习》</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>华为比赛</tag>
      </tags>
  </entry>
  <entry>
    <title>20190707《明朝那些事1》明朝的建立</title>
    <url>/2019/07/07/20190707%E3%80%8A%E6%98%8E%E6%9C%9D%E9%82%A3%E4%BA%9B%E4%BA%8B1%E3%80%8B%E6%98%8E%E6%9C%9D%E7%9A%84%E5%BB%BA%E7%AB%8B/</url>
    <content><![CDATA[<h3 id="一、序言"><a href="#一、序言" class="headerlink" title="一、序言"></a>一、序言</h3><p>以前我小觑了明朝，看完此书方知其宏伟恢弘。一个持久了两三百年的王朝，中间既有繁荣、胜利、正气；亦有凋敝、惨败与阴邪。历史有趣的就是在这来来回回的博弈中，道义精神的永不磨灭，历史规律的永恒不变。在此，我存着对历史的温情与敬意，以人物性格的角度，记录二三。</p><h3 id="二、人物"><a href="#二、人物" class="headerlink" title="二、人物"></a>二、人物</h3><p>明太祖朱元璋，最初本是穷苦人家的放牛娃。为生计所迫曾辗转为和尚，后来饥荒和压迫，最终他连和尚也做不成了，云游了几年加入了红巾军。在农民军里，他是一个很突出的人，不但作战勇敢，而且很有计谋，处事冷静，思虑深远，还很讲义气，有危险的时候第一个上，这一切都让他有了崇高的威信。</p><a id="more"></a>

<p><strong>将军——统率之人，必有更多素质要求。其中战略、远见、理想、勇气、气量等等皆不可缺。</strong></p>
<p>后续，朱元璋大败陈友谅、消灭张士诚，这些都是很精彩的战役。他不仅个人强，周边的人也都很强。他有贤内助妻子马皇后；身边大将如云、徐达、常遇春、李文忠、冯胜、朱文正、耿炳文、参谋刘基、李善长等等，我仅选部分介绍，详细的还是看书吧。</p>
<p>陈友谅，敢作敢当，但心黑手狠，胆大妄为，不重义气、背信弃义、骄横暴力。最终被诱敌深入的伏击给干掉了。巧的是那场鄱阳湖决战真的很像赤壁之战，果真历史来回重现。</p>
<p>张士诚，有勇气、意志坚强、却无大志，但他的的确确是个大好人。他待人宽大，免除了江浙一带的赋税。但他的过于宽大和无主见也使得他无法成为枭雄，而只能做一个豪杰。乱世中小富即安的思想可是不够生存的，在这种历史的淘汰赛里，只有胜负。</p>
<p>此处引用下朱元璋的战略分析，果真知人知彼啊，所以最后的赢家是朱元璋。</p>
<blockquote>
<p>张士诚的特点是器小，陈友谅的特点是志骄；器小无远见，志骄好生事。如果我进攻陈友谅，张士诚必然不会救他；而进攻张士诚，陈友谅就一定会动员全国兵力来救，我就要两线作战，到时就很难说了。</p>
</blockquote>
<p>马皇后，一心一意对待朱元璋，贤良仁德。在朱元璋称帝后乱杀大臣，马皇后“刀下留人”救了众多开国功臣。在教育子女上，也是要求他们生活简朴、用功读书。</p>
<p><strong>这样的女子不知道为朱元璋笼络了多少人心、培养了多少子女人才啊。</strong></p>
<p>常遇春，先锋大将，冷静观察形势，勇猛敢站，擅长骑兵突破，但却嗜好杀戮。后来常遇春主动向陈友谅挑事，活埋了降兵三千，带来了很多麻烦。</p>
<p><strong>可见，一个人的缺陷会很有可能导致大问题出现。</strong></p>
<p>徐达、善谋略、身先士卒、令出无二、为人谨慎，刚毅武勇，持重有谋，纪律严明，屡统大军，转战南北，治军严整，功高不矜，名列功臣第一。他是大破元军的关键人物，他也是活到最后的人之一了。</p>
<p>朱文正，善防守、排兵布阵。有军事才能，却不懂为人，性格乖张，心胸狭隘，最后竟然因为分攻奖赏不满而勾结张士诚，最终被囚禁。</p>
<p>刘基，神机军事，年少好学，运筹帷幄，准确判断。陈友谅进攻，其他人都在建议撤退之时，只有他在坚持，并且提出了诱敌伏击的策略。在多次战役中，他的判断甚至比朱元璋的判断还要准确。“三分天下诸葛亮，一统江山刘伯温”，在我看来他甚至比诸葛亮的成就还要高呢。不过，可惜最终死于政治斗争中。</p>
<p><strong>学习和实践从来都是成为一个有所建树的人的前提条件。</strong></p>
<h3 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h3><p>最后引用下原文对优秀将领成长过程的总结：</p>
<blockquote>
<p>第一个年级要学习的是军事理论。所有想成为名将的人，必须要学习一些经典的理论知识，包括《孙子兵法》《吴子兵法》等等。<br>第二个年级学习的内容是实战。这是极为重要的，那些理论学习的优秀者如果不能过这一关，他们就将被授予一个光荣的称号——纸上谈兵。<br>三年级要学习的是冷酷。 成为一个名将，就必须和仁慈、温和之类的名词说再见。他必须心如铁石、冷酷无情。<br>四年级要学习的是理智。<br>五年级学习判断，准确判断并决策。<br>六年级学习坚强，那些最优秀的人能够从失败中爬起来，去挑战那个多次战胜自己的人，这就叫做坚强。</p>
</blockquote>
<p>明朝的建立，经历了好几场大战。战场千变万化，胜者的智慧，败者的教训都是值得学习借鉴的。毕竟从人性、历史规律上看，一切都还是有章可循的。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>历史</tag>
      </tags>
  </entry>
  <entry>
    <title>20190507paper the Numenta Anomaly Benchmark</title>
    <url>/2019/05/07/20190507paper-the-Numenta-Anomaly-Benchmark/</url>
    <content><![CDATA[<h3 id="1-ABS-amp-Introduction"><a href="#1-ABS-amp-Introduction" class="headerlink" title="1 ABS &amp; Introduction"></a>1 ABS &amp; Introduction</h3><h4 id="1-1-Abstract"><a href="#1-1-Abstract" class="headerlink" title="1.1 Abstract"></a>1.1 Abstract</h4><p>对象：streams, time-series data, sequence</p><p>异常检测难点：real-time processing</p><p>NAB是一个测试评估针对流数据的异常检测算法的开源工具。</p><p>理想的异常检测器 </p><ol>
<li><p>检测到所有出现的异常 </p>
</li>
<li><p>尽早检测出异常，最好在人们看到异常之前 </p>
</li>
<li><p>no FP 不误报 </p>
</li>
<li><p>实时检测、没有前瞻（不看前面的数据） </p>
</li>
<li><p>自动化检测、无人工调节</p>
</li>
<li>适用性广泛，具有泛化性</li>
</ol><a id="more"></a>




<h4 id="1-2-Intro"><a href="#1-2-Intro" class="headerlink" title="1.2 Intro"></a>1.2 Intro</h4><p>静态基准不适合用于实时性算法。Precision和Recall无法反应出早检测这个效果。人工划分训练集测试集不适合流场景。NAB设计了新的评价标准，整合了各类数据集。其他数据集还有the UC- Irvine dataset ，Yahoo Labs。本论文比较了HTM、Skyline、与Twitter的两种方法<a href="https://blog.twitter.com/engineering/en_us/a/2015/introducing-practical-and-robust-anomaly-detection-in-a-time-series.html" target="_blank" rel="noopener">Twitter 方法，翻</a> （AnomalyDetectionTs and AnomalyDetectionVec. ）。</p>
<h3 id="2，NAB-scoring"><a href="#2，NAB-scoring" class="headerlink" title="2，NAB scoring"></a>2，NAB scoring</h3><h4 id="2-1-基础"><a href="#2-1-基础" class="headerlink" title="2.1 基础"></a>2.1 基础</h4><p>异常定义：We define anomalies in a data stream to be patterns that do not conform to past patterns of behavior for the stream. 包括空间异常和时间异常。</p>
<p><img src="/images/20191210anomaly.jpg" alt="20191210anomaly"></p>
<p>Dataset：范围从IT指标（例如网络利用率）到工业机器上的传感器再到社交媒体聊天。我们还包括一些人工生成的数据文件，用于测试尚未在语料库的真实数据中表示的异常行为，以及几个没有任何异常的数据文件。当前的NAB数据集包含58个数据文件，每个文件具有1000-22,000个数据实例（github里有）</p>
<p>标记异常：按一定规则，标记ground truth label</p>
<h4 id="2-2-算法"><a href="#2-2-算法" class="headerlink" title="2.2 算法"></a>2.2 算法</h4><p>算法核心三个方面：anomaly Window，the scoring function，application Profiles（配置文件）</p>
<h5 id="2-2-1-异常窗口"><a href="#2-2-1-异常窗口" class="headerlink" title="2.2.1 异常窗口"></a>2.2.1 异常窗口</h5><p>异常窗口是代表一系列以真实异常标签（ a ground truth anomaly label ）为中心的数据点。</p>
<p>异常窗口的作用是判断真假检测，检测在窗外的话是FP。</p>
<p>评分函数基于窗口识别、加权TP，FP，FN。前面紫色部分只用来初始学习，不需测试。</p>
<p>1，窗口内最早的TP检测被计分，其他忽略。</p>
<p>2，sigmoidal scoring function 给早检测的TP高分。给FP负分数。</p>
<p>3，窗口大小 = 10%*总数据长度/异常数量。实验测试了5% - 20%，由于缩放评分函数，这个百分比对最后结果不敏感。</p>
<p><img src="/images/20191210AnomalyWindow.jpg" alt="20191210AnomalyWindow"></p>
<p>application profile配置：FN对工业机器来说会造成损失，FP要求技术人员查看。（对监视数据中心中各个服务器状态的应用程序可能对误报的数量敏感，并且由于大多数服务器群集都相对容错，因此偶尔会遗漏异常情况很好。）因此配置文件用于：对于TP，FP，FN和TN，NAB应用与每个配置文件相关的不同相对权重以获得每个配置文件的单独分数。</p>
<h5 id="2-2-2-计算过程"><a href="#2-2-2-计算过程" class="headerlink" title="2.2.2 计算过程"></a>2.2.2 计算过程</h5><p>1，配置权重$A$</p>
<script type="math/tex; mode=display">A_{T P}, A_{F P}, A_{F N}, A_{T N}, 0 \leq A_{TP},A_{TN} \leq 1, -1 \leq A_{FP},A_{FN} \leq 0</script><p>$D$ 是数据集，$Y_d$是数据 $d$ 中被检测出来的异常。$f_d$表示没有检测到任何异常的窗口数量，</p>
<p><img src="/images/20191210NABScoring.jpg" alt="20191210NABScoring"></p>
<p>2，单个窗口的得分计算</p>
<p>图中TP：早检测则，增加NAB score；点2：早检测的TP，贡献+0.999 。</p>
<p>FP：减分（窗外后面的FP的减分更大）；点1：FP，贡献-1，点4：权重为-0.8093是根据$\sigma^{A}(y)$得到的。5：5更有害，因此5贡献-1。</p>
<p>FN：完全没有检测到，减分。</p>
<p>总的来看这个窗口的得分就是：$−1.0A_{FP} + 0.9999A_{TP} −0.8093A_{FP} − 1.0A_{FP} $ ，公式是：</p>
<script type="math/tex; mode=display">\sigma^{A}(y)=\left(A_{T P}-A_{F P}\right)\left(\frac{1}{1+e^{5 y}}\right)-1</script><p>$\sigma^{A}(y)$中，y表示是检测在异常检测窗的相对位置，参数被设置为窗口右侧，$\sigma ( y = 0.0 ) = 0$。 </p>
<p>3，一个数据文件的得分计算</p>
<p>得分是每个检测的得分+错过的Window</p>
<script type="math/tex; mode=display">S_{d}^{A}=\left(\sum_{y \in Y_{d}} \sigma^{A}(y)\right)+A_{F N} f_{d}</script><p>4，一个异常检测算法对所有数据集的得分</p>
<script type="math/tex; mode=display">S ^ { A } = \sum _ { d \in D } S _ { d } ^ { A }</script><p>5，归一化这个算法的分数，normalized NAB score</p>
<script type="math/tex; mode=display">S _ { N A B } ^ { A } = 100 \cdot \frac { S ^ { A } - S _ { \text {null} } ^ { A } } { S _ { \text {perfect} } ^ { A } - S _ { \text {null} } ^ { A } }</script><p>完美检测器检测到所有TP，无FP。NULL检测器就是没有检测到任何异常。</p>
<h5 id="2-2-3-其他"><a href="#2-2-3-其他" class="headerlink" title="2.2.3 其他"></a>2.2.3 其他</h5><p>HTM算法，Skyline统计算法，Twitter统计算法等</p>
<p>每个异常检测器输出是0-1之间的分数，使用固定阈值对分数进行阈值处理，以检测异常。 NAB包括自动爬坡搜索，用于为每种算法选择最佳阈值。其中要最大化的目标函数是NAB评分函数。一个阈值针对所有的数据集dataset（The detection threshold is thus tuned based on the full NAB dataset）。</p>
<h3 id="3-result"><a href="#3-result" class="headerlink" title="3 result"></a>3 result</h3><p>见github首页</p>
<p>一些小结论</p>
<p>1，HTM和Skyline对漂移适应得更快</p>
<p>2，HTM和Skyline各自也有误报但HTM可以早检测（3h，机器温度传感器数据）</p>
<p>3，行为的时间变化通常先于容易检测到的大变化（做提前检测）。 </p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，Lavin A, Ahmad S. Evaluating Real-Time Anomaly Detection Algorithms—The Numenta Anomaly Benchmark[C]//2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA). IEEE, 2015: 38-44.</p>
<p>2, <a href="https://github.com/numenta/NAB" target="_blank" rel="noopener">https://github.com/numenta/NAB</a> 很好的学习项目</p>
]]></content>
      <categories>
        <category>AIOps</category>
      </categories>
      <tags>
        <tag>时间序列</tag>
        <tag>AIOps</tag>
      </tags>
  </entry>
  <entry>
    <title>装window、ubuntu双系统</title>
    <url>/2019/04/24/%E8%A3%85window%E3%80%81ubuntu%E5%8F%8C%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h2 id="装window10、ubuntu16-04双系统"><a href="#装window10、ubuntu16-04双系统" class="headerlink" title="装window10、ubuntu16.04双系统"></a>装window10、ubuntu16.04双系统</h2><p>周末趁空装了个双系统，记录记录过程吧。</p><h3 id="装windows10"><a href="#装windows10" class="headerlink" title="装windows10"></a>装windows10</h3><ol>
<li>首先下载好win10的系统镜像ISO文件，由于我不咋用win10就装了家庭版<br>链接: <a href="http://pan.baidu.com/s/1sj3JNRJ" target="_blank" rel="noopener">http://pan.baidu.com/s/1sj3JNRJ</a> 密码: z49r</li>
</ol><ol>
<li><p>准备好空的U盘，准备做系统启动盘。<br>下载安装好UltraISO，插入U盘。<br>点击打开，选择ISO文件<br>点击启动 - 写入硬盘映像<br>写入方式选择的是USB-HDD，USB-HDD+，一般默认就好<br>在点击写入，就等着他默默写好就好了<br><img src="https://img-blog.csdnimg.cn/20190422141325858.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_16,color_FFFFFF,t_70" alt="ULtraISO刻录系统启动盘"></p>
</li>
<li><p>制作好的系统启动U盘插入要装系统的电脑。开启电脑，一直按 F2或在F12等（这个键根据电脑确定，可以查查，但一般就是这个），进入电脑的Bios设置。<br>选择usb storage device，放到最前面，表示系统启动优先从USB开始。点击apply，再点exit。</p>
</li>
<li><p>之后电脑自动重启，然后进入windows10的安装。<br>默认简体中文，下一步<br>哪种类型的安装：选择自定义，以前windows的东西会变成windows.old<br>输入产品密钥那里跳过。<br>你想将windows安装在哪？ 选择分区，选择之前C盘所在分区位置。我这选择的是分区1，476G的盘。<br>后面就等着自己装就好了。</p>
</li>
<li><p>装完后注意，系统会重新启动。此时要拔掉U盘。产品密钥那个后面可以去找破解工具破解。暂时不管，然后设置用户密码进入就好。</p>
</li>
</ol><a id="more"></a>


<h3 id="装ubuntu16-04"><a href="#装ubuntu16-04" class="headerlink" title="装ubuntu16.04"></a>装ubuntu16.04</h3><ol>
<li>同理下载好U盘，将ubuntu的系统镜像刻录到U盘里。</li>
<li>设置好bios优先从U盘启动。</li>
<li>preparing to install Ubuntu: 这里可以选择第二项（Erase disk and install Ubuntu 单独装个Ubuntu系统）或者something else（我这装双系统，本来电脑里分区比较多，因此要选择之前从window划分出来的空闲空间）</li>
<li>挂载分区到根路径 / ,如果空间足够大，就只挂载这个，剩下的Ubuntu自己会分。如果不够，可以单独跟/home , /boot那些单独分。<br><img src="https://img-blog.csdnimg.cn/2019042409082143.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_16,color_FFFFFF,t_70" alt="挂载"></li>
<li>继续时区，创建用户，后面就会重启了。重启的时候，注意拔掉U盘。</li>
</ol>
]]></content>
      <categories>
        <category>配置</category>
      </categories>
      <tags>
        <tag>配置</tag>
        <tag>ubuntu</tag>
        <tag>装系统</tag>
      </tags>
  </entry>
  <entry>
    <title>20190408AnomalyDetectionBackground</title>
    <url>/2019/04/08/20190408AnomalyDetectionBackground/</url>
    <content><![CDATA[<h3 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h3><h4 id="1-1-企业背景"><a href="#1-1-企业背景" class="headerlink" title="1.1 企业背景"></a>1.1 企业背景</h4><p>分布式系统结构的广泛应用。具有高并发，低时延，高可靠性等特点，但同时由于需求的增长，其规模，复杂性和动态生成的数据也急剧增加，这使其可靠性降低。为了避免系统故障，因此异常检测故障预判很重要。</p><p>简单来说目前的一些应用痛点，也是我企业调研的结果：</p><p>1，测试人员时间有限，不能有效测试，全覆盖测试。系统BUG是难免的。</p><a id="more"></a>


<p>2，系统故障后排查困难，需要及时定位。</p>
<p>3，运维人员希望可以提前预测故障，越早越好，从而进行排查。</p>
<p>4，目前企业的监控数据是有的，如何利用起来对系统更好的运维。</p>
<h4 id="2-1-研究背景"><a href="#2-1-研究背景" class="headerlink" title="2.1 研究背景"></a>2.1 研究背景</h4><p>流数据的异常检测难点有：</p>
<p>1，流数据高速实时产生  ，传统的对整个数据集离线学习很难。</p>
<p>2，异常行为很少发生，异常检测器训练困难，难以学习对于重要的不平衡数据集的满意模型。</p>
<p>3，流数据的时变特性。两类异常，空间异常和上下文异常。概念漂移问题。</p>
<p>4，Precision与Recall之前的权衡问题。</p>
<p>5，不同的时序数据有不同属性。周期性，平稳性，非平稳性等等性质，对不同的方法有要求。</p>
<p>6，异常数据的标记很难得。</p>
<p>7，提前检测很重要，也很困难。</p>
<h4 id="2-2-智能运维背景"><a href="#2-2-智能运维背景" class="headerlink" title="2.2 智能运维背景"></a>2.2 智能运维背景</h4><p>于是Gartner首先推出了人工智能运算（AIOP，这个方向国内还有清华大学的裴丹老师），包括性能监视，异常检测和系统故障检测任务等。理想的智能运维具有以下能力：历史数据管理、流数据（即时序数据）管理、日志数据提取、网络数据提取、性能数据提取、文本数据提取、自动化模型的发现和预测、异常检测、根因分析、按需交付等  </p>
<blockquote>
<p>AIOps is the application of artificial intelligence for IT operations. It is the future of ITOps, combining algorithmic and human intelligence to provide full visibility into the state and performance of the IT systems that businesses rely on.</p>
</blockquote>
<p>性能监控里包括了对系统的CPU、memory，storage，网络，进程等资源使用的监控信息。通过对性能监控的时间序列进行异常检测，发现故障之前的征兆。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1, “Everything you need to know about AIOps”, from <a href="https://www.moogsoft.com/resources/aiops/guide/everything-aiops/" target="_blank" rel="noopener">https://www.moogsoft.com/resources/aiops/guide/everything-aiops/</a> (retrieved as of Feb. 12, 2019)</p>
]]></content>
      <categories>
        <category>AIOps</category>
      </categories>
      <tags>
        <tag>异常检测</tag>
        <tag>AIOps</tag>
      </tags>
  </entry>
  <entry>
    <title>PCL在Mac上环境问题</title>
    <url>/2019/03/27/20190327PCL%E5%9C%A8Mac%E4%B8%8A%E7%8E%AF%E5%A2%83%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="PCL库"><a href="#PCL库" class="headerlink" title="PCL库"></a>PCL库</h3><h6 id="1、安装过程参考官网，环境是Mac10-14-4，mojave"><a href="#1、安装过程参考官网，环境是Mac10-14-4，mojave" class="headerlink" title="1、安装过程参考官网，环境是Mac10.14.4，mojave"></a>1、安装过程参考官网，环境是Mac10.14.4，mojave</h6><p><a href="http://www.pointclouds.org/documentation/tutorials/installing_homebrew.php" target="_blank" rel="noopener">pcl install on Mac</a><br><code>brew install pcl</code> ，一直装就好了，我这里的版本是1.9.1_1</p><h6 id="2、使用xcode创建pcl工程"><a href="#2、使用xcode创建pcl工程" class="headerlink" title="2、使用xcode创建pcl工程"></a>2、使用xcode创建pcl工程</h6><p><a href="http://dragonwood-blastevil.blogspot.com/2013/02/install-pcl-and-first-project-in-xcode.html" target="_blank" rel="noopener">翻墙搜的pcl project in xcode</a><br>此处注意编译器的选择，Switch Compiler for C/C++/Objective-C from Apple LLVM compiler 4.2 -&gt; LLVM GCC 4.2，注意”Header Search Paths”的配置，链接里没有全部配置完全，项目要用到的库都应该加进去。</p><a id="more"></a>

<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTQyNjUxLThhYzQxZGFkYjIyNjA0MzEucG5n?x-oss-process=image/format,png" alt="工程配置"></p>
<p>然后注意还有添加Link binary with libraries，点击下面的加号，add other把lib文件夹里的都加进来，只要你用到boost库，其他库类似这样处理。<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTQyNjUxLTg1NzNiNjZmMThiYzdjNmEucG5n?x-oss-process=image/format,png" alt="lib库添加1"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTQyNjUxLTYzNDA3MDZhYTIyMGUyODAucG5n?x-oss-process=image/format,png" alt="lib库添加2"></p>
<h6 id="3、问题1：undifine-symbols-基本就是下面提示的库没有添加进去"><a href="#3、问题1：undifine-symbols-基本就是下面提示的库没有添加进去" class="headerlink" title="3、问题1：undifine symbols 基本就是下面提示的库没有添加进去"></a>3、问题1：undifine symbols 基本就是下面提示的库没有添加进去</h6><p><code>Undefined symbols for architecture x86_64: 
  &quot;boost::this_thread::interruption_point()</code><br><code>&quot;vtkSphereSource::New()&quot;, referenced from:
  vtkSmartPointer&lt;vtkSphereSource&gt;::New() in 4viewtest.o</code><br>一般这种报错就是因为上面的lib库没有加进去的原因。这个问题，我居然被困了半天，气死了。。。。</p>
<h6 id="4、由于我升级了Mac到mojave，出现问题Reason-image-not-found"><a href="#4、由于我升级了Mac到mojave，出现问题Reason-image-not-found" class="headerlink" title="4、由于我升级了Mac到mojave，出现问题Reason: image not found"></a>4、由于我升级了Mac到mojave，出现问题Reason: image not found</h6><p><code>dylid: Library not loaded: /opt/X11/lib/libglut.3.dylib
  Referenced from: /usr/local/opt/pcl/lib/libpcl_simulation_io.1.9.dylib
  Reason: image not found</code><br><a href="https://tex.stackexchange.com/questions/208001/cant-compile-image-after-upgrading-to-os-x-yosemite" target="_blank" rel="noopener">X11 is not erased but moved to /opt/X11</a><br>还要安装 <a href="http://xquartz.macosforge.org/landing" target="_blank" rel="noopener">installing the latest XQuartz</a><br>升级就是麻烦多，各位开发者别随便升级了</p>
]]></content>
      <categories>
        <category>配置</category>
      </categories>
      <tags>
        <tag>配置</tag>
        <tag>三维点云</tag>
      </tags>
  </entry>
  <entry>
    <title>EM算法</title>
    <url>/2018/12/28/20200104EM%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h3><p>EM算法是一种迭代算法，用于含有隐变量的概率模型参数的极大似然估计。 </p><p>E步：求期望；M步，求极大。 </p><h4 id="1-1-例子"><a href="#1-1-例子" class="headerlink" title="1.1 例子"></a>1.1 例子</h4><p>P176三硬币模型： </p><script type="math/tex; mode=display">p_{(y/\theta)}=\sum_{\mathcal{Z}} P(y, z | \theta)=\sum_{\mathcal{Z}} P(z | \theta) P(y | z, \theta)</script><a id="more"></a>


<script type="math/tex; mode=display">= \pi p^y(1-p)^{(1-y)} + (1-\pi)q^y (1-q)^{(1-y)}</script><p>y是观测变量，表示一次试验结果是1或0； </p>
<p>z（随机变量）是隐变量，表示未观测到的抛硬币A的结果 </p>
<p>$\theta = (\pi,p,q)$ 是模型参数。 </p>
<p>这个模型是以上数据的生成模型 </p>
<h4 id="1-2-模型"><a href="#1-2-模型" class="headerlink" title="1.2 模型"></a>1.2 模型</h4><p>观测数据是$Y=\left(Y_{1}, Y_{2}, \cdots, Y_{n}\right)^{\mathrm{T}}$，未观测数据表示为$Z=(Z_1,Z_2…Z_n)^{\mathrm{T}}$，则观测数据的似然函数是： </p>
<script type="math/tex; mode=display">P(Y | \theta)=\sum_{Z} P(Z | \theta) P(Y | Z, \theta)</script><p>即： </p>
<script type="math/tex; mode=display">P(Y | \theta)=\prod_{j=1}^{n}\left[\pi p^{y_{j}}(1-p)^{1-y_{j}}+(1-\pi) q^{y_{j}}(1-q)^{1-y_{j}}\right]</script><p>求模型参数 $\theta = (\pi,p,q)$的极大似然估计是： </p>
<script type="math/tex; mode=display">\hat{\theta} = argmax_{\theta} log(P(Y|\theta))</script><h4 id="1-3-迭代算法"><a href="#1-3-迭代算法" class="headerlink" title="1.3 迭代算法"></a>1.3 迭代算法</h4><p>这个问题只能通过迭代的方法求解，EM算法就是用于求解这个问题的一种迭代算法。 </p>
<p>1，选取参数的初值，记作 $\theta^0 = (\pi^0,p^0,q^0)$，然后迭代计算参数的估计值，直至收敛为止。第i次迭代的参数估计值是 $\theta^i = (\pi^i,p^i,q^i)$ </p>
<p>2, E步，计算在模型参数$\theta^i$下观测数据$y_i$来自硬币B的概率： </p>
<script type="math/tex; mode=display">\mu_{j}^{(i+1)}=\frac{\pi^{(i)}\left(p^{(i)}\right)^{y_{j}}\left(1-p^{(i)}\right)^{1-y_{j}}}{\pi^{(i)}\left(p^{(i)}\right)^{y_{j}}\left(1-p^{(i)}\right)^{1-y_{j}}+\left(1-\pi^{(i)}\right)\left(q^{(i)}\right)^{y_{j}}\left(1-q^{(i)}\right)^{1-y_{j}}}</script><p>M步计算模型参数的新估计值(n是独立重复n次实验)：</p>
<script type="math/tex; mode=display">\pi^{i+1} = \frac{1}{n}\sum_{j=1}^n \mu_j^{i+1}</script><script type="math/tex; mode=display">p^{(i+1)}=\frac{\sum_{j=1}^{n} \mu_{j}^{(i+1)} y_{j}}{\sum_{j=1}^{n} \mu_{j}^{(i+1)}}</script><script type="math/tex; mode=display">q^{(i+1)}=\frac{\sum_{j=1}^{n}\left(1-\mu_{j}^{(i+1)}\right) y_{j}}{\sum_{j=1}^{n}\left(1-\mu_{j}^{(i+1)}\right)}</script><p>P177的计算例子，不同的初值得到不同的参数估计值。</p>
<h3 id="2-EM算法"><a href="#2-EM算法" class="headerlink" title="2 EM算法"></a>2 EM算法</h3><p>Y表示观测随机变量的数据，Z表示隐随机变量的数据。Y和Z连到一起称为完全数据。不完全数据Y的似然函数是$P(Y|\theta)$，Y和Z的联合概率分布是$P(Y,Z|\theta)$，完全数据的对数似然函数是$logP(Y,Z|\theta)$，EM算法通过迭代求$L(\theta) = logP(Y|\theta)$</p>
<p>(1) 选择参数初始值$\theta^{(0)}$，开始迭代。</p>
<p>(2) <strong>E步</strong>，记$\theta^i$是第i次迭代参数$\theta$的估计值，在第i+1次迭代的E步，计算：</p>
<script type="math/tex; mode=display">Q\left(\theta, \theta^{(i)}\right)=E_{Z}\left[\log P(Y, Z | \theta) | Y, \theta^{(i)}\right] = \sum_{Z} \log P(Y, Z | \theta) P\left(Z | Y, \theta^{(i)}\right)</script><p>这离的$P(Z|Y,\theta^{(i)})$是在给定观测数据Y和当前参数估计$\theta^{(i)}$下隐变量数据Z的条件分布。</p>
<p>(3) <strong>M步</strong>，求使得$Q\left(\theta, \theta^{(i)}\right)$ 极大化的$\theta$，确定第i+1次迭代的参数估计值$\theta^{(i+1)}$。</p>
<script type="math/tex; mode=display">\theta^{(i+1)}=\arg \max _{\theta} Q\left(\theta, \theta^{(i)}\right)</script><p>(4) 重复2、3步直到收敛。Q函数是EM算法的核心。</p>
<p>EM算法也是要先假设数据分布的。EM算法就是当抽取得到的每个样本都不知道是从哪个分布来的时候，通过迭代计算的方法来近似实现对观测数据的极大似然估计。EM 算法解决这个的思路是使用启发式的迭代方法，既然我们无法直接求出模型分布参数，那么我们可以先猜想隐含参数（EM 算法的 E 步），接着基于观察数据和猜测的隐含参数一起来极大化对数似然，求解我们的模型参数（EM算法的M步)。</p>
<h3 id="3-Reference"><a href="#3-Reference" class="headerlink" title="3 Reference"></a>3 Reference</h3><p>1，<a href="https://zhuanlan.zhihu.com/p/36331115" target="_blank" rel="noopener">知乎 EM算法</a></p>
<p>2，《李航 统计学习方法》</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>集成学习</title>
    <url>/2018/12/25/20191225%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h3><p>集成学习（Ensemble learning）通过组合几种模型来提高机器学习的效果。构建并结合多个学习器，个体学习器要“好而不同”，一定的准确性/多样性。</p><h3 id="2-提升方法"><a href="#2-提升方法" class="headerlink" title="2 提升方法"></a>2 提升方法</h3><h4 id="2-1-提升方法之Adaboost"><a href="#2-1-提升方法之Adaboost" class="headerlink" title="2.1 提升方法之Adaboost"></a>2.1 提升方法之Adaboost</h4><p>一般过程：训练—基学习器—调整训练样本分布—重复得到更多基学习器 T个—将这T个基学习器加权结合。代表是Adaboost：提高那些被前一轮弱分类器分错的样本的权值。最后加权多数表决方法、加大分类误差率小的弱分类器的权值。属于序列集成。</p><a id="more"></a>

<p>算法（书P156）：</p>
<p>输入训练集$T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$，其中实例$x_{i} \in \mathcal{X}=\mathbf{R}^{n}$，$y_i \in \mathcal{Y} = \left\{ -1,+1 \right\}$</p>
<p>1，初始化训练数据的权值分布为均匀分布 。$w_{1i} = \frac{1}{N}$。</p>
<p>2，使用具有权值分布的$D_m$的训练数据集学习得到基分类器$G_{m}(x): \mathcal{X} \rightarrow\{-1,+1\}$。</p>
<p>3，计算$G_m(x)$在训练数据集上的分类误差率:</p>
<script type="math/tex; mode=display">e_{m}=\sum_{i=1}^{N} P\left(G_{m}\left(x_{i}\right) \neq y_{i}\right)=\sum_{i=1}^{N} w_{m i} I\left(G_{m}\left(x_{i}\right) \neq y_{i}\right)</script><p>计算得到$G_m(x)$的系数，它表示了$G_m(x)$在最终分类器中的重要性。他随$e_m$的减小而增大。</p>
<script type="math/tex; mode=display">\alpha_{m}=\frac{1}{2} \log \frac{1-e_{m}}{e_{m}}</script><p>在更新训练数据集的权值分布</p>
<script type="math/tex; mode=display">D_{m+1}=\left(w_{m+1,1}, \cdots, w_{m+1, i}, \cdots, w_{m+1, N}\right)</script><script type="math/tex; mode=display">w_{m+1, i}=\frac{w_{m i}}{Z_{m}} \exp \left(-\alpha_{m} y_{i} G_{m}\left(x_{i}\right)\right), \quad i=1,2, \cdots, N</script><p>其中$Z_m$是规范化因子：</p>
<script type="math/tex; mode=display">Z_{m}=\sum_{i=1}^{N} w_{m i} \exp \left(-\alpha_{m} y_{i} G_{m}\left(x_{i}\right)\right)</script><p>4，构建基分类器的线性组合 $f(x) = \sum_{m=1}^M  \alpha_m  G_m(x)$</p>
<p>得到最终分类器：</p>
<script type="math/tex; mode=display">G(x) = \operatorname{sign}\left(\sum_{m=1}^{M} \alpha_{m} G_{m}(x)\right)</script><h4 id="2-2-提升方法之提升树-Boosting"><a href="#2-2-提升方法之提升树-Boosting" class="headerlink" title="2.2 提升方法之提升树 Boosting"></a>2.2 提升方法之提升树 Boosting</h4><p>采用加法模型（基函数的线性组合，基函数为树的时候叫Boosting tree），前向分步算法。减小偏差。</p>
<h5 id="2-2-1-前向分步算法："><a href="#2-2-1-前向分步算法：" class="headerlink" title="2.2.1 前向分步算法："></a>2.2.1 前向分步算法：</h5><p>1，确定初始提升树$f_0(x) = 0$</p>
<p>2，第m步的模型是$f_m(x) = f_{m-1}(x) + T(x: \theta_m)$</p>
<p>这里需要通过经验风险极小化来确定下一棵决策树参数参数:</p>
<script type="math/tex; mode=display">\hat{\theta_m} = argmin_{\theta_m} \sum_{i=1}^N L(y_i, f_{m-1}(x_i) + T(x_i:\theta_m))</script><p>不同问题的提升树学习算法区别在于使用的损失函数不同。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>问题</th>
<th>学习算法</th>
</tr>
</thead>
<tbody>
<tr>
<td>回归树</td>
<td>平方误差（拟合残差）</td>
</tr>
<tr>
<td>分类问题</td>
<td>指数损失函数</td>
</tr>
<tr>
<td>一般决策问题</td>
<td>一般损失函数</td>
</tr>
</tbody>
</table>
</div>
<p>对于二分类问题，提升树算法只需将Adaboost算法中基本分类器限制为二分类树即可。</p>
<h5 id="2-2-2-回归问题的提升树，拟合残差"><a href="#2-2-2-回归问题的提升树，拟合残差" class="headerlink" title="2.2.2 回归问题的提升树，拟合残差"></a>2.2.2 回归问题的提升树，拟合残差</h5><p>1，初始化$f0(x)=0$</p>
<p>2，对m=1,2..M计算残差，N是样本数。当前模型拟合数据的残差。</p>
<script type="math/tex; mode=display">r_{mi} = y_i -f_{m-1}(x_i), i=1.2..N</script><p>拟合残差$r_{mi}$学习一个回归树$T(x: \theta_m)$。更新：</p>
<script type="math/tex; mode=display">f_m(x) = f_{m-1}(xi) + T(x: \theta_m)</script><p>3，得到回归问题提升树 </p>
<script type="math/tex; mode=display">f_M(x) = \sum_{m=1}^M T(x; \theta_m)</script><h5 id="2-2-3-一般决策问题GBDT"><a href="#2-2-3-一般决策问题GBDT" class="headerlink" title="2.2.3 一般决策问题GBDT"></a>2.2.3 一般决策问题GBDT</h5><p>一般损失函数：</p>
<p>梯度提升gradientBoosting （GBDT）：利用最速下降法的近似方法，关键是利用损失函数的负梯度在当前模型的值</p>
<script type="math/tex; mode=display">-\left[\frac{\partial L\left(y, f\left(x_{i}\right)\right)}{\partial f\left(x_{i}\right)}\right]_{f(x)=f_{m-1}(x)}</script><p>作为回归问题提升树算法中的残差的近似值，拟合一个回归树。</p>
<p>过程：</p>
<p>输入训练集$T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$，其中实例$x_{i} \in \mathcal{X} \subseteq \mathbf{R}^{n}, y_{i} \in \mathcal{Y} \subseteq \mathbf{R}$</p>
<p>输出回归树： $\hat{f(x)}$</p>
<p>(1) 初始化</p>
<script type="math/tex; mode=display">f_{0}(x)=\arg \min _{c} \sum_{i=1}^{N} L\left(y_{i}, c\right)</script><p>(2) 对m = 1,2…M</p>
<p>对 i = 1,2,…N 计算：</p>
<script type="math/tex; mode=display">r_{m i}=-\left[\frac{\partial L\left(y_{i}, f\left(x_{i}\right)\right)}{\partial f\left(x_{i}\right)}\right]_{f(x)=f_{m-1}(x)}</script><p>对$r_{mi}$ 拟合一个回归树。得到第m棵树的叶节点区域$R_{m j}, j=1,2, \cdots, J$</p>
<p>对 j = 1,2 …J 计算：</p>
<script type="math/tex; mode=display">c_{m j}=\arg \min _{c} \sum_{x_{i} \in R_{m j}} L\left(y_{i}, f_{m-1}\left(x_{i}\right)+c\right)</script><p>更新</p>
<script type="math/tex; mode=display">f_{m}(x)=f_{m-1}(x)+\sum_{j=1}^{J} c_{m j} I\left(x \in R_{m j}\right)</script><p>(3) 得到回归树</p>
<script type="math/tex; mode=display">\hat{f}(x)=f_{M}(x)=\sum_{m=1}^{M} \sum_{j=1}^{J} c_{m j} I\left(x \in R_{m j}\right)</script><h4 id="2-3-其他"><a href="#2-3-其他" class="headerlink" title="2.3 其他"></a>2.3 其他</h4><p>XGBoost：</p>
<p>经过优化的分布式梯度提升（Gradient Boosting）库，实现了并行方式的决策树提升(Tree Boosting)。XGBoost采用的是level（depth）-wise生长策略，如下所示，能够同时分裂同一层的叶子，从而进行多线程优化，不容易过拟合；但不加区分的对待同一层的叶子，带来了很多没必要的开销。</p>
<p>XGBoost使用的是pre-sorted算法，能够更精确的找到数据分隔点；XGBoost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。</p>
<p>XGBoost在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。</p>
<p><img src="/images/20191225Xgboost.jpg" alt="20191225Xgboost"></p>
<p>LightGBM：</p>
<p>LightGBM的设计思路主要是两点：1. 减小数据对内存的使用，保证单个机器在不牺牲速度的情况下，尽可能地用上更多的数据；2. 减小通信的代价，提升多机并行时的效率，实现在计算上的线性加速。</p>
<p>LightGBM采用leaf-wise生长策略，如Figure 2所示，每次从当前所有叶子中找到分裂增益最大（一般也是数据量最大）的一个叶子，然后分裂，如此循环；但会生长出比较深的决策树，产生过拟合。</p>
<p>LightGBM使用的是histogram算法，占用的内存更低，数据分隔的复杂度更低。</p>
<p><img src="/images/20191225LightGBM.jpg" alt="20191225LightGBM"></p>
<h3 id="3-Bagging"><a href="#3-Bagging" class="headerlink" title="3 Bagging"></a>3 Bagging</h3><h4 id="3-1-Bagging"><a href="#3-1-Bagging" class="headerlink" title="3.1 Bagging"></a>3.1 Bagging</h4><p>Bagging是有放回样本采样boostrap——产生互相有交叠的采样子集63.2% 。一般对分类任务使用简单投票法。剩下36.8%的数据可以用作验证集对泛化性能进行包外估计out-of-bag-estimate。</p>
<script type="math/tex; mode=display">f(x)=1 / M \sum_{m=1}^{M} f_{m}(x)</script><p>在不同样本集上训练不同的树，通常分类任务使用投票的方式集成，而回归任务通过平均的方式集成。减小方差。</p>
<h4 id="3-2-随机森林"><a href="#3-2-随机森林" class="headerlink" title="3.2 随机森林"></a>3.2 随机森林</h4><p>随机森林：样本采样+属性采样构建多棵决策树，最终决定结果。方差小，偏差也小。</p>
<h3 id="4-Stacking方法"><a href="#4-Stacking方法" class="headerlink" title="4 Stacking方法"></a>4 Stacking方法</h3><p>Stacking是通过一个元分类器或者元回归器来整合多个分类模型或回归模型的集成学习技术。基础模型利用整个训练集做训练，元模型将基础模型的特征作为特征进行训练。</p>
<p>其实就是先训练多个初级分类器，然后基于初级分类器对样本预测，将预测值作为新的训练集训练次级学习器。</p>
<p><img src="/images/20191225Stacking.jpg" alt="20191225Stacking"></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，李航《统计学习方法》</p>
<p>2，<a href="https://zhuanlan.zhihu.com/p/36161812" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/36161812</a> 集成学习</p>
<p>3， <a href="https://blog.csdn.net/v_JULY_v/article/details/81410574" target="_blank" rel="noopener">https://blog.csdn.net/v_JULY_v/article/details/81410574</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>朴素贝叶斯</title>
    <url>/2018/12/24/20191224%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
    <content><![CDATA[<h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h3><p>朴素贝叶斯法基于<u>贝叶斯定理</u>与<u>特征条件独立</u>假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入输出的联合概率分布（学习到生成数据的机制，是生成模型），然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出 $y$。</p><p>输入空间 $\mathcal{X} \subseteq \mathbf{R}^{n}$ 为n维向量的集合。</p><a id="more"></a>

<p>输出空间 $\mathcal{Y} = \left\{c_{1}, c_{2}, \cdots, c_{K}\right\}$</p>
<p>输入特征向量 $x$，输出类标记 $y$</p>
<p>随机向量$X$是定义在输入空间 $\mathcal{X}$，$Y$是定义在输出空间 $\mathcal{Y}$ 的随机变量。</p>
<p>训练数据集 $T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$ 由$P(X,Y)$ 独立同分布产生。</p>
<h4 id="1-1-学习"><a href="#1-1-学习" class="headerlink" title="1.1 学习"></a>1.1 学习</h4><p>朴素贝叶斯法先学习先验概率分布及条件概率分布。</p>
<p>先验概率分布：</p>
<script type="math/tex; mode=display">P(Y = c_k), k=1,2 \cdots K</script><p>条件概率分布：它有指数级数量的参数，基于条件独立性假设</p>
<script type="math/tex; mode=display">P\left(X=x | Y=c_{k}\right)=P\left(X^{(1)}=x^{(1)}, \cdots, X^{(n)}=x^{(n)} | Y=c_{k}\right), \quad k=1,2, \cdots, K</script><script type="math/tex; mode=display">=\prod_{j=1}^{n} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)</script><p>条件独立假设：用于分类的特征在类确定的条件下，都是属于条件独立的</p>
<h4 id="1-2-预测"><a href="#1-2-预测" class="headerlink" title="1.2 预测"></a>1.2 预测</h4><p>对给定的输入$x$，通过学习到的模型计算后验概率，最大的类作为预测结果。</p>
<p>后验概率计算根据的是贝叶斯定理：</p>
<script type="math/tex; mode=display">P\left(Y=c_{k} | X=x\right)=\frac{P\left(X=x | Y=c_{k}\right) P\left(Y=c_{k}\right)}{\sum_{k} P\left(X=x | Y=c_{k}\right) P\left(Y=c_{k}\right)}</script><p>将前面学习到的代入得：</p>
<script type="math/tex; mode=display">P\left(Y=c_{k} | X=x\right)=\frac{P\left(Y=c_{k}\right) \prod_{j}^n P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}{\sum_{k} P\left(Y=c_{k}\right) \prod_{j}^n P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}, \quad k=1,2, \cdots, K</script><p>！！！因此<strong>朴素贝叶斯分类器</strong>就是这样子了：</p>
<script type="math/tex; mode=display">y = f(x)=argmin_{c_k} \frac{P\left(Y=c_{k}\right) \prod_{j}^n P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}{\sum_{k} P\left(Y=c_{k}\right) \prod_{j}^n P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}, \quad k=1,2, \cdots, K</script><h4 id="1-3-后验概率最大化的含义"><a href="#1-3-后验概率最大化的含义" class="headerlink" title="1.3 后验概率最大化的含义"></a>1.3 后验概率最大化的含义</h4><p>将实例分到后验概率最大的类中，等价于期望风险最小化。</p>
<p>假设损失函数：</p>
<script type="math/tex; mode=display">L(Y, f(X))=\left\{\begin{array}{ll}{1,} & {Y \neq f(X)} \\ {0,} & {Y=f(X)}\end{array}\right.</script><p>期望风险函数:</p>
<script type="math/tex; mode=display">R_{\mathrm{exp}}(f)=E[L(Y, f(X))]</script><p>取条件期望</p>
<script type="math/tex; mode=display">R_{\exp }(f)=E_{X} \sum_{k=1}^{K}\left[L\left(c_{k}, f(X)\right)\right] P\left(c_{k} | X\right)</script><p>为了使得期望风险最小化，需要对$X = x$ 逐个极小化:</p>
<script type="math/tex; mode=display">f(x)=\arg \min _{y \in \mathcal{Y}} \sum_{k=1}^{K} L\left(c_{k}, y\right) P\left(c_{k} | X=x\right)</script><script type="math/tex; mode=display">= \arg \min _{y \in \mathcal{Y}} \sum_{k=1}^{K} P\left(y \neq c_{k} | X=x\right)</script><script type="math/tex; mode=display">= \arg \max _{y \in \mathcal{Y}} P\left(y=c_{k} | X=x\right)</script><h3 id="2-极大似然估计"><a href="#2-极大似然估计" class="headerlink" title="2 极大似然估计"></a>2 极大似然估计</h3><p>学习即估计先验概率分布与条件概率分布：</p>
<script type="math/tex; mode=display">P\left(Y=c_{k}\right)=\frac{\sum_{i=1}^{N} I\left(y_{i}=c_{k}\right)}{N}, \quad k=1,2, \cdots, K</script><p>设第$j$个特征$x^{(j)}$的可能取值的集合为 $\left\{a_{j 1}, a_{j 2}, \cdots, a_{j S_{j}}\right\}$，条件概率 $P\left(X^{(j)}=a_{j l} | Y = c_k )\right.$ 的极大似然估计是：</p>
<script type="math/tex; mode=display">P\left(X^{(j)}=a_{j l} | Y=c_{k}\right)=\frac{\sum_{i=1}^{N} I\left(x_{i}^{(j)}=a_{j l}, y_{i}=c_{k}\right)}{\sum_{i=1}^{N} I\left(y_{i}=c_{k}\right)}</script><script type="math/tex; mode=display">j=1,2, \cdots, n ; \quad l=1,2, \cdots, S_{j} ; \quad k=1,2, \cdots, K</script><h3 id="3-算法过程"><a href="#3-算法过程" class="headerlink" title="3 算法过程"></a>3 算法过程</h3><p>(1) 计算先验概率和条件概率（见2，极大似然估计部分）</p>
<p>(2) 对于给定实例 $x=\left(x^{(1)}, x^{(2)}, \cdots, x^{(n)}\right)^{\mathrm{T}}$计算，取最大值</p>
<script type="math/tex; mode=display">y = f(x)=argmin_{c_k} \frac{P\left(Y=c_{k}\right) \prod_{j}^n P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}{\sum_{k} P\left(Y=c_{k}\right) \prod_{j}^n P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}, \quad k=1,2, \cdots, K</script>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>感知机 &amp; KNN</title>
    <url>/2018/12/09/20191224%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8EKNN/</url>
    <content><![CDATA[<h3 id="1-感知机"><a href="#1-感知机" class="headerlink" title="1 感知机"></a>1 感知机</h3><h4 id="1-1-简介"><a href="#1-1-简介" class="headerlink" title="1.1 简介"></a>1.1 简介</h4><p>感知机是二分类<u>线性分类</u>模型，感知机对输入空间中将实例划分为正负两类的分离超平面，属于判别模型。使用基于误分类的损失函数，利用梯度下降法对损失函数进行最小化。</p><p>感知机：</p><script type="math/tex; mode=display">f(x)=\operatorname{sign}(w \cdot x+b)</script><script type="math/tex; mode=display">\operatorname{sign}(x)=\left\{\begin{array}{ll}{+1,} & {x \geqslant 0} \\ {-1,} & {x<0}\end{array}\right.</script><a id="more"></a>

<p><img src="/images/20181204InceptionMachine.jpg" alt="20181204InceptionMachine"></p>
<h4 id="1-2-学习策略"><a href="#1-2-学习策略" class="headerlink" title="1.2 学习策略"></a>1.2 学习策略</h4><p>损失函数的自然选择是误分类点的总数（但这样$w,b$不是连续可导函数，不易优化）</p>
<p>故采用误分类点到超平面$S$的总距离：</p>
<script type="math/tex; mode=display">\frac{1}{\|w\|}\left|w \cdot x_{0}+b\right|</script><p>由于对于一个误分类的数据$(x_i,y_i)$来说：</p>
<script type="math/tex; mode=display">-y_i(w \cdot x_i + b) > 0</script><p>因此感知机的损失函数是（忽略常数）：</p>
<script type="math/tex; mode=display">L(w, b)=-\sum_{x_{i} \in M} y_{i}\left(w \cdot x_{i}+b\right)</script><h4 id="1-3-随机梯度下降"><a href="#1-3-随机梯度下降" class="headerlink" title="1.3 随机梯度下降"></a>1.3 随机梯度下降</h4><p>一次随机选取一个误分类点使其梯度下降。</p>
<p>损失函数的梯度：</p>
<script type="math/tex; mode=display">\nabla_{w} L(w, b)=-\sum_{x_{i} \in M} y_{i} x_{i}</script><script type="math/tex; mode=display">\nabla_{b} L(w, b)=-\sum_{x_{i} \in M} y_{i}</script><p>选取一个误分类点$(x_i,y_i)$进行更新w，b。</p>
<script type="math/tex; mode=display">w = w + \alpha y_i x_i , b = b + \alpha y_i</script><h4 id="1-4-感知机算法过程"><a href="#1-4-感知机算法过程" class="headerlink" title="1.4 感知机算法过程"></a>1.4 感知机算法过程</h4><p>输入：训练数据集$T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$，其中$x_{i} \in \mathcal{X}=\mathbf{R}^{n}, y_i \in y=\{-1,+1\}, i=1,2, \cdots, N$ 。学习率 $\alpha$，</p>
<p>输出： 求解感知机模型 $f(x) = sign(w \cdot x + b)$</p>
<p>(1) 选取初值$w_0,b_0$</p>
<p>(2) 在训练数据中选取数据 $(x_i,y_i)$</p>
<p>(3) 如果$y_{i}\left(w \cdot x_{i}+b\right) \leqslant 0$ ，则 $w = w + \alpha y_i x_i, b = b + \alpha y_i$</p>
<h3 id="2-K近邻KNN"><a href="#2-K近邻KNN" class="headerlink" title="2 K近邻KNN"></a>2 K近邻KNN</h3><h4 id="2-1-简介"><a href="#2-1-简介" class="headerlink" title="2.1 简介"></a>2.1 简介</h4><p>KNN是一种基本的<u>分类</u>与回归方法。KNN法假设给定一个训练数据集，其中实例类别已定。分类时，对新的实例根据其K个最近邻的训练实例的类别，通过多数表决来预测。</p>
<p>基本要素：K值的选择，距离度量，分类决策规则</p>
<h4 id="2-2-K近邻法算法"><a href="#2-2-K近邻法算法" class="headerlink" title="2.2 K近邻法算法"></a>2.2 K近邻法算法</h4><p>输入：训练数据集$T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$，其中 $x_{i} \in \mathcal{X}=\mathbf{R}^{n}, y_i \in y=\{c_1,c_2,\cdot \cdot, c_k\}, i=1,2, \cdots, N$</p>
<p>输出：新实例 $x$ 所属的类别 $y$</p>
<p>(1) 根据给定的距离度量，在训练集中找出与x最临近的k个点，涵盖这k个点的x的邻域记作$N_k(x)$</p>
<p>(2) 在$N_k(x)$中根据分类决策规则（如多数表决）来判定x的类别y</p>
<script type="math/tex; mode=display">y=\arg \max _{c_{j}} \sum_{x_{i} \in N_{k}(x)} I\left(y_{i}=c_{j}\right), \quad i=1,2, \cdots, N ; j=1,2, \cdots, K</script><p>$I$是指示函数，当$y_i = c_j$ 时为1。</p>
<h4 id="2-3-距离度量"><a href="#2-3-距离度量" class="headerlink" title="2.3 距离度量"></a>2.3 距离度量</h4><p>距离是两个点相似度的反映。设特征空间$\mathcal{X}$是n维实数向量空间$\mathbf{R}^{n}$, </p>
<script type="math/tex; mode=display">x_{i}, x_{j} \in \mathcal{X}, x_{i}=\left(x_{i}^{(1)}, x_{i}^{(2)}, \cdots, x_{i}^{(n)}\right)^{\mathrm{T}}</script><script type="math/tex; mode=display">x_{j}=\left(x_{j}^{(1)}, x_{j}^{(2)}, \cdots, x_{j}^{(n)}\right)^{\mathrm{T}}</script><p>则P范数距离是：</p>
<script type="math/tex; mode=display">L_p(x_i,x_j) = ( \sum_{l=1}^n |x_i^{(l)} - x_j^{(l)}|^p)^{\frac{1}{p}}</script><p>p=1 曼哈顿距离，p=2 欧氏距离，p=$\infty$，是切比雪夫距离，各个坐标距离的最大值。</p>
<script type="math/tex; mode=display">L_{\infty}\left(x_{i}, x_{j}\right)=\max _{l}\left|x_{i}^{(l)}-x_{j}^{(l)}\right|</script><h4 id="2-4-K值的影响"><a href="#2-4-K值的影响" class="headerlink" title="2.4 K值的影响"></a>2.4 K值的影响</h4><p>1，k较小时，使用较小的邻域中的训练实例进行预测，“学习”的近似误差减小，但是估计误差增大。即预测结果对邻近点非常敏感，如果邻近的点是噪声则会预测出错（容易过拟合）。</p>
<h4 id="2-5-分类决策规则"><a href="#2-5-分类决策规则" class="headerlink" title="2.5 分类决策规则"></a>2.5 分类决策规则</h4><p>一般多数表决。误分类的概率是：</p>
<script type="math/tex; mode=display">P(Y \neq f(X))=1-P(Y=f(X))</script><p>则误分类率是：</p>
<script type="math/tex; mode=display">\frac{1}{k} \sum_{x_{i} \in N_{k}(x)} I\left(y_{i} \neq c_{j}\right)=1-\frac{1}{k} \sum_{x_{i} \in N_{k}(x)} I\left(y_{i}=c_{j}\right)</script><h4 id="2-6-k-d-tree"><a href="#2-6-k-d-tree" class="headerlink" title="2.6 k-d tree"></a>2.6 k-d tree</h4><p>为了提高k近邻的搜索效率。用特殊的结构存储训练数据，减少计算距离的次数。构造kd树相当于不断地用垂直于坐标轴的超平面将k维空间切分（递归），构成一系列的k维超矩形矩阵区域。（李航书P53）</p>
<p>搜索：首先找到包含目标点的叶节点，然后从该叶节点出发依次回退到父节点，不断查找与目标点最邻近的节点。当确定不存在更近的结点时终止。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，《统计学习方法》李航</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>SVM推导</title>
    <url>/2018/12/09/20191209SVM%E6%8E%A8%E5%AF%BC/</url>
    <content><![CDATA[<h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h3><p>标签：二分类模型，特征空间上的间隔最大的线性分类器，核技巧（非线性问题），求解凸二次规划问题。</p><p>三类：线性可分支持向量机与硬间隔最大化，线性支持向量机与软间隔最大化，非线性支持向量机与核函数。</p><h3 id="2-线性可分支持向量机"><a href="#2-线性可分支持向量机" class="headerlink" title="2 线性可分支持向量机"></a>2 线性可分支持向量机</h3><p>学习的目标是在特征空间中找出一个分离超平面，将实例分到不同的类。</p><script type="math/tex; mode=display">wx + b = 0</script><a id="more"></a>


<p>$w$代表法向量，指向的一般是正类；$b$是截距。</p>
<p>利用误分类最小的策略求得分离超平面。利用间隔最大化求最优分离超平面。</p>
<p>在超平面确定的情况下，$|wx+b|$能够相对表示点$x$距离超平面的远近，$y (wx+b)$的符号是否一致表示分类是否正确。</p>
<h4 id="2-1-函数间隔"><a href="#2-1-函数间隔" class="headerlink" title="2.1 函数间隔"></a>2.1 函数间隔</h4><p>1，函数间隔  $\hat{\gamma}_{i}=y_{i}\left(w \cdot x_{i}+b\right)$，超平面关于训练数据$T$ 的函数间隔 $\hat{\gamma}=\min _{i=1, \cdots, N} \hat{\gamma}_{i}$</p>
<p>函数间隔可以表示分类预测的正确性及确信度。</p>
<p>2，几何间隔：</p>
<p>对分离超平面的法向量 $w$加上某些约束，如规范化 $||w||=1$，使得间隔确定，这时函数间隔为<strong>几何间隔</strong>。</p>
<p>给定训练集$T$ 和超平面$(w,b)$，定义超平面关于样本点$(x_i,y_i)$的几何间隔是：</p>
<p><img src="/images/20191209margin.jpg" alt="20191209几何间隔"></p>
<script type="math/tex; mode=display">\gamma_{i}=y_{i}\left(\frac{w}{\|w\|} \cdot x_{i}+\frac{b}{\|w\|}\right)</script><h4 id="2-2-间隔最大化"><a href="#2-2-间隔最大化" class="headerlink" title="2.2 间隔最大化"></a>2.2 间隔最大化</h4><p>1，SVM基本思想</p>
<p>求解能够正确划分训练数据集并且几何间隔最大的分离超平面。</p>
<script type="math/tex; mode=display">\max _{w, b} \frac{\hat{\gamma}}{\|w\|}</script><script type="math/tex; mode=display">\text { s.t. } \quad y_{i}\left(w \cdot x_{i}+b\right) \geqslant \hat{\gamma}, \quad i=1,2, \cdots, N</script><p><strong>函数间隔$\hat{\gamma}$ 不影响最优化问题的解，可以得到下面的线性可分支持向量机学习的最优化问题，凸二次规划问题，有最优解且唯一。（原始最优化问题）</strong> （备注，判断一个问题是否是凸问题，<a href="https://www.zhihu.com/question/334515180" target="_blank" rel="noopener">凸优化</a>）</p>
<script type="math/tex; mode=display">\min _{w, b} \frac{1}{2}\|w\|^{2}</script><script type="math/tex; mode=display">\text { s.t. } \quad y_{i}\left(w \cdot x_{i}+b\right)-1 \geqslant 0, \quad i=1,2, \cdots, N</script><p>求解得到分离超平面：</p>
<script type="math/tex; mode=display">w^{*}·x+b^{*}=0</script><p>分类决策函数是：</p>
<script type="math/tex; mode=display">f(x)=\operatorname{sign}\left(w^{*} \cdot x+b^{*}\right)</script><p>2，支持向量</p>
<p>在线性可分情况下，训练数据集的样本点中与分离超平面距离最近的样本点的实例称为支持向量。支持向量是使约束$\text { s.t. } \quad y_{i}\left(w \cdot x_{i}+b\right)-1 = 0$ 成立。</p>
<p><img src="/images/20191209SupportVector.jpg" alt="20191209SupportVector"></p>
<p>间隔等于$\frac{2}{||w||}$</p>
<h4 id="2-3-对偶问题"><a href="#2-3-对偶问题" class="headerlink" title="2.3 对偶问题"></a>2.3 对偶问题</h4><p>通过求解对偶问题得到原始问题的最优解。</p>
<p><strong>首先构建拉格朗日函数</strong>，不等式约束引入拉格朗日乘子 $\alpha_{i} \geqslant 0 , i=1,2, \cdots, N$</p>
<script type="math/tex; mode=display">L(w, b, \alpha)=\frac{1}{2}\|w\|^{2}-\sum_{i=1}^{N} \alpha_{i} y_{i}\left(w \cdot x_{i}+b\right)+\sum_{i=1}^{N} \alpha_{i}</script><p>其中 $\alpha=\left(\alpha_{1}, \alpha_{2}, \cdots, \alpha_{N}\right)^{\mathrm{T}}$ 是拉格朗日乘子向量</p>
<p><strong>需求$\max _{\alpha} \min _{w, b} L(w, b, \alpha)$</strong></p>
<p>Step1，先求$\min _{w, b} L(w, b, \alpha)$</p>
<p>拉格朗日函数 $L(w, b, \alpha) $ 分别对$w,b$求偏导并令其等于0。</p>
<script type="math/tex; mode=display">\nabla_{w} L(w, b, \alpha)=w-\sum_{i=1}^{N} \alpha_{i} y_{i} x_{i}=0</script><script type="math/tex; mode=display">\nabla_{b} L(w, b, \alpha)=-\sum_{i=1}^{N} \alpha_{i} y_{i}=0</script><p>代入回拉格朗日函数中 $L(w,b,\alpha)$ 并化简：</p>
<script type="math/tex; mode=display">L(w, b, \alpha)=\frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j}\left(x_{i} \cdot x_{j}\right)-\sum_{i=1}^{N} \alpha_{i} y_{i}\left(\left(\sum_{j=1}^{N} \alpha_{j} y_{j} x_{j}\right) \cdot x_{i}+b\right)+\sum_{i=1}^{N} \alpha_{i}</script><p>化简推导过程见[5]，也可以代入简单的例子去看，化简得到：</p>
<script type="math/tex; mode=display">\min _{w, b} L(w, b, \alpha)=-\frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j}\left(x_{i} \cdot x_{j}\right)+\sum_{i=1}^{N} \alpha_{i}</script><p>Step2，求$\min _{w, b} L(w, b, \alpha)$ 对$\alpha$的极大值，<strong>即是对偶问题</strong>：</p>
<script type="math/tex; mode=display">\max _{\alpha}-\frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j}\left(x_{i} \cdot x_{j}\right)+\sum_{i=1}^{N} \alpha_{i}</script><p>转换为求极小</p>
<script type="math/tex; mode=display">\min _{\alpha} \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j}\left(x_{i} \cdot x_{j}\right)-\sum_{i=1}^{N} \alpha_{i}</script><script type="math/tex; mode=display">\text { s.t. } \quad \sum_{i=1}^{N} \alpha_{i} y_{i}=0 , \alpha_i \geqslant 0</script><p>注意：为什么线性规划中求解原始问题可以转为求解对偶问题，对偶问题有良好的性质。对偶问题的对偶是原问题，无论原始问题是否是凸对偶问题都是凸优化问题，对偶问题可以给出原始问题的一个下界，满足一定条件时原始问题的解与对偶问题的解是完全等价的（备注 <a href="https://zhuanlan.zhihu.com/p/31131842" target="_blank" rel="noopener">拉格朗日对偶问题</a>）。</p>
<p>Step3，根据KKT条件求得 $w^{\star}$ 与 $b^{\star}$</p>
<p>过程如下，设 $\alpha^{\star}=\left(\alpha_{1}^{\star}, \alpha_{2}^{\star}, \cdots, \alpha_{N}^{\star}\right)^{\mathrm{T}}$ 是对偶最优化问题的解。根据原问题的不等式约束，KKT条件成立。</p>
<script type="math/tex; mode=display">\nabla_{w} L\left(w^{\star}, b^{\star}, \alpha^{\star}\right)=w^{\star}-\sum_{i=1}^{N} \alpha_{i}^{\star} y_{i} x_{i}=0</script><script type="math/tex; mode=display">\nabla_{b} L\left(w^{\star}, b^{\star}, \alpha^{\star}\right)=-\sum_{i=1}^{N} \alpha_{i}^{\star} y_{i}=0</script><script type="math/tex; mode=display">\alpha_{i}^{\star}\left(y_{i}\left(w^{\star} \cdot x_{i}+b^{\star}\right)-1\right)=0, \quad i=1,2, \cdots, N</script><script type="math/tex; mode=display">y_{i}\left(w^{\star} \cdot x_{i}+b^{\star}\right)-1 \geqslant 0, \quad i=1,2, \cdots, N</script><script type="math/tex; mode=display">\alpha_{i}^{\star} \geqslant 0, \quad i=1,2, \cdots, N</script><p>由此可得:</p>
<script type="math/tex; mode=display">w^{*}=\sum_{i} \alpha_{i}^{\star} y_{i} x_{i}</script><p>至少有一个$\alpha_i^{\star} &gt; 0$，将$w^*$ 代入$y_{j}\left(w^{\star} \cdot x_{j}+b^{\star}\right)-1=0$ （注意 $y_j^2 = 1$）得:</p>
<script type="math/tex; mode=display">b^{\star}=y_{j}-\sum_{i=1}^{N} \alpha_{i}^{\star} y_{i}\left(x_{i} \cdot x_{j}\right)</script><p>最终分类决策函数是：</p>
<script type="math/tex; mode=display">f(x)=\operatorname{sign}\left(\sum_{i=1}^{N} \alpha_{i}^{\star} y_{i}\left(x \cdot x_{i}\right)+b^{\star}\right)</script><p><img src="/images/20191209SVMAlgorithm.jpg" alt="20191209SVMAlgorithm"></p>
<p>《李航》书P125例子好</p>
<h3 id="3-线性支持向量机与软间隔最大化"><a href="#3-线性支持向量机与软间隔最大化" class="headerlink" title="3 线性支持向量机与软间隔最大化"></a>3 线性支持向量机与软间隔最大化</h3><p>线性不可分问题（即某些样本点不满足函数间隔大于等于1的约束条件），用软间隔最大化（引入松弛变量 ）:</p>
<script type="math/tex; mode=display">y_i(w \cdot x_i + b) \geqslant 1 - \xi_i</script><p>原始问题：</p>
<script type="math/tex; mode=display">\min _{w, b} \frac{1}{2}\|w\|^{2} + C \sum_{i=1}^N \xi_i</script><script type="math/tex; mode=display">\text { s.t. } \quad y_{i}\left(w \cdot x_{i}+b\right) \geqslant 1 - \xi_i, \quad i=1,2, \cdots, N</script><script type="math/tex; mode=display">\xi_i \geqslant 0,i=1,2, \cdots, N</script><p>对偶问题：</p>
<script type="math/tex; mode=display">\min _{\alpha} \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j}\left(x_{i} \cdot x_{j}\right)-\sum_{i=1}^{N} \alpha_{i}</script><script type="math/tex; mode=display">\text { s.t. } \quad \sum_{i=1}^{N} \alpha_{i} y_{i}=0</script><script type="math/tex; mode=display">0 \leq \alpha_i \leq C, i=1,2, \cdots, N</script><h3 id="4-非线性支持向量机"><a href="#4-非线性支持向量机" class="headerlink" title="4 非线性支持向量机"></a>4 非线性支持向量机</h3><p>核技巧。例子从椭圆变到线性可分，设原空间：$\mathcal{X} \subset \mathbf{R}^{2}, x=\left(x^{(1)}, x^{(2)}\right)^{\mathrm{T}} \in \mathcal{X}$，新空间 $\mathcal{Z} \subset \mathbf{R}^{2}, z=\left(z^{(1)}, z^{(2)}\right)^{\mathrm{T}} \in \mathcal{Z}$，从原空间到新空间的映射：$z=\phi(x)=\left(\left(x^{(1)}\right)^{2},\left(x^{(2)}\right)^{2}\right)^{\mathrm{T}}$</p>
<h4 id="4-1-核函数"><a href="#4-1-核函数" class="headerlink" title="4.1 核函数"></a>4.1 核函数</h4><p>核函数定义</p>
<p>设$\mathcal{X}$ 是输入空间（欧式空间$R^n$ 的子集或者离散集合），设$\mathcal{H}$为特征k空间（希尔伯特空间），如果存在一个映射：</p>
<script type="math/tex; mode=display">\phi(x): \mathcal{X} \rightarrow \mathcal{H}</script><p>使得对所有$x, z \in \mathcal{X}$ ，函数K(x,z) 满足条件 $K(x, z)=\phi(x) \cdot \phi(z)$ 则K为核函数，$\phi(x)$是映射函数。</p>
<p>对偶问题的目标函数中内积用核函数来替代表示为：</p>
<script type="math/tex; mode=display">W(\alpha)=\frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j} K\left(x_{i}, x_{j}\right)-\sum_{i=1}^{N} \alpha_{i}</script><p>通常所说的核函数就是正定核函数。定义映射，定义内积使其成为内积空间（证明定义的运算是内积，证明其加法和数乘是封闭的。），将内积空间完备化为希尔伯特空间。</p>
<p>常用的核函数：</p>
<p><img src="/images/20191209KernelFunction.jpg" alt="20191209KernelFunction"></p>
<h4 id="4-2-序列最小最优化算法"><a href="#4-2-序列最小最优化算法" class="headerlink" title="4.2 序列最小最优化算法"></a>4.2 序列最小最优化算法</h4><p>SMO算法包括两部分：求解两个变量二次规划的解析方法和选择变量的启发式方法。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1, <a href="https://www.zhihu.com/question/334515180" target="_blank" rel="noopener">https://www.zhihu.com/question/334515180</a></p>
<p>2，陈宝林，最优化理论与算法</p>
<p>3，李航《统计学习方法》</p>
<p>4，<a href="https://zhuanlan.zhihu.com/p/31131842" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31131842</a></p>
<p>5，优秀博文 <a href="https://blog.csdn.net/v_JULY_v/article/details/7624837" target="_blank" rel="noopener">https://blog.csdn.net/v_JULY_v/article/details/7624837</a></p>
<p>6，支持向量机通俗导论(理解 SVM 的三层境界)  ，这个也讲的好</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>LR原理</title>
    <url>/2018/12/08/20191208LR%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h3 id="1、线性回归"><a href="#1、线性回归" class="headerlink" title="1、线性回归"></a>1、线性回归</h3><h4 id="1-1-单变量线性回归"><a href="#1-1-单变量线性回归" class="headerlink" title="1.1 单变量线性回归"></a>1.1 单变量线性回归</h4><p>x ——&gt; hypothesis（假设）——&gt; y，此处假设为线性函数，y输出为数值（若是分类则为0或1）</p><script type="math/tex; mode=display">h_{\theta}{(x)} = \theta^Tx</script><p>为了让hypothesis尽量根据数据拟合好曲线，需要设计损失函数，并对此损失函数优化。损失函数是参数$\theta$ 的 Cost function: </p><a id="more"></a>

<script type="math/tex; mode=display">J(\theta)=\min \frac{1}{2m} \sum_{i=1}^{m}\left(h_{\theta}(x)-y\right)^{2}</script><p>优化损失函数用到梯度下降法：</p>
<p>为了 $min J(\theta)$，我们采用随机梯度下降方法。（其实也可以用一些矩阵直接计算的方法，最优化里的牛顿法、BFGS等等）</p>
<p>repeat until convergence{</p>
<script type="math/tex; mode=display">\theta_{j}=\theta_{j}-\alpha \frac{\partial}{\partial \theta_{j}} J(\theta) \quad(for j=0 \cdots)</script><p>}</p>
<p>展开就是:</p>
<script type="math/tex; mode=display">\theta_j = \theta_j - \alpha \frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)})- y^{(i)}) \frac{\partial h_\theta(x)}{\partial \theta_{j}}</script><p><strong>注意</strong>：</p>
<p>1，学习率影响了梯度下降的步长，一般越大下降越快（但如果最初就在靠近局部最优处，则容易震荡发散），一般设置在0.001~0.003, 取比最大值稍小一点的值即可。</p>
<p>2，不同的初始$\theta$ 可能下降到不同的局部最优点（因此，我们希望损失函数最好是凸函数，线性回归的$J$就是凸函数，是碗面）。</p>
<p>3，数据处理的小技巧，将特征归一化到0-1或者-1-1可以避免量纲影响 x- mean / std。</p>
<p>4，<strong>特征工程非常重要</strong>，特征组合，平方，开根号等等。</p>
<h3 id="2，逻辑回归LR"><a href="#2，逻辑回归LR" class="headerlink" title="2，逻辑回归LR"></a>2，逻辑回归LR</h3><p>逻辑回归是用来解决二分类问题的机器学习方法，用于估计某种事物的可能性。</p>
<p>逻辑回归中x ——&gt; hypothesis（假设）——&gt; y，sigmoid函数将预测值转换为0-1之间的值。</p>
<script type="math/tex; mode=display">0 \leq h_{\theta}(x) \leqslant 1</script><script type="math/tex; mode=display">h_{\theta}(x)=g\left(\theta^{\top} x\right)</script><script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script><p>解释：$h_{\theta}(x)$ 是对输入x，y=1的概率估计，$h_{\theta}(x)=P(y=1 / x ; \theta)$ 给定特征x与参数$\theta$时，y=1的概率。也可以这样理解，一个事件的发生几率指的是该事件发生的概率p与该事件不发生的概率1-p的比值。</p>
<script type="math/tex; mode=display">logit(p) = \log{\frac{p}{1-p}}</script><script type="math/tex; mode=display">\log \frac{P(Y=1|x)}{1-P(Y=1|x)} = \theta^T x</script><p>LR中，输出Y=1的对数几率是输入x的线性函数。</p>
<p>损失函数这里有所不同，因为sigmoid函数代入到平方误差中得到$J$ 是非凸函数，所以cost function用的是交叉熵（信息量中度量不确定性的度量）。</p>
<script type="math/tex; mode=display">J\left(h_{\theta}(x), y\right)=-\frac{1}{m} [ \sum_{i=1}^m y^{(i)} \log \left(h_{\theta}(x^{(i)})\right) + (1-y^{(i)}) \log \left(1-h_{\theta}(x^{(i)})\right) ]</script><p>这个非常像似然函数。</p>
<p>LR的梯度下降公式（对各个参数的偏导 or 链式求导），因为sigmoid函数求导特殊g(z)’ = g(z) (1-g(z))’。</p>
<script type="math/tex; mode=display">\theta_j = \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta)</script><script type="math/tex; mode=display">\theta_{j}=\theta_j-\alpha\frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}</script><p>推导过程：</p>
<script type="math/tex; mode=display">\frac{\partial}{\partial \theta_j} J(\theta) =-\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)} \frac{1}{\left.h_{\theta}\left(x^{(i)}\right)\right)} \frac{\partial}{\partial \theta_{j}} h_{\theta}\left(x^{(i)}\right)-\left(1-y^{(i)}\right) \frac{1}{1-h_{\theta}\left(x^{(i)}\right)} \frac{\partial}{\partial \theta_{j}} h_{\theta}\left(x^{(i)}\right)\right]</script><script type="math/tex; mode=display">\frac{\partial}{\partial \theta_j} h_\theta(x^{(i)}) = \frac{e^{-\theta^{T} x^{(i)}}}{\left(1+e^{-\theta^{T} x^{(i)}}\right)^{2}} \frac{\partial}{\partial \theta_{j}} \theta^{T} x^{(i)} = g\left(\theta^{T} x^{(i)}\right)\left(1-g\left(\theta^{T} x^{(i)}\right)\right) x_{j}^{(i)}</script><p>最后代入化简即可。</p>
<p>其实逻辑回归还可以用于多分类问题上，分别拟合三个分类器$h_{\theta}^{(i)}(x)$，选择 $max {h_{\theta}^{(i)}(x)}$的类i。</p>
<p><strong>注意：</strong></p>
<p>优点：</p>
<p>1，对逻辑回归来说，多重共线性并不是问题，它可以结合L2正则化来解决</p>
<p>2，属于判别式模型</p>
<p>3，在线梯度下降算法-online gradient descent</p>
<p>4，便利的观测样本概率分数</p>
<p>缺点</p>
<p>1，特征空间很大时，逻辑回归的性能不是很好（不能很好地处理大量多类特征或变量，one hot很大）</p>
<p>2，容易欠拟合，一般准确度不太高；</p>
<p>3，对于非线性特征，需要进行转换。</p>
<h3 id="3，过拟合与正则化"><a href="#3，过拟合与正则化" class="headerlink" title="3，过拟合与正则化"></a>3，过拟合与正则化</h3><h4 id="3-1-欠拟合与过拟合"><a href="#3-1-欠拟合与过拟合" class="headerlink" title="3.1 欠拟合与过拟合"></a>3.1 欠拟合与过拟合</h4><p>欠拟合：模型过于简单，underfit，带来高偏差high bias，就是说模型偏见很强；</p>
<p>过拟合：模型复杂，overfit，太过于拟合训练数据，经验误差虽小但结构误差大，无法拟合新数据。</p>
<p><img src="/images/20191209overfit.jpg" alt="20191209overfit"></p>
<p>避免过拟合的方法：数据增强more data，简化模型（早停，限制权值正则化，多种模型Bagging，Boosting），增加噪声，集成ensemble，贝叶斯等。</p>
<h4 id="3-2-正则化"><a href="#3-2-正则化" class="headerlink" title="3.2 正则化"></a>3.2 正则化</h4><p>正则化，损失部分尽量拟合数据，后面部分尽量保持参数较小，起到正则化作用。</p>
<p>线性回归的损失函数：</p>
<script type="math/tex; mode=display">J(\theta) = \frac{1}{2m}[\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)} )^2 + \lambda \sum_{i=1}^{n} \theta_j^2]</script><p>逻辑回归的损失函数</p>
<script type="math/tex; mode=display">J(\theta)=-\left[\frac{1}{m} \sum_{i=1}^{m} y^{(i)} \log \left(h_{\theta}(x^{(i)}\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right] + \frac{\lambda}{2m} \sum_{j=1}^n\theta_j^2</script><p>另外可以参考 <a href="https://zhuanlan.zhihu.com/p/25707761" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25707761</a></p>
<h3 id="4，优化方法复习"><a href="#4，优化方法复习" class="headerlink" title="4，优化方法复习"></a>4，优化方法复习</h3><h4 id="4-1-最速下降法即负梯度方向"><a href="#4-1-最速下降法即负梯度方向" class="headerlink" title="4.1 最速下降法即负梯度方向"></a>4.1 最速下降法即负梯度方向</h4><script type="math/tex; mode=display">f(x_k+\alpha \vec P) = f(x_k) + \alpha P^T \nabla f(x_k) + o(\alpha)</script><script type="math/tex; mode=display">min{f(x_k+\alpha \vec P)}</script><p>则需要$min{P^T \nabla f(x_k)}$</p>
<script type="math/tex; mode=display">P = -\frac{\nabla f(x_k)}{||\nabla f(x_k)||}</script><p>此处$\alpha$是学习率</p>
<p>一般来说，损失函数偏碗状的时候，比较圆的时候，下降比较快。如果，函数形状椭圆形，会来回震荡着走。</p>
<h4 id="4-2-牛顿法"><a href="#4-2-牛顿法" class="headerlink" title="4.2 牛顿法"></a>4.2 牛顿法</h4><p>牛顿法考虑二阶导信息</p>
<script type="math/tex; mode=display">f\left(x_{k} + P\right)=f\left(x_{k}\right)+p^T \nabla f_{k}+\frac{1}{2} p^{T} \nabla^{2} f_{k} P</script><p>则$P = - \nabla^2 f(x_k)^{-1} \nabla f(x_k)$</p>
<p>此处二阶导大于0，即要求$\nabla^2 f(x_k)$ 正定。</p>
<p>总结：逻辑回归主要是增加了一个sigmoid函数，将预测值映射为概率。为了避免损失函数变为非凸函数，损失函数变为对数损失函数。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>模型选择</title>
    <url>/2018/12/07/20200107%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/</url>
    <content><![CDATA[<h3 id="1-偏差与方差"><a href="#1-偏差与方差" class="headerlink" title="1 偏差与方差"></a>1 偏差与方差</h3><h4 id="1-1-点估计"><a href="#1-1-点估计" class="headerlink" title="1.1 点估计"></a>1.1 点估计</h4><p>对参数$\theta$ 的一个预测，记为$\hat{\theta}$ ，假设$\left\{x_{1}, x_{2}, \cdots, x_{m}\right\}$ 是独立同分布的数s据点，该分布由参数$\theta$ 决定，则参数$\theta$ 的点估计为某个函数：</p><script type="math/tex; mode=display">\hat{\theta}_{m}=g\left(x_{1}, x_{2}, \cdots, x_{m}\right)</script><a id="more"></a>
<p>频率学派：真实参数$\theta$ 是固定的，但是未知。$\hat{\theta_m}$ 是数据点的函数（可以用极大似然估计计算）。</p>
<h4 id="1-2-偏差"><a href="#1-2-偏差" class="headerlink" title="1.2 偏差"></a>1.2 偏差</h4><p>偏差：学习算法的期望预测与真实结果的偏离程度，与真实世界的偏离。偏差衡量的是偏离真实值的误差的期望。</p>
<script type="math/tex; mode=display">\operatorname{bias}\left(\hat{\theta}_{m}\right)=\mathbb{E}\left(\hat{\theta}_{m}\right)-\theta</script><p>高偏差 —— 欠拟合：模型有偏离。模型偏简单。</p>
<p>如果$\operatorname{bias}\left(\hat{\theta}_{m}\right)=0$ 则估计量$\hat{\theta_m}$是无偏的。如果$\lim _{m \rightarrow \infty} \operatorname{bias}\left(\hat{\theta}_{m}\right)=0$ 则估计量$\hat{\theta_m}$是渐进无偏的。</p>
<h4 id="1-3-方差"><a href="#1-3-方差" class="headerlink" title="1.3 方差"></a>1.3 方差</h4><p>方差：理解1，同样大小的训练集的变动所导致的学习性能的变化，接受不同数据后的模型输出的稳定程度。理解2，从潜在的数据分布中独立的获取样本集时，估计量的变化程度。理解3，方差衡量的是由于数据采样的随机性可能导致的估计值的波动。</p>
<script type="math/tex; mode=display">\operatorname{Var}(\hat{\theta})</script><p>高方差 —— 过拟合：完全拟合训练数据。模型可能偏向复杂。</p>
<p><strong>噪声</strong>表达了当前任务上任何学习算法所能达到的期望泛化误差的下界，也就是最小值。</p>
<p>eg：RF减少的是方差。Adaboost是减小偏差，尽量去拟合数据。</p>
<p>当交叉验证和测试集误差都很大的时候，怎么判断是bias problem还是variance problem呢？</p>
<p>bias problem：训练误差大，交叉验证误差大。</p>
<p>variance problem：则是训练误差小，交叉验证误差远远比训练误差大。</p>
<p>统计理论表明：如果训练集和测试集中的样本都是独立同分布产生的，则有 <strong>模型的训练误差的期望等于模型的测试误差的期望</strong> 。</p>
<p>机器学习的“没有免费的午餐定理”表明：在所有可能的数据生成分布上，没有一个机器学习算法总是比其他的要好。意思是特点任务的数据的分布往往满足某类假设，从而设计在这类分布上效果好的算法。</p>
<h3 id="2-正则化"><a href="#2-正则化" class="headerlink" title="2 正则化"></a>2 正则化</h3><script type="math/tex; mode=display">J(\theta)=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}+\frac{\lambda}{2 m} \sum_{j=1}^{m} \theta_{j}^{2}</script><p>正则化中的$\lambda$和偏差，方差的关系。</p>
<p>训练误差：随着$\lambda$ 增大的时候，训练损失增大，$\lambda$ 太大的时候对参数惩罚过重，因此容易有高偏差问题。此时对训练集都无法很好拟合。当$\lambda$ 太小的时候，非常容易的去拟合训练集。</p>
<p>交叉验证集的误差：$\lambda$ 过大，欠拟合，高偏差时交叉验证的误差也很大。在最左边是高方差问题，$\lambda$ 小，对数据过拟合交叉验证的误差也很大。</p>
<p><img src="/images/20200107lambda.jpg" alt="20200107lambda"></p>
<h3 id="3-学习曲线"><a href="#3-学习曲线" class="headerlink" title="3 学习曲线"></a>3 学习曲线</h3><h4 id="3-1-曲线随样本量变化"><a href="#3-1-曲线随样本量变化" class="headerlink" title="3.1 曲线随样本量变化"></a>3.1 曲线随样本量变化</h4><p>高偏差：训练误差随着样本数据逐渐增大。交叉验证误差随着样本数量减小（样本量越来越多无助于改善算法）。</p>
<p><img src="/images/20200107high_bias.jpg" alt="20200107high_bias"></p>
<p>高方差：样本增大训练误差也增大，但相对而言误差小一点（因为一直在尽量拟合数据）。交叉验证的误差也慢慢下降，但总的来说样本越多训练得越好。</p>
<p><img src="/images/20200107high_var.jpg" alt="20200107high_var"></p>
<h4 id="3-2-解决方法"><a href="#3-2-解决方法" class="headerlink" title="3.2 解决方法"></a>3.2 解决方法</h4><p>高方差：缓解过拟合。</p>
<p>用更多数据训练（数据增强，更多训练数据），更少量的feature（做），增加正则项$\lambda$（贝叶斯估计中，正则化项对应于模型的先验概率$\log \frac{1}{g(\theta)}$），噪声注入（输入、输出、权重噪声等）、早停法。</p>
<p>高偏差：缓解欠拟合。</p>
<p>加更多的特征，减小正则项 $\lambda$ ，用更复杂的神经网络，对误分类的数据增加权重Adaboost。</p>
<h4 id="3-3-误差分析"><a href="#3-3-误差分析" class="headerlink" title="3.3 误差分析"></a>3.3 误差分析</h4><p>首先构建一个baseline，画出学习曲线，分析是否有高方差偏差的问题，关注那些被分错的数据（共同的特征和规律）。关注交叉验证的结果。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1， <a href="http://www.huaxiaozhuan.com/" target="_blank" rel="noopener">http://www.huaxiaozhuan.com/</a>  参考资料太棒了</p>
<p>2，吴恩达《机器学习》</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>《浪潮之巅》—— IT浮沉</title>
    <url>/2018/10/30/20181030%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="1-行业历史"><a href="#1-行业历史" class="headerlink" title="1 行业历史"></a>1 行业历史</h2><h4 id="AT-amp-T-通信技术"><a href="#AT-amp-T-通信技术" class="headerlink" title="AT&amp;T-通信技术"></a>AT&amp;T-通信技术</h4><p><strong>兴衰</strong>：AT&amp;T是个百年老人，他技术实力在当时贼强。AT&amp;T贝尔电话的发明首先引领通信浪潮，同时，AT&amp;T下贝尔实验室创造了众多世界级发明，如射电天文望远镜、晶体管、数字交换机，半导体，Unix操作系统、C语言，香农信息论等，奠定了整个信息通信领域的基础技术。</p><a id="more"></a>
<p>然而在拆分、销售作假、包装上市后，他失去了在电信业的竞争能力；而外部的互联网的兴起也侵占了传统电话业务，加速了他的衰落。</p>
<p><strong>一方面要保持公司内部活力，另一方面要对行业有敏锐、远见、布局。</strong></p>
<hr>
<h4 id="IBM-计算机制造与服务"><a href="#IBM-计算机制造与服务" class="headerlink" title="IBM-计算机制造与服务"></a>IBM-计算机制造与服务</h4><p><strong>兴衰</strong>：IBM靠为政府企业提供办公机器，军事武器，民用高性能大型计算机，Linux开源服务器得到巨大利润。</p>
<p>而微机逐渐胜任大型机的可以做的事，郭世纳则将IBM从计算机硬件制造公司转变为以服务和软件为核心的公司后，IBM得以继续发展。</p>
<p>IBM还是个保守的创新者，IBM实验室有许多专利，专利盈利也是一笔大钱。</p>
<p>他不断扩大全球市场，目前也是比较稳的立足于企业IT服务上。</p>
<p><strong>在技术上的开拓和发展，并稳扎稳打于自己的核心市场也是一条大道啊</strong></p>
<hr>
<h4 id="苹果公司"><a href="#苹果公司" class="headerlink" title="苹果公司"></a>苹果公司</h4><p><strong>兴衰</strong>：开创个人电脑，结合科技与艺术的时尚手机电脑，进入音乐市场。不断创新产品，精益求精使其成为全球最值钱的公司。</p>
<p><strong>高端市场钱多，求知若渴，革新产品，精益求精，营销品牌</strong></p>
<hr>
<h4 id="Intel-芯片"><a href="#Intel-芯片" class="headerlink" title="Intel-芯片"></a>Intel-芯片</h4><p><strong>兴衰</strong>：intel产低性能的8086微处理器，与IBM合作后一战成名。投资研发高端的奔腾处理器，至此Intel开始垄断计算机处理器市场。他还靠市场份额和与微软的合作赢得了摩托罗拉的竞争，与AMD竞争不断完善创新产品。<br>但他也面临精简指令集处理器的挑战，急需开拓新的成长点。</p>
<p><strong>把握时势，合作博弈，专注自己的领域</strong></p>
<hr>
<h4 id="微软-罗马帝国"><a href="#微软-罗马帝国" class="headerlink" title="微软-罗马帝国"></a>微软-罗马帝国</h4><blockquote>
<p>盖茨空手套白狼（惯用手法），用7.5w美元买来磁盘操作系统DOS，转手卖给IBM。盖茨一边跟IBM合作开发了新的操作系统OS/2，一方面下大力气开发视窗操作系统windows。</p>
</blockquote>
<p>这一段我看呆了，盖茨这波操作很6.操作系统垄断之后，他吞并几大软件市场（Office），开发IE浏览器挤压网景。</p>
<p>不过微软在互联网布局上略慢与雅虎，雅虎的免费的互联网基础服务将微软狙击住了一时。</p>
<p><strong>商业战略敏锐，执行迅速抓住市场，开放兼容，联合厂商形成规模</strong></p>
<hr>
<h4 id="思科-通信设备制造"><a href="#思科-通信设备制造" class="headerlink" title="思科-通信设备制造"></a>思科-通信设备制造</h4><p>成为世界最大的通信设备制造公司（路由器）。他在最合适的时期（互联网）创办了世界最需要的公司。</p>
<p>另外思科能长久发展下去，企业文化起了重要作用。思科鼓励员工留在公司内部创业，提供投资与支持，然后更容易的收购新企业。</p>
<p>不过目前思科遇到了华为的挑战，中国制造压缩了利润空间，这场竞争值得期待。</p>
<p><strong>抓住时机，鼓励创业并收购</strong></p>
<hr>
<h4 id="雅虎公司-互联网"><a href="#雅虎公司-互联网" class="headerlink" title="雅虎公司-互联网"></a>雅虎公司-互联网</h4><blockquote>
<p>一百年后，如果人们只记得两个对互联网贡献最大的人，那么这两个人很可能是杨致远和菲洛。他们不仅创建了世界上最大的互联网门户网站，更重要的是制定下互联网行业的游戏规则——开放、免费、广告盈利。</p>
</blockquote>
<p>雅虎最早对网站进行分类整理，为网页建立索引。免费开放给公众使用，然后通过媒体广告进行盈利。他还投资了阿里，赚翻了。</p>
<p>然而它在与Google的广告系统竞争中失去了技术优势，在不断的扩张中丧失了做行业老大的机会。</p>
<p><strong>好的商业模式十分重要，不可盲目扩张分散产品线</strong></p>
<hr>
<h4 id="惠普-微机厂商"><a href="#惠普-微机厂商" class="headerlink" title="惠普-微机厂商"></a>惠普-微机厂商</h4><p>世界上最大的微机产商，与斯坦福大学合作，发明了喷墨打印机，科学仪器，医疗仪器等产品。后期只做PC的直销，简化供应链，扩充打印机产品，这暂时保住了市场。</p>
<p>但由于领导的失误和中国制造的影响，惠普发展也不太顺利。</p>
<p><strong>保持现金流，直截了当的用数字说明业务情况</strong></p>
<hr>
<h4 id="Google-微软的挑战者"><a href="#Google-微软的挑战者" class="headerlink" title="Google-微软的挑战者"></a>Google-微软的挑战者</h4><blockquote>
<p>Google联合惠普、戴尔等公司预装Google搜索工具条以此抵抗微软</p>
</blockquote>
<p>佩奇的PageRank算法大大改善了搜索准确率，这项技术应用到了搜索广告系统后大获成功。Google还积极建立数据中心，与微软抢人才，开发手机Android操作系统。</p>
<p>他的企业文化强调“不作恶”洁身自好。“个人英雄主义”，给人才足够的自由。这些我都十分欣赏。</p>
<p><strong>在商业竞争中进攻通常是最好的防守。挑战对手，挑战自己</strong></p>
<hr>
<h2 id="2-行业规律"><a href="#2-行业规律" class="headerlink" title="2 行业规律"></a>2 行业规律</h2><ol>
<li>摩尔定律：集成电路的集成度每18个月翻一倍。</li>
<li>反摩尔定律：一个IT公司18月后卖掉跟之前同样多的，同样的产品，营业额降一半</li>
<li>安迪-比尔定律：软件商开发新系统消耗硬件资源，然后促进硬件商的销售</li>
<li>诺维格定律：一家公司的市场份额超过50%后，就不用去想再把市场翻番了。需要发展其他方面</li>
</ol>
<hr>
<h2 id="3-其他规律"><a href="#3-其他规律" class="headerlink" title="3 其他规律"></a>3 其他规律</h2><ol>
<li>当一个公司开始垄断一个行业时，它更倾向于利用自己的垄断资源，而不是科技进步获得的利润</li>
<li>评价一个上市公司的好坏，只要看那些最优秀的人是流进这家公司还是流出这家公司 （此处我看到了百度）</li>
<li>专注于最重要的事情，主要的产品与业务（能盈利的，未来布局）</li>
<li>避免企业机构庞大，官僚主义，舒适环境</li>
<li>为企业提供的服务要稳定可靠</li>
<li>有一个商业竞争者是好事，相互促进创新</li>
<li>一流品牌的公司会选择在一流的媒体上做广告</li>
<li>持有竞争对手的股票进行对冲</li>
<li>1/3的营业额应该来自于近几年的创新；适当淘汰看似还在赚钱但前景不好的产品；发明和产品针对的是广大群众消费者</li>
</ol>
<hr>
<h2 id="4-评价"><a href="#4-评价" class="headerlink" title="4 评价"></a>4 评价</h2><p>吴军博士对各个企业的兴衰进行了梳理，介绍了通信，微机，芯片，操作系统，互联网，门户网站，家庭娱乐中心等技术对应的大公司，解释了技术如何带来IT商业变革，融合了众多商业规律。读完这本书，心中对技术改变商业有了更神的感触，我对整个行业的工业链有了新的理解。<br><img src="https://upload-images.jianshu.io/upload_images/1542651-87d275a35c6f1fe8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="IT行业工业链"></p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>IT行业</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>笑递的青葱岁月</title>
    <url>/2018/08/05/20180805%E7%AC%91%E9%80%92%E7%9A%84%E9%9D%92%E8%91%B1%E5%B2%81%E6%9C%88/</url>
    <content><![CDATA[<p>初踏校园，</p><p>与静军装肩并肩，</p><p>相伴合唱，</p><p>天青色等烟雨。</p><p><br></p><p>班群热聊，</p><p>送第一外号董小姐。</p><p>高数一排，</p><p>笔锋同游求极限。</p><p><br></p><p>同入社团，</p><p>三人共学ps。</p><p>惺惺相惜，</p><p>科研集结三剑客。</p><p><br></p><p>食堂角落，</p><p>歪歪扭扭线稿出，</p><p>教室窗边，</p><p>鼠标漂移始设计。</p><p><br></p><p>机缘巧合，</p><p>韩学长授产品之道，</p><p>笑递出生，</p><p>惊叹产品设计之美。</p><p><br></p><p>应用大赛，</p><p>棱骨分明是培宇，</p><p>初出江湖，</p><p>静收眼底四人团。</p><a id="more"></a>




























<p><br></p>
<p>清冷寒假，</p>
<p>活动室内满热情，</p>
<p>苦学勤画，</p>
<p>多一味开飞雪飘。</p>
<p><br>设计大赛，</p>
<p>文字设计与编码，</p>
<p>早起晚睡，</p>
<p>校赛初赛忙不停。</p>
<p><br></p>
<p>重师密雨，</p>
<p>正装高跟勇上阵。</p>
<p>志愿服务，</p>
<p>更喜伟琳初相遇。</p>
<p><br></p>
<p>易班担当，</p>
<p>技术强人当官霸。</p>
<p>国创之机，</p>
<p>一语相邀共大事。</p>
<p><br></p>
<p>遥远一方，</p>
<p>一坤心思竟相合，</p>
<p>经管计院，</p>
<p>千里因缘一线牵。</p>
<p><br></p>
<p>少年风华，</p>
<p>国创培训笑飞扬，</p>
<p>挥斥方遒，</p>
<p>共书峥嵘好岁月。</p>
<p><br></p>
<p>软院基地，</p>
<p>工作游戏两不误，</p>
<p>投资问询，</p>
<p>豪气万丈迎难上。</p>
<p><br></p>
<p>静引美女，</p>
<p>喝酒干活女汉子。</p>
<p>驰书而行，</p>
<p>干净利落直爽性。</p>
<p><br></p>
<p>十月迎新，</p>
<p>开发测试压力大。</p>
<p>终于上线，</p>
<p>再回虎溪广宣传。</p>
<p><br></p>
<p>官霸生日，</p>
<p>蜡烛跳动圆蛋糕。</p>
<p>笑递一岁，</p>
<p>满桌斟酒干一杯。</p>
<p><br></p>
<p>寒冬泠冽，</p>
<p>联合小薇暖人心。</p>
<p>全校抢果，</p>
<p>圣诞老人现真身。</p>
<p><br></p>
<p>年会开办，</p>
<p>实验室里煮火锅。</p>
<p>游戏抢答，</p>
<p>阿伟表演PPAP。</p>
<p><br></p>
<p>女生节里，</p>
<p>虎溪广场立海报。</p>
<p>玩偶玫瑰，</p>
<p>笑递传送小情谊。</p>
<p><br></p>
<p>碰碰车上，</p>
<p>静仰驰翻挨惨撞。</p>
<p>公园小船，</p>
<p>两队划船来竞赛。</p>
<p><br></p>
<p>国创结项，</p>
<p>厚厚文档诉不尽。</p>
<p>答辩当前，</p>
<p>大声齐喊try your best！</p>
<p><br></p>
<p>风雨一程，</p>
<p>临行约拍将告别。</p>
<p>最后大餐，</p>
<p>歌声嘹亮唱青春！</p>
<p><br></p>
<p>无悔无憾，</p>
<p>整理合照放回忆。</p>
<p>抱拳诚道，</p>
<p>前程锦绣多珍重！</p>
]]></content>
      <categories>
        <category>经历</category>
      </categories>
      <tags>
        <tag>创新创业</tag>
        <tag>经历</tag>
      </tags>
  </entry>
  <entry>
    <title>雪的诗集</title>
    <url>/2018/07/29/20180729%E8%AF%97%E9%9B%86/</url>
    <content><![CDATA[<h3 id="1-明眸"><a href="#1-明眸" class="headerlink" title="1 明眸"></a>1 明眸</h3><p>有一双眼 </p><p>净得仿佛天池的水 </p><p>无法让我凝视 </p><p>我怕 </p><p>这水 </p><p>洗净我的伪装 </p><p>流出我的秘密 </p><p>2013/1/13 高中自习后，家里夜晚</p><h3 id="2-临江晨跑"><a href="#2-临江晨跑" class="headerlink" title="2 临江晨跑"></a>2 临江晨跑</h3><p>江上薄雾笼渔船，两岸青山护千帆。</p><p>渔翁静坐顾相望，少年乘风欲胜舟。</p><p>2018/07/29 暑期早起滨江路跑步</p><h3 id="3-港科游学"><a href="#3-港科游学" class="headerlink" title="3 港科游学"></a>3 港科游学</h3><p>碧海金鳞闪，千岛天光升。 </p><p>白鸥长空翔，渡船独行江。 </p><a id="more"></a>












<p>浩瀚大河山，苍茫一粟人。 </p>
<p>劝君昔少年，朝海好读书！ </p>
<p>2019/03/10 香港科大的朝海图书馆真是好啊，若可一直读书多好</p>
<h3 id="4-南京凌冬"><a href="#4-南京凌冬" class="headerlink" title="4 南京凌冬"></a>4 南京凌冬</h3><p>冬雨凉</p>
<p>千树黄</p>
<p>身无所依易感伤</p>
<p>时事变</p>
<p>多无常</p>
<p>山河无疆天地长</p>
<h3 id="5-平凡"><a href="#5-平凡" class="headerlink" title="5 平凡"></a>5 平凡</h3><p>寒窗十年不曾倦 </p>
<p>忽得一夜伤客心。 </p>
<p>不见多难笑登临。 </p>
<p>终是浮云总归尘。 </p>
<p>2020/01/14 读书好，读书好</p>
<p>（持续更）</p>
<h3 id="6-往京都"><a href="#6-往京都" class="headerlink" title="6 往京都"></a>6 往京都</h3><p>贤士向京都，成败又何如。</p>
<p>莫道前路难，与君共安在。</p>
<p>2020/02/27</p>
]]></content>
      <categories>
        <category>文学创作</category>
      </categories>
      <tags>
        <tag>诗集</tag>
      </tags>
  </entry>
  <entry>
    <title>20180318《乔布斯传》——伟大的人和伟大的产品</title>
    <url>/2018/03/18/20180318%E3%80%8A%E4%B9%94%E5%B8%83%E6%96%AF%E4%BC%A0%E3%80%8B%E2%80%94%E2%80%94%E4%BC%9F%E5%A4%A7%E7%9A%84%E4%BA%BA%E5%92%8C%E4%BC%9F%E5%A4%A7%E7%9A%84%E4%BA%A7%E5%93%81/</url>
    <content><![CDATA[<p>你在使用iPhone或者Mac吗？如果有，那你一定要了解下创造它的人，到底怎样一个人才能创造这样伟大的产品呢。 </p><p>我手里有台Mac，大二的时候，因为看中了它的设计感自己掏钱买了。我喜欢他的简洁，流畅，易用，也喜欢苹果开发者们创造出的各类好玩实用的应用，比如sketch。当我买后，班上静和官霸也跟着买了，哈哈。可见他的吸引力多大，那么这背后这个人该更有吸引力吧。</p><a id="more"></a>

<p>记得初中的公开课开课前，有位老师说，乔帮主去世了。当时，我还不知道，但听老师的赞美和惋惜。我才知晓了苹果和他，但未曾多关注，不过这也算是种下了一个好奇心吧。过年，老家没网，也就最适合整天阅读了，我孜孜不倦读完了《乔布斯传》。书中故事很有趣，读的时候我还自己笑了出来，读完共鸣感悟颇多。</p>
<p>乔帮主的特质很多，<strong>突出的是他的现实扭曲场、优雅简约，精致的细节控、强烈的使命感与控制欲、细节把控、出众的演讲能力、识人用人、向渊博的人摄取知识、注重品牌等等</strong>。当然，人也是有缺陷的，但总觉得他的缺陷变成了促进苹果发展的动力。</p>
<h3 id="1、现实扭曲场——专注"><a href="#1、现实扭曲场——专注" class="headerlink" title="1、现实扭曲场——专注"></a>1、现实扭曲场——专注</h3><p>他是一个极其专注的人，极其投入的人。在设计MAC的时候，即使是开机多用了10s，他不满意他就会要求员工必须做到开机时间减少。他自己也会深信不疑，于是再难的问题再不可能的事情，他总会使用各种方法，哄骗、安抚、劝说、奉承、威胁等让员工服从并做到。这就是他的现实扭曲力场，是一种自身的坚定，不屈的意志，让现实屈从与自己意图的热切渴望。</p>
<p> 其中还有个好玩的故事，也有员工们为了在一些极端问题上改变乔帮主的想法，勇于挑战他。于是，苹果公司设立了一个奖项，每年给最能抵抗得住乔布斯的现实扭曲力场的人颁发。我觉得他们真是有趣，公司也真是有活力。</p>
<p>人最难的就是坚信自己，专注投入。我们的想法都很容易受到身边人和世俗的影响，但其实想法万千，哪有什么标准的原则来评判对错呢。只要坚信自己的想法，专注投入到自己认定的事情上，不断追求极致，我们的现实扭曲力场也将出现。</p>
<h3 id="2、个人电脑、至繁归于至简、站在科技与设计的前沿交汇点"><a href="#2、个人电脑、至繁归于至简、站在科技与设计的前沿交汇点" class="headerlink" title="2、个人电脑、至繁归于至简、站在科技与设计的前沿交汇点"></a>2、个人电脑、至繁归于至简、站在科技与设计的前沿交汇点</h3><p>1、个人电脑：MAC最初也是诞生于车库，当时乔的心愿是做个人电脑，人人都有的电脑，这个想法甚至先于微软。当时的许多公司的产品大多面向企业级顾客，可见乔的远见。他最先将电脑一体化组装，最先将图形界面引入，最先将触屏技术应用。</p>
<p>2、苹果的电脑和手机设计得像个艺术品一样，不得不赞叹乔帮主的要求和品味。其实，这些品味和要求都来自于其追求优雅简约、来源于他总是站在技与设计的前沿交汇点去思考感受产品。他具有工匠和艺术设计者的本心。MAC电脑表里如一，即使隐藏的部分也做的漂亮；设计追随情感，设计表达情感；造型优美，细节中充满乐趣，至繁归于至简。这些也是他的产品别出一裁、受欢迎的关键原因。</p>
<p>3、皮克斯与迪士尼：乔帮主被自己的公司开除期间，他喜欢上了另一个具有艺术特质的行业，他想将科技与动画结合。他欣赏拉塞特这样一位具有绅士气质的艺术家，他尊重他的设计。</p>
<p>乔带来的技术让皮克斯的动画光影、3D效果更棒，加上电影内涵。他创造了另一个最好的品牌——皮克斯动画。现在我们经常在电影开头，看到迪士尼的城堡后会出现皮克斯和一盏跳跳的台灯。这盏台灯动画《顽皮跳跳灯》是皮克斯第一次参加SIGGRAPH大会展示的短片，并被评为最佳影片。后来甚至迪士尼为了挽救自己的电影地位，也不得不和皮克斯合作了。</p>
<p>跨界交叉的创新来源于人的心灵想法的跨界，如果不是乔对科技和动画艺术的喜爱，怎么会有皮克斯这么棒的动画公司呢。</p>
<p> 4、音乐变革+数字中枢</p>
<p>音乐产品ipod的想法来源是乔帮主对版权的保护、为了自己能听最高质量的音乐。他坚定的去和许多唱片公司、音乐人谈判。于是iPod和iTunes出现。2001年互联网泡沫破裂，计算机被预测变为无聊的东西。这时候乔帮主继续思考，他说个人计算机不会成为边缘产品，而将成为数字中枢，管理音乐图片视频信息等等。他又一次站在科技和人文的位置上，先人一步，有了对数字中枢的设想。iTunes后续逐步销售视频、应用程序、订阅服务，慢慢形成了一个数字中枢，它将苹果代入了数字商业的新时代。</p>
<p>  不得不说，个人电脑产品，各种手持电子产品，路演，产品发布会，数字战略……这些是影响了当今互联网产业的多少方方面面啊。</p>
<p>他做的是自己喜欢和希望的事情，热情和思考成就了苹果。</p>
<h3 id="3、强烈的使命感、细节控"><a href="#3、强烈的使命感、细节控" class="headerlink" title="3、强烈的使命感、细节控"></a>3、强烈的使命感、细节控</h3><p>带团队首先自己要有强烈的使命感和愿景的，团队带头人必定知道要去哪。知道怎么去。</p>
<p>乔帮主总能构建出宏伟强烈的使命感，他最爱的格言是“过程就是奖励”，MAC团队是有着崇高使命的特殊团队。在使命感之下，痛苦会变成过眼云烟，最后长久的留下人生的巅峰时刻。他把控宏观，同时又及其关注细节。伟大的产品，总是在细节之处体现品牌和价值，因此它可以长久的引领潮流。</p>
<p>他们每次设计一款产品，会有无数多的模型，每一个试用，并不断对比细节处的不同设计。即使到了发布前，如果不满意，他们也会推迟发布会，重新返工打磨产品。这样的呕心沥血，怎会不诞生出伟大的产品呢？</p>
<h3 id="4、识人用人——向渊博的人摄取知识"><a href="#4、识人用人——向渊博的人摄取知识" class="headerlink" title="4、识人用人——向渊博的人摄取知识"></a>4、识人用人——向渊博的人摄取知识</h3><p>乔帮主的品味、知识、远见不仅仅来源于自身，他是个非常喜欢结交有才华的人。他和艺术大师、广告大师、动画大师、厉害的工程师都会有许多交流。</p>
<p>他取百家之所长，不断学习和完善自己，于是他成为了强者。同时他的核心圈子里聚集的也都是真正的强者，相互成就。</p>
<p>乔布斯，他用大师级手法把理念、科技、艺术融合在了一体，创造了未来。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>产品</tag>
      </tags>
  </entry>
  <entry>
    <title>20171020周国平《生活的幸福》</title>
    <url>/2017/10/20/20171020%E5%91%A8%E5%9B%BD%E5%B9%B3%E3%80%8A%E7%94%9F%E6%B4%BB%E7%9A%84%E5%B9%B8%E7%A6%8F%E3%80%8B/</url>
    <content><![CDATA[<p>老周（周国平）说，幸福的源泉是生命和精神的幸福，感受生命本身的美好，追求精神上的快乐。我是十分赞同的，虽然这看上去有些偏离现实。其实，我觉得这是最贴切的说法，没有偏离现实。</p><p>生命的幸福在身体的健康，情感的丰满。大家其实都能感觉疾病带来的抑郁和沉闷，生病的我真的是完全缺乏生命的活力，不肯动也不肯学，不肯说话不肯笑，这样的我连他也看不下去了。身体健康是多么重要的事情啊。这是最基本的，而生命深层次的快乐还在于情感体验，我们的朋友、亲人、恋人组成了我们周围的生活。我们和喜欢的他们在一起，并让他们也感到快乐，这也是生命最简单的幸福。其实这算是我们现在很多平凡人追求的，我爸妈基本也是希望我过上这样的生活，身体健康、衣食无忧、家庭和睦、朋友友好。</p><a id="more"></a>

<p>以前我不明白为什么我总是不太想按照父母的希望去生活，那时是觉得这样的被安排着没有自由，但现在我想我内心真实拒绝的原因的因为我想有属于自己的精神生活，那个独属于我的人生。</p>
<p>精神生活包括智力思考、实践意志。</p>
<p>智力思考就是要有好奇心和独立思考的能力。其实小时候，每个人都会很好奇世界，那时最让我困扰的问题是“为什么我是我，我知道自己的想法感受，我能生活我的生活，但是别人为什么不是我，不能有我同样的感受，不能过我的生活。”我对我这个个体是非常好奇的，这曾经带给我许多的思考。我才惊觉，原来这是哲学的开端啊。老周说：“我认为一个人在受过大学教育以后，应该成为一个知识分子。什么是知识分子？就是热爱智力生活的人，养成了智力活动习惯的人。”我才意识现在快毕业的我真的还算不上知识分子，庆幸我还有时间，可以重拾我的好奇心，慢慢开始自己的研究之路吧。</p>
<p>实践意志就是要过自己的内心的精神灵魂生活，就是要做喜欢的事情、积极思考、写日记记录。一个人有了持续的内心生活，会感到你在这个世界上生活的时候是有灵魂的。有灵魂的人才是真正的不同与他人的人，才是最独立的个体，不然与咸鱼有什么区别呢。我们人最先进就是在于精神生活，而现代人，仿佛因为忙碌而越来越缺乏了。大家都过着具体的日子，很少有人从局部中跳出来，看看人生全景，想想人生的大问题。</p>
<p>这次在决定我读出国读博的问题上，我想了想这段时间与我一生而言，应该是最简单的学习思考写作的时光了，这对我一生而言都会是很珍贵的、自由的精神生活的时光，所以我选择了这个生活。</p>
<p>老周说：“优秀，就是我一直所强调的，要让老天赋予你的各种精神能力得到很好的生长，智、情、德全面发展，拥有自由的头脑、丰富的心灵和高贵的灵魂。”以前觉得这句话在教育上说得很空，现在我想与我个人而言，这句话很实在。我也正朝着这样的优秀而努力，过智力生活，体验生命的美好，提高德行修养。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>哲思</tag>
      </tags>
  </entry>
  <entry>
    <title>我的创新创业“笑递”行（四）</title>
    <url>/2017/06/20/20170620%E6%88%91%E7%9A%84%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E2%80%9C%E7%AC%91%E9%80%92%E2%80%9D%E8%A1%8C%EF%BC%88%E5%9B%9B%EF%BC%89/</url>
    <content><![CDATA[<p>创业之路，记录我们一路走来~<br>（我的最后一期了，前几期请关注公众号“笑递代送平台”，服务号“笑递物品代送平台”）</p><p><img src="http://mmbiz.qpic.cn/mmbiz_jpg/xoDHJj3mofuVibiaF8JE57ficqzeMSEhW6Iqd3GuZH7Qp6FzJS1QcibngYO4vLwgcTicEyMZq3hnzxyAAo6W6rJoiaoA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" width="200" height="200" alt="笑递微信号" align="center/"></p><center>笑递微信号</center><p>我在产品方面我尽自己全力的思考迭代，尽力完成工作。但是还是有很多地方值得改进。比如，做事要有细节更要有远见，考虑周到。创业有小步快跑的思想，先做简单的版本。都是十分宝贵的经验呀！最好的是这种团队的温馨感，真的让我十分具有归属感。能在大学有这样一个归属感是很不容易的，有这么群伙伴也是十分不容易的，真的很幸运，我有笑递。</p><a id="more"></a>




<p>不知不觉，国创项目也快完了。笑递在这一年的发展挺快的，其实已经超过了我们当初制定的目标——种子用户500人。这个过程中，我们有过很多争执，也有过心酸，有过劳累，也有过快乐，五味陈杂皆遍尝。我不知道该说是我们丰富了笑递，还是笑递丰富了我们的生活，总之一切都是充实的。</p>
<p>青涩的我们开始年幼的笑递。前期，暑假我们一起留校设计开发笑递，这个过程其实感觉有点闭门造车了，我们没有数据没有太多参考就上路了。分析设计了几个基本的功能后，就经过一次评审就开始了安卓的开发。其实我们没有深思过更远，于是就这样青涩的开始了。但是创业其实就是要快速开始。暑期我们争执过功能设计，争执过界面设计，也探讨了笑点的设置，我们都在为笑递贡献自己的一份心力。毕竟，没有经验，我们开发了一个原型demo，安卓应用开发的进度不如我们想象的那么容易…… 暑期是充实的，我们一边开发，一边玩“三国杀”，阿伟是老手了，说的头头是道，敢杀敢恨的样子印在我深深的脑海里。还有培宇坐对面开发，一会又叫“XX，过来~”，一会又叫，惹得我这个产品经理十分无奈，深刻感受到了什么叫开发人员的地位高于产品了。</p>
<p>上线前夕，开学了笑递还没有做好上线的准备，连要先上哪个平台微信还是APP都还很争执，我们其实蛮急的。培宇去跟老师交流了，极力觉得要改变方向，上线微信。现在其实是一个重要的决策时间点，静最后选择了微信。其实我本身不愿意放弃安卓app的，原生的有原生的好处，但是其实从后期迭代更新，用户的获取，的确是微信快。但是如果更远来看的话，想要持续运营做大还是会归到安卓上，不过作为创业者，从微信开始小步快跑绝对是正确的。</p>
<p>官霸被关在实验室408，国庆熬开发。这段时间，相信是官霸最辛苦的日子了，从10月1日后开发任务一下子全落在了他的头上。而且静也提前联系了微软在“百团纳新”的时候进行上线宣传，这让压力更大了。这个时候，其实学生团队的缺点就暴露无遗了，学生团队没法一起上班，没法一起交流立刻解决问题，这些其实是创业的大忌。百团纳新虎溪宣传，我们没能上线，只能宣传微信了。我劝静延迟宣传，到上线后，去虎溪宣传的时候就可以立即体验使用。不过，静的作风一直是执行派，说了什么时候做就要去做。虎溪宣传获得了300的微信关注，也是进步。这件事，真正让我们体会到了创业的瞬息万变，想要把握局势，做出战略决策真是很重要的。</p>
<p>开发完了不是就可以上线了，我组织了我们班级的人去协助做测试。第一次看到笑递在不同的手机上运行。当时，同学们按照写好的测试流程进行测试，中间意外百出。用户一会问我这是怎么回事，这个怎么这样了，这不能用了。我真是尴尬的记下这些bug，然后去找官霸，再面面相觑，缓缓而笑…… 这给我最大的提醒就是，做前端一定别忘了苹果这个机型呀。</p>
<p>测试完了基本bug也改完了，我们启动上线。一开始，我们拉好友来注册使用，差不多没大问题了我们就开始策划更大的活动了。此时，临近双11，对以快递切入的我们来说这是最好的机会了。但，真正的宣传开始于双11过去的5、6天后。我可能是比较急，问了静，一坤的方案出来了吗，双11要怎么做。忘了是什么原因延迟了会，然后开始了快递点的连续三天蹲点宣传，全体出动去地推，连快递点都贴着我们的海报。当时去拔牙的我做了幕后工作者。双11的订单是比之前可观的，而且有了第一笔充值费，这让我很兴奋。</p>
<p>很快12月了，郭老师发来了一条邀约消息，我们开始了和新闻网合作。新闻网给我们讲了关于我们项目的建议，也承诺我们后期我们可以一起办活动并且给予我们部分支持。我是很开心的，毕竟有了学校的支持，我们的发展会更好。果然圣诞节，我们和新闻网一起联合举办了圣诞节送苹果的活动，这个活动是小薇和我们在微信上开通抢苹果的功能，用户抢到苹果在笑递平台下单并且由我们进行派送到寝室。这个活动其实是打响我们名号非常重要的一战，我非常重视，我们可以借此大力宣传我们自身，可以让用户体验笑递的便捷。但是，这个活动被静和一坤定义为了“给新闻网做苦力办活动”，方向跟我预想的不一样了，活动举行的前天我和赵静吵起来了，因为我们自己没有做宣传的问题，我气愤的在qq上质问了赵静。我想这件事的问题是出在我们团队的沟通上，我们的沟通很多时候是在qq上，其实我非常摒弃qq来讨论这些大事。</p>
<p>一，没有充分的沟通交流，讨论活动的举办细节，导致了我们想法不一。二，qq沟通效率低，没有情感表情的传达容易引起误解。 吃一堑长一智吧，我们在后面开展女生节活动的时候，就开会讨论了，这就是我们的团队，成长非常快。</p>
<p>圣诞一过，我们的首届年会开始了。热闹的节日氛围，年终奖，游戏，火锅，三国杀，这种团队的温馨感真的让我十分具有归属感。能在大学有这样一个归属感是很不容易的，有这么群伙伴也是十分不容易的，真的很幸运，我有笑递。<br>17年是新的一年了，笑递在3月开展了女生节活动。这次活动是我们自己主办的，我们做了展板海报在虎溪宣传。这次其实也是一个很重要的活动，这算是笑递盈利试探的第一步，这次是线上抢购我们派送。毕竟要花钱购买产品与服务了，用户不一定能接受。不过，最后效果还是比较好的，我们有了100的流水，虽然不多，但可见笑递的增值服务是可以盈利的。<br>时间流逝得很快，我们大三了，是要抉择学业与创业了。笑递这一年，我们经历了很多，也学会了很多，团队的故事还在继续……<br>我总结下自己的工作吧，在产品方面我尽自己全力的思考迭代，尽力完成工作。但是还是有很多地方值得改进。比如，做事要有细节更要有远见，考虑周到。自己还有个坏习惯是说好了变了，信任是来源于说一是一，承诺必做，这方面我的确没有做好，要改变。另外不要在做完之后抱怨，而要积极在做前去完善，做后反思。做之前多问为什么，说服自己才能说服别人。创业有小步快跑的思想，先做简单的版本。都是十分宝贵的经验呀！</p>
]]></content>
      <categories>
        <category>经历</category>
      </categories>
      <tags>
        <tag>创新创业</tag>
        <tag>经历</tag>
      </tags>
  </entry>
  <entry>
    <title>mac与virtualbox虚拟机的ubuntu文件共享</title>
    <url>/2017/03/09/20170309MAC%E7%9A%84virtualbox%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84ubuntu%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB/</url>
    <content><![CDATA[<p>1、坑是啥？</p><p>我在进行hadoop的配置的时候，需要从mac共享一个文件到ubuntu访问，并且也查了网上很多共享的方法。都试过了，先设置共享文件，路径，永久保存。然后在终端敲命令：sudo mount -t vboxsf share /home/wangxue/share （前一个是新建的文件夹，后一个是mac的文件夹）。</p><a id="more"></a>

<p>坑就是“文件系统错误，共享文件有超级坏块。。。”我去，我搜了半天居然没解决，还是同学帮忙搞定了</p>
<p>2、办法</p>
<p>要卸载并重新安装 virtualbox-guest-utils virtualbox-guest-additions-iso，linux源有这个。我旧的出问题了。</p>
<p>贴一下笔记：</p>
<p>客户、宿主机共享目录</p>
<p>设置 -&gt; 共享文件夹 -&gt; 固定分配 -&gt; 添加一个本地文件夹，并设置自动挂载或不挂载</p>
<p>安装后有下面的文件</p>
<p>/usr/share/virtualbox/VBoxGuestAdditions.iso</p>
<p>之后再进行mount -t vboxsf share /home/wangxue/share</p>
<p>virtualbox的ubuntu是关闭剪贴板共享，共享剪贴板需要选择 虚拟机 -&gt; 设置 -&gt; 常规 -&gt; 高级 -&gt; 共享剪贴板 -&gt; 双向</p>
<p>好了，晚安！</p>
]]></content>
      <categories>
        <category>配置</category>
      </categories>
      <tags>
        <tag>配置</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>我的创新创业“笑递”行（三）</title>
    <url>/2016/12/12/20161212%E6%88%91%E7%9A%84%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E2%80%9C%E7%AC%91%E9%80%92%E2%80%9D%E8%A1%8C%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<p> 猜猜今天笑递团队在干什么呢？小提示：结合最近有啥新鲜事啊~</p><p>当然，就属于“圣诞节.平安夜”的事情了！<br>“笑递”say：<br>圣诞节来了，也快到新年了，笑递要给大家准备个什么礼物呢？应广大人民呼声，当然还是免费送苹果啦！！!是不是很吃吃啊~</p><p>你还记得笑递么？<br><img src="/images/XDintro.png" alt="笑递简介"></p><center>笑递简介</center><p> 其实昨天晚上，我们和重庆大学小薇（重庆大学的官方微博）一起合作办了场“线上抢苹果”的活动，其实大家都知道，办活动不是那么简单的当天“上”就是，需要前期的各种准备，比如活动策划，活动分工，物资准备，功能流程确定，开发准备等等。做这个抢的大活动，还是很考验我们自己的能力的，毕竟这是第一次。何况还是和重庆大学官方一起做，肯定得做好准备，别出bug啊！（喔，原谅我是一位计算机学院的）</p><a id="more"></a>





<p> <img src="/images/ActivityPub.jpg" width="200" height="200" alt="活动群宣传" align="center"><br> <center>活动宣传</center></p>
<p> 其实，我刚说的是我预想中的繁忙的活动准备过程，实际是遇到了很多问题的，来看一看，避免广大同胞们以后掉坑。</p>
<p>1、前期团队沟通不足，对活动的目标定位不充分。导致了活动开始的前一天我和团队另一位负责人起了争执。因为团队完全没有准备宣传材料，没有进行自我宣传，我着急了下。因为自己对这个活动的定义根本就不是帮小薇办活动，而是借助小薇宣传我们自己，也借助小薇的苹果给用户们一点圣诞福利。早点宣传自己是希望传播更远，获取更多用户，让用户体验整个代送的流程知道“笑递” how to use！</p>
<p>2、活动宣传里对自身的宣传要充分。尽管是活动前一天开始我们自己的宣传的，临时做了推文，活动图片，然后在QQ群和空间进行短语宣传，希望能尽快传播出去。</p>
<p>当然，还是重大小薇对我们的宣传是最官方，在活动开始的前一秒的推文中一段是介绍笑递的，很高兴我们笑递得到了学校的鼓励和支持！所以我们微信平台（笑递代送平台）的关注量也蹭蹭上涨了~</p>
<p><img src="/images/ActivityMetric.png" alt="活动数据"></p>
<center>微信后台关注量</center>

<p>3、活动开始了，最最最可怕的是服务器hold不住。请记住做活动要注意CPU，升级服务器，增大带宽😊。</p>
<p>4、客服得及时解决回复。</p>
<pre><code>     我们中间遇到了很多来咨询的。我表示我的电话呗打爆了，第一次这么频繁的做了个温馨的客服。
</code></pre><p>“我打不开。。。。”，“我注册不了”，“页面怎么没有抢了，啊啊啊，为什么啊”</p>
<p>“您好，这里是笑递客服中心，请问遇到什么问题了吗？”</p>
<p>及时做好客服也很重要啊，特别是在这种关键时刻。</p>
<p>5、线上活动做完了，配送工作继续，这才是重头戏。终于是线下直面用户了，活动还在继续，此文还待更新</p>
<p>最后看看我们昨儿+今儿的数据情况吧！开心的是，有人夸我们呢(^o^)/</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>日期</th>
<th>流量次数PV</th>
<th>独立访客UV</th>
<th>IP</th>
<th>新独立访客</th>
<th>访问次数</th>
</tr>
</thead>
<tbody>
<tr>
<td>today</td>
<td>1489</td>
<td>449</td>
<td>351</td>
<td>258</td>
<td>834</td>
</tr>
<tr>
<td>yesterday</td>
<td>7590</td>
<td>1005</td>
<td>740</td>
<td>1005</td>
<td>4414</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>经历</category>
      </categories>
      <tags>
        <tag>创新创业</tag>
        <tag>经历</tag>
      </tags>
  </entry>
  <entry>
    <title>我的创新创业“笑递”行（二）</title>
    <url>/2016/12/05/20161205%E6%88%91%E7%9A%84%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E2%80%9C%E7%AC%91%E9%80%92%E2%80%9D%E8%A1%8C%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<p>现在我大三上，还在做着笑递（服务于高校师生的物品互助代送信息平台）的事业。但大三，学业繁忙，作业项目颇多，自然笑递运营迭代的压力就来了。</p><p><img src="/images/XDlogo.png" alt="笑递logo"></p><p><center>笑递logo</center><br>阿伟说想退了，一段时间里，也在团队里静默下来了。因为和团队里另外一位技术大神无法合作，因为对团队不再有归属感和主人感，没能参与产品的构建；在团队里没有成就感逐渐有了落差，不想继续创业.这确实出乎意料，他是最初创意的提出者，最早的创始人。我以为会没什么事情，不过一些小的情绪，因为我那么信任他。</p><a id="more"></a>


<p>我不能去用道德或者自己的想法去约束他，一个人只有真心留下继续才是真正的留下的，心不在了做什么都没有动力也不会认真。所以我们三剑客找了时间，去柏树林餐厅就谈谈心，聊聊天。</p>
<p><img src="/images/TreeHall.jpg" alt="柏树林餐厅"></p>
<p><center>柏树林餐厅</center><br>每个人能做的其实很少，而且难免有不足。静有，阿伟有，我也有。几乎所有人都吐槽过我，比如宇会说我思考过于局限，想的简单；坤会说这里设计不好，比如淘宝会怎样怎样；官会说设计稿没有及时更新；赵静会说这里文档不行那里不行……我也会有挫败感甚至觉得在团队不被认可，自己辛苦做的仿佛都被否决，那种感觉是很伤心失望。但我得撑着，因为TYB，try your best。不足我尽量慢慢改进。</p>
<p>也许团队的确缺了一些鼓励和赞扬，缺了点包容和承担。大家相互去期望对方做的更好更专业，因而自然压力大，压力大可能会促进团队前进，但太多了也会有负担，所以得合理调整自己的心态，调整生活节奏。</p>
<p>我觉得说笑递是创业项目，可以；不过简单一点，其实就是一个国创，不过像真的创业一样更认真了。我是这样说服自己的，为什么一定要背负这么重的包袱，不过就是认真做国创，让笑递逐渐用起来而已。我把很多想得简单，是因为我很多时候信淘宝的一句话叫“简单源于信任”。当初说创业失败也没什么亏了，不过长经验学习新东西而已。</p>
<p>前面一周，我们去快递点做了很多宣传，现在笑递的用户量有100，微信关注量有600了。这是我们的小起步，挺开心的，终于踏出这一步了。大家付出的一点一点，积累起来到现在，过程是艰辛而快乐了。双11过去了，接下来是圣诞节和新年，我们准备和学校合作策划下一次的大型活动，总是充满着期待的。我们团队只要坚持着，一人做一点点事情，慢慢的总会变好。</p>
<p><img src="/images/11poster.png" alt="双11海报"></p>
<p><center>笑递“双11”代送到寝海报</center><br>小总结：<br>1、有些琐事得放开，有些看似不能做的事情其实你也可以。（比如做产品做运营做技术做设计）<br>2、不值得仅仅是为了退出的轻松而放弃，有时候虽然难，但却不得不担当。<br>3、团队合作起来加把劲，笑递就在慢慢用起来，这是最令人欣慰的事情，还有很多我们可以去做的，创新创业在路上。<br>4、有些事情，得真正试过后才知道是否真的适合，做一件事最重要的是找到他的快乐和兴趣</p>
]]></content>
      <categories>
        <category>经历</category>
      </categories>
      <tags>
        <tag>创新创业</tag>
        <tag>经历</tag>
      </tags>
  </entry>
  <entry>
    <title>我的创新创业“笑递”行（一）</title>
    <url>/2016/09/04/20160904%E6%88%91%E7%9A%84%E5%88%9B%E6%96%B0%E5%88%9B%E4%B8%9A%E2%80%9C%E7%AC%91%E9%80%92%E2%80%9D%E8%A1%8C%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>如果要总结一下我的大学创新创业项目——笑递，得从2015年9月说起，那时我大一下。</p><p><img src="/images/XDlogo.png" alt="笑递logo" title="APP Logo"></p><center>笑递logo</center><p>学校组织申报SRTP项目，大学生科研训练计划。咋一听这个名词，瞬间感觉高大上了，然后再辅导员的积极宣传下，我找了静，阿伟一起参加。先找的是阿伟，或许是因为同班而且也一起学了PS吧。后来大一下参加的网页设计大赛，看中了静。而且静是那个军训就在我旁边认真训练的女生，那时一起和波波教官讲讲笑笑，一起唱的青花瓷。这么庆幸大家就在一起了，然后想创意。我想做一个校园信息整合平台，不过毕竟年轻，想法真的是简单，都不知这个早就被萌学长做过了。</p><a id="more"></a>




<p>最后我们去找了郭老师聊，那是大一某天晚上9左右了，我们在那个嫩绿色的办公室里和郭老师谈想法。阿伟提出了如果可以代买代送到寝室就好了，郭老师只是笑谈你们去做做试试看吧。就这么一个简单的想法，居然延伸至今，扩展变大。我们立刻行动，先拿笔在长宽不到10cm的小笔记本上画草图，把什么功能啥的都放上去，一个简略版的笑递设计稿就出炉了，那天吃饭的时候都是超开心的。</p>
<p>第二天，我和阿伟就去找了自习室做界面。作为初学PS的孩子，连抠图都没有用过几次小鲜肉，我们自信满满地开始我们的APP界面设计。PS只有用起来才学得最快吧，不会百度，再互相帮个忙，简单的画个框框做个圆还是不难的。不过做出来的效果，那就不敢恭维了。不过那时的我们还觉得还是挺好看的，因为那是自己亲手做的，即是在丑也觉得是一种自我突破。</p>
<p>原本打算就这样去答辩SRTP了，不过中间还好遇上了他。韩学长，一位大四的有经验的UI设计学长。因为第一届APP设计大赛，我们结识了高高的友善的韩学长。大一的我们没有技术，没有专业设计能力，甚至审美意识也很差，但是学长用产品的思维悉心指导。在虎溪的二食堂，那个称号为“屌丝食堂”的负一楼，我们从中午聊到了晚上。我们的idea也逐渐丰富了许多，最大的不同是积分制与社交板块的增加，那时候感觉原来一个APP可以这么丰富，瞬间觉得受教了。</p>
<p>后来学长充当了产品经理的角色，给了笑递的初步定位、结构框架，基本功能点。那时候，我才发觉原来一个简单的应用都是来源于抽象的归纳，再有设计。第一次感受到了做一个真正的产品的魅力。还记得那天和班级一起参加户外挑战赛，QQ收到了学长发来的笑递几个主界面。青绿色为主色的界面，灰色边框简洁大方，整个APP界面清爽活泼，带着大学的气息。</p>
<p>生活其实就是这样充满了机会，只要你一直努力做着，那总会有一个你的舞台。<br>   靠着学长指导，我们以这样一个简略版的想法去申报了srtp。答辩前我做了ppt的内容，包含了笑递的创意来源，调查结果，基本定位，意义，演讲流程，界面初步展示。然后有了整个框架的掌握以后，再自己撰写演讲稿。我在准备演讲的同时，队友做ppt的设计优化和其他相关准备。</p>
<p>那天，我着橙色衬衣，牛仔裤走上了第一个答辩舞台。教室很大，前面是有资历的几位评委。因为这一届srtp宣传好申报队伍众多，仅大一就约100多人。我面向所有人，自信的开始了我的第一次正式的笑递答辩展示……</p>
<p>有备而来，自然不出所料，我们成功晋级SRTP，这只是开始，路就这样走起来了~</p>
]]></content>
      <categories>
        <category>经历</category>
      </categories>
      <tags>
        <tag>创新创业</tag>
        <tag>经历</tag>
      </tags>
  </entry>
  <entry>
    <title>旧楼里的七里香</title>
    <url>/2007/03/17/20070901%E6%97%A7%E6%A5%BC%E9%87%8C%E7%9A%84%E4%B8%83%E9%87%8C%E9%A6%99/</url>
    <content><![CDATA[<p>​         “咳-!”我到黑乎乎的楼下，,向楼灯打着招呼。它边也以那暗黄的灯光回应着我, 我背着一个长长的书包两步两岁地爬上楼，一如往常。我边跑边闻着一种很淡很淡的味道，像薄雾那般不可寻的香味。疑感着,这是什么香味啊。</p><p>​         当我走到三楼的楼道旁,那味道便更浓了，我仔细嗅着，寻了几眼，我惊喜的发现它就在窗边。有几分凌乱的姿态，花儿却还打着精神散发着幽香，只那么静静地散发着, 这种香很自然，有种阻挡人们摘下它的魄力。我越闻越觉熟悉，似乎是一种我似曾相识的花，可无论如也想个不起它的名字。这香味仿佛当年的夜来香，便下意识地将它当了夜来香。</p><a id="more"></a>

<p>​        看它花儿还未开得饱满， 还有几串小骨朵未开，我怜惜地将地上的它带回家去，用矿泉水瓶装了水插了进去，摆在了客厅一角。</p>
<p>  “花在那儿弄的哦? ” 父亲问道。</p>
<p>  “楼道边上、你没闻到香味吗? 这么好闻！”</p>
<p>  “是吗,我觉着没多香，现在我还没闻到呢。”也许是因为父亲鼻炎的缘故吧。</p>
<p>  “切.我不屑的应付道 ，只一心弄着我的花儿”</p>
<p>  妈在里屋、我叫她出来闻。老父亲却笑道 ，“什么夜香夜，夜来香的花比它香多了,花儿还可以像黄花那样用来吃呢! “</p>
<p>  “ 嗯.不是? 我怎么觉着这香味就是呢?”</p>
<p>  “ 这肯定不是、你没见过夜来香 。” 我爸老是用一种老练的语气说我。<br>  “ 反正比妈妈上回拿回来的芳香剂好闻多了。” 我内心可是一直不爱芳香剂不自然的味道。我闻着那个简直是受不了，那个香味怪怪的。<br>  “你多闻闻，真的很清新啊 ”，我不断跟父亲强调。 </p>
<p>  “ 好了,快去洗脸吧.” </p>
<p>​        我把它放在冰箱旁边, 因为我觉得那儿安全，没人会踢倒。我又专门闻了下,笑嘻啥地去洗脸了,准备睡觉了。睡觉前,我又跑到客厅把它小心挪到了我的小卧室里，放在了角落边，我想多闻闻说不定我还可以睡得更香呢，然后我才满意地躺进了被窝。</p>
<p>​        一大早起床，闻着这香，心情一下就舒畅了很多。想着昨晚似乎做了一个梦。在一片种这种花的林子里慢慢行走。不过之后是忘得一干二净了，怎么回想也想不起了，不过是很美好的画面。花儿比昨夜开得更盛些了，小小的白色骨朵开在淡绿色的枝上，挤得满满的。就像是挂满了白色星星一样，有满天星的感觉。只是满天星缺了一点清香。</p>
<p>​        我今天得上学，一清早便去学校，没能当嗅下便匆忙开。下楼时，我碰见了洋我的邻房好朋友, ” 你闻到楼里的花香没?”。</p>
<p>​    “真的是好香啊，很好闻呢。这种花好像是七里香，我奶奶那里有 ”。<br>​    原来是七里香，这名字很好听，知道名字的我很开心。</p>
<p>（2007年，在旧楼的生活小场景）</p>
]]></content>
      <categories>
        <category>文学创作</category>
      </categories>
      <tags>
        <tag>散文</tag>
      </tags>
  </entry>
</search>
