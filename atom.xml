<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>WangXue</title>
  
  <subtitle>快乐学习，慢慢赚钱</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-01-16T09:30:49.661Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>WangXue</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>点云的三种可视化方法</title>
    <link href="http://yoursite.com/2020/01/16/20200116%E7%82%B9%E4%BA%91%E7%9A%84%E4%B8%89%E7%A7%8D%E5%8F%AF%E8%A7%86%E5%8C%96%E6%96%B9%E6%B3%95/"/>
    <id>http://yoursite.com/2020/01/16/20200116%E7%82%B9%E4%BA%91%E7%9A%84%E4%B8%89%E7%A7%8D%E5%8F%AF%E8%A7%86%E5%8C%96%E6%96%B9%E6%B3%95/</id>
    <published>2020-01-16T08:48:20.000Z</published>
    <updated>2020-01-16T09:30:49.661Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-点云介绍"><a href="#1-点云介绍" class="headerlink" title="1 点云介绍"></a>1 点云介绍</h3><p>点云数据是来自斯坦福大学的HDF5格式数据。HDF5 格式是用于存储和分发科学数据的一种多对象文件格式。可以用 HDFView 打开文件，查看数据。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">www = &apos;https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip</span><br></pre></td></tr></table></figure><a id="more"></a><p>点云还有PLY格式：PLY 文件格式是 Stanford 大学开发的一套三维 mesh 模型数据格式，图形学领域最初很多模型都是基于此格式，我使用了此格式的点云物体文件进行了部分物体的参考和对比。</p><p>点云还有PCD格式：一种新的 3D 点云数据文件格式，是当初为了解决某些不支持 PCL 为 3D点云处理进行的文件扩展。他的文件头部具有固定格式，必须用 ASCII 编码，包含标题、对点云数据的某些属性的声明。PCD 文件可以使用 PCL 库里的 PCL_Viewer 打开，从而直接查看到点云的三维图像。</p><p>MAC上的PCL_Viewer需要装PCL库，当时配置的一些问题记录在博客里了。<a href="[https://saruagithub.github.io/2019/03/27/PCL%E5%9C%A8Mac%E4%B8%8A%E7%8E%AF%E5%A2%83%E9%97%AE%E9%A2%98/](https://saruagithub.github.io/2019/03/27/PCL在Mac上环境问题/">PCL 在 Mac 上环境问题</a>)</p><h3 id="2-可视化方法"><a href="#2-可视化方法" class="headerlink" title="2 可视化方法"></a>2 可视化方法</h3><h4 id="2-1-Matplotlib方法"><a href="#2-1-Matplotlib方法" class="headerlink" title="2.1 Matplotlib方法"></a>2.1 Matplotlib方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">'3d'</span>)</span><br><span class="line"><span class="comment"># point_range = range(0, points.shape[0], skip) # skip points to prevent crash</span></span><br><span class="line">point_range = range(<span class="number">0</span>, points.shape[<span class="number">0</span>])</span><br><span class="line">ax.scatter(points[point_range, <span class="number">0</span>],   <span class="comment"># x</span></span><br><span class="line">           points[point_range, <span class="number">1</span>],   <span class="comment"># y</span></span><br><span class="line">           points[point_range, <span class="number">2</span>],   <span class="comment"># z</span></span><br><span class="line">           c=points[point_range, <span class="number">2</span>], <span class="comment"># height data for color</span></span><br><span class="line">           cmap=<span class="string">'spectral'</span>,</span><br><span class="line">           marker=<span class="string">"x"</span>)</span><br><span class="line">ax.axis(<span class="string">'scaled'</span>)  <span class="comment"># &#123;equal, scaled&#125;</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>效果如下：</p><p><img src="/images/20200116MatPlotLib_PointCloud.jpg" alt="20200116MatPlotLib_PointCloud"></p><h4 id="2-2-PCD格式转化用PCL-Viewer可视化"><a href="#2-2-PCD格式转化用PCL-Viewer可视化" class="headerlink" title="2.2 PCD格式转化用PCL_Viewer可视化"></a>2.2 PCD格式转化用PCL_Viewer可视化</h4><p>对 HDF5 格式的数据进行了重写为 PCD 文件格式，主要 就是将数据写入的时候需要满足 PCD 文件顶头部分的特定格式。 PCL_viewer 是可视化点云文件的 PCL 工具，它需要用到 PCL 库里的 vtk 库进 行可视化。 </p><p>详情见我的github项目里 <a href="https://github.com/saruagithub/PointCloudClassification_keras" target="_blank" rel="noopener">点云分类</a> 的H5toPcd.py。</p><h4 id="2-3-Three-js-网页可视化"><a href="#2-3-Three-js-网页可视化" class="headerlink" title="2.3 Three.js 网页可视化"></a>2.3 Three.js 网页可视化</h4><p>首先构建一个场景，遍历添加 3D 点云的所有 点到场景里，并给点赋值颜色 RGB 值和材质，其实场景就是物体的一个容器。然后设置好相机，相机的角度决定了场景中某一角度的 3D 点云物体的图像。相机对 旋转的点云拍照，从而渲染显示在页面上即可看到可视化的点云物体了。最后设置 好渲染器。使用渲染器的 render(scene, camera)函数，设置渲染器的像素和页面元 素大小，渲染器将相机拍到的图形渲染显示在页面的元素内，从而在页面中可以看到图像。 </p><p>详情见github项目 <a href="https://github.com/saruagithub/PointCloudUpload" target="_blank" rel="noopener">点云分类网页展示</a> 的draw2.html</p><p><img src="/images/20200116Three_PointCloud.jpg" alt="20200116Three_PointCloud"></p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol><li><p>普林斯顿大学 Modelnet 官网，<a href="http://modelnet.cs.princeton.edu/" target="_blank" rel="noopener">http://modelnet.cs.princeton.edu/</a> 2018 Princeton Vision &amp; </p><p>Robotics Labs ‒ Department of Computer Science </p></li><li><p>PCL 官网，<a href="http://www.pointclouds.org/about/#open" target="_blank" rel="noopener">http://www.pointclouds.org/about/#open</a> 2018/5/23 </p></li><li><p>Three.js 官网 <a href="https://threejs.org/" target="_blank" rel="noopener">https://threejs.org/</a> 2018/5/23 </p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-点云介绍&quot;&gt;&lt;a href=&quot;#1-点云介绍&quot; class=&quot;headerlink&quot; title=&quot;1 点云介绍&quot;&gt;&lt;/a&gt;1 点云介绍&lt;/h3&gt;&lt;p&gt;点云数据是来自斯坦福大学的HDF5格式数据。HDF5 格式是用于存储和分发科学数据的一种多对象文件格式。可以用 HDFView 打开文件，查看数据。 &lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;www = &amp;apos;https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="可视化" scheme="http://yoursite.com/categories/%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    
    
      <category term="三维点云" scheme="http://yoursite.com/tags/%E4%B8%89%E7%BB%B4%E7%82%B9%E4%BA%91/"/>
    
      <category term="可视化" scheme="http://yoursite.com/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>BatchNormalization理解</title>
    <link href="http://yoursite.com/2020/01/16/20200116BatchNormalization%E7%90%86%E8%A7%A3/"/>
    <id>http://yoursite.com/2020/01/16/20200116BatchNormalization%E7%90%86%E8%A7%A3/</id>
    <published>2020-01-16T07:33:04.000Z</published>
    <updated>2020-01-16T07:33:04.234Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>二分查找题目</title>
    <link href="http://yoursite.com/2020/01/13/20200113%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E9%A2%98%E7%9B%AE/"/>
    <id>http://yoursite.com/2020/01/13/20200113%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E9%A2%98%E7%9B%AE/</id>
    <published>2020-01-13T14:13:32.000Z</published>
    <updated>2020-01-13T14:27:45.499Z</updated>
    
    <content type="html"><![CDATA[<h3 id="基本二分查找"><a href="#基本二分查找" class="headerlink" title="基本二分查找"></a>基本二分查找</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// return index of target</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">binarySearch</span><span class="params">(<span class="keyword">int</span> numbers[],<span class="keyword">int</span> length, <span class="keyword">int</span> target)</span></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> low = <span class="number">0</span>, high = length<span class="number">-1</span>, middle = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span>(low &lt; high)&#123;</span><br><span class="line">    middle = (low + high) / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span>(target == numbers[middle]) <span class="keyword">return</span> middle;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(target &lt; numbers[middle]) high = middle;</span><br><span class="line">    <span class="keyword">else</span> low = middle + <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><a id="more"></a><p>二分查找的时间复杂度是 $O(logn)$</p><p>基于二分查找的题目很多，但基本很多情况都是给排序好的数组之类的进行查找。</p><h3 id="SwordToOffer"><a href="#SwordToOffer" class="headerlink" title="SwordToOffer"></a>SwordToOffer</h3><p>每次选取数组的右上角元素，如果目标值较小，就逐渐往左下走。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// P47 题目s4，二维数组查找数字</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">find_num</span><span class="params">(<span class="keyword">int</span>* matrix, <span class="keyword">int</span> rows, <span class="keyword">int</span> columns, <span class="keyword">int</span> number)</span></span>&#123;</span><br><span class="line">    <span class="keyword">bool</span> found = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (matrix != <span class="literal">nullptr</span> &amp;&amp; rows&gt;<span class="number">0</span> &amp;&amp; columns&gt;<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> row = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> col = columns - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (row &lt; rows &amp;&amp; col &gt;=<span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (matrix[row * columns + col] == number) &#123;</span><br><span class="line">                found = <span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (matrix[row * columns + col] &gt; number) --col;</span><br><span class="line">            <span class="keyword">else</span> ++row;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> found;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实我觉得这里也可以考虑用二分查找法来解，毕竟二维数组从左到右，从上到下是排序了的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;基本二分查找&quot;&gt;&lt;a href=&quot;#基本二分查找&quot; class=&quot;headerlink&quot; title=&quot;基本二分查找&quot;&gt;&lt;/a&gt;基本二分查找&lt;/h3&gt;&lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// return index of target&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;binarySearch&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; numbers[],&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; length, &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; target)&lt;/span&gt;&lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; low = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, high = length&lt;span class=&quot;number&quot;&gt;-1&lt;/span&gt;, middle = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt;(low &amp;lt; high)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    middle = (low + high) / &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(target == numbers[middle]) &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; middle;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(target &amp;lt; numbers[middle]) high = middle;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; low = middle + &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;-1&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="算法" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="SwordToOffer" scheme="http://yoursite.com/tags/SwordToOffer/"/>
    
  </entry>
  
  <entry>
    <title>剑指OfferP41与哈希散列</title>
    <link href="http://yoursite.com/2020/01/12/20200112%E5%89%91%E6%8C%87OfferP41/"/>
    <id>http://yoursite.com/2020/01/12/20200112%E5%89%91%E6%8C%87OfferP41/</id>
    <published>2020-01-12T13:44:52.000Z</published>
    <updated>2020-01-13T09:09:30.508Z</updated>
    
    <content type="html"><![CDATA[<h3 id="数组中重复的数字"><a href="#数组中重复的数字" class="headerlink" title="数组中重复的数字"></a>数组中重复的数字</h3><p>思路1：排序，然后比较当前个与下一个是否相同，相同则为重复元素。</p><p>思路2：一遍遍历，hash表将数组元素存起来，每次判断是否在hash里出现过。t:O(n)，space: O(n)</p><p>思路3：题目限制得比较死，数字在0~n-1的范围。所以可以采取书中的特殊交换解法。交换有限次即可找到，因此time O(n)。</p><a id="more"></a><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unordered_map&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// solution2</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; duplicate2(<span class="keyword">int</span> numbers[],<span class="keyword">int</span> length)&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; duplication;</span><br><span class="line">    <span class="built_in">unordered_map</span>&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; mmap;</span><br><span class="line">    <span class="keyword">if</span> (numbers==<span class="literal">nullptr</span> || length&lt;=<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> duplication;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;length; i++) &#123;</span><br><span class="line">        <span class="comment">// 可以去除这个限制了</span></span><br><span class="line">        <span class="keyword">if</span> (numbers[i] &lt; <span class="number">0</span> || numbers[i] &gt; length+<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> duplication;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (mmap.<span class="built_in">find</span>(numbers[i]) != mmap.<span class="built_in">end</span>() ) &#123;</span><br><span class="line">            duplication.push_back(numbers[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            mmap[i] = numbers[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> duplication;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// solution 3</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; duplicate(<span class="keyword">int</span> numbers[],<span class="keyword">int</span> length)&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; duplication;</span><br><span class="line">    <span class="comment">// Boundary conditions</span></span><br><span class="line">    <span class="keyword">if</span> (numbers==<span class="literal">nullptr</span> || length &lt;=<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> duplication;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (numbers[i] &lt; <span class="number">0</span> || numbers[i] &gt; length<span class="number">-1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> duplication;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;length; i++) &#123;</span><br><span class="line">        <span class="keyword">while</span> (numbers[i] != i) &#123;</span><br><span class="line">            <span class="keyword">if</span> (numbers[i] == numbers[numbers[i]]) &#123;</span><br><span class="line">                duplication.push_back(numbers[i]);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//swap num[i] and num[num[i]]</span></span><br><span class="line">            swap(numbers[i], numbers[numbers[i]]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> duplication;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// 测试输出重复的数字 the duplicate num</span></span><br><span class="line">    <span class="keyword">int</span> num[<span class="number">7</span>] = &#123;<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">3</span>&#125;;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; duplication;</span><br><span class="line">    duplication = duplicate(num, <span class="keyword">sizeof</span>(num)/<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> item:duplication) <span class="built_in">cout</span>&lt;&lt;item&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我修改了下，直接返回vector重复的数字。</p><h3 id="hash原理"><a href="#hash原理" class="headerlink" title="hash原理"></a>hash原理</h3><h4 id="hash原理-1"><a href="#hash原理-1" class="headerlink" title="hash原理"></a>hash原理</h4><p>根据关键码值直接访问表。如可以把关键码值映射到数组中的位置来访问记录，这个就是散列。把关键码值映射到位置的函数称为散列函数，用h表示。存放记录的数组称为散列表 HT。散列表中的第一个位置称为槽 slot，HT中槽的数目用M表示。$i = h(K)$ 是表中满足 $0 \leq h(K) &lt; M$ 的一个槽，记录在HT[i] 的关键码值与K相等。</p><p>散列方法不适合多条记录有相同关键码的应用程序。散列方法一般不适合范围检索。适合的是精确查找。有吗？那条记录是关键码值K呢？应用：主存的检索，磁盘的检索，组织存储在磁盘上的大型数据库。</p><p>适用情况，记录关键码值的范围很大，并且把记录存储在一个槽数目相对较少的表中。</p><p>散列函数：一般来说希望选择的散列函数能把记录以相同的概率分布到散列表的所有槽中。但是在一般情况下，根据关键码值的分布来选择散列 函数。</p><p>一些常见的散列函数：取余、平方取中法，字符串散列函数，折叠方法——ASCII码累加起来 % M（散列表长）</p><h4 id="开散列方法——单链方法"><a href="#开散列方法——单链方法" class="headerlink" title="开散列方法——单链方法"></a>开散列方法——单链方法</h4><p>冲突解决方法之开散列方法。</p><p>《数据结构与算法分析》P212，最简单的形式是：把散列表中的每个槽定义为一个链表的表头，散列到一个槽的所有记录都放到这个槽的链表内。链表中的记录可以按照插入次序排列，按照关键码值次序排列，按照访问频率次序排列等等。</p><p>适用于主存中。</p><h4 id="闭散列方法——开地址方法"><a href="#闭散列方法——开地址方法" class="headerlink" title="闭散列方法——开地址方法"></a>闭散列方法——开地址方法</h4><p>把所有记录直接存储到散列表中。每条关键码值标记为$k_R$ ，记录R有一个基槽，就是$h(k_R)$ ，即由散列函数计算出来的槽。如果要插入一条记录R，另一条记录占据了R的基槽，就把R存储在表的其他槽内。</p><p>桶式散列。把散列表中的槽分成多个桶。先进入桶中的槽，再进入溢出槽里。散列函数把记录在各个桶之间平均分布，使得进入溢出桶的记录尽可能少。</p><p>适用于磁盘的散列表。可以把桶的大小设置为磁盘块的大小。</p><h6 id="线性探查"><a href="#线性探查" class="headerlink" title="线性探查"></a>线性探查</h6><p>当基槽被占用时，在散列表中找到一个空槽，冲突策略就到达这个组中的下一个槽。如果这个槽也被占用了，就找下一个空槽。探测序列由探测函数P生成。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">typename</span> E&gt;</span><br><span class="line"><span class="keyword">void</span> hashdict&lt;Key,E&gt;::hashInsert(<span class="keyword">const</span> Key&amp;k, <span class="keyword">const</span> E&amp;e)&#123;</span><br><span class="line">  <span class="keyword">int</span> <span class="built_in">home</span>; <span class="comment">// home position for k</span></span><br><span class="line">  <span class="keyword">int</span> pos = <span class="built_in">home</span> = h(k); <span class="comment">//Init proble sequence</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; EMPTYKEY!=(HT[pos]).key(); i++)&#123;</span><br><span class="line">    pos = (<span class="built_in">home</span> + p(k,i) % M); <span class="comment">// probe</span></span><br><span class="line">    Assert(k != (HT[pos]).key(), <span class="string">"Duplication not allowed!"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  KVpair&lt;Key,E&gt; temp(k,e);</span><br><span class="line">  HT[pos] = temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第i次对P调用，返回第i次要用到的偏移量。</p><p>探测函数：线性探测，避免聚集可P(k,i) = ci</p><p>好的探测序列是在回到基槽之前，把散列表的所有槽都走一遍。理想的探测函数应该在探查序列中随机的从未走过的槽中选择下一个位置，即探查序列应当是散列表位置的随机排列。如伪随机探查。$( h(K) + r_i ) mod M$, $r_i$ 是1到M-1之间的数的随机排列。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;数组中重复的数字&quot;&gt;&lt;a href=&quot;#数组中重复的数字&quot; class=&quot;headerlink&quot; title=&quot;数组中重复的数字&quot;&gt;&lt;/a&gt;数组中重复的数字&lt;/h3&gt;&lt;p&gt;思路1：排序，然后比较当前个与下一个是否相同，相同则为重复元素。&lt;/p&gt;&lt;p&gt;思路2：一遍遍历，hash表将数组元素存起来，每次判断是否在hash里出现过。t:O(n)，space: O(n)&lt;/p&gt;&lt;p&gt;思路3：题目限制得比较死，数字在0~n-1的范围。所以可以采取书中的特殊交换解法。交换有限次即可找到，因此time O(n)。&lt;/p&gt;
    
    </summary>
    
    
      <category term="算法" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="SwordToOffer" scheme="http://yoursite.com/tags/SwordToOffer/"/>
    
  </entry>
  
  <entry>
    <title>20180915pointnet论文3——TensorFlow源码阅读</title>
    <link href="http://yoursite.com/2020/01/11/20180915pointnet%E8%AE%BA%E6%96%873%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
    <id>http://yoursite.com/2020/01/11/20180915pointnet%E8%AE%BA%E6%96%873%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</id>
    <published>2020-01-11T12:59:40.000Z</published>
    <updated>2020-01-16T08:44:57.017Z</updated>
    
    <content type="html"><![CDATA[<h3 id="目录说明"><a href="#目录说明" class="headerlink" title="目录说明"></a>目录说明</h3><p>根目录下：</p><p>train.py用于点云分类训练</p><p>provider.py 用于点云的数据预处理（旋转，抖动等）</p><p>evaluate用于评估训练结果。</p><p>其他目录：<strong>data</strong>目录下存放用于训练的样例文件h5，test_files与train_files中列举的用于训练及测试的文件路径。<strong>log</strong> 存放的是训练结果，默认情况下只存放最近一次训练结果。<strong>models</strong>存放的是模型文件，pointnet_cls.py（POINTNET）和pointnet_cls_basic.py（baseline模型）中的MLP是分类模型结构。pointnet_seg.py是点云分割模型网络；transform_nets.py为原始点云对称变换以及特征变换，即论文中的T-net网络。</p><a id="more"></a><h3 id="1，数据预处理provider"><a href="#1，数据预处理provider" class="headerlink" title="1，数据预处理provider"></a>1，数据预处理provider</h3><p>前面下载数据以及后面的hdf5格式加载数据就略过了。说一说数据预处理部分干了些什么。</p><p>1，shuffle_data函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shuffle_data</span><span class="params">(data, labels)</span>:</span></span><br><span class="line">    idx = np.arange(len(labels))</span><br><span class="line">    np.random.shuffle(idx)</span><br><span class="line">    <span class="keyword">return</span> data[idx, ...], labels[idx], idx</span><br></pre></td></tr></table></figure><p>根据labels的长度创建idx下标集合，对下标集合随机打乱，返回打乱的数据data[idx,…] 和labels[idx]。</p><p>2，随机旋转点云rotate_point_cloud（参数batch_data）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rotate_point_cloud</span><span class="params">(batch_data)</span>:</span></span><br><span class="line">    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(batch_data.shape[<span class="number">0</span>]):</span><br><span class="line">        rotation_angle = np.random.uniform() * <span class="number">2</span> * np.pi</span><br><span class="line">        cosval = np.cos(rotation_angle)</span><br><span class="line">        sinval = np.sin(rotation_angle)</span><br><span class="line">        rotation_matrix = np.array([[cosval, <span class="number">0</span>, sinval],</span><br><span class="line">                                    [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                                    [-sinval, <span class="number">0</span>, cosval]])</span><br><span class="line">        shape_pc = batch_data[k, ...]</span><br><span class="line">        rotated_data[k, ...] = np.dot(shape_pc.reshape((<span class="number">-1</span>, <span class="number">3</span>)), rotation_matrix)</span><br><span class="line">    <span class="keyword">return</span> rotated_data</span><br></pre></td></tr></table></figure><p>遍历这批点云物体batch_data.shape[0] 即B的大小。</p><p>旋转角度是随机生成的，乘以2$\pi$ ，即使角度多大都没关系，反正按角度算。</p><p>计算cos和sin值。</p><p>注意此处的旋转矩阵。原一个点云物体k的大小的n*3与旋转矩阵做点积。其实就是物体逆时针旋转那么多角度。对这一批点云物体都做这一个随机旋转角度值。</p><script type="math/tex; mode=display">\left[\begin{array}{lll}{cosval} & {0} & {sinval} \\ {0} & {1} & {0} \\ {-sinval} & {0} & {cosval}\end{array}\right]</script><p>rotate_point_cloud_by_angle旋转也是同理，不过是指定角度旋转。角度作为参赛输入函数。</p><p>3，jitter_point_cloud随机抖动点云</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">jitter_point_cloud</span><span class="params">(batch_data, sigma=<span class="number">0.01</span>, clip=<span class="number">0.05</span>)</span>:</span></span><br><span class="line">    B, N, C = batch_data.shape</span><br><span class="line">    <span class="keyword">assert</span>(clip &gt; <span class="number">0</span>)</span><br><span class="line">    jittered_data = np.clip(sigma * np.random.randn(B, N, C), <span class="number">-1</span>*clip, clip)</span><br><span class="line">    jittered_data += batch_data</span><br><span class="line">    <span class="keyword">return</span> jittered_data</span><br></pre></td></tr></table></figure><p>sigma = 0.01， clip = 0.05</p><p>sigma <em> sigma </em> np.random.randn(B, N, C) 是均值为sigma的正态分布数据，大小是$B\times N \times C$</p><p>将这些数值切割到-0.05到0.05之间，并与原始点云的坐标数据相加。</p><p>相当于给点云数据加微小的噪声，增强数据有助于模型的泛化性。</p><h3 id="2，基础模型baseline"><a href="#2，基础模型baseline" class="headerlink" title="2，基础模型baseline"></a>2，基础模型baseline</h3><p>pointnet_cla_basic.py 函数。就是不看T-net的网络部分。</p><p><img src="/images/20180914pointnet.jpg" alt="20180914pointnet"></p><p>placeholder_inputs() 根据点云物体一批大小，以及每个点云物体的点的数目声明变量占位。</p><p>get_model() 输入大小BxNx3, 输出Bx40 （这个是40个类别分类向量</p><p>其中input_image的shape是$B \times N \times 3 \times 1$ ， 而输出大小是$B \times 40$ 因为物体是40个类别。</p><p>然后就是点云的卷积网络多层感知层MLP，卷积层的卷积核个数为64，大小是$1 \times 3$ ，步长是 $1 \times 1$，padding = valid 不补0，激活函数是Relu。 这几个参数，其中卷积核个数为64表示卷积中输出滤波器filter的数量，$1 \times 3$  的卷积核大小是因为坐标为xyz。卷积核就会在训练过程中逐步得到一些与点云物体的特殊的特征点。</p><p><img src="/images/20200114POINTNET_CNN.png" alt="20200114POINTNET_CNN"></p><center>卷积图，输入是2048 × 3，输出其实有64个特征地图，其实就是论文图中的 n × 64</center><p>同理，后续的卷积核大小都是(1,1)，步长也是(1,1) 都是为了挑选这些特征点（信息点，有趣点），即局部感知，可以想这个网络只是把每个点连接起来而已。</p><p>然后经过5个卷积层之后，采用了最大池化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MaxPooling2D(pool_size=(NUM_POINT,<span class="number">1</span>),strides=[<span class="number">2</span>,<span class="number">2</span>],padding=<span class="string">'valid'</span>)</span><br></pre></td></tr></table></figure><p>最大池化采用大小为(2,2) 将特征地图缩小一半，并提取关键信息点。同时这里的最大池化将特征点起了对称作用，最后将全局的特征进行聚合。</p><script type="math/tex; mode=display">f\left(\left\{x_{1}, \ldots, x_{n}\right\}\right) \approx g\left(h\left(x_{1}\right), \ldots, h\left(x_{n}\right)\right)</script><script type="math/tex; mode=display">f: 2^{\mathrm{R}^{N}} \rightarrow \mathbb{R}, h \quad: \mathbb{R}^{N} \rightarrow \mathbb{R}^{K}</script><p>g是一个对称函数，即maxpool；h是卷积网络；下图中的$\gamma$ 是拟合分类函数（即全连接层逼近复杂函数）。</p><p><img src="https://img-blog.csdn.net/20180507150427685?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzE1MzMyOTAz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="POINTNET原理" style="zoom:50%;"></p><p>最后的三个全连接网络，大小分别是512，256，40。最后的40输出类别。激活函数为softmax输出概率，哪个概率大则输出就是哪个类别的物体。全连接网络好理解，就是对特征点汇总为全局描述符，最后用于分类。</p><h3 id="3，POINTNET网络"><a href="#3，POINTNET网络" class="headerlink" title="3，POINTNET网络"></a>3，POINTNET网络</h3><p>T-Net的作用：我们期望通过网络学习到的表征（特征）对于这些仿射变换是不变的。</p><h4 id="3-1-Input-Transform网络"><a href="#3-1-Input-Transform网络" class="headerlink" title="3.1 Input Transform网络"></a>3.1 Input Transform网络</h4><h5 id="3-1-1-论文原理"><a href="#3-1-1-论文原理" class="headerlink" title="3.1.1 论文原理"></a>3.1.1 论文原理</h5><p>我们通过<strong>微型网络（图2中的T-net）预测仿射变换矩阵</strong>，将该变换直接应用于输入点的坐标。</p><h5 id="3-1-2-源码"><a href="#3-1-2-源码" class="headerlink" title="3.1.2 源码"></a>3.1.2 源码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">transform = input_transform_net(point_cloud, is_training, bn_decay, K=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><p>这个T-net网络也是一个类似前面的baseline模型。这里point_cloud的输入大小是(B = 32, N = 2048, 3) 。然后分别由三个卷积层，大小是64（卷积核大小1×3），128（1×1），1024（1×1），一个最大池化层，两个全连接网络组成。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'transform_XYZ'</span>) <span class="keyword">as</span> sc:</span><br><span class="line">    <span class="keyword">assert</span>(K==<span class="number">3</span>)</span><br><span class="line">    weights = tf.get_variable(<span class="string">'weights'</span>, [<span class="number">256</span>, <span class="number">3</span>*K],</span><br><span class="line">                              initializer=tf.constant_initializer(<span class="number">0.0</span>),</span><br><span class="line">                              dtype=tf.float32)</span><br><span class="line">    biases = tf.get_variable(<span class="string">'biases'</span>, [<span class="number">3</span>*K],</span><br><span class="line">                             initializer=tf.constant_initializer(<span class="number">0.0</span>),</span><br><span class="line">                             dtype=tf.float32)</span><br><span class="line">    biases += tf.constant([<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>], dtype=tf.float32)</span><br><span class="line">    transform = tf.matmul(net, weights)</span><br><span class="line">    transform = tf.nn.bias_add(transform, biases)</span><br><span class="line"></span><br><span class="line">transform = tf.reshape(transform, [batch_size, <span class="number">3</span>, K])</span><br><span class="line"><span class="keyword">return</span> transform</span><br></pre></td></tr></table></figure><p>初始化weights是(256, 9) 大小，biases大小是(9,)，biases初始化加常量。transform将net网络即卷积网络（大小是 n × 256，n是个点）于权重（大小是 256 × 9）相乘。</p><p>input transform是对空间中点云进行调整，直观上理解是旋转出一个更有利于分类或分割的角度，比如把物体转到正面。</p><h4 id="3-2-Feature-Transform网络"><a href="#3-2-Feature-Transform网络" class="headerlink" title="3.2 Feature Transform网络"></a>3.2 Feature Transform网络</h4><h5 id="3-2-1-论文原理"><a href="#3-2-1-论文原理" class="headerlink" title="3.2.1 论文原理"></a>3.2.1 论文原理</h5><p>可以在点特征（point features）上插入另一个对齐网络，并预测一个特征转换矩阵以对齐来自不同输入点云（point clouds）的特征。由于特征空间中的变换矩阵具有比空间变换矩阵高（much higher）的维数，这大大增加了优化的难度。 因此，我们在softmax训练损失中添加了一个正则化项。</p><p> 我们约束特征变换矩阵使其接近正交矩阵：</p><script type="math/tex; mode=display">L_{r e g}=\left\|I-A A^{T}\right\|_{F}^{2}</script><p>$A$ 是特征对齐矩阵（由a mini-network T-net预测的），正交变换将不会丢失输入中的信息，因此是需要的。 我们发现通过添加正则项，优化变得更加稳定，并且我们的模型获得了更好的性能。</p><p>正交变换是线性变换的一种，它从实内积空间V映射到V自身，且保证变换前后内积不变。对一个由空间投射到同一空间的线性转换，如果转换后的向量长度与转换前的长度相同，则为正交变换。这里正交变换矩阵其实就是用于点云做仿射变换的。</p><h5 id="3-1-3-源码"><a href="#3-1-3-源码" class="headerlink" title="3.1.3 源码"></a>3.1.3 源码</h5><p>1，网络部分</p><p>第二次feature transform是对提取出的64维特征进行对齐，即在特征层面对点云进行变换。</p><p>2，损失函数部分</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_loss</span><span class="params">(pred, label, end_points, reg_weight=<span class="number">0.001</span>)</span>:</span></span><br><span class="line">    <span class="string">""" pred: B*NUM_CLASSES,</span></span><br><span class="line"><span class="string">        label: B, """</span></span><br><span class="line">    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=label)</span><br><span class="line">    classify_loss = tf.reduce_mean(loss)</span><br><span class="line">    tf.summary.scalar(<span class="string">'classify loss'</span>, classify_loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Enforce the transformation as orthogonal matrix</span></span><br><span class="line">    transform = end_points[<span class="string">'transform'</span>] <span class="comment"># BxKxK</span></span><br><span class="line">    K = transform.get_shape()[<span class="number">1</span>].value</span><br><span class="line">    mat_diff = tf.matmul(transform, tf.transpose(transform, perm=[<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>]))</span><br><span class="line">    mat_diff -= tf.constant(np.eye(K), dtype=tf.float32)</span><br><span class="line">    mat_diff_loss = tf.nn.l2_loss(mat_diff) </span><br><span class="line">    tf.summary.scalar(<span class="string">'mat loss'</span>, mat_diff_loss)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> classify_loss + mat_diff_loss * reg_weight</span><br></pre></td></tr></table></figure><p>损失函数部分由两部分构成，一部分是交叉熵损失，一部分就是正则化项。</p><p>这里Transform的大小是（32,64,64）就是特征转换矩阵，把它与它的转置矩阵相乘$AA^T$。然后与对角矩阵相减 $AA^T - I$ 使这个损失变小。</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1, 开源代码 <a href="https://github.com/charlesq34/pointnet" target="_blank" rel="noopener">https://github.com/charlesq34/pointnet</a></p><p>2，1*1 的卷积核 <a href="https://zhuanlan.zhihu.com/p/40050371" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/40050371</a></p><p>3，卷积神经网络 <a href="https://zhuanlan.zhihu.com/p/47184529" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/47184529</a></p><p>4，点云POINTNET解读 <a href="https://blog.csdn.net/tumi678/article/details/80499998" target="_blank" rel="noopener">https://blog.csdn.net/tumi678/article/details/80499998</a></p><p>5，损失函数 <a href="https://blog.csdn.net/mao_xiao_feng/article/details/53382790" target="_blank" rel="noopener">https://blog.csdn.net/mao_xiao_feng/article/details/53382790</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;目录说明&quot;&gt;&lt;a href=&quot;#目录说明&quot; class=&quot;headerlink&quot; title=&quot;目录说明&quot;&gt;&lt;/a&gt;目录说明&lt;/h3&gt;&lt;p&gt;根目录下：&lt;/p&gt;&lt;p&gt;train.py用于点云分类训练&lt;/p&gt;&lt;p&gt;provider.py 用于点云的数据预处理（旋转，抖动等）&lt;/p&gt;&lt;p&gt;evaluate用于评估训练结果。&lt;/p&gt;&lt;p&gt;其他目录：&lt;strong&gt;data&lt;/strong&gt;目录下存放用于训练的样例文件h5，test_files与train_files中列举的用于训练及测试的文件路径。&lt;strong&gt;log&lt;/strong&gt; 存放的是训练结果，默认情况下只存放最近一次训练结果。&lt;strong&gt;models&lt;/strong&gt;存放的是模型文件，pointnet_cls.py（POINTNET）和pointnet_cls_basic.py（baseline模型）中的MLP是分类模型结构。pointnet_seg.py是点云分割模型网络；transform_nets.py为原始点云对称变换以及特征变换，即论文中的T-net网络。&lt;/p&gt;
    
    </summary>
    
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="三维点云" scheme="http://yoursite.com/tags/%E4%B8%89%E7%BB%B4%E7%82%B9%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>20180915pointnet论文2——实验部分</title>
    <link href="http://yoursite.com/2020/01/11/20180915pointnet%E8%AE%BA%E6%96%872/"/>
    <id>http://yoursite.com/2020/01/11/20180915pointnet%E8%AE%BA%E6%96%872/</id>
    <published>2020-01-11T02:35:05.000Z</published>
    <updated>2020-01-14T15:43:49.949Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-论文中实验"><a href="#1-论文中实验" class="headerlink" title="1 论文中实验"></a>1 论文中实验</h3><h4 id="1-1-点云分类classification"><a href="#1-1-点云分类classification" class="headerlink" title="1.1 点云分类classification"></a>1.1 点云分类classification</h4><p>数据集：ModelNet40，12311CAD模型，40个类别，9843个训练，2468测试。</p><p>我们根据网格区域对网格表面上的1024个点进行统一采样，并将其标准化为单位球体。</p><p>数据增强：1，沿上轴随机旋转对象（随机旋转 or 旋转某一角度）。2，通过具有零均值和0.02标准偏差的高斯噪声使每个点的位置抖动来动态地增加点云。</p><a id="more"></a><p>对比实验，table1中SPH[11]，3DShapeNets[28]，VoxNet[17]，Subvolume[18]，LFD[28]，MVCNN[23]（这个的平均每个类别的准确率达到了90.1%，很好诶）与我们的基模型（卷积+最大池化+全连接），PointNet（总体分类准确率89.2 %）的分类准确率比较。</p><p>比MVCNN的效果差可能原因是：认为这是由于可以通过渲染图像捕获的精细几何细节的丢失。</p><h4 id="1-2-点云零件分割"><a href="#1-2-点云零件分割" class="headerlink" title="1.2 点云零件分割"></a>1.2 点云零件分割</h4><p>3D对象零件分割零件分割是一项具有挑战性的细粒度3D识别任务。</p><p>数据集：对来自[29]的ShapeNet零件数据集进行评估，该数据集包含16个类别的16,881个形状，总共标注了50个零件。</p><p>我们将零件分割公式化为每个点的分类问题。 评估指标是按点计算。 对于类别C（如杯子）的每个形状S（杯柄与内杯），要计算形状S的mIoU：<strong>如果groundtruth（真实标记）和预测点的并集为空，则将零件IoU计为1</strong>。然后，我们对类别C中所有零件类型的IoU进行平均，以得到该形状的mIoU。 要计算类别的mIoU，我们对该类别中所有形状的mIoU取平均值。</p><p>Table2，我们报告每个类别，并表示IoU（％）得分。 我们观察到平均IoU改善了2.3％，我们的网络在大多数类别中都超过了基本方法。</p><h4 id="1-3-场景语义分割"><a href="#1-3-场景语义分割" class="headerlink" title="1.3 场景语义分割"></a>1.3 场景语义分割</h4><p>零件分割网络扩展到场景语义分割。其中点标签成为语义对象类（semantic object class），而不是对象零件标签（object part label）。</p><p>数据集：斯坦福3D语义分割数据集上进行了实验[1]。 数据集包含来自6个区域（包括271个房间）的Matterport扫描仪的3D扫描。 扫描中来自13个类别（椅子，桌子，地板，墙壁等，加上混乱）的每个点都有语义标签进行标注。</p><p>为了准备训练数据，首先按房间来划分points，然后将房间采样为面积为1m x 1m的块。我们训练PointNet的分割segmentation版本以预测每个块中的每个点类。</p><p>在训练时，我们会在每个飞行块中随机抽取4096个点。在测试时，我们对所有方面进行测试。我们将我们的方法与使用手工制作的点特征的基线进行比较。基线提取相同的9-dim局部特征和三个附加特征：局部点密度，局部曲率和法线。我们使用标准的MLP作为分类器。结果显示在表3中，其中我们的PointNet方法明显优于基线方法。</p><h3 id="2-我的理解"><a href="#2-我的理解" class="headerlink" title="2 我的理解"></a>2 我的理解</h3><p>1，卷积的过程</p><p>如何对点进行卷积，提取关键点（信息点）</p><p>在卷积的时候，把点云看做是（2048,3,1）的一张灰度图来进行卷积计算。但第一步的卷积核大小是(1,3)  是对点进行计算，提取他的特征点。后续的卷积卷积核也是(1,1)的，也是提取一些关键点。</p><p><img src="/images/20200114POINTNET_CNN.png" alt="20200114POINTNET_CNN"></p><p>2，对称函数 max pool的作用</p><p>解决无序性问题（为什么可以解决无序性）</p><p>原生的PointNet就是这样一种g函数。使用multi-layer perceptron (MLP) 和 max pooling 来建模g函数。</p><p>3，相邻点的交互信息必须考虑进去（通过共享的MLP或者2D卷积解决）：解决相邻点之间的关联信息问题？</p><p>4，网络结构中的T-net作用</p><p>论文中指的是将输入点和特征进行对齐、适用于刚性or仿射变换。</p><p>通过<strong>微型网络（图2中的T-net）预测仿射变换矩阵</strong>（仿射变换前是直线，仿射变换后还是直线，直线比例保持不变。），并将该变换直接应用于输入点的坐标。why？</p><p>其中的正则化项？ 我们约束特征变换矩阵使其接近正交矩阵？</p><p>避免n! 排列</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-论文中实验&quot;&gt;&lt;a href=&quot;#1-论文中实验&quot; class=&quot;headerlink&quot; title=&quot;1 论文中实验&quot;&gt;&lt;/a&gt;1 论文中实验&lt;/h3&gt;&lt;h4 id=&quot;1-1-点云分类classification&quot;&gt;&lt;a href=&quot;#1-1-点云分类classification&quot; class=&quot;headerlink&quot; title=&quot;1.1 点云分类classification&quot;&gt;&lt;/a&gt;1.1 点云分类classification&lt;/h4&gt;&lt;p&gt;数据集：ModelNet40，12311CAD模型，40个类别，9843个训练，2468测试。&lt;/p&gt;&lt;p&gt;我们根据网格区域对网格表面上的1024个点进行统一采样，并将其标准化为单位球体。&lt;/p&gt;&lt;p&gt;数据增强：1，沿上轴随机旋转对象（随机旋转 or 旋转某一角度）。2，通过具有零均值和0.02标准偏差的高斯噪声使每个点的位置抖动来动态地增加点云。&lt;/p&gt;
    
    </summary>
    
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="三维点云" scheme="http://yoursite.com/tags/%E4%B8%89%E7%BB%B4%E7%82%B9%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>20180914pointnet论文1——论文部分</title>
    <link href="http://yoursite.com/2020/01/08/20180914pointnet%E8%AE%BA%E6%96%871/"/>
    <id>http://yoursite.com/2020/01/08/20180914pointnet%E8%AE%BA%E6%96%871/</id>
    <published>2020-01-08T12:26:29.000Z</published>
    <updated>2020-01-15T14:05:32.493Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-Abs-amp-Intro"><a href="#1-Abs-amp-Intro" class="headerlink" title="1 Abs &amp; Intro"></a>1 Abs &amp; Intro</h3><p>点云是一种重要的几何数据结构（自动驾驶的数据），由于不规则性许多研究者之前用3D体素网络 voxel grids（体积CNN：[28、17、18]是在体素化形状上应用3D卷积神经网络的先驱。由于数据稀疏性和3D卷积的计算成本，体积表示受到其分辨率的限制。）或图片集合（将点云数据投影到二维平面，扩展性以及提取特征的表示能力的限制。）来进行识别，但这使得数据变庞大，引入了量化伪像，这些伪像会掩盖数据的自然不变性。</p><a id="more"></a><p>本文设计了一种新颖的神经网络，直接输入点云，该网络很好地考虑了输入中点的排列不变性（点云是无序向量集。）。POINTNET可以用于分类，零件分割，场景语义分割等。典型的卷积体系结构需要高度规则的输入数据格式，例如图像网格或3D体素，以执行权重共享和其他内核优化。点云是简单统一的结构，避免了网格的组合不规则性和复杂性，因此更易于学习。但是，PointNet仍然必须尊重这样一个事实，即点云只是一组点，因此其成员的排列是不变的，因此在网络计算中必须具有一定的对称性。</p><p><strong>（核心原理）我们方法的关键是使用一个简单的对称函数，即最大池化max pool。 网络有效地学习了一组最优标准，它选择了点云的有趣点或信息点，并对选择它们的原因进行了编码。</strong> 网络的最终全连接层将这些学习的最优值汇总到整个描述符的全局描述符中（如上所述）（形状分类），或用于预测每个点云的类别标签（形状分割）。我们的网络<strong>学会了通过稀疏的一组关键点来总结输入点云，根据可视化，这些关键点大致对应于对象的骨架。</strong></p><p>我们的输入格式易应用于刚性或仿射变换，因为每个点都是独立变换的。 因此，我们可以添加一个依赖数据的空间转换器网络，该网络尝试在PointNet处理数据之前对数据进行规范化，以进一步改善结果。</p><p>文章主要贡献：</p><p>1，我们设计了可以直接对3D无序点云处理的深度网络架构。</p><p>2，这个网络如何被训练执行3D形状分类，零件分割和场景分割。</p><p>3，经验与理论分析其稳定性与有效性。</p><p>4，说明选定的神经元在网络中计算出的3D特征，并对其性能进行直观的解释。</p><h3 id="2-Problem-Statement"><a href="#2-Problem-Statement" class="headerlink" title="2 Problem Statement"></a>2 Problem Statement</h3><p>深度学习架构，直接将无序点云输入。一个点云表示为3D点的集合$\left\{P_{i} | i=1, \dots, n\right\}$，其中每个点$P_i$ 是其坐标(x,y,z) 的坐标（也可以加上另外的特征，如颜色，法向量等）。</p><p>对于对象分类任务，可以直接从形状中采样输入点云，也可以从场景点云中预先分割输入点云。 我们建议的深度网络针对所有k个候选类输出k个分数。</p><p> 对于语义分割，输入可以是用于部分零件区域分割的单个对象，也可以是3D场景中的用于对象区域分割。 我们的模型输出n×m分数，即输出每个点（一共n个）的每一个m个语义子类别。</p><h3 id="3-点集上的深度学习"><a href="#3-点集上的深度学习" class="headerlink" title="3 点集上的深度学习"></a>3 点集上的深度学习</h3><h4 id="3-1-点集属性"><a href="#3-1-点集属性" class="headerlink" title="3.1 点集属性"></a>3.1 点集属性</h4><p>1，无序性。 与图像中的像素阵列或体积网格中的体素阵列不同，点云是一组没有特定顺序的点。换句话说，消耗N个3D点集的网络需要对于输入集的N个排列按数据馈送顺序保持不变。（无论点如何顺序输入，都要能够识别）</p><p>2，点之间的相互作用。 这些点来自具有距离度量的空间。 这意味着这些点不是孤立的，相邻点形成一个有意义的子集。 因此，模型需要能够从附近的点捕获局部结构，以及局部结构之间的组合相互作用。</p><p>3，变换下的不变性。 作为几何对象，学习到的点集表示应不变于某些变换。 例如，一起旋转和平移点都不应修改全局点云类别或点的分割。</p><h4 id="3-2-点云架构"><a href="#3-2-点云架构" class="headerlink" title="3.2 点云架构"></a>3.2 点云架构</h4><p><img src="/images/20180914pointnet.jpg" alt="20180914pointnet"></p><p>我们的网络具有<strong>三个关键模块：最大池层（作为对称函数，用于汇总来自所有点的信息），一个局部和全局信息组合结构，以及两个对齐输入点集和点特征的联合对齐网络。</strong></p><h5 id="3-2-1-无序输入的对称函数！！！"><a href="#3-2-1-无序输入的对称函数！！！" class="headerlink" title="3.2.1 无序输入的对称函数！！！"></a>3.2.1 无序输入的对称函数！！！</h5><p>为了使模型对输入排列不变，存在以下三种策略：</p><p>1）按规范顺序对输入进行排序； </p><p>尽管排序听起来很简单，但实际上在高维空间中不存在稳定的排序，关于一般意义上的点扰动。 矛盾很容易说明。 如果存在这种排序策略，它将在高维空间和1d实线之间定义一个双射映射（输入的点不论顺序，通过一一对应的函数映射到高维空间）。 不难发现，关于点扰动要求顺序是稳定的，就等同于要求此映射随着维度减小而保留空间邻近性，这是一般情况下无法实现的任务。</p><p>因此，排序无法完全解决ordering问题，并且随着ordering问题的持续存在，网络很难学习从输入到输出的一致映射。 如实验所示（图5），我们发现直接在排序点集上应用MLP效果较差，尽管比直接处理未排序的输入要好一些。</p><p>2）将输入作为训练RNN的序列，但通过各种排列来增强训练数据； </p><p>使用RNN的想法将点集视为序列信号，并希望通过用随机排列的序列训练RNN，RNN将对输入顺序不变。 但是，在“ OrderMatters” [25]中，作者表明顺序确实很重要，不能完全省略。 尽管RNN对长度较短（数十个）的序列的输入排序具有相对较好的鲁棒性，但很难扩展到数千个输入元素，这是点集的常见大小。 根据经验，我们还表明，基于RNN的模型的性能不如我们提出的方法。</p><p>3）使用简单的<strong>对称函数</strong>汇总每个点的信息。 在此，对称函数将n个向量作为输入，并输出一个与输入顺序不变的新向量。 例如，+和∗运算符是对称二进制函数。</p><script type="math/tex; mode=display">f\left(\left\{x_{1}, \ldots, x_{n}\right\}\right) \approx g\left(h\left(x_{1}\right), \ldots, h\left(x_{n}\right)\right)</script><script type="math/tex; mode=display">f: 2^{\mathrm{R}^{N}} \rightarrow \mathbb{R}, h \quad: \mathbb{R}^{N} \rightarrow \mathbb{R}^{K}</script><p>g是一个对称函数。</p><p><strong>基本思想</strong>：从经验上讲，我们的基本模块非常简单，我们通过多层感知器网络近似模拟h函数，通过单个变量函数和最大池函数的组合来近似g。 通过实验发现这种方法效果很好。 通过收集h，我们可以学习多个f来捕获集合的不同属性。</p><h5 id="3-2-2-分类、分割"><a href="#3-2-2-分类、分割" class="headerlink" title="3.2.2 分类、分割"></a>3.2.2 分类、分割</h5><p><strong>点云的分类</strong>：轻松地在形状全局特征向量上训练SVM或多层感知器分类器以进行分类。</p><p><strong>点云的分割</strong>：需要结合局部信息和全局信息。将全局特征向量与每一个点的特征联合起来再送回每个点特征（feed it back to per point features）。再基于此提取每个新点的特征，这样每个点特征既了解本地信息又了解全局信息。（个人理解：由于需要对逐点的语义分割，所以将<em>global feature</em> 与每一点的feature向量连接，作用是使每一个点都同时具有自身点的feature和global feature，更有利于进行逐点的分类。）</p><p>（附录）分割网络是分类网络的扩展。局部特征（第二个feature transform T-net 网络输出）和全局特征（最大池化的输出）联合到一起 for each point。分割网络没有Dropout，训练参数与分类网络一样。输出是每n个点的每一个m个语义子类别。</p><p>对比实验：3D CNN Segmentation Network 模型：对于给定的点云，我们首先将其转换为具有32×32×32分辨率的占用网格的体积表示形式。然后，依次应用五个3D卷积运算，每个具有32个输出通道，步幅为1。 每个体素的感受野为19。 最后，将内核大小为1×1×1的3D卷积层序列附加到计算的特征图中，以预测每个体素的分割标签。</p><p><img src="/images/20200111_3DCNN.jpg" alt="20200111_3DCNN"></p><p>（附录）<strong>零件part分割</strong>。我们添加了一个ont-hot向量表明输入的类别，并将它和最大池化层的输出拼接。我们还在某些层layer增加神经元并添加了跳过链接以收集不同层中的局部点特征，并将它们连接起来以形成点特征输入到分割网络中。</p><p><img src="/images/20200111PartSegmentation.jpg" alt="20200111PartSegmentation"></p><p>通过这种修改，我们的网络能够预测依赖于局部几何和全局语义的每点数量。 例如，我们可以准确地预测每个点的法线（补充图），从而验证网络能够汇总该点的局部邻域的信息？。 </p><h5 id="3-2-3-对齐网络-Joint-Alignment-Network"><a href="#3-2-3-对齐网络-Joint-Alignment-Network" class="headerlink" title="3.2.3 对齐网络 Joint Alignment Network"></a>3.2.3 对齐网络 Joint Alignment Network</h5><p>如果点云经过某些几何变换（例如刚性变换），则该点云的语义标记必须不变。因此，我们期望通过网络学习到的表征（特征）对于这些变换是不变的。</p><p>我们通过<strong>微型网络（图2中的T-net）预测仿射变换矩阵</strong>（仿射变换前是直线，仿射变换后还是直线，直线比例保持不变。如平移，翻转，拉伸变换等），并将该变换直接应用于输入点的坐标。 T-net网络本身类似于大型网络，由点独立特征提取（point independent feature extraction），最大池化和完全连接层的基本模块组成。 </p><p>这个想法也可以进一步扩展到特征空间的对齐。 我们可以在点特征（point features）上插入另一个对齐网络，并预测一个特征转换矩阵以对齐来自不同输入点云（point clouds）的特征（理解：对齐特征有利于分类）。 然而，特征空间中的变换矩阵具有比空间变换矩阵高（much higher）的维数，这大大增加了优化的难度。 因此，我们在softmax训练损失中添加了一个正则化项。 我们约束特征变换矩阵使其接近正交矩阵</p><script type="math/tex; mode=display">L_{r e g}=\left\|I-A A^{T}\right\|_{F}^{2}</script><p>$A$ 是特征对齐矩阵（由a mini-network T-net预测的），正交变换将不会丢失输入中的信息，因此是需要的。 我们发现通过添加正则项，优化变得更加稳定，并且我们的模型获得了更好的性能。</p><h6 id="3-2-3-1-附录部分解释Network-Architecture-and-Training-Details"><a href="#3-2-3-1-附录部分解释Network-Architecture-and-Training-Details" class="headerlink" title="3.2.3.1 附录部分解释Network Architecture and Training Details"></a>3.2.3.1 附录部分解释Network Architecture and Training Details</h6><p>1，第一个 input transform T-net微型网络是一个minit-PointNet，输入是原始点集并回归到3 * 3大小的矩阵。他是由在每个点上的共享MLP（64，128，1024即CNN）组成，一个最大池化层，两个大小为512，256的全连接网络组成。输出矩阵被初始化为单位矩阵。除最后一层外，所有层均包括ReLU和批处理规范化（batch normalization）。</p><p>2，第二层feature transform T-net微型网络与第一个有相同的结构。除了输出是64*64大小的矩阵。矩阵也是被初始化为单位矩阵。将正则化损失（权重为0.001）添加到softmax分类损失中，以使矩阵接近正交。</p><h3 id="4-理论分析"><a href="#4-理论分析" class="headerlink" title="4 理论分析"></a>4 理论分析</h3><h4 id="4-1-函数逼近"><a href="#4-1-函数逼近" class="headerlink" title="4.1 函数逼近"></a>4.1 函数逼近</h4><p>令$\mathcal{X}=\left\{S: S \subseteq[0,1]^{m} \text { and }|S|=n\right\}$，$f: \mathcal{X} \rightarrow \mathbb{R}$ 是一个在$\mathcal{X}$ 上关于豪斯多夫距离的连续集合函数（set function），即$\forall \epsilon&gt;0, \exists \delta&gt;0, \text { for any } S, S^{\prime} \in \mathcal{X}$，如果$d_{H}\left(S, S^{\prime}\right)&lt;\delta$ ，则$\left|f(S)-f\left(S^{\prime}\right)\right|&lt;\epsilon$。我们的定理说，在最大池化层有足够的神经元的情况下，我们的网络可以任意近似f。PointNet模型的表征能力和maxpooling操作输出的数据维度(K)相关，K值越大，模型的表征能力越强。</p><p>Theorem 1：假设$f: \mathcal{X} \rightarrow \mathbb{R}$ 是一个关于豪斯多夫距离 $d_{H}(\cdot, \cdot)$ 的连续集合函数，对$\forall \epsilon&gt;0, \exists$ 一个连续函数 $h$ 和一个对称函数 $g\left(x_{1}, \ldots, x_{n}\right)=\gamma \circ M A X$，对任何$S \in \mathcal{X}$ ，</p><script type="math/tex; mode=display">\left|f(S)-\gamma\left(\underset{x_{i} \in S}{\operatorname{MAX}}\left\{h\left(x_{i}\right)\right\}\right)\right|<\epsilon</script><p>此处 $x_1, \dots,x_n$ 是任意顺序的S的全部元素。$\gamma$ 是一个连续函数，MAX是一个向量最大操作。</p><p>定理证明看论文补充材料（ supplementary material. ）</p><p>个人理解：表达式的意思是可以找出一个函数r，向量元素$x_i$经过$h$，足够多的神经元的MAX操作和r函数后任意近似原函数 $f(S)$，而$h$  在文章里值的是许多的卷积函数，MAX是最大池化函数，r是全连接分类映射网络。原函数$f(S)$ 可以想成是S是原所有点的特征空间，f是对原特征空间映射为点云物体的函数。</p><h4 id="4-2-瓶颈与稳定性"><a href="#4-2-瓶颈与稳定性" class="headerlink" title="4.2 瓶颈与稳定性"></a>4.2 瓶颈与稳定性</h4><p>理论上和实验上，我们发现网络的表现力受到最大池化层的尺寸（即（1）中的K）的强烈影响。</p><p>定义：$\mathbf{u}=\underset{x_{i} \in S}{\operatorname{MAX}}\left\{h\left(x_{i}\right)\right\}$ 是f的子网络，它映射 a point set in $[0,1]^m$ 为K维的向量。输入集中的小损坏或额外的噪声点不太可能改变网络的输出：</p><p>Theorem 2：假设$\mathbf{u}: \mathcal{X} \rightarrow \mathbb{R}^{K}$ ，$\mathbf{u} = {MAX}_{x_{i} \in S}\left\{h\left(x_{i}\right)\right\}$ 且 $f=\gamma \circ \mathbf{u}$ ，则：</p><script type="math/tex; mode=display">\text { (a) } \forall S, \exists \mathcal{C}_{S}, \mathcal{N}_{S} \subseteq \mathcal{X}, f(T)=f(S) \text { if } \mathcal{C}_{S} \subseteq T \subseteq \mathcal{N}_{S}</script><script type="math/tex; mode=display">(b)\left|\mathcal{C}_{S}\right| \leq K</script><p>a说明对于任何输入数据集S，可以找到最小集Cs和一个最大集Ns，使得对Cs和Ns之间的任何集合T，其网络输出都和S一样。模型对输入数据在有噪声(引入额外的数据点，趋于Ns)和有数据损坏(缺少数据点，趋于Cs)的情况都是<strong>鲁棒</strong>的。定理2(b)说明了最小集Cs的数据多少由maxpooling操作输出数据的维度K给出上界。</p><p>直观地，我们的网络学习通过稀疏的关键点来总结形状。在实验部分，我们看到关键点形成了对象的骨架。（实验部分请参考下一篇博客）</p><h3 id="5-PointNet-改进部分"><a href="#5-PointNet-改进部分" class="headerlink" title="5 PointNet++改进部分"></a>5 PointNet++改进部分</h3><p>简单说一下POINTNET的缺点是没有考虑点之间的局部关系。POINTNET++ 进行了改进。</p><p>提取一个点的局部特征。一个图片像素点的局部是其周围一定曼哈顿距离下的像素点，通常由卷积层的卷积核大小确定。同理，点云数据中的一个点的局部由其周围给定半径划出的球形空间内的其他点构成。组合层的作用就是找出通过采样层后的每一个点的所有构成其局部的点，以方便后续对每个局部提取特征。</p><p>特征提取层（feature learning）：因为PointNet给出了一个基于点云数据的特征提取网络，因此可以用PointNet对组合层给出的各个局部进行特征提取来得到局部特征。</p><p>分组层，在上一层提取出的中心点的某个范围内寻找最近个k近邻点组成patch；特征提取层是将这k个点通过小型pointnet网络进行卷积和pooling得到的特征作为此中心点的特征，再送入下一个分层继续。</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，知乎PointNet解读 <a href="https://zhuanlan.zhihu.com/p/44809266" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/44809266</a></p><p>2，Point perception <a href="http://mech.fsv.cvut.cz/~dr/papers/CC05/node6.html" target="_blank" rel="noopener">http://mech.fsv.cvut.cz/~dr/papers/CC05/node6.html</a></p><p>3，仿射变换概念：<a href="https://www.zhihu.com/question/20666664" target="_blank" rel="noopener">https://www.zhihu.com/question/20666664</a></p><p>4，豪斯多夫距离 <a href="https://www.cnblogs.com/icmzn/p/8531719.html" target="_blank" rel="noopener">https://www.cnblogs.com/icmzn/p/8531719.html</a> （即 A集合中的任一点ai 到集合B中的任意点的最短的距离di，然后在这些距离di中选择距离<strong>最长（远）</strong>的，即作为两个集合A与B之间的Hausdoff Distance。豪斯多夫距离量度度量空间中紧子集之间的距离。）</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-Abs-amp-Intro&quot;&gt;&lt;a href=&quot;#1-Abs-amp-Intro&quot; class=&quot;headerlink&quot; title=&quot;1 Abs &amp;amp; Intro&quot;&gt;&lt;/a&gt;1 Abs &amp;amp; Intro&lt;/h3&gt;&lt;p&gt;点云是一种重要的几何数据结构（自动驾驶的数据），由于不规则性许多研究者之前用3D体素网络 voxel grids（体积CNN：[28、17、18]是在体素化形状上应用3D卷积神经网络的先驱。由于数据稀疏性和3D卷积的计算成本，体积表示受到其分辨率的限制。）或图片集合（将点云数据投影到二维平面，扩展性以及提取特征的表示能力的限制。）来进行识别，但这使得数据变庞大，引入了量化伪像，这些伪像会掩盖数据的自然不变性。&lt;/p&gt;
    
    </summary>
    
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="三维点云" scheme="http://yoursite.com/tags/%E4%B8%89%E7%BB%B4%E7%82%B9%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>LightGBM_paper</title>
    <link href="http://yoursite.com/2020/01/03/20200103LightGBM-paper/"/>
    <id>http://yoursite.com/2020/01/03/20200103LightGBM-paper/</id>
    <published>2020-01-03T13:16:46.000Z</published>
    <updated>2020-01-07T08:04:49.187Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-摘要简介"><a href="#1-摘要简介" class="headerlink" title="1 摘要简介"></a>1 摘要简介</h3><h4 id="1-1-简介"><a href="#1-1-简介" class="headerlink" title="1.1 简介"></a>1.1 简介</h4><p>GBDT的实现有XGBoost，pGBRT等。但当特征维度高，数据集size大的时候有效性还不够。主要原因在于对每一个特征，都要扫描所有实例并估计所有可能的划分节点的信息增益。</p><p>LightGBM提出的方法是：Gradient-based one-side sampling (GOSS) ，Exclusive feature bundling (EFB)。</p><a id="more"></a><h4 id="1-2-GOSS"><a href="#1-2-GOSS" class="headerlink" title="1.2 GOSS"></a>1.2 GOSS</h4><p>GOSS的作用排除相当一部分小的梯度的数据实例（instance），只使用剩下的来估计信息增益。<strong>更大的梯度的数据实例在计算信息增益上起到更重要的作用</strong>。</p><p>GBDT中没有数据实例权重。但具有不同梯度的数据实例在信息增益的计算中起着不同的作用。根据信息增益的定义，<u>那些具有较大梯度的实例（即训练不足的实例）将为信息增益做出更大的贡献</u>。下采样那些梯度大的实例（阈值or百分比），并随机丢弃那些小的梯度的实例。</p><h4 id="1-3-EFB的作用"><a href="#1-3-EFB的作用" class="headerlink" title="1.3 EFB的作用"></a>1.3 EFB的作用</h4><p>EFB的作用：捆绑互斥特征（即，他们很少同时采用非零值）贪心策略来找最优互斥特征。</p><p>现实中，特征空间稀疏。这为我们提供了一种设计几乎无损方法以减少有效特征数量的可能性。在稀疏特征空间中，许多特征几乎是互斥的，即他们很少同时采用非零值（文本挖掘里one hot词表征）。我们可以很安全的捆绑这些互斥特征。</p><p>设计了一个以恒定近似比率的贪心算法将最优特征捆绑问题转换为图着色问题。通过将特征作为顶点并为每两个特征（如果它们之间不是互斥的话）添加边。</p><p><strong>而Hitogram算法的主要作用是减少候选分裂点数量，GOSS算法的作用是减少样本的数量，EFB算法的作用是减少特征的数量。</strong></p><h3 id="2-GBDT回顾"><a href="#2-GBDT回顾" class="headerlink" title="2 GBDT回顾"></a>2 GBDT回顾</h3><p>GBDT是决策树的集成模型。每次迭代GBDT通过拟合负梯度（残差）学习决策树。他的主要成本是在于学习决策树。划分节点的选择是非常耗时的，之前有预排序算法，它每次枚举所有可能的划分点，基于预排序的特征值，从而找到最优划分节点。</p><p>另一种是基于直方图的算法。他将连续特征值分桶为离散的bins，利用bins来构建特征直方图。（内存消耗更少，训练速度更快）。直方图建立是 O(#data <em> #feature)，划分节点是 O(#bin </em> #feature)。</p><p>实际应用中使用的大规模数据集通常很少。 带有预排序算法的GBDT可以通过忽略零值的特征来降低训练成本[13]。 但是，具有基于直方图的算法的GBDT没有有效的稀疏优化解决方案。 原因是，无论特征值是否为零，基于直方图的算法都需要为每个数据实例检索特征仓值（请参阅算法1）。</p><p><img src="/images/20200104GBDT_Algo.jpg" alt="20200104GBDT_Algo"></p><p><center>图1</center></p><h4 id="2-1-直方图算法"><a href="#2-1-直方图算法" class="headerlink" title="2.1 直方图算法"></a>2.1 直方图算法</h4><p><img src="/images/20200105Histogram.jpg" alt="20200105Histogram"></p><p><center>图2</center><br>for node in nodeSet (for all leaf p in Tc-1(x)) 这里是对当前层的叶子节点遍历。（需要遍历所有的特征，来找到增益最大的特征及其划分值，以此来分裂该叶子节点。）</p><p>for k=1 to m (for all f in X.Features) 这里是对所有特征进行遍历。<strong>对于每个特征，为其创建一个直方图</strong>。</p><p>for j in usedRows do ( for i in (0, num_of_row)) 这里是对此节点的样本row进行统计计算。这个直方图存储了两类信息，分别是每个bin中样本的梯度之和 $H[f \cdot b i n s[i]] \cdot g$, 还有就是每个bin中样本数量$H[f . \text { bins }[i]] . n$ 。下面图2的循环 for i in (0, len(H)) 是遍历所有bin，分别以当前bin作为分割点，累加其左边的bin至当前bin的梯度和$S_L$以及样本数量$n_L$，与父节点的梯度和$S_p,n_p$ 相减得到右边的。</p><p>然后计算增益，在遍历过程中取最大的增益，以此时的特征和bin的特征值作为分裂节点的特征和分裂特征取值。</p><p>连续特征的分桶和离散特征的分桶是不一样的。先把连续的浮点特征值离散化成k个整数（其实又是分桶的思想，而这些桶称为bin，比如[0,0.1)→0, [0.1,0.3)→1），同时构造一个宽度为k的直方图。离散特征直接对特征的每个取值进行计数。即LightGBM可以直接将<strong>每个类别取值和一个bin关联</strong>，从而自动地处理它们，而无需预处理成onehot编码多此一举。</p><p>对比Xgboost的预排序算法：预排序算法首先将样本按照特征取值排序，然后从全部特征取值中找到最优的分裂点位，该算法的候选分裂点数量与样本数量成正比。</p><h3 id="3-Gradient-based-One-side-Sampling"><a href="#3-Gradient-based-One-side-Sampling" class="headerlink" title="3 Gradient-based One-side Sampling"></a>3 Gradient-based One-side Sampling</h3><p>在AdaBoost中，样本权重可以很好地表明数据实例的重要性。但GBDT里面就没有这个权重，但我们注意到GBDT中每个数据实例的梯度为我们提供了有用的数据采样信息。如果实例与较小的坡度关联，则该实例的训练误差很小，并且已经过良好训练。 一个简单的主意是丢弃那些梯度小的数据实例。 但是，这样做会改变数据分布，这会损害学习模型的准确性。 为避免此问题，我们提出基于梯度的单边采样（GOSS）。</p><p>GOSS保留所有具有大梯度的实例，并对具有小梯度的实例执行随机采样。为了补偿对数据分布的影响，在计算信息增益时，GOSS为具有较小梯度的数据实例引入了一个常数乘法器（constant multiplier）。</p><p>GOSS首先根据数据实例的梯度绝对值进行排序，选出最高的a%的实例。随机从剩余的数据实例中采样出 b% 的数据。GOSS放大采样的梯度较小的数据实例，乘常量因子$\frac{1-a}{b}$。</p><h4 id="3-1-理论分析"><a href="#3-1-理论分析" class="headerlink" title="3.1 理论分析"></a>3.1 理论分析</h4><p>$\mathcal{X}$ 输入空间</p><p>$\mathcal{G}$ 是梯度空间</p><p>$n$ 是样本实例个数。</p><p>$\{g_1,g_2…g_n\}$ 是损失函数关于模型输出（即$f_{m-1}的预测值$）的负梯度。</p><p>对于GBDT，信息增益经常是由划分后的方差度量的。</p><p>定义：令$O$ 是在决策树的一个固定节点的训练数据集training dataset，划分特征 $j$ 在点 $d$ （我的理解是特征取值d）的方差增益定义是（理解一下就是划分的两边的平均负梯度的平方的平均）：</p><script type="math/tex; mode=display">V_{j | O}(d)=\frac{1}{n_{O}}\left(\frac{\left(\sum_{\left\{x_{i} \in O: x_{i j} \leq d\right\}} g_{i}\right)^{2}}{n_{l | O}^{j}(d)}+\frac{\left(\sum_{\left\{x_{i} \in O: x_{i j}>d\right\}} g_{i}\right)^{2}}{n_{r | O}^{j}(d)}\right)</script><script type="math/tex; mode=display">n_{O}=\sum I\left[x_{i} \in O\right], n_{l | O}^{j}(d)=\sum I\left[x_{i} \in O: x_{i j} \leq d\right] \text { and } n_{r | O}^{j}(d)=\sum I\left[x_{i} \in O: x_{i j}>d\right]</script><p>对于特征 $j$ ，决策树算法选择：</p><script type="math/tex; mode=display">d_{j}^{*}=\operatorname{argmax}_{d} V_{j}(d)</script><p>并计算最大增益：$V_{j}\left(d_{j}^{*}\right)$</p><p>然后数据由特征 $j^{\star}$ 在划分点 $d_{j^{\star}}$ 为左右子节点。</p><p>在我们提出的GOSS方法中，首先，我们将训练实例根据其梯度的绝对值按降序排列。然后保存前 $a * 100%$ 的数据实例子集 $A$ ，剩下的数据 $A^c$ 是随机采样大小为 $b \times\left|A^{c}\right|$子集$B$。 最后通过在数据 $A \cup B$对估计的方差增益 $\tilde{V}_{j}(d)$ 划分数据实例</p><script type="math/tex; mode=display">\tilde{V}_{j}(d)=\frac{1}{n}\left(\frac{\left(\sum_{x_{i} \in A_{l}} g_{i}+\frac{1-a}{b} \sum_{x_{i} \in B_{l}} g_{i}\right)^{2}}{n_{l}^{j}(d)}+\frac{\left(\sum_{x_{i} \in A_{r}} g_{i}+\frac{1-a}{b} \sum_{x_{i} \in B_{r}} g_{i}\right)^{2}}{n_{r}^{j}(d)}\right)</script><script type="math/tex; mode=display">A_{l}=\left\{x_{i} \in A: x_{i j} \leq d\right\}, A_{r}=\left\{x_{i} \in A: x_{i j}>d\right\}, B_{l}=\left\{x_{i} \in B: x_{i j} \leq d\right\}, B_{r}=\left\{x_{i} \in B: x_{ij} > d \}\right.</script><p>该系数$\frac{1-a}{b}$用于将B上的梯度总和归一化为A的大小，GOSS放大采样的梯度较小的数据实例。</p><h3 id="4-Exclusive-feature-Bundling"><a href="#4-Exclusive-feature-Bundling" class="headerlink" title="4 Exclusive feature Bundling"></a>4 Exclusive feature Bundling</h3><p>目的：减少特征数量。</p><p>高维数据经常是稀疏的，特征空间的稀疏性为我们提供了一种设计几乎无损方法以减少特征数量的可能性。在稀疏的特征空间中，许多特征是互斥的，即它们永远不会同时采用非零值（意思是所有样本在这两特征的取值不是同时采用非零值，这个很像我之前看的HTM里的SDR），因此可以绑定这俩特征为一个单特征。</p><p>可以有趣的是，对于类别特征，如果转换成onehot编码，则这些onehot编码后的多个特征相互之间是互斥的，从而可以被捆绑成为一个特征。we can build the same feature histograms from the feature bundles as those from individual features. </p><h4 id="4-1-绑哪些feature"><a href="#4-1-绑哪些feature" class="headerlink" title="4.1 绑哪些feature"></a>4.1 绑哪些feature</h4><p>背景图着色问题：给顶点着色，相连的顶点颜色都不同，最少需要多少颜色，这是NP难问题。</p><p>给定$G = (V,E)$。$V$ 是特征数，通过将特征作为顶点并为每两个特征（如果它们之间不是互斥的话）添加边。则互斥特征是有着相同颜色的节点。最后采用贪心策略来产生bundle。</p><p><img src="/images/20200105EFB.jpg" alt="20200105EFB"></p><p>算法过程：</p><p>1,首先，我们构造一个具有加权边的图，其权重对应于特征之间的总冲突（特征并不是100%的互斥，只要很少很少的同时为非零值也可 allow a small fraction of conflicts）。 </p><p>2, 其次，我们按特征在图中的度（degrees ）降序对特征进行排序。 </p><p>3, 最后，我们依次检查排序列表中的每个feature，要么将其分配给冲突很小（由γ控制）的现有bundle，或创建一个新包bundle。 Alg.3 的时间复杂度是$O(feature^2)$，在训练之前仅处理一次使得操作之后的总体冲突最小。</p><p>​    当特征数量不是很大时，这种复杂性是可以接受的，但如果有数百万个特征，则可能仍然会受到影响。 为了进一步提高效率，我们提出了一种更有效的排序策略，而无需构建图表：通过非零值的计数进行排序，这类似于按度排序，因为更多的非零值通常会导致发生冲突的可能性更高（类似于根据度degree排序）。</p><h4 id="4-2-如何捆绑bundle"><a href="#4-2-如何捆绑bundle" class="headerlink" title="4.2 如何捆绑bundle"></a>4.2 如何捆绑bundle</h4><p>对于第二个问题，我们需要一种很好的方法来合并同一捆绑bundle中的特征，以减少相应的训练复杂性。 关键是要确保可以从feature bundles中识别原始feature的值。</p><p>由于基于直方图的算法存储的是离散的bins而不是特征feature的连续值，因此我们可以通过让互斥特征驻留在不同的bins中来构造feature bundle。 这可以通过向特征原始值添加偏移量来完成。 例如，假设我们在feature bundle中有两个特征。 最初，特征A取值[0，10），特征B取值[0，20）。 然后，我们向特征B的值添加10的偏移量，以使经过改进的特征采用[10，30）中的值。 之后，可以安全地合并特征A和B，并使用范围为[0，30]的feature bundle替换原始特征A和B。详细算法在Alg 4。</p><p>EFB算法可以将许多互斥特征捆绑到少得多的密集特征上，从而可以<strong>有效避免零特征值</strong>的不必要计算。</p><p>实际上，我们还可以优化基本的基于直方图的算法，通过为每个特征使用一个表table 记录具有非零值的数据来忽略零特征值。 通过扫描此表中的数据，构建功能的直方图的成本将从$O(data)$变为$O(non-zero-data)$。 但是，此方法需要额外的内存和计算成本才能在整个树生长过程中维护这些per-feature tables。 我们在LightGBM中将这种优化实现为基本功能。 请注意，此优化不会与EFB冲突，因为当bundle稀疏时我们仍然可以使用它。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>LightGBM的优化点总结</p><ul><li>基于Histogram的决策树算法。直方图做差加速。</li><li>带深度限制的Leaf-wise的叶子生长策略：level-wise 过一次数据可以同时分裂同一层的叶子，容易进行多线程优化，不容易过拟合。但实际上level-wise是一种低效的算法，因为它不加区分的对待同一层的叶子，带来了很多没必要的开销。因为实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。leaf-wise则是一种更为高效的策略，每次从当前所有叶子中，找到分裂增益最大(一般也是数据量最大)的一个叶子，然后分裂，如此循环。因此同 level-wise 相比，在分裂次数相同的情况下，leaf-wise 可以降低更多的误差，得到更好的精度。leaf-wise 的缺点是可能会长出比较深的决策树，产生过拟合。因此 LightGBM 在leaf-wise 之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合。</li><li>直接支持类别特征(Categorical Feature)：类别特征最优分割</li><li>基于梯度的单边采样算法</li><li>特征捆绑策略</li></ul><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，论文 LightGBM: A highly efficient gradient boosting decision tree.</p><p>2，<a href="https://blog.csdn.net/anshuai_aw1/article/details/83040541" target="_blank" rel="noopener">LightGBM直方图优化算法</a></p><p>3，<a href="https://juejin.im/post/5d25e1d0e51d4556da53d151" target="_blank" rel="noopener">一些面试问题</a></p><p>4，<a href="https://zhuanlan.zhihu.com/p/91167170" target="_blank" rel="noopener">LightGBM</a></p><p>5， <a href="https://zhuanlan.zhihu.com/p/87885678" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/87885678</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-摘要简介&quot;&gt;&lt;a href=&quot;#1-摘要简介&quot; class=&quot;headerlink&quot; title=&quot;1 摘要简介&quot;&gt;&lt;/a&gt;1 摘要简介&lt;/h3&gt;&lt;h4 id=&quot;1-1-简介&quot;&gt;&lt;a href=&quot;#1-1-简介&quot; class=&quot;headerlink&quot; title=&quot;1.1 简介&quot;&gt;&lt;/a&gt;1.1 简介&lt;/h4&gt;&lt;p&gt;GBDT的实现有XGBoost，pGBRT等。但当特征维度高，数据集size大的时候有效性还不够。主要原因在于对每一个特征，都要扫描所有实例并估计所有可能的划分节点的信息增益。&lt;/p&gt;&lt;p&gt;LightGBM提出的方法是：Gradient-based one-side sampling (GOSS) ，Exclusive feature bundling (EFB)。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>20191231面试2</title>
    <link href="http://yoursite.com/2020/01/02/20191231%E9%9D%A2%E8%AF%952_%E7%9F%A5%E4%B9%8E%E7%BD%91%E6%98%93/"/>
    <id>http://yoursite.com/2020/01/02/20191231%E9%9D%A2%E8%AF%952_%E7%9F%A5%E4%B9%8E%E7%BD%91%E6%98%93/</id>
    <published>2020-01-02T03:07:35.000Z</published>
    <updated>2020-01-07T09:16:22.788Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1，项目介绍"><a href="#1，项目介绍" class="headerlink" title="1，项目介绍"></a>1，项目介绍</h3><p>首先自我介绍。再介绍异常检测项目。在介绍广告CTR项目。</p><p>1，对每个项目的细节梳理清楚：</p><p>如lightGBM如何对类别特征进行节点分裂的？（<a href="http://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradi" target="_blank" rel="noopener">lightGBM论文</a>）</p><p>2，然后就是要仔细思考进一步的优化的地方在哪。</p><p>如何进一步提高点云的识别率呢？当时做了实验加多卷积层并没有明显的提升效果了，物体结构的特征点已经提取充分，所以并没用更深的网络。另一方面继续优化的点可以考虑点与点之间的领域结构，就像图像主要是考虑了相对位置关系，才可以用一些高反差核之类的卷积核提取图像的局部信息。</p><a id="more"></a><h3 id="2-基础知识"><a href="#2-基础知识" class="headerlink" title="2 基础知识"></a>2 基础知识</h3><p>中间问了机器学习的一些算法。</p><p>1，随机森林的采样体现在哪些地方？</p><p>（1）随机森林主要是Bagging和特征采用。Bagging是有放回的抽样，每次约63.2%的数据样本作为训练集。</p><p>随机森林每次没有用的样本数据有用吗？做包外预测$H^{oob}(x)$：</p><script type="math/tex; mode=display">H^{o o b}(\boldsymbol{x})=\underset{y \in \mathcal{Y}}{\arg \max } \sum_{t=1}^{T} \mathbb{I}\left(h_{t}(\boldsymbol{x})=y\right) \cdot \mathbb{I}\left(\boldsymbol{x} \notin D_{t}\right)</script><p>Bagging的泛化误差包外估计是：</p><script type="math/tex; mode=display">\epsilon^{o o b}=\frac{1}{|D|} \sum_{(\boldsymbol{x}, y) \in D} \mathbb{I}\left(H^{o o b}(\boldsymbol{x}) \neq y\right)</script><p>包外估计可以辅助剪枝。</p><p>Bagging可以降低方差。</p><p>（2）另外RF引入了随机特征选择。就是每个结点都会随机选择一些特征来构建树。如下图的算法流程。第5行，先选取了部分特征用来构建树（森林中每棵树都只随机的选择特征集中的一部分特征进行训练，因而森林中的每棵树都不会全都关注某些有很强预测性的特征上面），然后每个结点都有选择特征子集（line 5）来计算Gini impurity或均方误差，以此挑选最优划分特征（line 6），计算最优划分点（line7）。</p><p>（额额额，后面我居然给直接忘了，还有后面算法题短路得不行，捂脸）</p><p>每个结点的特征子集的好处：如果特征A1,A2彼此相关。树根据信息增益选择了A1后，A2的信息增益一定会变得很小，因为A1和A2所引起的不确定度是同一个不确定度，确定了A1后那么这个不确定度就没有了，确定A2后数据集的不确定性不会再减小了，因而造成的结果就是虽然说A1和A2同等重要，但是所有的树每次选择A1后就不会选择A2了。</p><p><img src="/images/20200102RandomForest.jpg" alt="20200102RandomForest"></p><p>（3）其他</p><p>随机森林的结合策略有：平均法（简单平均、加权平均），投票法，stacking（先从初始数据集训练出初始学习器，然后生成一个新数据集用于训练次级学习器，交叉验证）</p><p><img src="/images/20200102Stacking.jpg" alt="20200102Stacking"></p><p>2，梯度下降算法在GBDT有吗？动量法可以用到里面吗？</p><p>GBDT本身就是梯度提升法。在构建树的时候，是根据上一次的预测值和真实值的预测残差来构建的，其实就是拟合的损失函数的负梯度。</p><h3 id="3-算法题"><a href="#3-算法题" class="headerlink" title="3 算法题"></a>3 算法题</h3><p>海量数据，找出最大的k个数。紧张得面红耳赤，下来了总结学习下咯。</p><p>思路1，将数据qsort从大道小排序，取前k-1个数。回顾下qsort，复杂度O(nlogn)。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> A[], <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> temp = A[i];</span><br><span class="line">    A[i] = A[j];</span><br><span class="line">    A[j] = temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">partition</span><span class="params">(<span class="keyword">int</span> A[],<span class="keyword">int</span> l, <span class="keyword">int</span> r, <span class="keyword">int</span>&amp; pivot)</span></span>&#123;</span><br><span class="line">    <span class="keyword">do</span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(A[++l] &gt; pivot);</span><br><span class="line">        <span class="keyword">while</span>((l&lt;r) &amp;&amp; (A[--r] &lt; pivot));</span><br><span class="line">        swap(A,l,r);</span><br><span class="line">    &#125;<span class="keyword">while</span>(l&lt;r);</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">myqsort</span><span class="params">(<span class="keyword">int</span> A[],<span class="keyword">int</span> i,<span class="keyword">int</span> j)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (j &lt;= i) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">int</span> pivotIndex = (i+j)/<span class="number">2</span>;</span><br><span class="line">    swap(A,pivotIndex,j);</span><br><span class="line">    <span class="keyword">int</span> k = partition(A,i<span class="number">-1</span>,j,A[j]);</span><br><span class="line">    swap(A,k,j);</span><br><span class="line">    myqsort(A,i,k<span class="number">-1</span>);</span><br><span class="line">    myqsort(A,k+<span class="number">1</span>,j);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// function call: myqsort(num, 0, N-1);</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> k;</span><br><span class="line">    <span class="keyword">int</span> num[<span class="number">3</span>] = &#123;<span class="number">1</span>,<span class="number">-2</span>,<span class="number">0</span>&#125;;</span><br><span class="line">    myqsort(num, <span class="number">0</span>, N<span class="number">-1</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;k; i++) &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;num[i]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>思路2，用partition函数每次划分，两边排好序来做。当中间pivot下标正好是k-1则左边部分就是前k大个数。左边大的数的个数大于k，则最大的k个数在左边。否则在右边，个数为k-count个，复杂度是O(nlog2K)。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">KthBig</span><span class="params">(<span class="keyword">int</span> A[],<span class="keyword">int</span> i,<span class="keyword">int</span> j,<span class="keyword">int</span> kBig)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (j &lt;= i || A == <span class="literal">NULL</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">int</span> pivotIndex = (i+j)/<span class="number">2</span>;</span><br><span class="line">    swap(A,pivotIndex,j);</span><br><span class="line">    <span class="keyword">int</span> index = partition0(A,i<span class="number">-1</span>,j,A[j]); <span class="comment">// k is index</span></span><br><span class="line">    swap(A,index,j);</span><br><span class="line">    count = index - i + <span class="number">1</span>; <span class="comment">// count the k big data</span></span><br><span class="line">    <span class="keyword">if</span> (kBig == count) &#123;</span><br><span class="line">        <span class="keyword">return</span> index;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(count &gt; kBig)&#123;</span><br><span class="line">        <span class="keyword">return</span> KthBig(A, i, index, kBig);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> KthBig(A, index, j, kBig-count);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>思路3，k个的最大堆。然后后面的数一遍遍历过去，每次有比堆当前最小值小的即替换，调整堆结构。</p><p>首先堆的思想：完全二叉树，局部有序，O(logn)。简单基于数组的实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MAX_N = <span class="number">100</span>;</span><br><span class="line"><span class="keyword">int</span> heap[MAX_N],sz=<span class="number">0</span>; <span class="comment">//sz is global variable, meaning the lengh of heap</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">heap_push</span><span class="params">(<span class="keyword">int</span> x)</span></span>&#123;</span><br><span class="line">    <span class="comment">//own node's num.</span></span><br><span class="line">    <span class="keyword">int</span> node_index = sz++;</span><br><span class="line">    <span class="keyword">while</span> (node_index &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> p = (node_index<span class="number">-1</span>)/<span class="number">2</span>; <span class="comment">//i's parent</span></span><br><span class="line">        <span class="keyword">if</span> (heap[p] &gt;= x) &#123;</span><br><span class="line">            <span class="keyword">break</span>; <span class="comment">// sequence is ok</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// parent's value put down, node value go up</span></span><br><span class="line">        heap[node_index] = heap[p];</span><br><span class="line">        node_index = p;</span><br><span class="line">    &#125;</span><br><span class="line">    heap[node_index] = x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">heap_pop</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// max (root)</span></span><br><span class="line">    <span class="keyword">int</span> rec = heap[<span class="number">0</span>];</span><br><span class="line">    <span class="comment">// The value to put in the root</span></span><br><span class="line">    <span class="keyword">int</span> x = heap[--sz];</span><br><span class="line">    <span class="comment">//Swap from root</span></span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (i*<span class="number">2</span>+<span class="number">1</span> &lt; sz) &#123;</span><br><span class="line">        <span class="comment">//compare the children value</span></span><br><span class="line">        <span class="keyword">int</span> a = i*<span class="number">2</span>+<span class="number">1</span>; <span class="comment">// left child</span></span><br><span class="line">        <span class="keyword">int</span> b = i*<span class="number">2</span>+<span class="number">2</span>; <span class="comment">// right child</span></span><br><span class="line">        <span class="keyword">if</span> (b &lt; sz &amp;&amp; heap[b] &gt; heap[a]) &#123;</span><br><span class="line">            a = b;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// sequence is right</span></span><br><span class="line">        <span class="keyword">if</span> (heap[a] &lt;= x) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// child's value go up</span></span><br><span class="line">        heap[i] = heap[a];</span><br><span class="line">        i=a;</span><br><span class="line">    &#125;</span><br><span class="line">    heap[i] = x;</span><br><span class="line">    <span class="keyword">return</span> rec;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">//push(3);</span></span><br><span class="line">    heap_push(<span class="number">9</span>);</span><br><span class="line">    heap_push(<span class="number">2</span>);</span><br><span class="line">    heap_push(<span class="number">6</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;sz; i++) &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;heap[i]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"pop:"</span>&lt;&lt;heap_pop()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// also we can use library</span></span><br><span class="line">    priority_queue&lt;<span class="keyword">int</span>&gt; qqueue;</span><br><span class="line">    qqueue.push(<span class="number">9</span>);</span><br><span class="line">    qqueue.push(<span class="number">2</span>);</span><br><span class="line">    qqueue.push(<span class="number">6</span>);</span><br><span class="line">    <span class="comment">//loop until it is empty</span></span><br><span class="line">    <span class="keyword">while</span> (!qqueue.empty()) &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;qqueue.top()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        qqueue.pop();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最近面了三次，也见识了，知道哪该查漏补缺了。</p><p>1，项目的总结博客（启发式算法、三维点云、异常检测部分）</p><p>2，深度模型CTR（DeepCTR入手）</p><p>3，leecode刷题系列</p><p>4，其他（印象笔记搬迁到博客，kaggle比赛开源代码读读）</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://blog.csdn.net/weixin_37688445/article/details/79272319" target="_blank" rel="noopener">https://blog.csdn.net/weixin_37688445/article/details/79272319</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1，项目介绍&quot;&gt;&lt;a href=&quot;#1，项目介绍&quot; class=&quot;headerlink&quot; title=&quot;1，项目介绍&quot;&gt;&lt;/a&gt;1，项目介绍&lt;/h3&gt;&lt;p&gt;首先自我介绍。再介绍异常检测项目。在介绍广告CTR项目。&lt;/p&gt;&lt;p&gt;1，对每个项目的细节梳理清楚：&lt;/p&gt;&lt;p&gt;如lightGBM如何对类别特征进行节点分裂的？（&lt;a href=&quot;http://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradi&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;lightGBM论文&lt;/a&gt;）&lt;/p&gt;&lt;p&gt;2，然后就是要仔细思考进一步的优化的地方在哪。&lt;/p&gt;&lt;p&gt;如何进一步提高点云的识别率呢？当时做了实验加多卷积层并没有明显的提升效果了，物体结构的特征点已经提取充分，所以并没用更深的网络。另一方面继续优化的点可以考虑点与点之间的领域结构，就像图像主要是考虑了相对位置关系，才可以用一些高反差核之类的卷积核提取图像的局部信息。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="面试" scheme="http://yoursite.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Stochastic Gradient Descent</title>
    <link href="http://yoursite.com/2019/12/23/20181015StochasticGradientDescent/"/>
    <id>http://yoursite.com/2019/12/23/20181015StochasticGradientDescent/</id>
    <published>2019-12-23T02:20:15.000Z</published>
    <updated>2019-12-23T14:13:45.711Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1 概述"></a>1 概述</h3><h4 id="1-1-梯度下降"><a href="#1-1-梯度下降" class="headerlink" title="1.1 梯度下降"></a>1.1 梯度下降</h4><p>梯度下降是经典的局部优化算法。在2000年L Bottou使得随机梯度下降再次被提出。</p><p>对于数据$\left\{\left(X_{j}, Y_{j}\right)\right\}_{j=1}^{M}$ 需要求解：</p><script type="math/tex; mode=display">\min _{\theta \in \mathbb{R}^{n}} J(\theta), \quad J(\theta)=\frac{1}{M} \sum_{j=1}^{M} L\left(\theta ; X_{j}, Y_{j}\right)</script><a id="more"></a><p>梯度下降迭代格式：</p><script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-\alpha_{i} \nabla J\left(\theta_{i}\right), \quad \alpha_{i} \in \mathbb{R}^{+}</script><p>直接针对损失函数的梯度下降存在的问题是容易陷入局部极小，计算量大（每一次都要计算$\nabla_{\theta} L\left(\theta_{i} ; X_{j}, Y_{j}\right)$）, 鞍点终止问题（鞍点梯度为0）。</p><h4 id="1-2-随机梯度下降"><a href="#1-2-随机梯度下降" class="headerlink" title="1.2 随机梯度下降"></a>1.2 随机梯度下降</h4><p>因此提出随机梯度下降。每次仅仅随机取一个数据$\left(X_{R_{i}}, Y_{R_{i}}\right)$来近似均值的损失$\frac{1}{M} \sum_{j=1}^{M} \nabla_{\theta} L\left(\theta_{i} ; X_{j}, Y_{j}\right)$。</p><script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-\alpha_{i} \nabla_{\theta} L\left(\theta_{i} ; X_{R_{i}}, Y_{R_{i}}\right)</script><h4 id="1-3-三种梯度下降"><a href="#1-3-三种梯度下降" class="headerlink" title="1.3 三种梯度下降"></a>1.3 三种梯度下降</h4><p>梯度下降：全部数据迭代计算梯度。</p><script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-\alpha_{i} \frac{1}{M} \sum_{j=1}^{M} \nabla_{\theta} L\left(\theta_{i} ; X_{j}, Y_{j}\right)</script><p>随机梯度：随机取一个数据来更新梯度。</p><script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-\alpha_{i} \nabla_{\theta} L\left(\theta_{i} ; X_{R_{i}}, Y_{R_{i}}\right)</script><p>小批量梯度：随机取$m(\in[50,300])$ 个数据来计算梯度。</p><script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-\alpha_{i} \frac{1}{m} \sum_{j=1}^{m} \nabla_{\theta} L\left(\theta_{i} ; X_{R_{i, j}}, Y_{R_{i, j}}\right)</script><p>下批量梯度下降的好处。加噪，避免梯度法终止于鞍点，存在一定概率跳出局部极小，小批量计算量可接受。</p><p>如果$J_M(\theta)$满足强凸条件，对于批量梯度法，线性收敛。对于随机梯度下降法，次线性收敛。</p><h4 id="1-4-Github代码"><a href="#1-4-Github代码" class="headerlink" title="1.4 Github代码"></a>1.4 Github代码</h4><p><a href="https://github.com/saruagithub/AIcourse_gradientDescent" target="_blank" rel="noopener">https://github.com/saruagithub/AIcourse_gradientDescent</a></p><h3 id="2-SGD技巧"><a href="#2-SGD技巧" class="headerlink" title="2 SGD技巧"></a>2 SGD技巧</h3><p>1，SGD缺点：梯度方向不一定好，固定的学习率太小收敛慢太大则阻碍收敛，如何快速穿过山谷（狭窄山谷的震荡）平原呢。</p><script type="math/tex; mode=display">v_i = \alpha \nabla_{\theta} J\left(\theta_{i}\right)</script><script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-v_{i}</script><p>2，动量法：梯度的加权平均，递归的添加方向的历史信息（即$v_{i-1}$）。但转弯会慢。</p><script type="math/tex; mode=display">v_{i}=\gamma v_{i-1}+\alpha \nabla_{\theta} J\left(\theta_{i}\right)</script><p>其中$\gamma$ 是阻力因子。</p><script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-v_{i}</script><p>3，Nesterov：加速梯度法，更早的注意到梯度的变化。在动量法梯度更新前减去动量项。</p><script type="math/tex; mode=display">v_{i}=\gamma v_{i-1}+\alpha \nabla_{\theta} J\left(\theta_{i}-\gamma v_{i-1}\right)</script><script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-v_{i}</script><p>就是使用上一步的$v_{i-1}$先走一步再计算合并梯度。这里的$- \gamma v_{i-1}$就是下图B-C这段。</p><p>优点：前瞻性，在原方向虚拟走了一步后的梯度。收敛速度明显加快。波动也小了很多。</p><p><img src="/images/20181015Nesterov.jpg" alt="20181015Nesterov"></p><p>4，Adagrad：自适应梯度，弱化频繁变化的参数。$G_i$指的是历史与当前梯度的平方的累加。</p><script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-\frac{\alpha}{\sqrt{G_{i}+\epsilon}} \nabla_{\theta} J\left(\theta_{i}\right)</script><script type="math/tex; mode=display">G_{i}=G_{i-1} + (\nabla_{\theta} J\left(\theta_{i}\right))^{2}</script><p>$\epsilon$ 平滑项，避免除数为0。</p><p>5，RMSProp，对AdaGrad的一种改进，使用加权平均于梯度平方项。当前梯度平方项加上上一时刻的平均值。</p><script type="math/tex; mode=display">G_{i}=\gamma G_{i-1}+(1-\gamma)(\nabla_{\theta} J\left(\theta_{i}\right))^{2}</script><script type="math/tex; mode=display">\theta_{i+1}=\theta_{i}-\frac{\alpha}{\sqrt{G_{i}+\epsilon}} \nabla_{\theta} J\left(\theta_{i}\right)</script><p>另一个改进是定义指数衰减均值，AdaDelta2使用Delta平方的exponential moving average替代learning rate。</p><script type="math/tex; mode=display">\theta_{i+1} = \theta_i -\frac{\sqrt{D_{i-1}+\epsilon}}{\sqrt{G_{i}+\epsilon}} \nabla_{\theta} J(\theta_{i})</script><script type="math/tex; mode=display">D_{i}=\gamma D_{i-1}+(1-\gamma)\left[\Delta \theta_{t}\right]^{2}</script><script type="math/tex; mode=display">G_{i}=\gamma G_{i-1}+(1-\gamma)(\nabla_{\theta} J\left(\theta_{i}\right))^{2}</script><script type="math/tex; mode=display">\Delta \theta_{t}=\theta_{t}-\theta_{t-1}</script><p>6，Adam:Adam是对Momentum和RMPprop的一个结合。像 Adadelta 和 RMSprop 一样存储了过去梯度的平方 vt 的指数衰减平均值 ，也像 momentum 一样保持了过去梯度 mt 的指数衰减平均值。</p><p>首先令：</p><script type="math/tex; mode=display">v_{i}=\gamma_{1} v_{i-1}+\left(1-\gamma_{1}\right) \nabla_{\theta} J\left(\theta_{i}\right)</script><script type="math/tex; mode=display">u_{i}=\gamma_{2} u_{i-1}+\left(1-\gamma_{2}\right) (\nabla_{\theta} J\left(\theta_{i}\right))^{2}</script><p>则：</p><script type="math/tex; mode=display">\hat{v}_{i}=\frac{v_{i}}{1-\gamma_{1}^{i}}, \quad \hat{u}_{i}=\frac{u_{i}}{1-\gamma_{2}^{i}}</script><p>最终得：</p><script type="math/tex; mode=display">\theta_{i+1} = \theta_i - \frac{\alpha}{\sqrt{\hat{u}_{i}+\epsilon}} \hat{v}_{i}</script><p>梯度部分像Momentum里一样使用V即梯度的exponential moving average来替代当前梯度来更新权重。学习率部分像RMSprop里一样用学习率除以S(即梯度的exponential moving average)来进行学习。V和S都初始化为0。一般$\alpha=0.001, \quad \gamma_{1}=0.9, \quad \gamma_{2}=0.999, \quad \epsilon=10^{-8}$</p><p>7, 推荐技巧：</p><script type="math/tex; mode=display">v_{i}=\gamma v_{i-1}+(1-\gamma) \nabla_{\theta} J\left(\theta_{i}-\gamma v_{i-1}\right)</script><script type="math/tex; mode=display">u_{i}=\gamma u_{i-1}+(1-\gamma)\left(\nabla_{\theta} J\left(\theta_{i}-\gamma v_{i-1}\right)\right)^{2}</script><script type="math/tex; mode=display">w_{i}=\gamma w_{i-1}+(1-\gamma) \Delta \theta_{i}^{2}</script><p>可得：</p><script type="math/tex; mode=display">\theta_{i+1}=\theta_{i} -\frac{\sqrt{w_{i-1}+\epsilon}}{\sqrt{u_{i}+\epsilon}} v_{i}</script><p>所有技巧的目的都是为了根据历史梯度和当前梯度来更新梯度。学习率迭代则是为了能适应梯度，梯度太大则更新小，将学习率learning rate除以当前的梯度，就能得到一个“适应”好的学习率的值。</p><p>数学回顾：一元函数的导数与泰勒级数</p><p>函数f(x)在x0上的导数定义为：</p><script type="math/tex; mode=display">f^{\prime}\left(x_{0}\right)=\lim _{x \rightarrow x_{0}} \frac{f(x)-f\left(x_{0}\right)}{x-x_{0}}</script><p>f(x)在x0附近的Taylor级数是：</p><script type="math/tex; mode=display">f(x)=f\left(x_{0}\right)+f^{\prime}\left(x_{0}\right)\left(x-x_{0}\right)+\frac{f^{\prime \prime}\left(x_{0}\right)}{2}\left(x-x_{0}\right)^{2}+O\left(\left|x-x_{0}\right|^{3}\right)</script><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，智能技术基础课PPT &amp; 印象笔记，智能技术基础课2，3</p><p>2，<a href="https://blog.csdn.net/tsyccnh/article/details/76673073" target="_blank" rel="noopener">https://blog.csdn.net/tsyccnh/article/details/76673073</a></p><p>3, <a href="https://www.zhihu.com/question/305638940/answer/770984541" target="_blank" rel="noopener">https://www.zhihu.com/question/305638940/answer/770984541</a> 梯度下降法</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1 概述&quot;&gt;&lt;/a&gt;1 概述&lt;/h3&gt;&lt;h4 id=&quot;1-1-梯度下降&quot;&gt;&lt;a href=&quot;#1-1-梯度下降&quot; class=&quot;headerlink&quot; title=&quot;1.1 梯度下降&quot;&gt;&lt;/a&gt;1.1 梯度下降&lt;/h4&gt;&lt;p&gt;梯度下降是经典的局部优化算法。在2000年L Bottou使得随机梯度下降再次被提出。&lt;/p&gt;&lt;p&gt;对于数据$\left\{\left(X_{j}, Y_{j}\right)\right\}_{j=1}^{M}$ 需要求解：&lt;/p&gt;&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min _{\theta \in \mathbb{R}^{n}} J(\theta), \quad J(\theta)=\frac{1}{M} \sum_{j=1}^{M} L\left(\theta ; X_{j}, Y_{j}\right)&lt;/script&gt;
    
    </summary>
    
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>leecode168周赛</title>
    <link href="http://yoursite.com/2019/12/22/20191222leecode168%E5%91%A8%E8%B5%9B/"/>
    <id>http://yoursite.com/2019/12/22/20191222leecode168%E5%91%A8%E8%B5%9B/</id>
    <published>2019-12-22T07:06:13.000Z</published>
    <updated>2019-12-22T10:08:55.195Z</updated>
    
    <content type="html"><![CDATA[<h3 id="leecode5291统计位数为偶数的数字"><a href="#leecode5291统计位数为偶数的数字" class="headerlink" title="leecode5291统计位数为偶数的数字"></a>leecode5291统计位数为偶数的数字</h3><p>给你一个整数数组 <code>nums</code>，请你返回其中位数为 <strong>偶数</strong> 的数字的个数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">输入：nums = [12,345,2,6,7896]</span><br><span class="line">输出：2</span><br><span class="line">解释：</span><br><span class="line">12 是 2 位数字（位数为偶数） </span><br><span class="line">345 是 3 位数字（位数为奇数）  </span><br><span class="line">2 是 1 位数字（位数为奇数） </span><br><span class="line">6 是 1 位数字 位数为奇数） </span><br><span class="line">7896 是 4 位数字（位数为偶数）  </span><br><span class="line">因此只有 12 和 7896 是位数为偶数的数字</span><br><span class="line"></span><br><span class="line">输入：nums = [555,901,482,1771]</span><br><span class="line">输出：1 </span><br><span class="line">解释： </span><br><span class="line">只有 1771 是位数为偶数的数字。</span><br><span class="line"></span><br><span class="line">1 &lt;= nums.length &lt;= 500</span><br><span class="line">1 &lt;= nums[i] &lt;= 10^5</span><br></pre></td></tr></table></figure><a id="more"></a><p>思路1：c++，位数是除以10，而判断是否偶数是对2取余判断是否为0。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">findNumbers</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> res=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> num: nums)&#123;</span><br><span class="line">        <span class="keyword">int</span> weishu=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(num / <span class="number">10</span> &gt; <span class="number">0</span>)&#123;</span><br><span class="line">            weishu ++;</span><br><span class="line">            num /= <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;weishu&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">if</span>(weishu % <span class="number">2</span> == <span class="number">0</span>)&#123;</span><br><span class="line">            res ++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; test1 = &#123;<span class="number">12</span>,<span class="number">345</span>,<span class="number">2</span>,<span class="number">6</span>,<span class="number">7896</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> res = findNumbers(test1);</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;res&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>思路2：Python，遍历nums里的数字。将数字转换为string。判断string的长度对2取余是否为0，是0则取1，否则取0（表示位数不是偶数）。再将是偶数的数字求和 sum。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">findNumbers</span><span class="params">(nums: List[int])</span> -&gt; int:</span></span><br><span class="line">        <span class="keyword">return</span> sum(<span class="number">1</span> <span class="keyword">if</span> len(str(x)) % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> nums)</span><br></pre></td></tr></table></figure><h3 id="leecode5292划分数组为连续数字的集合"><a href="#leecode5292划分数组为连续数字的集合" class="headerlink" title="leecode5292划分数组为连续数字的集合"></a>leecode5292划分数组为连续数字的集合</h3><p>给你一个整数数组 nums 和一个正整数 k，请你判断是否可以把这个数组划分成一些由 k 个连续数字组成的集合。<br>如果可以，请返回 True；否则，返回 False。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">实例1</span><br><span class="line">输入：nums = [1,2,3,3,4,4,5,6], k = 4</span><br><span class="line">输出：true</span><br><span class="line">解释：数组可以分成 [1,2,3,4] 和 [3,4,5,6]。</span><br><span class="line"></span><br><span class="line">示例2</span><br><span class="line">输入：nums = [3,2,1,2,3,4,3,4,5,9,10,11], k = 3</span><br><span class="line">输出：true</span><br><span class="line">解释：数组可以分成 [1,2,3] , [2,3,4] , [3,4,5] 和 [9,10,11]。</span><br><span class="line"></span><br><span class="line">示例3 </span><br><span class="line">输入：nums = [3,3,2,2,1,1], k = 3</span><br><span class="line">输出：true</span><br><span class="line"></span><br><span class="line">示例4</span><br><span class="line">输入：nums = [1,2,3,4], k = 3</span><br><span class="line">输出：false</span><br><span class="line">解释：数组不能分成几个大小为 3 的子数组。</span><br><span class="line"></span><br><span class="line">1 &lt;= nums.length &lt;= 10^5</span><br><span class="line">1 &lt;= nums[i] &lt;= 10^9</span><br><span class="line">1 &lt;= k &lt;= nums.length</span><br></pre></td></tr></table></figure><p>思路1：简单基本思路，将nums里的最小取出来，然后每次取[min,min+k]的值，不断从原nums里去除掉。如果可以这样去空原nums则返回true，否则只要有值不在nums里，则返回false。（但这个方法的时间复杂度太高$O(kn^2)$）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isPossibleDivide</span><span class="params">(nums, k)</span>:</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">:type nums: List[int]</span></span><br><span class="line"><span class="string">:type k: int</span></span><br><span class="line"><span class="string">:rtype: bool</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">if</span> (len(nums) % k != <span class="number">0</span>):</span><br><span class="line"><span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (len(nums) != <span class="number">0</span>):</span><br><span class="line"><span class="comment"># each list</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> range(min(nums), min(nums)+k):</span><br><span class="line"><span class="keyword">if</span> x <span class="keyword">in</span> nums:</span><br><span class="line">nums.remove(x)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">nums = [<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>]</span><br><span class="line">k = <span class="number">3</span></span><br><span class="line">res = isPossibleDivide(nums,k)</span><br><span class="line">print(res)</span><br></pre></td></tr></table></figure><p>进一步，用hash优化查找x in nums。(c++中的map是平衡二叉树)，排序时间复杂度$O(nlogn)$，</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isPossibleDivide</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (nums.<span class="built_in">size</span>() % k != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    sort(nums.<span class="built_in">begin</span>(), nums.<span class="built_in">end</span>());</span><br><span class="line">    <span class="built_in">map</span>&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; hash;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> num:nums) hash[num]++;</span><br><span class="line">    <span class="keyword">int</span> groups = nums.<span class="built_in">size</span>() / k;</span><br><span class="line">    <span class="comment">//group nums</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;groups; i++) &#123;</span><br><span class="line">        <span class="keyword">int</span> min_index = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (hash[nums[min_index]] == <span class="number">0</span>) &#123;</span><br><span class="line">            min_index++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//if min~min+k is not in nums, false</span></span><br><span class="line">        <span class="keyword">int</span> start = nums[min_index];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=start; j&lt;start+k; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (hash[j] == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> hash[j]--;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; test2 = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> res2 = isPossibleDivide(test2,<span class="number">3</span>);</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;res2&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>思路3。新学习了multiset。避免了while这一段找min_index（见上），直接在multiset里查找并去掉，时间要短一点点，但空间用的要更多（因为multiset允许存储重复元素）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isPossibleDivide2</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (nums.<span class="built_in">size</span>() % k != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">multiset</span>&lt;<span class="keyword">int</span>&gt; s;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> num:nums) s.insert(num);</span><br><span class="line">  <span class="comment">//multiset&lt;int&gt; s(a.begin(), a.end());</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;nums.<span class="built_in">size</span>() / k; i++) &#123;</span><br><span class="line">        <span class="keyword">int</span> <span class="built_in">min</span> = *s.<span class="built_in">begin</span>();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="built_in">min</span>; j&lt;<span class="built_in">min</span>+k; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (s.<span class="built_in">find</span>(j) == s.<span class="built_in">end</span>()) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            s.erase(s.<span class="built_in">find</span>(j));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1, <a href="https://leetcode-cn.com/problems/find-numbers-with-even-number-of-digits" target="_blank" rel="noopener">https://leetcode-cn.com/problems/find-numbers-with-even-number-of-digits</a></p><p>2, <a href="https://leetcode-cn.com/problems/divide-array-in-sets-of-k-consecutive-numbers" target="_blank" rel="noopener">https://leetcode-cn.com/problems/divide-array-in-sets-of-k-consecutive-numbers</a></p><p>3，<a href="https://leetcode-cn.com/contest/weekly-contest-168/" target="_blank" rel="noopener">https://leetcode-cn.com/contest/weekly-contest-168/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;leecode5291统计位数为偶数的数字&quot;&gt;&lt;a href=&quot;#leecode5291统计位数为偶数的数字&quot; class=&quot;headerlink&quot; title=&quot;leecode5291统计位数为偶数的数字&quot;&gt;&lt;/a&gt;leecode5291统计位数为偶数的数字&lt;/h3&gt;&lt;p&gt;给你一个整数数组 &lt;code&gt;nums&lt;/code&gt;，请你返回其中位数为 &lt;strong&gt;偶数&lt;/strong&gt; 的数字的个数。&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;输入：nums = [12,345,2,6,7896]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;输出：2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;解释：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12 是 2 位数字（位数为偶数） &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;345 是 3 位数字（位数为奇数）  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2 是 1 位数字（位数为奇数） &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6 是 1 位数字 位数为奇数） &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7896 是 4 位数字（位数为偶数）  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;因此只有 12 和 7896 是位数为偶数的数字&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;输入：nums = [555,901,482,1771]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;输出：1 &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;解释： &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;只有 1771 是位数为偶数的数字。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;1 &amp;lt;= nums.length &amp;lt;= 500&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;1 &amp;lt;= nums[i] &amp;lt;= 10^5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="算法" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="leecode" scheme="http://yoursite.com/tags/leecode/"/>
    
  </entry>
  
  <entry>
    <title>20191219leecode142快慢指针学习</title>
    <link href="http://yoursite.com/2019/12/19/20191219leecode142%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2019/12/19/20191219leecode142%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88%E5%AD%A6%E4%B9%A0/</id>
    <published>2019-12-19T13:25:02.000Z</published>
    <updated>2019-12-19T13:39:55.918Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-题目"><a href="#1-题目" class="headerlink" title="1 题目"></a>1 题目</h3><p>leecode142，给定一个链表，返回链表开始入环的第一个节点。 如果链表无环，则返回NULL。</p><h3 id="2-hash法与快慢指针法"><a href="#2-hash法与快慢指针法" class="headerlink" title="2 hash法与快慢指针法"></a>2 hash法与快慢指针法</h3><p>快慢指针法有意思的推导：</p><p>x：link起点到入环点距离</p><p>y: 入环点到相遇点距离</p><p>c：circle的长度</p><p>相遇时候，慢指针走了x+n1 c  + y （n1假设走了n1圈），快指针走了2倍(x+ n1c+y)</p><a id="more"></a><p>快指针比慢指针多走的路程一定是环长度的整数倍，有2(x+ n1c+y) - (x+ n1c+y) = n2 c </p><p>所以又x + y = (n2 - n1) c</p><p>可以相遇时快指针从起点再走（1倍速），慢指针也走，则相遇点就是入环点。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//  leecode 142 circle link detection</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;set&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ListNode</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> val;</span><br><span class="line">    ListNode *next;</span><br><span class="line">    ListNode(<span class="keyword">int</span> x) : val(x), next(<span class="literal">NULL</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// save elem to set, time O(n) space O(n)</span></span><br><span class="line"><span class="function">ListNode *<span class="title">detectCycle</span><span class="params">(ListNode *head)</span> </span>&#123;</span><br><span class="line">    ListNode* p = head;</span><br><span class="line">    <span class="built_in">set</span>&lt;ListNode*&gt; elem_set;</span><br><span class="line">    <span class="keyword">while</span>(p)&#123;</span><br><span class="line">        <span class="keyword">if</span> (elem_set.<span class="built_in">find</span>(p) != elem_set.<span class="built_in">end</span>()) &#123;</span><br><span class="line">            <span class="keyword">return</span> p;</span><br><span class="line">        &#125;</span><br><span class="line">        elem_set.insert(p);<span class="comment">//O(logN)</span></span><br><span class="line">        p = p-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//fast and slow pointer</span></span><br><span class="line"><span class="function">ListNode *<span class="title">detectCycle1</span><span class="params">(ListNode *head)</span></span>&#123;</span><br><span class="line">    ListNode *slow,*fast;</span><br><span class="line">    slow = head;</span><br><span class="line">    fast = head;</span><br><span class="line">    <span class="keyword">while</span> (slow!=<span class="literal">NULL</span> &amp;&amp; fast-&gt;next!=<span class="literal">NULL</span>) &#123;</span><br><span class="line">        slow = slow-&gt;next;</span><br><span class="line">        fast = fast-&gt;next-&gt;next;</span><br><span class="line">        <span class="keyword">if</span> (slow == fast) &#123;</span><br><span class="line">            <span class="comment">//fast pointer go from and start of the link</span></span><br><span class="line">            fast = head;</span><br><span class="line">            <span class="keyword">while</span> (fast != slow) &#123;</span><br><span class="line">                fast = fast-&gt;next;</span><br><span class="line">                slow = slow-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> fast;<span class="comment">//now both pointer is in the start of the citcle</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">//input</span></span><br><span class="line">    ListNode* res;</span><br><span class="line">    ListNode *dummyhead,*head,*temp0,*temp1;</span><br><span class="line">    dummyhead = <span class="keyword">new</span> ListNode(<span class="number">-1</span>);</span><br><span class="line">    head = <span class="keyword">new</span> ListNode(<span class="number">1</span>);</span><br><span class="line">    dummyhead -&gt;next = head;</span><br><span class="line">    temp0 = <span class="keyword">new</span> ListNode(<span class="number">2</span>);</span><br><span class="line">    head-&gt;next = temp0;</span><br><span class="line">    temp1 = <span class="keyword">new</span> ListNode(<span class="number">4</span>);</span><br><span class="line">    temp0-&gt;next = temp1;</span><br><span class="line">    temp1-&gt;next = temp0;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//algorithm</span></span><br><span class="line">    <span class="comment">//res = detectCycle(head);</span></span><br><span class="line">    res = detectCycle1(head);</span><br><span class="line">    <span class="keyword">if</span> (res == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="string">"no circle"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="built_in">cout</span>&lt;&lt;res-&gt;val&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1 题目&quot;&gt;&lt;/a&gt;1 题目&lt;/h3&gt;&lt;p&gt;leecode142，给定一个链表，返回链表开始入环的第一个节点。 如果链表无环，则返回NULL。&lt;/p&gt;&lt;h3 id=&quot;2-hash法与快慢指针法&quot;&gt;&lt;a href=&quot;#2-hash法与快慢指针法&quot; class=&quot;headerlink&quot; title=&quot;2 hash法与快慢指针法&quot;&gt;&lt;/a&gt;2 hash法与快慢指针法&lt;/h3&gt;&lt;p&gt;快慢指针法有意思的推导：&lt;/p&gt;&lt;p&gt;x：link起点到入环点距离&lt;/p&gt;&lt;p&gt;y: 入环点到相遇点距离&lt;/p&gt;&lt;p&gt;c：circle的长度&lt;/p&gt;&lt;p&gt;相遇时候，慢指针走了x+n1 c  + y （n1假设走了n1圈），快指针走了2倍(x+ n1c+y)&lt;/p&gt;
    
    </summary>
    
    
      <category term="算法" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="leecode" scheme="http://yoursite.com/tags/leecode/"/>
    
  </entry>
  
  <entry>
    <title>20191216面试1&amp;图论问题回顾</title>
    <link href="http://yoursite.com/2019/12/17/20191216%E5%AD%97%E8%8A%82%E9%9D%A2%E8%AF%95%E4%B8%8E%E5%8D%8E%E4%B8%BA%E5%9B%BE%E8%AE%BA%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2019/12/17/20191216%E5%AD%97%E8%8A%82%E9%9D%A2%E8%AF%95%E4%B8%8E%E5%8D%8E%E4%B8%BA%E5%9B%BE%E8%AE%BA%E9%97%AE%E9%A2%98/</id>
    <published>2019-12-17T07:44:14.000Z</published>
    <updated>2020-01-02T09:24:13.329Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1，一面"><a href="#1，一面" class="headerlink" title="1，一面"></a>1，一面</h3><p>第一次面试，居然去面了目前北京最火的一家公司。emmm，真的是胆大。不过一面的面试官超级可爱，很温和，我也太幸运了吧。先让自我介绍，然后问项目，然后出了一个很简单的算法题。</p><h4 id="1-1-图论问题"><a href="#1-1-图论问题" class="headerlink" title="1.1 图论问题"></a>1.1 图论问题</h4><p>项目是我大三做的一个图论赛题，回顾总结一下。</p><p>问题：“服务器选址问题”，从图中选出一些节点安放服务器（图中绿色节点 表示为$S_i$），服务器输出流量供给消费节点（图中红色节点，表示为$C_i$）</p><a id="more"></a><p>目标：第一要满足每个消费节点的流量需求，第二费用最小。</p><p>约束：每个路径有流量限制$flow_{constrain}$，但上下行都可以。也有流量单位费用$UnitCost$。举例子比如图右上角从1到15节点，留出流量13，则费用是13 * 2 = 26，此条路后面只能再流过16 - 13 = 3的流量了。另外其他限制是90秒内必须输出结果，否则没有成绩，使用内存不超过2GB。</p><p>输出：每条路径，及流过的流量。</p><p><img src="/images/20170305HuaWeiFlow.png" alt="20170305HuaWeiFlow"></p><h4 id="1-2-我的算法"><a href="#1-2-我的算法" class="headerlink" title="1.2 我的算法"></a>1.2 我的算法</h4><h5 id="策略1：选择前n个可以流出带宽最大的节点"><a href="#策略1：选择前n个可以流出带宽最大的节点" class="headerlink" title="策略1：选择前n个可以流出带宽最大的节点"></a>策略1：选择前n个可以流出带宽最大的节点</h5><p>1，选择n个可以流出带宽最大的节点</p><p>step1 计算每个结点可以输出的带宽之和</p><p>step2 排序</p><p>step3 选择前n个，放置服务器</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getServerlocation</span><span class="params">(Graph&amp; g,<span class="keyword">int</span>* server)</span><span class="comment">//bigest bandwith Id</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> location=<span class="number">0</span>,i,bandwidth=<span class="number">0</span>,SecondBandWidth=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;g.numV();i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(g.Bandwidth[i] &gt; bandwidth)&#123;</span><br><span class="line">            SecondBandWidth = bandwidth;</span><br><span class="line">            location = i;</span><br><span class="line">            bandwidth = g.Bandwidth[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;g.numC();i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(location == server[i])&#123;</span><br><span class="line">            <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;g.numV();i++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(g.Bandwidth[i] == SecondBandWidth)</span><br><span class="line">                    location = i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> location;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>step4 用Dijkstra计算服务器到消费节点的最短路径（只根据$flow_{constrain}$来计算），计算这条路径的可以流过的最大流量，分配流量，计算费用。</p><p>Dijkstra算法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(w=<span class="number">0</span>;w&lt;g.CountsOfConnectNode[v];w++)&#123;</span><br><span class="line"><span class="keyword">if</span> (D[w] &gt; D[v] + g.getUnitConsumeCost(v, w))  计算server到各个点的距离，判断并更新</span><br><span class="line">D[w] = D[v] + g.getUnitConsumeCost(v, w);</span><br></pre></td></tr></table></figure><p>获取本条路径可以流过的最大流量</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getflow</span><span class="params">(Graph* G,<span class="keyword">int</span> path[maxN][maxN],<span class="keyword">int</span> cn)</span><span class="comment">//get cn-consumenode minflow</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> flow = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> Cnode  = G-&gt;Con_Nodes[cn];</span><br><span class="line">    <span class="keyword">int</span> minflow = INFINITY,i;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;maxN;i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(minflow &gt; G-&gt;getWeight(path[Cnode][i], path[Cnode][i+<span class="number">1</span>]))&#123;</span><br><span class="line">            minflow = G-&gt;getWeight(path[Cnode][i], path[Cnode][i+<span class="number">1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(path[Cnode][i+<span class="number">2</span>] == <span class="number">-1</span>)&#123;</span><br><span class="line">            flow = minflow;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(flow &gt; G-&gt;Demand[cn])</span><br><span class="line">        flow = G-&gt;Demand[cn];</span><br><span class="line">    <span class="keyword">return</span> flow;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>更新图和消费节点的流量需求。</p><p>反过来消费点去找离他最近的服务器节点，分配流量。</p><h5 id="策略2：实在不行选择与消费点的直连点放服务器。"><a href="#策略2：实在不行选择与消费点的直连点放服务器。" class="headerlink" title="策略2：实在不行选择与消费点的直连点放服务器。"></a>策略2：实在不行选择与消费点的直连点放服务器。</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* server is in the consumenode */</span></span><br><span class="line">   <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;graph.numC();i++)&#123;</span><br><span class="line">       <span class="keyword">if</span>(server[ser<span class="number">-1</span>] == graph.Con_Nodes[i])&#123;</span><br><span class="line">           pathpath[pathi][<span class="number">0</span>] = server[ser<span class="number">-1</span>];  <span class="comment">//add to the answer</span></span><br><span class="line">           pathpath[pathi][<span class="number">1</span>] = i;</span><br><span class="line">           pathpath[pathi][<span class="number">2</span>] = graph.Demand[i];</span><br><span class="line">           pathi++;</span><br><span class="line">           graph.Demand[i] = <span class="number">0</span>;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h4 id="1-3-其他方法"><a href="#1-3-其他方法" class="headerlink" title="1.3 其他方法"></a>1.3 其他方法</h4><p>整数规划模型</p><p>启发式算法（模拟退火，遗传算法，去网上找了资料学了点基础）</p><h4 id="当年的反思"><a href="#当年的反思" class="headerlink" title="当年的反思"></a>当年的反思</h4><p><img src="/images/20191218HuaWeiRes.jpg" alt="20191218HuaWeiRes"></p><p>1、一个类里面空间是有限的，如果开了几个1000*1000的二维数组是不行的，要么static，要么设置全局。</p><p>2、在Dijkstra 里CountsOfConnectNode不能因为单边减少而减一，因为单边减少就减一的话会造成无法访问一些边，因为我是先遍历的在判断的周边路径是否存在，即weight &gt; 0。</p><p>3、一些存DotId的数组我初始化为了-1，其实-1是很容易造成下标越界的，但本来dot的范围是0~maxN，所以造成后面很多的判断 ！= -1 ，希望大家引以为戒。（因为-1 ，我的graph里的成员变量servercost竟然从100变成了-1，就是因为-1下标的范围导致内存访问异常，数据被修改，当时真是急哭我了）</p><p>4、记住所有变量定义的时候一定初始化，否则为任意值的话会造成不可知的错误，只能一直debug一步步找变量的变化，真是心累。</p><p>5、如果你的数据很多，请注释每个的含义，包括下标，否则你的队友会看不懂你的代码，自己写一写的就会弄混。</p><p>6、算法上的缺陷</p><p>没有反馈：一直计算的出来的结果，没有经过比较选择这是缺乏了优化的过程的。应该要一直迭代，随机取、放一些服务器后就算一遍最短路径和成本进行比较取优。其实我的代码跑完整个用的时间是ms级的，那么其实还要很多时间可以进行计算。因为最后来不及了也就没有做，自然成本高。</p><p>7、团队分工：队友要充分合作（一个人再强大真的比不上三个臭皮匠）、分工写任务，一定要充分相信对方。队长要想好整体，再把模块分开写，把需求明确，免得最后代码合并要哭。</p><p>8、编程基本功：编程基本功要多写多练才扎实，不然写这样的复杂稍大的程序就很容易出现一些低级错误</p><p>9、多去学习大佬怎么做的，站在前人大佬的基础上才不会自己太犯傻，至少基本的方向不会错！</p><h3 id="2，算法题"><a href="#2，算法题" class="headerlink" title="2，算法题"></a>2，算法题</h3><p>1，写出二叉树的最短路径长度。长度 = 路径上节点的值的和。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int MaxPath(TreeNode* root)&#123;</span><br><span class="line">if (root -&gt; NULL) return 0;</span><br><span class="line">else return root-&gt;val + max(MaxPath(root-&gt;left),MaxPath(root-&gt;right));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2，给出一个数组[1 3 2 6 5 7 10]，找出后面的比他大的第一个值，返回下标，答案 [1 3 3 5 5 6 -1]。</p><p>思路：倒过来遍历，取一个最小的stack</p><p>倒着遍历，维护一个递减的stack(top保持最小）。先10和其index绑定入stack，然后轮到7，判断stack top，若大于7就把stack top的数的index返回，否则弹出stack top，直到找到大于7或者stack弹空，若弹空则返回-1.然后把7绑定index压到stack里。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ListNode</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> value;</span><br><span class="line">    <span class="keyword">int</span> index;</span><br><span class="line">    ListNode(<span class="keyword">int</span> a,<span class="keyword">int</span> b)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;value=a;</span><br><span class="line">        <span class="keyword">this</span>-&gt;index=b;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">stack</span>&lt;ListNode&gt; stk;</span><br><span class="line">    <span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; res;</span><br><span class="line">    <span class="keyword">int</span> N; <span class="comment">//N &gt; 0</span></span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;N;</span><br><span class="line">    <span class="keyword">int</span> arr[N];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;N; i++) &#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;arr[i];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//algotithm</span></span><br><span class="line">    res.push(<span class="number">-1</span>);</span><br><span class="line">    <span class="function">ListNode <span class="title">temp</span><span class="params">(arr[N<span class="number">-1</span>],N<span class="number">-1</span>)</span></span>;</span><br><span class="line">    stk.push(temp);<span class="comment">//put last value,arr[N-1]</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=N<span class="number">-1</span>; i&gt;=<span class="number">0</span>; i--) &#123;</span><br><span class="line">        <span class="keyword">while</span> ( !stk.empty()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (arr[i] &lt; stk.top().value) &#123;<span class="comment">//compare with stack top value</span></span><br><span class="line">                res.push(stk.top().index);<span class="comment">//remember the result</span></span><br><span class="line">                <span class="function">ListNode <span class="title">temp</span><span class="params">(arr[i],i)</span></span>;</span><br><span class="line">                stk.push(temp);<span class="comment">//put current arr[i]</span></span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                stk.pop();</span><br><span class="line">                <span class="keyword">if</span> (stk.empty()) &#123;</span><br><span class="line">                    res.push(<span class="number">-1</span>); <span class="comment">//no bigger data, so res is -1</span></span><br><span class="line">                    <span class="function">ListNode <span class="title">temp</span><span class="params">(arr[i],i)</span></span>; <span class="comment">//put this value in it</span></span><br><span class="line">                    stk.push(temp);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;N; i++) &#123;<span class="comment">//print the result</span></span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;res.top()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        res.pop();</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1，一面&quot;&gt;&lt;a href=&quot;#1，一面&quot; class=&quot;headerlink&quot; title=&quot;1，一面&quot;&gt;&lt;/a&gt;1，一面&lt;/h3&gt;&lt;p&gt;第一次面试，居然去面了目前北京最火的一家公司。emmm，真的是胆大。不过一面的面试官超级可爱，很温和，我也太幸运了吧。先让自我介绍，然后问项目，然后出了一个很简单的算法题。&lt;/p&gt;&lt;h4 id=&quot;1-1-图论问题&quot;&gt;&lt;a href=&quot;#1-1-图论问题&quot; class=&quot;headerlink&quot; title=&quot;1.1 图论问题&quot;&gt;&lt;/a&gt;1.1 图论问题&lt;/h4&gt;&lt;p&gt;项目是我大三做的一个图论赛题，回顾总结一下。&lt;/p&gt;&lt;p&gt;问题：“服务器选址问题”，从图中选出一些节点安放服务器（图中绿色节点 表示为$S_i$），服务器输出流量供给消费节点（图中红色节点，表示为$C_i$）&lt;/p&gt;
    
    </summary>
    
    
      <category term="算法" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="面试" scheme="http://yoursite.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>20191210Skyline源码阅读</title>
    <link href="http://yoursite.com/2019/12/10/20191210Skyline%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
    <id>http://yoursite.com/2019/12/10/20191210Skyline%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</id>
    <published>2019-12-10T01:32:49.000Z</published>
    <updated>2019-12-31T10:33:24.904Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-基类结构"><a href="#1-基类结构" class="headerlink" title="1 基类结构"></a>1 基类结构</h3><p>首先看异常检测基类base.py，所有检测器都是由它继承而来：</p><p>1，init() ：初始化dataSet，probationaryPercent 数据的最初一部分数据不做测试。inputMin, inputMax初始化最大最小值。</p><p>2，initialize()：多进程问题。进程池pool（它默认调用的是CPU的核数）</p><a id="more"></a><p>3，handleRecord(): 返回每一个时间点的异常分数值，Returns a list [anomalyScore, *]。这个函数子类必须继承。</p><p>4，getAdditionalHeaders()：如HTM检测器里会添加’anomalyscore’ , ‘rawscore’。添加并返回列名的，run函数中调用它拼接最后返回的dataframe。</p><p>5，detectDataSet(): 在运行给定检测器的每个检测器进程中调用的函数。参数 (i, detectorInstance, detectorName, labels, outputDir, relativePath) = args，主要是创建保存文件的路径，调用detectorInstance.initialize()，results = detectorInstance.run() </p><p>6，run()：为整个dataSet打分并返回结果（dataframe格式）</p><h3 id="2-Etsy的Skyline算法"><a href="#2-Etsy的Skyline算法" class="headerlink" title="2 Etsy的Skyline算法"></a>2 Etsy的Skyline算法</h3><p>继承异常检测器基类。另外它的算法是根据几个小算法各自的评分进行平均投票得到。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">self.algorithms =   [median_absolute_deviation,</span><br><span class="line">                     first_hour_average,</span><br><span class="line">                     stddev_from_average,</span><br><span class="line">                     stddev_from_moving_average,</span><br><span class="line">                     mean_subtraction_cumulation,</span><br><span class="line">                     least_squares,</span><br><span class="line">                     histogram_bins]</span><br></pre></td></tr></table></figure><h5 id="median-absolute-deviation"><a href="#median-absolute-deviation" class="headerlink" title="median_absolute_deviation"></a>median_absolute_deviation</h5><p>计算数据的中位数，偏差 = 每个值-中位数，得到偏差中位数</p><script type="math/tex; mode=display">\mathrm{MAD}=\operatorname{median}\left(\left|X_{i}-\operatorname{median}(X)\right|\right)</script><p>MAD对数据集中的异常值比标准偏差更具弹性。在标准偏差中，与均值的距离的平方，较大的异常值会影响更大。可以通过判断一个点的偏差是否过于偏离MAD来判断异常，此处是如果偏差6倍大于中位数，则判断为异常。</p><h5 id="first-hour-average"><a href="#first-hour-average" class="headerlink" title="first_hour_average"></a>first_hour_average</h5><p>上一天的这个时间段1h的均值是$mean$，标准差是$std$，如果$|X_t - mean| &gt; 3 * std$ 则是异常。</p><h5 id="stddev-from-average"><a href="#stddev-from-average" class="headerlink" title="stddev_from_average"></a>stddev_from_average</h5><p>值减去移动平均值大于平均值的三个标准偏差则为异常。</p><script type="math/tex; mode=display">|X_t - mean| > 3 * std</script><h5 id="stddev-from-moving-average"><a href="#stddev-from-moving-average" class="headerlink" title="stddev_from_moving_average"></a>stddev_from_moving_average</h5><p>值减去指数加权移动平均值大于平均值的三个标准偏差则为异常。</p><p>expAvg = series.ewm().mean()</p><p>stdDev = series.ewm().std()</p><script type="math/tex; mode=display">| X_t - expAvg | > 3 * stdDev</script><h5 id="mean-subtraction-cumulation"><a href="#mean-subtraction-cumulation" class="headerlink" title="mean_subtraction_cumulation"></a>mean_subtraction_cumulation</h5><p>从每个数据源点减去过去历史平均值之后，如果该序列中下一个数据点的值比累积项中的三个标准差远，则该时间序列是异常的。</p><h5 id="least-squares"><a href="#least-squares" class="headerlink" title="least_squares"></a>least_squares</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#X——代表时间 timestamp，Y——代表 value</span><br><span class="line">results = np.linalg.lstsq(A, Y)</span><br><span class="line">residual = results[1] #残差</span><br><span class="line">m, c = np.linalg.lstsq(A, Y)[0] #斜率与截距</span><br><span class="line">  for i, value in enumerate(y):</span><br><span class="line">    projected = m * X[i] + c</span><br><span class="line">    error = value - projected</span><br><span class="line">    errors.append(error)</span><br></pre></td></tr></table></figure><p>最后点投影到最小二乘上误差大于所有误差的std的3sigma时，判断为异常。</p><script type="math/tex; mode=display">Error_t > ErrorsStd</script><h5 id="histogram-bins"><a href="#histogram-bins" class="headerlink" title="histogram_bins"></a>histogram_bins</h5><p>最后时间点的值落入带有少于threshold个其他数据点的直方图bin中，则时间序列是异常的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-基类结构&quot;&gt;&lt;a href=&quot;#1-基类结构&quot; class=&quot;headerlink&quot; title=&quot;1 基类结构&quot;&gt;&lt;/a&gt;1 基类结构&lt;/h3&gt;&lt;p&gt;首先看异常检测基类base.py，所有检测器都是由它继承而来：&lt;/p&gt;&lt;p&gt;1，init() ：初始化dataSet，probationaryPercent 数据的最初一部分数据不做测试。inputMin, inputMax初始化最大最小值。&lt;/p&gt;&lt;p&gt;2，initialize()：多进程问题。进程池pool（它默认调用的是CPU的核数）&lt;/p&gt;
    
    </summary>
    
    
      <category term="AIOps" scheme="http://yoursite.com/categories/AIOps/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AIOps" scheme="http://yoursite.com/tags/AIOps/"/>
    
  </entry>
  
  <entry>
    <title>mac上hexo的mathjax配置</title>
    <link href="http://yoursite.com/2019/11/26/20191126mac%E4%B8%8Ahexo%E7%9A%84mathjax%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoursite.com/2019/11/26/20191126mac%E4%B8%8Ahexo%E7%9A%84mathjax%E9%85%8D%E7%BD%AE/</id>
    <published>2019-11-26T03:50:08.000Z</published>
    <updated>2019-12-10T01:46:28.124Z</updated>
    
    <content type="html"><![CDATA[<p>博文中要写公式是难免的，因为配置hexo支持数学公式是必要的。 Next 主题提供了两个渲染引擎，分别是 mathjax 和 katex，后者相对前者来说渲染速度更快，而且支持更丰富的公式。我这里hexo是4.0版本了，因此又折腾了下。</p><h6 id="1，更改next下的config"><a href="#1，更改next下的config" class="headerlink" title="1，更改next下的config"></a>1，更改next下的config</h6><p>配置next主题里的_config如下，只需要改一个地方就是mathjax的enable为true。</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># Math Formulas Render Support</span><br><span class="line">math:</span><br><span class="line">  # Default (true) will load mathjax / katex script on demand.</span><br><span class="line">  # That is it only render those page which has `mathjax: true` in Front-matter.</span><br><span class="line">  # If you set it to false, it will load mathjax / katex srcipt EVERY PAGE.</span><br><span class="line">  per_page: true</span><br><span class="line"></span><br><span class="line">  # hexo-renderer-pandoc (or hexo-renderer-kramed) required for full MathJax support.</span><br><span class="line">  mathjax:</span><br><span class="line">    enable: true</span><br><span class="line">    # See: https://mhchem.github.io/MathJax-mhchem/</span><br><span class="line">    mhchem: false</span><br></pre></td></tr></table></figure><h6 id="2-去掉hexo自带的数学渲染"><a href="#2-去掉hexo自带的数学渲染" class="headerlink" title="2, 去掉hexo自带的数学渲染"></a>2, 去掉hexo自带的数学渲染</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure><p>在修改下源文件。打开<code>node_modules/hexo-renderer-kramed/lib/renderer.js</code>，将</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// Change inline math rule</span><br><span class="line">function formatText(text) &#123;</span><br><span class="line">    // Fit kramed&apos;s rule: $$ + \1 + $$</span><br><span class="line">    return text.replace(/`\$(.*?)\$`/g, &apos;$$$$$1$$$$&apos;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>改为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// Change inline math rule</span><br><span class="line">function formatText(text) &#123;</span><br><span class="line">    return text;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>卸载hexo-math，安装新的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-math --save</span><br><span class="line">npm install hexo-renderer-mathjax --save</span><br></pre></td></tr></table></figure><p>在修改源文件，打开<code>node_modules/hexo-renderer-mathjax/mathjax.html</code>，将最后一句script改为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure><p>打开<code>node_modules/kramed/lib/rules/inline.js</code> : </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,  注释掉改为下面一句</span><br><span class="line">escape: /^\\([`*\[\]()# +\-.!_&gt;])/,</span><br></pre></td></tr></table></figure><p>下面的em渲染也改了:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 注释掉改为下面一句</span><br><span class="line">em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br></pre></td></tr></table></figure><h6 id="3，开启bolg下的config支持"><a href="#3，开启bolg下的config支持" class="headerlink" title="3，开启bolg下的config支持"></a>3，开启bolg下的config支持</h6><p>在末尾添加内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mathjax:</span><br><span class="line">    enable: true</span><br></pre></td></tr></table></figure><p>就可以了，鉴于之前的博客可能有些老了，配置了半天就记录下。</p><h6 id="4，最后自己在写bolg的时候头部加上mathjax-true，表示本文要数学公式渲染。"><a href="#4，最后自己在写bolg的时候头部加上mathjax-true，表示本文要数学公式渲染。" class="headerlink" title="4，最后自己在写bolg的时候头部加上mathjax: true，表示本文要数学公式渲染。"></a>4，最后自己在写bolg的时候头部加上mathjax: true，表示本文要数学公式渲染。</h6>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;博文中要写公式是难免的，因为配置hexo支持数学公式是必要的。 Next 主题提供了两个渲染引擎，分别是 mathjax 和 katex，后者相对前者来说渲染速度更快，而且支持更丰富的公式。我这里hexo是4.0版本了，因此又折腾了下。&lt;/p&gt;&lt;h6 id=&quot;1，更改next下的config&quot;&gt;&lt;a href=&quot;#1，更改next下的config&quot; class=&quot;headerlink&quot; title=&quot;1，更改next下的config&quot;&gt;&lt;/a&gt;1，更改next下的config&lt;/h6&gt;&lt;p&gt;配置next主题里的_config如下，只需要改一个地方就是mathjax的enable为true。&lt;/p&gt;
    
    </summary>
    
    
      <category term="配置" scheme="http://yoursite.com/categories/%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="配置" scheme="http://yoursite.com/tags/%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>Numenta的HTM简介</title>
    <link href="http://yoursite.com/2019/11/25/20191125Numenta%E7%9A%84HTM%E7%AE%80%E4%BB%8B/"/>
    <id>http://yoursite.com/2019/11/25/20191125Numenta%E7%9A%84HTM%E7%AE%80%E4%BB%8B/</id>
    <published>2019-11-25T08:26:49.000Z</published>
    <updated>2019-12-04T04:18:05.801Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-Numenta的HTM简介"><a href="#1-Numenta的HTM简介" class="headerlink" title="1, Numenta的HTM简介"></a>1, Numenta的HTM简介</h4><p>Hierarchical Temporal Memeory(HTM,层级时间记忆，皮质学习) 是一种基于脑神经科学来模拟大脑进行学习和信息处理的神经网络。新皮质就是大脑里褶皱的皮层部分（图1），这只有哺乳动物有。将皮层纵向切开，不论是视觉还是听觉部分，切开后的结构是相似的（图2），很有可能大脑处理不同信息的方法是类似的。</p><a id="more"></a><p><img src="/images/20191125head.jpg" width="250"><br><img src="/images/20191125cells.png" width="200"> </p><p><center>图1 大脑皮层，图2 细胞图</center><br>新皮质分化为很多个区域（region，图3），这些区域通过神经纤维连接。这些区域以层次结构的方式连接在一起。低层级信息收集基础信号，经过不同层级逐渐加工，提取并理解更抽象信息，更高级的话或许可以关联到想法、事物活动等信息。这个有点类似卷积神经网络，低层级的网络提取图像边界等信息，高层级的网络识别物体类型等等。</p><p><img src="/images/20191125HierarchicalMode1.png" width="400"></p><p><center> 图 3 HTM分层示意图</center><br>目前，<strong>Numenta的HTM设计介绍讲解主要针对一个区域，即一层（图3，如黄色层），说明其数据输入方式，数据表征方式，神经元激活，以及时间记忆表示方式</strong>。HTM大概的原理是，首先将输入的数据编码为0、1稀疏数组，将这些稀疏数组经过空间池化转换为稀疏分布表征（SDR），然后时序记忆，建立突触，存储信息，进行预测等。</p><h4 id="2-数据输入"><a href="#2-数据输入" class="headerlink" title="2, 数据输入"></a>2, 数据输入</h4><p>数据输入一般有数字，日期，温度等，将这些数据编码为01稀疏数组（bit数组）。这在计算机领域十分常见，如一个字符的ASCⅡ表示，使用8bit表示的。n个bit可以表示$2^n$容量（capacity）的信息，bit数组可以有许多运算，与或非与异或等等。</p><p><img src="/images/20191125featureRepresentation1.png" width="400"></p><p>在HTM里，稀疏的每一个1可能表示了一个信息。在通过稀疏bit数组的压缩存储（只存1的下标位置），可以表示非常多的数据信息了。</p><h4 id="3-空间池化Spatial-Pooler"><a href="#3-空间池化Spatial-Pooler" class="headerlink" title="3, 空间池化Spatial Pooler"></a>3, 空间池化Spatial Pooler</h4><h5 id="3-1-稀疏分布表征-SDR"><a href="#3-1-稀疏分布表征-SDR" class="headerlink" title="3.1 稀疏分布表征 SDR"></a>3.1 稀疏分布表征 SDR</h5><p>稀疏分布表征（SDR）是空间池化的结果，通俗来看有点像大脑的数据结构，我们先看看SDR的一些特性，如图。计算SDR的容量:</p><script type="math/tex; mode=display">capacity = \left( \begin{array} { c } { n } \\ { w } \end{array} \right) = \frac { n! } { w! ( n - w )! } = C_n^w （组合数）</script><p>也就是说可以表示这么多的信息量。</p><p><img src="/images/20191125SDR_Define.png" width="400"></p><p>1，SDR的一些基本运算。overlap交集，两个SDR交起来，相同的激活的bit越多，表明这俩SDR越相似。判断俩SDR是否匹配，可以设置一定的阈值。当俩SDR overlap之后，交集bit  $&gt;=\theta$ (阈值)，则俩SDR匹配。</p><p>2，SDR的噪声容忍度（noise tolerant）强。在下图中，选取29%的比例翻转bit的值，对比两个SDR，重叠分数为30。当30大于等于$\theta=30$ 则匹配。意思是说如果俩SDR是原本一致，就算其中一个SDR不完全准确有噪声，则还是会匹配上的。当然也有可能确实两SDR不一致，但又因为噪声导致其匹配上了，这样的误报可能有，但是概率很低 $FP = 交集的基数 / 原始SDR的n w的组合数 $ </p><p><img src="/images/20191125NoiseTolerant.jpg" width="400"></p><h5 id="3-2-SDR的重叠集"><a href="#3-2-SDR的重叠集" class="headerlink" title="3.2 SDR的重叠集"></a>3.2 SDR的重叠集</h5><p>如果俩同样大小的SDR（即$n,w$ 分别相等），所有bit匹配，则匹配的SDR必然跟原SDR一模一样，就只有一个。那如果降低匹配阈值 $\theta$ ，当相同激活的bit数目为$\theta$时，可以有多少个SDR与原SDR相匹配呢？ 这是个排列组合问题。</p><script type="math/tex; mode=display">\left|\Omega(n, w, \theta)\right|=\left(\begin{array}{c}{w} \\ {\theta}\end{array}\right) \times\left(\begin{array}{l}{n-w} \\ {w-\theta}\end{array}\right)</script><p>相匹配的SDR，左边从原SDR里$w$里选出$\theta$个bit来激活，这是俩SDR相同激活的bit。右边从原SDR里没有激活的$n-w$ 个bit里选出 $w-\theta$ 来激活即可。若 $n=600, w=40, \theta = 39$，算一算可以有 $40 * 560$个不同的SDR与原SDR匹配，是不是很多呀。</p><p>这有个好处就是，SDR可以表示很多相似的信息，而且可以直接通过俩SDR的交集来判断是否相似，误报率也很低。</p><h5 id="3-3-SDR栈"><a href="#3-3-SDR栈" class="headerlink" title="3.3 SDR栈"></a>3.3 SDR栈</h5><p>随着时间序列值逐步产生，即SDR也逐步产生。我们模拟看到SDR进行匹配的过程。new SDR与栈里的SDRs匹配，看看之前是不是见到过。匹配的SDR会有很多重叠的bit。</p><p><img src="/images/20191204SDR_Stack.jpg" width="400"></p><p>为了加快计算，之前的所有SDR采用Union合并到一起进行匹配。其实由于$n$很大，错误匹配的概率还是很小的。</p><h4 id="5-时序记忆-Temporal-Memory"><a href="#5-时序记忆-Temporal-Memory" class="headerlink" title="5, 时序记忆 Temporal Memory"></a>5, 时序记忆 Temporal Memory</h4><h4 id="6-总结"><a href="#6-总结" class="headerlink" title="6, 总结"></a>6, 总结</h4><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p>1，<a href="https://www.bilibili.com/video/av35735228?from=search&amp;seid=7001690129614399170" target="_blank" rel="noopener">bilibili的翻译HTM school</a></p><p>2，<a href="https://numenta.org/htm-school/" target="_blank" rel="noopener">numenta的YouTube视频</a></p><p>3， Ahmad S, Lavin A, Purdy S, et al. Unsupervised real-time anomaly detection for streaming data[J]. Neurocomputing, 2017, 262: 134-147.</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;1-Numenta的HTM简介&quot;&gt;&lt;a href=&quot;#1-Numenta的HTM简介&quot; class=&quot;headerlink&quot; title=&quot;1, Numenta的HTM简介&quot;&gt;&lt;/a&gt;1, Numenta的HTM简介&lt;/h4&gt;&lt;p&gt;Hierarchical Temporal Memeory(HTM,层级时间记忆，皮质学习) 是一种基于脑神经科学来模拟大脑进行学习和信息处理的神经网络。新皮质就是大脑里褶皱的皮层部分（图1），这只有哺乳动物有。将皮层纵向切开，不论是视觉还是听觉部分，切开后的结构是相似的（图2），很有可能大脑处理不同信息的方法是类似的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="AIOps" scheme="http://yoursite.com/categories/AIOps/"/>
    
    
      <category term="AIOps" scheme="http://yoursite.com/tags/AIOps/"/>
    
      <category term="神经网络" scheme="http://yoursite.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>[paper]2019/11/06AIOps: Real-World Challenges and Research Innovations</title>
    <link href="http://yoursite.com/2019/11/06/paper-2019-11-06AIOps-Real-World-Challenges-and-Research-Innovations/"/>
    <id>http://yoursite.com/2019/11/06/paper-2019-11-06AIOps-Real-World-Challenges-and-Research-Innovations/</id>
    <published>2019-11-06T12:56:04.000Z</published>
    <updated>2019-11-06T12:56:38.592Z</updated>
    
    <content type="html"><![CDATA[<h3 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h3><p>论文名字：AIOps: Real-World Challenges and Research Innovations<br>引用：Dang Y, Lin Q, Huang P. AIOps: real-world challenges and research innovations[C]//Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings. IEEE Press, 2019: 4-5.</p><a id="more"></a><h3 id="AIOps定义"><a href="#AIOps定义" class="headerlink" title="AIOps定义"></a>AIOps定义</h3><p>智能运维的定义：通过AI与ML有效构建运维应用 AIOps is about empowering software and service engineers (e.g., developers, program managers, support engineers, site reliability engineers) to efficiently and effectively build and operate online services and applications at scale with artificial intelligence (AI) and machine learning (ML) techniques. </p><p>DevOps 连续开发部署应用（来源于 G. Kim, P. Debois, et al, “The DevOps Handbook: How to Create World- Class Agility, Reliability, and Security in Technology Organizations”, IT Revolution Press, Oct. 2016）</p><h3 id="AIOps的三个目标"><a href="#AIOps的三个目标" class="headerlink" title="AIOps的三个目标"></a>AIOps的三个目标</h3><p>1，服务智能化<br>及时观察多方面变化，质量下降，成本增加，工作量增加等，基于AIOps的服务还可以根据其历史行为，工作量模式和基础来预测其未来状态。根据状态自我调整，trigger self-adaption or auto-healing behaviors of a service, with low human intervention.</p><p>思考：要监控性能，监控反应时间，问题调整策略（自动化调整）</p><p>2，较高的客户满意度<br>具有内置智能的服务可以了解客户的使用行为，并采取积极的行动来提高客户满意度。 例如，服务可以自动向客户推荐调整建议，以使其获得最佳性能（例如，调整配置，冗余级别，资源分配）</p><p>思考：网络不好的话如何自动调整？</p><p>3，高工程生产率<br> 工程师和操作员免于繁琐的工作，例如（1）从各种来源手动收集信息以调查问题； （2）解决重复出现的问题。 工程师和操作人员还可以使用AI / ML技术来学习系统行为的模式，预测服务行为和客户活动的未来，以进行必要的体系结构更改和服务适应策略更改等。</p><h3 id="challenges"><a href="#challenges" class="headerlink" title="challenges"></a>challenges</h3><p>整体思考，充足理解系统<br>工程架构转变 the AIOps engineering principles should include data/label quality monitoring and assurances, continuous model-quality validation, and actionability of insights.<br>缺乏label，极端失衡，数量太少，噪声程度高等，监督或半监督模型<br>组件服务之间的复杂依存关系</p><p>思考：还有服务变更带来的问题，新学习吗？<br>实时数据大量产生，怎么利用?</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;论文信息&quot;&gt;&lt;a href=&quot;#论文信息&quot; class=&quot;headerlink&quot; title=&quot;论文信息&quot;&gt;&lt;/a&gt;论文信息&lt;/h3&gt;&lt;p&gt;论文名字：AIOps: Real-World Challenges and Research Innovations&lt;br&gt;引用：Dang Y, Lin Q, Huang P. AIOps: real-world challenges and research innovations[C]//Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings. IEEE Press, 2019: 4-5.&lt;/p&gt;
    
    </summary>
    
    
      <category term="AIOps" scheme="http://yoursite.com/categories/AIOps/"/>
    
    
      <category term="AIOps" scheme="http://yoursite.com/tags/AIOps/"/>
    
      <category term="论文综述" scheme="http://yoursite.com/tags/%E8%AE%BA%E6%96%87%E7%BB%BC%E8%BF%B0/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu16配置GPU深度学习环境、CUDA、cuNDD等</title>
    <link href="http://yoursite.com/2019/11/06/ubuntu16%E9%85%8D%E7%BD%AEGPU%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E3%80%81CUDA%E3%80%81cuNDD%E7%AD%89/"/>
    <id>http://yoursite.com/2019/11/06/ubuntu16%E9%85%8D%E7%BD%AEGPU%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E3%80%81CUDA%E3%80%81cuNDD%E7%AD%89/</id>
    <published>2019-11-06T03:15:21.000Z</published>
    <updated>2019-12-25T04:10:59.719Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1、准备"><a href="#1、准备" class="headerlink" title="1、准备"></a>1、准备</h3><ol><li>请先看好各种软件的版本对应要求，这仨一定要对应好。<pre><code>  [Tensorflow不同版本要求与CUDA及CUDNN版本对应关系](https://blog.csdn.net/omodao1/article/details/83241074)</code></pre></li><li><p>知道要下哪些版本了，就预先做好各种软件下载工作。<br> 首先下载好英伟达的驱动 <a href="https://www.nvidia.cn/Download/index.aspx?lang=cn" target="_blank" rel="noopener">NVIDIA驱动下载</a><br> 注意！！！下载好跟自己显卡对应的驱动。显卡的产品类型、系列那些如果之前已经装好了驱动，则可以通过命令 nvidia-smi查询到。没有装刚买来就自己查。<br><img src="https://img-blog.csdnimg.cn/20190519153242367.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="我的显卡驱动"><br>即使你的机器之前已经装过驱动，那也最好重新装一遍驱动，因为那个CUDA一定要对应起来。不然后面有坑！</p><p>下载CUDA，链接 <a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">cuda-toolkit-archive</a><br><img src="https://img-blog.csdnimg.cn/20190519154540803.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="下载CUDA9.0版本"><br>请注意这里一定要选择下载runfilw文件，不是deb！，不然会覆盖之前的显卡驱动带来问题。<br><img src="https://img-blog.csdnimg.cn/20190519154709423.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="对应操作系统下载CUDA"><br>最后下载cuDNN，<a href="https://developer.nvidia.com/rdp/cudnn-archive" target="_blank" rel="noopener">cuDNN下载地址</a>，我下的7.0.5版本<br><img src="https://img-blog.csdnimg.cn/20190519160003336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="cuDNN下载"></p><h3 id="2、安装驱动"><a href="#2、安装驱动" class="headerlink" title="2、安装驱动"></a>2、安装驱动</h3><h4 id="2-1、正常装驱动。"><a href="#2-1、正常装驱动。" class="headerlink" title="2.1、正常装驱动。"></a>2.1、正常装驱动。</h4><p>按ctrl+alt+f2（有的是f1）进入字符界面命令行，先删除以前的驱动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get purge nvidia*</span><br><span class="line">sudo apt-get autoremove</span><br></pre></td></tr></table></figure><p>禁止自带的nouveau nvidia驱动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 打开配置文件</span><br><span class="line">sudo vim /etc/modprobe.d/blacklist-nouveau.conf</span><br></pre></td></tr></table></figure><p>添加以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">blacklist nouveau</span><br><span class="line">options nouveau modeset=0</span><br></pre></td></tr></table></figure><p>再更新一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo update-initramfs -u</span><br></pre></td></tr></table></figure><p>最后需要进行重启。查看下Nouveau是否已经禁止，无输出则为成功：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsmod | grep nouveau</span><br></pre></td></tr></table></figure><p>按ctrl+alt+f2，接着关闭图形化界面：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service lightdm stop</span><br></pre></td></tr></table></figure><p>然后准备开始装驱动了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sh NVIDIA-Linux-x86_64-XXX.run  –-no-opengl-files</span><br></pre></td></tr></table></figure><p>然后重新打开图形界面：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service lightdm start</span><br></pre></td></tr></table></figure><p>再ctrl+alt+f7进入图形界面，再测试下驱动是否装好：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><p>安装完成后，重启:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo reboot</span><br></pre></td></tr></table></figure><p>在命令行通过nvidia-smi还可以查看到驱动的话就没有问题了，以上皆为顺利的过程。</p></li></ol><a id="more"></a><h4 id="2-2、意外情况"><a href="#2-2、意外情况" class="headerlink" title="2.2、意外情况"></a>2.2、意外情况</h4><p>当然我装的时候是遇到了个大坑的。我看到之前机器上装好了驱动就没管，然后开始装后面的CUDA，结果下的CUDA又是deb的包，导致安装中覆盖了之前的驱动，然后ubuntu打开正确输入密码也无法进入桌面了。</p><h5 id="2-2-1-安装libelf-dev"><a href="#2-2-1-安装libelf-dev" class="headerlink" title="2.2.1 安装libelf-dev"></a>2.2.1 安装libelf-dev</h5><p>于是我又修复，倒回到2.1开始，清理驱动，重装。中间在执行sudo sh NVIDIA-Linux-x86_64-XXX.run  –-no-opengl-files的时候还遇到了build出错，如图：<br><img src="https://img-blog.csdnimg.cn/20190519162933827.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="驱动编译出错"><br>打开他提示的nvidia-installer.log看，里面提示了很多<br><img src="https://img-blog.csdnimg.cn/20190519163249938.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="问题提示"><br>这里还挺好的提示了请安装libelf-dev这种信息，于是我又去下载 <a href="https://pkgs.org/download/libelf-dev" target="_blank" rel="noopener">libelf-dex安装包</a>。本来我只下了1那个，然后输入命令安装：<br><img src="https://img-blog.csdnimg.cn/20190519163856594.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="libelf的版本"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg -i libelf-dev_0.165-3ubuntu1_amd64.deb</span><br></pre></td></tr></table></figure><br>很无情的又报了个错，提示amd64 system is ….ubuntu1.1，于是我又下了2那个更新包，再dpkg安装。<br><img src="https://img-blog.csdnimg.cn/20190519164151594.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>终于顺利给装上了，没有报错了。</p><h5 id="2-2-2-gcc和g-版本问题"><a href="#2-2-2-gcc和g-版本问题" class="headerlink" title="2.2.2 gcc和g++版本问题"></a>2.2.2 gcc和g++版本问题</h5><p>前面的装好了，我又准备执行sudo sh NVIDIA-Linux-x86_64-XXX.run  –-no-opengl-files 来着，然而还有问题，又通过命令查看log信息，sudo vim nvidia-installer.log。<br><img src="https://img-blog.csdnimg.cn/20190519164725139.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="不识别Command line"><br>这个问题就是由于gcc和g++版本太低编译不过导致的，因为我看之前有个教程是将这个版本降低了方便CUDA编译来着。但其实我这是CUDA9.0，CUDA9要求GCC版本是5.x或者6.x，其他版本不可以，需要自己进行配置。我之前就是5.5的版本，就不该降级。好的现在再根据那篇博文给换回来。<br><a href="https://blog.csdn.net/u011784994/article/details/80080938" target="_blank" rel="noopener">ubuntu 16.04 LTS 降级安装gcc 4.8</a></p><h5 id="2-2-3-装好驱动"><a href="#2-2-3-装好驱动" class="headerlink" title="2.2.3 装好驱动"></a>2.2.3 装好驱动</h5><p>在sh NVIDIA-Linux-x86_64-XXX.run安装就可以了，哎哟喂真是不容易啊。。。<br>然后我再重启，输入密码，终于可以进入桌面了呀，感动到哭。。。</p><h3 id="3、安装CUDA"><a href="#3、安装CUDA" class="headerlink" title="3、安装CUDA"></a>3、安装CUDA</h3><ol><li>安装CUDA<br>打开终端，执行命令，运行run文件：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sh cuda_9.0.176_384.81_linux.run</span><br></pre></td></tr></table></figure>注意提示，前面是一些法律信息啥的，enter过去就好。到后面提示是否安装图像驱动的时候，一定选择no ！！！<br><img src="https://img-blog.csdnimg.cn/20190519165519471.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_4,color_FFFFFF,t_70" alt="no Driver"><br>后面的一些提示选择y就行。出现下图，就表示安装完成。<br><img src="https://img-blog.csdnimg.cn/20190519165702507.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70" alt="CUDA安装"><br>如果出现其他问题，可能是某些依赖库没装好，反正我是没遇到。可以试试安装依赖，然后重启再试试。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler</span><br><span class="line">sudo apt-get install --no-install-recommends libboost-all-dev</span><br><span class="line">sudo apt-get install libopenblas-dev liblapack-dev libatlas-base-dev</span><br><span class="line">sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev</span><br></pre></td></tr></table></figure></li></ol><ol><li><p>配置环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit ~/.bashrc</span><br></pre></td></tr></table></figure><p>打开文件后在最后写入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export PATH=/usr/local/cuda-9.0/bin$&#123;PATH:+:$&#123;PATH&#125;&#125;  </span><br><span class="line">export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</span><br></pre></td></tr></table></figure><p>然后点save后关闭在source一下生效：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure></li><li><p>测试一下CUDA是否安装成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 第一步，进入例子文件</span><br><span class="line">cd /usr/local/cuda-8.0/samples/1_Utilities/deviceQuery</span><br><span class="line"># 第二步，执行make命令</span><br><span class="line">sudo make</span><br><span class="line"># 第三步</span><br><span class="line">./deviceQuery</span><br></pre></td></tr></table></figure><p>有提示GPU信息，就表示可以了。</p></li></ol><h3 id="4、安装cuDNN"><a href="#4、安装cuDNN" class="headerlink" title="4、安装cuDNN"></a>4、安装cuDNN</h3><p>安装命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg -i libcudnn7_7.0.5.15-1+cuda9.0_amd64.deb</span><br><span class="line">sudo dpkg -i libcudnn7-dev_7.0.5.11-1+cuda9.0_amd64.deb</span><br><span class="line">sudo dpkg -i libcudnn7-doc_7.0.5.11-1+cuda9.0_amd64.deb</span><br></pre></td></tr></table></figure><br>安装完以后需要进行测试是否安装成功，出现了“Test passed! ”，这几步我都没啥问题：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cp -r /usr/src/cudnn_samples_v7/ $HOME</span><br><span class="line">cd $HOME/cudnn_samples_v7/mnistCUDNN</span><br><span class="line">make clean &amp;&amp; make</span><br><span class="line">./mnistCUDNN</span><br></pre></td></tr></table></figure></p><h3 id="5、安装TensorFlow-gpu"><a href="#5、安装TensorFlow-gpu" class="headerlink" title="5、安装TensorFlow-gpu"></a>5、安装TensorFlow-gpu</h3><p>卸载以前的TensorFlow，我的python环境是3.6<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 uninstall tensorflow</span><br></pre></td></tr></table></figure><br>然后重新装gpu版本就可以，注意我要用的是TensorFlow-gpu1.7版本，这个跟前面的都是对应的！</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 -i https://pypi.tuna.tsinghua.edu.cn/simple/ install tensorflow-gpu==1.7.0</span><br></pre></td></tr></table></figure><p>跑程序的时候，自动就调用了gpu进行计算，学习起来快了6、7倍，真的是开心啊~</p><h3 id="6、总结"><a href="#6、总结" class="headerlink" title="6、总结"></a>6、总结</h3><ol><li>最关键的问题就是软件各个版本要对应好</li><li>注意先装驱动再CUDA再cuDNN，总之就是驱动要先搞好，不然就会有我那种意外。</li><li>CUDA一定下载runfile文件。</li></ol><h3 id="7、reference"><a href="#7、reference" class="headerlink" title="7、reference"></a>7、reference</h3><p><a href="https://blog.csdn.net/weixin_41863685/article/details/80303963" target="_blank" rel="noopener">Ubuntu18.04深度学习GPU环境配置</a><br>我进不了桌面，也连不了网，所以都是自己拿另外的电脑下了U盘弄过去的。<br><a href="https://blog.csdn.net/hhhhh89/article/details/54311161" target="_blank" rel="noopener">ubuntu中使用终端查看U盘里的内容</a><br><a href="https://blog.csdn.net/u011784994/article/details/80080938" target="_blank" rel="noopener">ubuntu 16.04 LTS 降级安装gcc 4.8</a><br><a href="https://blog.csdn.net/omodao1/article/details/83241074" target="_blank" rel="noopener">Tensorflow不同版本要求与CUDA及CUDNN版本对应关系</a><br>最后感谢各个外援~</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1、准备&quot;&gt;&lt;a href=&quot;#1、准备&quot; class=&quot;headerlink&quot; title=&quot;1、准备&quot;&gt;&lt;/a&gt;1、准备&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;请先看好各种软件的版本对应要求，这仨一定要对应好。&lt;pre&gt;&lt;code&gt;  [Tensorflow不同版本要求与CUDA及CUDNN版本对应关系](https://blog.csdn.net/omodao1/article/details/83241074)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;知道要下哪些版本了，就预先做好各种软件下载工作。&lt;br&gt; 首先下载好英伟达的驱动 &lt;a href=&quot;https://www.nvidia.cn/Download/index.aspx?lang=cn&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;NVIDIA驱动下载&lt;/a&gt;&lt;br&gt; 注意！！！下载好跟自己显卡对应的驱动。显卡的产品类型、系列那些如果之前已经装好了驱动，则可以通过命令 nvidia-smi查询到。没有装刚买来就自己查。&lt;br&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190519153242367.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70&quot; alt=&quot;我的显卡驱动&quot;&gt;&lt;br&gt;即使你的机器之前已经装过驱动，那也最好重新装一遍驱动，因为那个CUDA一定要对应起来。不然后面有坑！&lt;/p&gt;
&lt;p&gt;下载CUDA，链接 &lt;a href=&quot;https://developer.nvidia.com/cuda-toolkit-archive&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;cuda-toolkit-archive&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190519154540803.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70&quot; alt=&quot;下载CUDA9.0版本&quot;&gt;&lt;br&gt;请注意这里一定要选择下载runfilw文件，不是deb！，不然会覆盖之前的显卡驱动带来问题。&lt;br&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190519154709423.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70&quot; alt=&quot;对应操作系统下载CUDA&quot;&gt;&lt;br&gt;最后下载cuDNN，&lt;a href=&quot;https://developer.nvidia.com/rdp/cudnn-archive&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;cuDNN下载地址&lt;/a&gt;，我下的7.0.5版本&lt;br&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20190519160003336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_1,color_FFFFFF,t_70&quot; alt=&quot;cuDNN下载&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;2、安装驱动&quot;&gt;&lt;a href=&quot;#2、安装驱动&quot; class=&quot;headerlink&quot; title=&quot;2、安装驱动&quot;&gt;&lt;/a&gt;2、安装驱动&lt;/h3&gt;&lt;h4 id=&quot;2-1、正常装驱动。&quot;&gt;&lt;a href=&quot;#2-1、正常装驱动。&quot; class=&quot;headerlink&quot; title=&quot;2.1、正常装驱动。&quot;&gt;&lt;/a&gt;2.1、正常装驱动。&lt;/h4&gt;&lt;p&gt;按ctrl+alt+f2（有的是f1）进入字符界面命令行，先删除以前的驱动：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get purge nvidia*&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get autoremove&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;禁止自带的nouveau nvidia驱动：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 打开配置文件&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo vim /etc/modprobe.d/blacklist-nouveau.conf&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;添加以下内容：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;blacklist nouveau&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;options nouveau modeset=0&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;再更新一下：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo update-initramfs -u&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;最后需要进行重启。查看下Nouveau是否已经禁止，无输出则为成功：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;lsmod | grep nouveau&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;按ctrl+alt+f2，接着关闭图形化界面：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo service lightdm stop&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;然后准备开始装驱动了。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo sh NVIDIA-Linux-x86_64-XXX.run  –-no-opengl-files&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;然后重新打开图形界面：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo service lightdm start&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;再ctrl+alt+f7进入图形界面，再测试下驱动是否装好：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;nvidia-smi&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;安装完成后，重启:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo reboot&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在命令行通过nvidia-smi还可以查看到驱动的话就没有问题了，以上皆为顺利的过程。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="配置" scheme="http://yoursite.com/tags/%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>2019HUAWEI_DiGiX_CTR</title>
    <link href="http://yoursite.com/2019/07/20/20190810HUAWEI-DiGiX-CTR/"/>
    <id>http://yoursite.com/2019/07/20/20190810HUAWEI-DiGiX-CTR/</id>
    <published>2019-07-20T02:36:44.000Z</published>
    <updated>2020-01-03T13:12:49.665Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-赛题介绍"><a href="#1-赛题介绍" class="headerlink" title="1 赛题介绍"></a>1 赛题介绍</h3><p>7月HUAWEI-DIGIX比赛是广告CTR预估问题。 数据如下：</p><div class="table-container"><table><thead><tr><th>train.zip</th><th>zip（2.62GB）</th><th>2019-05-18 00:00:00</th><th></th></tr></thead><tbody><tr><td>test.zip</td><td>zip（15MB）</td><td>2019-05-18 00:00:00</td><td></td></tr><tr><td>user_info.zip</td><td>zip（291MB）</td><td>2019-05-18 00:00:00</td><td></td></tr><tr><td>ad_info.zip</td><td>zip（17.9KB）</td><td>2019-05-18 00:00:00</td><td></td></tr><tr><td>content_info.zip</td><td>zip（8.16KB）</td><td>2019-05-18 00:00:00</td></tr></tbody></table></div><a id="more"></a><p> 时间范围是某连续6天的行为数据。总体而言，数据集包含： 训练集数据文件、测试集数据文件、用户特征文件、广告任务特征文件、素材信息数据文件。train表和test表里的字段：</p><div class="table-container"><table><thead><tr><th>label</th><th>是否点击，1表示点击，0表示未点击</th></tr></thead><tbody><tr><td>uId</td><td>匿名化处理后的用户唯一标识(示例：u100000001)</td></tr><tr><td>adId</td><td>广告任务唯一标识</td></tr><tr><td>operTime</td><td>操作时间(精确到毫秒，示例: “2019-04-01 10:45:20:257”)</td></tr><tr><td>siteId</td><td>媒体Id</td></tr><tr><td>slotId</td><td>广告位Id</td></tr><tr><td>contentId</td><td>素材Id</td></tr><tr><td>netType</td><td>网络连接类型(示例：1, 2, 3, 4, 5, 6)</td></tr></tbody></table></div><p>user_info表</p><div class="table-container"><table><thead><tr><th>uId</th><th>匿名化处理后的用户唯一标识(示例：u100000001)</th></tr></thead><tbody><tr><td>age</td><td>年龄段(示例：1, 2, 3, 4, 5, 6)</td></tr><tr><td>gender</td><td>性别(示例：1, 2, 3)</td></tr><tr><td>city</td><td>常住城市编码(示例：1, 2, 3…)</td></tr><tr><td>province</td><td>常驻省份编码(示例：1, 2, 3…)</td></tr><tr><td>phoneType</td><td>设备型号(示例：1, 2, 3…)</td></tr><tr><td>carrier</td><td>运营商编号</td></tr></tbody></table></div><p> 广告任务特征文件ad_info.csv：</p><div class="table-container"><table><thead><tr><th>adId</th><th>广告任务唯一标识(示例：2556)</th></tr></thead><tbody><tr><td>billId</td><td>计费类型(示例：cpc, cpm, cpd)</td></tr><tr><td>primId</td><td>广告主唯一编号Id</td></tr><tr><td>creativeType</td><td>创意类型(示例：1. 文字广告，2. 图片广告，3. 图文广告，4. gif广告，5. 无具体创意类型)</td></tr><tr><td>intertype</td><td>交互类型(示例：0. 无交互，点击无响应，1. 点击后打开网，2. 点击下载应用，3. 点击后打开App)</td></tr><tr><td>spreadAppId</td><td>广告对应的appId</td></tr></tbody></table></div><p> 素材信息数据文件content_info.csv:</p><div class="table-container"><table><thead><tr><th>contentId</th><th>素材唯一标识Id</th></tr></thead><tbody><tr><td>firstClass</td><td>素材内容文本的一级分类(示例：电商)</td></tr><tr><td>secondClass</td><td>素材内容文本的二级分类，多值使用‘#’分割</td></tr></tbody></table></div><h3 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2 数据预处理"></a>2 数据预处理</h3><h4 id="2-1-分析数据"><a href="#2-1-分析数据" class="headerlink" title="2.1 分析数据"></a>2.1 分析数据</h4><h5 id="2-2-1-分布情况"><a href="#2-2-1-分布情况" class="headerlink" title="2.2.1 分布情况"></a>2.2.1 分布情况</h5><p>首先查看每个表里数据的分布情况。尤其注意训练集与测试集的分布情况。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.describe() # 查看计数，平均值、标准差，min max等值。</span><br></pre></td></tr></table></figure><p>有些特征取值频次低的考虑合并为其他类。</p><h5 id="2-2-2-可视化分析"><a href="#2-2-2-可视化分析" class="headerlink" title="2.2.2 可视化分析"></a>2.2.2 可视化分析</h5><p>对 Numerical Variable，可以用 Box Plot / 小提琴 来直观地查看它的分布。Categories Variable 用直方图。对于坐标类数据，可以用 Scatter Plot 来查看它们的分布趋势和是否有离群点的存在。（seaborn画图）</p><p>绘制变量之间两两的分布和相关度图表等，发现一些高相关和共线性的特征。</p><p>这些分析都有利于后续构造特征。</p><h4 id="2-2-数据处理"><a href="#2-2-数据处理" class="headerlink" title="2.2 数据处理"></a>2.2 数据处理</h4><p>1，缺失值处理</p><p>可以填补，丢弃等。</p><p>我在比赛中对content的firstclass和secondcalss根据spreadApp进行补全，因为广告类型可能会跟广告出现在哪类app有关系。 取出spreadApp相同的firstClass众数替换了少量缺失值。</p><p>2，异常值处理</p><p>比赛中，遇到了那种机器人用户，连续不停点击。这种数据应该在训练时过滤掉，在最后的提交结果也应该用规则处理下。</p><p>另外可以考虑分箱、均值、中位数、众数处理异常值缺失值等。</p><p>3，归一化和one hot的问题</p><p>SVM、LR模型等常常需要考虑归一化和one hot（dummy）的问题。</p><p>4，划分数据集</p><p>然后采用k折交叉验证。当线下的验证集和线上的测试集有同步的效果时最好，此时可以通过线下的验证集变化来验证线上情况。</p><p>比赛中我没有做到。但是后面问了大佬，做法是把训练集里的有点击广告行为的用户数据抽取出来作为的训练集。</p><h3 id="3-特征工程"><a href="#3-特征工程" class="headerlink" title="3 特征工程"></a>3 特征工程</h3><p>1，特征工程是最重要的。我们其实尝试用过自动特征工程，有一个featuretools，但这个做的所有统计特征都比较偏向数值类型的特征。做类别特征不太强。所以后面还是自己做特征。总的来说，我们应该生成尽量多的 Feature，相信 Model 能够挑出最有用的 Feature。</p><p>交叉特征：把俩取值连接起来，然后将str转换为数值。</p><p>俩俩特征之间的统计特征：比如用户看那些类别的广告数目，用户看广告主的次数等等。还有三个特征之间的统计特征。</p><p>还有就是word2ve的用户id和广告id序列特征（但这个效果不太好）。</p><p>2，筛选特征：</p><p>Random Forest 训练完以后得到的 Feature Importance。</p><p>也可以进行一些统计检验，卡方检验等。</p><p>直接观察CTR。比如特征对应的CTR数目。</p><h3 id="4-模型"><a href="#4-模型" class="headerlink" title="4 模型"></a>4 模型</h3><p>采用了lightGBM树模型。优点：基于直方图的树结点划分，内存消耗更少速度更快。lightGBM的论文阅读见博客。</p><p>注意一些模型选择：</p><ul><li><p>对于稀疏型特征（如文本特征，One-hot的ID类特征），我们一般使用线性模型，比如 Linear Regression 或者 Logistic Regression。Random Forest 和 GBDT 等树模型不太适用于稀疏的特征，但可以先对特征进行降维（如PCA，SVD/LSA等），再使用这些特征。稀疏特征直接输入 DNN 会导致网络 weight 较多，不利于优化，也可以考虑先降维，或者对 ID 类特征使用 Embedding 的方式；</p></li><li><p>对于稠密型特征，推荐使用 XGBoost 进行建模，简单易用效果好；</p></li><li>数据中既有稀疏特征，又有稠密特征，可以考虑使用线性模型对稀疏特征进行建模，将其输出与稠密特征一起再输入 XGBoost/DNN 建模。</li></ul><p>最后理论是要用“好而不同”的模型进行集成的，不过作为基模型lightGBM初期就够用了。</p><h3 id="5-学习"><a href="#5-学习" class="headerlink" title="5 学习"></a>5 学习</h3><p>大佬们的特征工程：</p><p>统计特征：当天广告曝光次数，当天用户曝光次数，当天广告主ID相对用户出现的次数，当天广告位相对用户出现的次数。</p><p>unique特征，用户相对广告的唯一ID，广告相对用户的唯一ID。</p><p>Ratio点击率特征：一维二维的点击率特征。</p><p>低频数据：置None，lightGBM对NULL数据处理友好。</p><p>序列数据：deepwalk或word2vec方法（Uid和广告id）</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，seaborn 可视化 <a href="http://seaborn.pydata.org/tutorial.html" target="_blank" rel="noopener">http://seaborn.pydata.org/tutorial.html</a></p><p>2，个人印象笔记《复赛答辩学习》</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-赛题介绍&quot;&gt;&lt;a href=&quot;#1-赛题介绍&quot; class=&quot;headerlink&quot; title=&quot;1 赛题介绍&quot;&gt;&lt;/a&gt;1 赛题介绍&lt;/h3&gt;&lt;p&gt;7月HUAWEI-DIGIX比赛是广告CTR预估问题。 数据如下：&lt;/p&gt;&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;train.zip&lt;/th&gt;
&lt;th&gt;zip（2.62GB）&lt;/th&gt;
&lt;th&gt;2019-05-18 00:00:00&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;test.zip&lt;/td&gt;
&lt;td&gt;zip（15MB）&lt;/td&gt;
&lt;td&gt;2019-05-18 00:00:00&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;user_info.zip&lt;/td&gt;
&lt;td&gt;zip（291MB）&lt;/td&gt;
&lt;td&gt;2019-05-18 00:00:00&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ad_info.zip&lt;/td&gt;
&lt;td&gt;zip（17.9KB）&lt;/td&gt;
&lt;td&gt;2019-05-18 00:00:00&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;content_info.zip&lt;/td&gt;
&lt;td&gt;zip（8.16KB）&lt;/td&gt;
&lt;td&gt;2019-05-18 00:00:00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="华为比赛" scheme="http://yoursite.com/tags/%E5%8D%8E%E4%B8%BA%E6%AF%94%E8%B5%9B/"/>
    
  </entry>
  
  <entry>
    <title>20190707《明朝那些事1》明朝的建立</title>
    <link href="http://yoursite.com/2019/07/07/20190707%E3%80%8A%E6%98%8E%E6%9C%9D%E9%82%A3%E4%BA%9B%E4%BA%8B1%E3%80%8B%E6%98%8E%E6%9C%9D%E7%9A%84%E5%BB%BA%E7%AB%8B/"/>
    <id>http://yoursite.com/2019/07/07/20190707%E3%80%8A%E6%98%8E%E6%9C%9D%E9%82%A3%E4%BA%9B%E4%BA%8B1%E3%80%8B%E6%98%8E%E6%9C%9D%E7%9A%84%E5%BB%BA%E7%AB%8B/</id>
    <published>2019-07-07T04:01:07.000Z</published>
    <updated>2019-12-10T04:06:01.922Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、序言"><a href="#一、序言" class="headerlink" title="一、序言"></a>一、序言</h3><p>以前我小觑了明朝，看完此书方知其宏伟恢弘。一个持久了两三百年的王朝，中间既有繁荣、胜利、正气；亦有凋敝、惨败与阴邪。历史有趣的就是在这来来回回的博弈中，道义精神的永不磨灭，历史规律的永恒不变。在此，我存着对历史的温情与敬意，以人物性格的角度，记录二三。</p><h3 id="二、人物"><a href="#二、人物" class="headerlink" title="二、人物"></a>二、人物</h3><p>明太祖朱元璋，最初本是穷苦人家的放牛娃。为生计所迫曾辗转为和尚，后来饥荒和压迫，最终他连和尚也做不成了，云游了几年加入了红巾军。在农民军里，他是一个很突出的人，不但作战勇敢，而且很有计谋，处事冷静，思虑深远，还很讲义气，有危险的时候第一个上，这一切都让他有了崇高的威信。</p><a id="more"></a><p><strong>将军——统率之人，必有更多素质要求。其中战略、远见、理想、勇气、气量等等皆不可缺。</strong></p><p>后续，朱元璋大败陈友谅、消灭张士诚，这些都是很精彩的战役。他不仅个人强，周边的人也都很强。他有贤内助妻子马皇后；身边大将如云、徐达、常遇春、李文忠、冯胜、朱文正、耿炳文、参谋刘基、李善长等等，我仅选部分介绍，详细的还是看书吧。</p><p>陈友谅，敢作敢当，但心黑手狠，胆大妄为，不重义气、背信弃义、骄横暴力。最终被诱敌深入的伏击给干掉了。巧的是那场鄱阳湖决战真的很像赤壁之战，果真历史来回重现。</p><p>张士诚，有勇气、意志坚强、却无大志，但他的的确确是个大好人。他待人宽大，免除了江浙一带的赋税。但他的过于宽大和无主见也使得他无法成为枭雄，而只能做一个豪杰。乱世中小富即安的思想可是不够生存的，在这种历史的淘汰赛里，只有胜负。</p><p>此处引用下朱元璋的战略分析，果真知人知彼啊，所以最后的赢家是朱元璋。</p><blockquote><p>张士诚的特点是器小，陈友谅的特点是志骄；器小无远见，志骄好生事。如果我进攻陈友谅，张士诚必然不会救他；而进攻张士诚，陈友谅就一定会动员全国兵力来救，我就要两线作战，到时就很难说了。</p></blockquote><p>马皇后，一心一意对待朱元璋，贤良仁德。在朱元璋称帝后乱杀大臣，马皇后“刀下留人”救了众多开国功臣。在教育子女上，也是要求他们生活简朴、用功读书。</p><p><strong>这样的女子不知道为朱元璋笼络了多少人心、培养了多少子女人才啊。</strong></p><p>常遇春，先锋大将，冷静观察形势，勇猛敢站，擅长骑兵突破，但却嗜好杀戮。后来常遇春主动向陈友谅挑事，活埋了降兵三千，带来了很多麻烦。</p><p><strong>可见，一个人的缺陷会很有可能导致大问题出现。</strong></p><p>徐达、善谋略、身先士卒、令出无二、为人谨慎，刚毅武勇，持重有谋，纪律严明，屡统大军，转战南北，治军严整，功高不矜，名列功臣第一。他是大破元军的关键人物，他也是活到最后的人之一了。</p><p>朱文正，善防守、排兵布阵。有军事才能，却不懂为人，性格乖张，心胸狭隘，最后竟然因为分攻奖赏不满而勾结张士诚，最终被囚禁。</p><p>刘基，神机军事，年少好学，运筹帷幄，准确判断。陈友谅进攻，其他人都在建议撤退之时，只有他在坚持，并且提出了诱敌伏击的策略。在多次战役中，他的判断甚至比朱元璋的判断还要准确。“三分天下诸葛亮，一统江山刘伯温”，在我看来他甚至比诸葛亮的成就还要高呢。不过，可惜最终死于政治斗争中。</p><p><strong>学习和实践从来都是成为一个有所建树的人的前提条件。</strong></p><h3 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h3><p>最后引用下原文对优秀将领成长过程的总结：</p><blockquote><p>第一个年级要学习的是军事理论。所有想成为名将的人，必须要学习一些经典的理论知识，包括《孙子兵法》《吴子兵法》等等。<br>第二个年级学习的内容是实战。这是极为重要的，那些理论学习的优秀者如果不能过这一关，他们就将被授予一个光荣的称号——纸上谈兵。<br>三年级要学习的是冷酷。 成为一个名将，就必须和仁慈、温和之类的名词说再见。他必须心如铁石、冷酷无情。<br>四年级要学习的是理智。<br>五年级学习判断，准确判断并决策。<br>六年级学习坚强，那些最优秀的人能够从失败中爬起来，去挑战那个多次战胜自己的人，这就叫做坚强。</p></blockquote><p>明朝的建立，经历了好几场大战。战场千变万化，胜者的智慧，败者的教训都是值得学习借鉴的。毕竟从人性、历史规律上看，一切都还是有章可循的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;一、序言&quot;&gt;&lt;a href=&quot;#一、序言&quot; class=&quot;headerlink&quot; title=&quot;一、序言&quot;&gt;&lt;/a&gt;一、序言&lt;/h3&gt;&lt;p&gt;以前我小觑了明朝，看完此书方知其宏伟恢弘。一个持久了两三百年的王朝，中间既有繁荣、胜利、正气；亦有凋敝、惨败与阴邪。历史有趣的就是在这来来回回的博弈中，道义精神的永不磨灭，历史规律的永恒不变。在此，我存着对历史的温情与敬意，以人物性格的角度，记录二三。&lt;/p&gt;&lt;h3 id=&quot;二、人物&quot;&gt;&lt;a href=&quot;#二、人物&quot; class=&quot;headerlink&quot; title=&quot;二、人物&quot;&gt;&lt;/a&gt;二、人物&lt;/h3&gt;&lt;p&gt;明太祖朱元璋，最初本是穷苦人家的放牛娃。为生计所迫曾辗转为和尚，后来饥荒和压迫，最终他连和尚也做不成了，云游了几年加入了红巾军。在农民军里，他是一个很突出的人，不但作战勇敢，而且很有计谋，处事冷静，思虑深远，还很讲义气，有危险的时候第一个上，这一切都让他有了崇高的威信。&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书笔记" scheme="http://yoursite.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="读书笔记" scheme="http://yoursite.com/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="历史" scheme="http://yoursite.com/tags/%E5%8E%86%E5%8F%B2/"/>
    
  </entry>
  
</feed>
