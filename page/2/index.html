<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="alternate" href="/atom.xml" title="WangXue" type="application/atom+xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Pisces',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":"mac"},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: true,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="本科重庆大学CS，研究生南京大学MS，主要研究AIOps，机器学习等，语言Python&amp;C++">
<meta property="og:type" content="website">
<meta property="og:title" content="WangXue">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;page&#x2F;2&#x2F;index.html">
<meta property="og:site_name" content="WangXue">
<meta property="og:description" content="本科重庆大学CS，研究生南京大学MS，主要研究AIOps，机器学习等，语言Python&amp;C++">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false,
    isPage: false,
    isArchive: false
  };
</script>

  <title>WangXue</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">WangXue</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">快乐学习，慢慢赚钱</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/saruagithub" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/20/20190810HUAWEI-DiGiX-CTR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="WangXue">
      <meta itemprop="description" content="本科重庆大学CS，研究生南京大学MS，主要研究AIOps，机器学习等，语言Python&C++">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WangXue">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/07/20/20190810HUAWEI-DiGiX-CTR/" class="post-title-link" itemprop="url">2019HUAWEI_DiGiX_CTR</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-07-20 10:36:44" itemprop="dateCreated datePublished" datetime="2019-07-20T10:36:44+08:00">2019-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-01-03 21:12:49" itemprop="dateModified" datetime="2020-01-03T21:12:49+08:00">2020-01-03</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2019/07/20/20190810HUAWEI-DiGiX-CTR/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2019/07/20/20190810HUAWEI-DiGiX-CTR/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-赛题介绍"><a href="#1-赛题介绍" class="headerlink" title="1 赛题介绍"></a>1 赛题介绍</h3><p>7月HUAWEI-DIGIX比赛是广告CTR预估问题。 数据如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>train.zip</th>
<th>zip（2.62GB）</th>
<th>2019-05-18 00:00:00</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>test.zip</td>
<td>zip（15MB）</td>
<td>2019-05-18 00:00:00</td>
<td></td>
</tr>
<tr>
<td>user_info.zip</td>
<td>zip（291MB）</td>
<td>2019-05-18 00:00:00</td>
<td></td>
</tr>
<tr>
<td>ad_info.zip</td>
<td>zip（17.9KB）</td>
<td>2019-05-18 00:00:00</td>
<td></td>
</tr>
<tr>
<td>content_info.zip</td>
<td>zip（8.16KB）</td>
<td>2019-05-18 00:00:00</td>
</tr>
</tbody>
</table>
</div>
<p> 时间范围是某连续6天的行为数据。总体而言，数据集包含： 训练集数据文件、测试集数据文件、用户特征文件、广告任务特征文件、素材信息数据文件。train表和test表里的字段：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>label</th>
<th>是否点击，1表示点击，0表示未点击</th>
</tr>
</thead>
<tbody>
<tr>
<td>uId</td>
<td>匿名化处理后的用户唯一标识(示例：u100000001)</td>
</tr>
<tr>
<td>adId</td>
<td>广告任务唯一标识</td>
</tr>
<tr>
<td>operTime</td>
<td>操作时间(精确到毫秒，示例: “2019-04-01 10:45:20:257”)</td>
</tr>
<tr>
<td>siteId</td>
<td>媒体Id</td>
</tr>
<tr>
<td>slotId</td>
<td>广告位Id</td>
</tr>
<tr>
<td>contentId</td>
<td>素材Id</td>
</tr>
<tr>
<td>netType</td>
<td>网络连接类型(示例：1, 2, 3, 4, 5, 6)</td>
</tr>
</tbody>
</table>
</div>
<p>user_info表</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>uId</th>
<th>匿名化处理后的用户唯一标识(示例：u100000001)</th>
</tr>
</thead>
<tbody>
<tr>
<td>age</td>
<td>年龄段(示例：1, 2, 3, 4, 5, 6)</td>
</tr>
<tr>
<td>gender</td>
<td>性别(示例：1, 2, 3)</td>
</tr>
<tr>
<td>city</td>
<td>常住城市编码(示例：1, 2, 3…)</td>
</tr>
<tr>
<td>province</td>
<td>常驻省份编码(示例：1, 2, 3…)</td>
</tr>
<tr>
<td>phoneType</td>
<td>设备型号(示例：1, 2, 3…)</td>
</tr>
<tr>
<td>carrier</td>
<td>运营商编号</td>
</tr>
</tbody>
</table>
</div>
<p> 广告任务特征文件ad_info.csv：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>adId</th>
<th>广告任务唯一标识(示例：2556)</th>
</tr>
</thead>
<tbody>
<tr>
<td>billId</td>
<td>计费类型(示例：cpc, cpm, cpd)</td>
</tr>
<tr>
<td>primId</td>
<td>广告主唯一编号Id</td>
</tr>
<tr>
<td>creativeType</td>
<td>创意类型(示例：1. 文字广告，2. 图片广告，3. 图文广告，4. gif广告，5. 无具体创意类型)</td>
</tr>
<tr>
<td>intertype</td>
<td>交互类型(示例：0. 无交互，点击无响应，1. 点击后打开网，2. 点击下载应用，3. 点击后打开App)</td>
</tr>
<tr>
<td>spreadAppId</td>
<td>广告对应的appId</td>
</tr>
</tbody>
</table>
</div>
<p> 素材信息数据文件content_info.csv:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>contentId</th>
<th>素材唯一标识Id</th>
</tr>
</thead>
<tbody>
<tr>
<td>firstClass</td>
<td>素材内容文本的一级分类(示例：电商)</td>
</tr>
<tr>
<td>secondClass</td>
<td>素材内容文本的二级分类，多值使用‘#’分割</td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2 数据预处理"></a>2 数据预处理</h3><h4 id="2-1-分析数据"><a href="#2-1-分析数据" class="headerlink" title="2.1 分析数据"></a>2.1 分析数据</h4><h5 id="2-2-1-分布情况"><a href="#2-2-1-分布情况" class="headerlink" title="2.2.1 分布情况"></a>2.2.1 分布情况</h5><p>首先查看每个表里数据的分布情况。尤其注意训练集与测试集的分布情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.describe() # 查看计数，平均值、标准差，min max等值。</span><br></pre></td></tr></table></figure>
<p>有些特征取值频次低的考虑合并为其他类。</p>
<h5 id="2-2-2-可视化分析"><a href="#2-2-2-可视化分析" class="headerlink" title="2.2.2 可视化分析"></a>2.2.2 可视化分析</h5><p>对 Numerical Variable，可以用 Box Plot / 小提琴 来直观地查看它的分布。Categories Variable 用直方图。对于坐标类数据，可以用 Scatter Plot 来查看它们的分布趋势和是否有离群点的存在。（seaborn画图）</p>
<p>绘制变量之间两两的分布和相关度图表等，发现一些高相关和共线性的特征。</p>
<p>这些分析都有利于后续构造特征。</p>
<h4 id="2-2-数据处理"><a href="#2-2-数据处理" class="headerlink" title="2.2 数据处理"></a>2.2 数据处理</h4><p>1，缺失值处理</p>
<p>可以填补，丢弃等。</p>
<p>我在比赛中对content的firstclass和secondcalss根据spreadApp进行补全，因为广告类型可能会跟广告出现在哪类app有关系。 取出spreadApp相同的firstClass众数替换了少量缺失值。</p>
<p>2，异常值处理</p>
<p>比赛中，遇到了那种机器人用户，连续不停点击。这种数据应该在训练时过滤掉，在最后的提交结果也应该用规则处理下。</p>
<p>另外可以考虑分箱、均值、中位数、众数处理异常值缺失值等。</p>
<p>3，归一化和one hot的问题</p>
<p>SVM、LR模型等常常需要考虑归一化和one hot（dummy）的问题。</p>
<p>4，划分数据集</p>
<p>然后采用k折交叉验证。当线下的验证集和线上的测试集有同步的效果时最好，此时可以通过线下的验证集变化来验证线上情况。</p>
<p>比赛中我没有做到。但是后面问了大佬，做法是把训练集里的有点击广告行为的用户数据抽取出来作为的训练集。</p>
<h3 id="3-特征工程"><a href="#3-特征工程" class="headerlink" title="3 特征工程"></a>3 特征工程</h3><p>1，特征工程是最重要的。我们其实尝试用过自动特征工程，有一个featuretools，但这个做的所有统计特征都比较偏向数值类型的特征。做类别特征不太强。所以后面还是自己做特征。总的来说，我们应该生成尽量多的 Feature，相信 Model 能够挑出最有用的 Feature。</p>
<p>交叉特征：把俩取值连接起来，然后将str转换为数值。</p>
<p>俩俩特征之间的统计特征：比如用户看那些类别的广告数目，用户看广告主的次数等等。还有三个特征之间的统计特征。</p>
<p>还有就是word2ve的用户id和广告id序列特征（但这个效果不太好）。</p>
<p>2，筛选特征：</p>
<p>Random Forest 训练完以后得到的 Feature Importance。</p>
<p>也可以进行一些统计检验，卡方检验等。</p>
<p>直接观察CTR。比如特征对应的CTR数目。</p>
<h3 id="4-模型"><a href="#4-模型" class="headerlink" title="4 模型"></a>4 模型</h3><p>采用了lightGBM树模型。优点：基于直方图的树结点划分，内存消耗更少速度更快。lightGBM的论文阅读见博客。</p>
<p>注意一些模型选择：</p>
<ul>
<li><p>对于稀疏型特征（如文本特征，One-hot的ID类特征），我们一般使用线性模型，比如 Linear Regression 或者 Logistic Regression。Random Forest 和 GBDT 等树模型不太适用于稀疏的特征，但可以先对特征进行降维（如PCA，SVD/LSA等），再使用这些特征。稀疏特征直接输入 DNN 会导致网络 weight 较多，不利于优化，也可以考虑先降维，或者对 ID 类特征使用 Embedding 的方式；</p>
</li>
<li><p>对于稠密型特征，推荐使用 XGBoost 进行建模，简单易用效果好；</p>
</li>
<li>数据中既有稀疏特征，又有稠密特征，可以考虑使用线性模型对稀疏特征进行建模，将其输出与稠密特征一起再输入 XGBoost/DNN 建模。</li>
</ul>
<p>最后理论是要用“好而不同”的模型进行集成的，不过作为基模型lightGBM初期就够用了。</p>
<h3 id="5-学习"><a href="#5-学习" class="headerlink" title="5 学习"></a>5 学习</h3><p>大佬们的特征工程：</p>
<p>统计特征：当天广告曝光次数，当天用户曝光次数，当天广告主ID相对用户出现的次数，当天广告位相对用户出现的次数。</p>
<p>unique特征，用户相对广告的唯一ID，广告相对用户的唯一ID。</p>
<p>Ratio点击率特征：一维二维的点击率特征。</p>
<p>低频数据：置None，lightGBM对NULL数据处理友好。</p>
<p>序列数据：deepwalk或word2vec方法（Uid和广告id）</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，seaborn 可视化 <a href="http://seaborn.pydata.org/tutorial.html" target="_blank" rel="noopener">http://seaborn.pydata.org/tutorial.html</a></p>
<p>2，个人印象笔记《复赛答辩学习》</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/07/20190707%E3%80%8A%E6%98%8E%E6%9C%9D%E9%82%A3%E4%BA%9B%E4%BA%8B1%E3%80%8B%E6%98%8E%E6%9C%9D%E7%9A%84%E5%BB%BA%E7%AB%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="WangXue">
      <meta itemprop="description" content="本科重庆大学CS，研究生南京大学MS，主要研究AIOps，机器学习等，语言Python&C++">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WangXue">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/07/07/20190707%E3%80%8A%E6%98%8E%E6%9C%9D%E9%82%A3%E4%BA%9B%E4%BA%8B1%E3%80%8B%E6%98%8E%E6%9C%9D%E7%9A%84%E5%BB%BA%E7%AB%8B/" class="post-title-link" itemprop="url">20190707《明朝那些事1》明朝的建立</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-07-07 12:01:07" itemprop="dateCreated datePublished" datetime="2019-07-07T12:01:07+08:00">2019-07-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-12-10 12:06:01" itemprop="dateModified" datetime="2019-12-10T12:06:01+08:00">2019-12-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">读书笔记</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2019/07/07/20190707%E3%80%8A%E6%98%8E%E6%9C%9D%E9%82%A3%E4%BA%9B%E4%BA%8B1%E3%80%8B%E6%98%8E%E6%9C%9D%E7%9A%84%E5%BB%BA%E7%AB%8B/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2019/07/07/20190707%E3%80%8A%E6%98%8E%E6%9C%9D%E9%82%A3%E4%BA%9B%E4%BA%8B1%E3%80%8B%E6%98%8E%E6%9C%9D%E7%9A%84%E5%BB%BA%E7%AB%8B/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="一、序言"><a href="#一、序言" class="headerlink" title="一、序言"></a>一、序言</h3><p>以前我小觑了明朝，看完此书方知其宏伟恢弘。一个持久了两三百年的王朝，中间既有繁荣、胜利、正气；亦有凋敝、惨败与阴邪。历史有趣的就是在这来来回回的博弈中，道义精神的永不磨灭，历史规律的永恒不变。在此，我存着对历史的温情与敬意，以人物性格的角度，记录二三。</p>
<h3 id="二、人物"><a href="#二、人物" class="headerlink" title="二、人物"></a>二、人物</h3><p>明太祖朱元璋，最初本是穷苦人家的放牛娃。为生计所迫曾辗转为和尚，后来饥荒和压迫，最终他连和尚也做不成了，云游了几年加入了红巾军。在农民军里，他是一个很突出的人，不但作战勇敢，而且很有计谋，处事冷静，思虑深远，还很讲义气，有危险的时候第一个上，这一切都让他有了崇高的威信。</p>
<p><strong>将军——统率之人，必有更多素质要求。其中战略、远见、理想、勇气、气量等等皆不可缺。</strong></p>
<p>后续，朱元璋大败陈友谅、消灭张士诚，这些都是很精彩的战役。他不仅个人强，周边的人也都很强。他有贤内助妻子马皇后；身边大将如云、徐达、常遇春、李文忠、冯胜、朱文正、耿炳文、参谋刘基、李善长等等，我仅选部分介绍，详细的还是看书吧。</p>
<p>陈友谅，敢作敢当，但心黑手狠，胆大妄为，不重义气、背信弃义、骄横暴力。最终被诱敌深入的伏击给干掉了。巧的是那场鄱阳湖决战真的很像赤壁之战，果真历史来回重现。</p>
<p>张士诚，有勇气、意志坚强、却无大志，但他的的确确是个大好人。他待人宽大，免除了江浙一带的赋税。但他的过于宽大和无主见也使得他无法成为枭雄，而只能做一个豪杰。乱世中小富即安的思想可是不够生存的，在这种历史的淘汰赛里，只有胜负。</p>
<p>此处引用下朱元璋的战略分析，果真知人知彼啊，所以最后的赢家是朱元璋。</p>
<blockquote>
<p>张士诚的特点是器小，陈友谅的特点是志骄；器小无远见，志骄好生事。如果我进攻陈友谅，张士诚必然不会救他；而进攻张士诚，陈友谅就一定会动员全国兵力来救，我就要两线作战，到时就很难说了。</p>
</blockquote>
<p>马皇后，一心一意对待朱元璋，贤良仁德。在朱元璋称帝后乱杀大臣，马皇后“刀下留人”救了众多开国功臣。在教育子女上，也是要求他们生活简朴、用功读书。</p>
<p><strong>这样的女子不知道为朱元璋笼络了多少人心、培养了多少子女人才啊。</strong></p>
<p>常遇春，先锋大将，冷静观察形势，勇猛敢站，擅长骑兵突破，但却嗜好杀戮。后来常遇春主动向陈友谅挑事，活埋了降兵三千，带来了很多麻烦。</p>
<p><strong>可见，一个人的缺陷会很有可能导致大问题出现。</strong></p>
<p>徐达、善谋略、身先士卒、令出无二、为人谨慎，刚毅武勇，持重有谋，纪律严明，屡统大军，转战南北，治军严整，功高不矜，名列功臣第一。他是大破元军的关键人物，他也是活到最后的人之一了。</p>
<p>朱文正，善防守、排兵布阵。有军事才能，却不懂为人，性格乖张，心胸狭隘，最后竟然因为分攻奖赏不满而勾结张士诚，最终被囚禁。</p>
<p>刘基，神机军事，年少好学，运筹帷幄，准确判断。陈友谅进攻，其他人都在建议撤退之时，只有他在坚持，并且提出了诱敌伏击的策略。在多次战役中，他的判断甚至比朱元璋的判断还要准确。“三分天下诸葛亮，一统江山刘伯温”，在我看来他甚至比诸葛亮的成就还要高呢。不过，可惜最终死于政治斗争中。</p>
<p><strong>学习和实践从来都是成为一个有所建树的人的前提条件。</strong></p>
<h3 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h3><p>最后引用下原文对优秀将领成长过程的总结：</p>
<blockquote>
<p>第一个年级要学习的是军事理论。所有想成为名将的人，必须要学习一些经典的理论知识，包括《孙子兵法》《吴子兵法》等等。<br>第二个年级学习的内容是实战。这是极为重要的，那些理论学习的优秀者如果不能过这一关，他们就将被授予一个光荣的称号——纸上谈兵。<br>三年级要学习的是冷酷。 成为一个名将，就必须和仁慈、温和之类的名词说再见。他必须心如铁石、冷酷无情。<br>四年级要学习的是理智。<br>五年级学习判断，准确判断并决策。<br>六年级学习坚强，那些最优秀的人能够从失败中爬起来，去挑战那个多次战胜自己的人，这就叫做坚强。</p>
</blockquote>
<p>明朝的建立，经历了好几场大战。战场千变万化，胜者的智慧，败者的教训都是值得学习借鉴的。毕竟从人性、历史规律上看，一切都还是有章可循的。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/05/07/20190507paper-the-Numenta-Anomaly-Benchmark/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="WangXue">
      <meta itemprop="description" content="本科重庆大学CS，研究生南京大学MS，主要研究AIOps，机器学习等，语言Python&C++">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WangXue">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/05/07/20190507paper-the-Numenta-Anomaly-Benchmark/" class="post-title-link" itemprop="url">20190507paper the Numenta Anomaly Benchmark</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-05-07 21:38:23" itemprop="dateCreated datePublished" datetime="2019-05-07T21:38:23+08:00">2019-05-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-12-11 17:31:32" itemprop="dateModified" datetime="2019-12-11T17:31:32+08:00">2019-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AIOps/" itemprop="url" rel="index">
                    <span itemprop="name">AIOps</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2019/05/07/20190507paper-the-Numenta-Anomaly-Benchmark/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2019/05/07/20190507paper-the-Numenta-Anomaly-Benchmark/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-ABS-amp-Introduction"><a href="#1-ABS-amp-Introduction" class="headerlink" title="1 ABS &amp; Introduction"></a>1 ABS &amp; Introduction</h3><h4 id="1-1-Abstract"><a href="#1-1-Abstract" class="headerlink" title="1.1 Abstract"></a>1.1 Abstract</h4><p>对象：streams, time-series data, sequence</p>
<p>异常检测难点：real-time processing</p>
<p>NAB是一个测试评估针对流数据的异常检测算法的开源工具。</p>
<p>理想的异常检测器 </p>
<ol>
<li><p>检测到所有出现的异常 </p>
</li>
<li><p>尽早检测出异常，最好在人们看到异常之前 </p>
</li>
<li><p>no FP 不误报 </p>
</li>
<li><p>实时检测、没有前瞻（不看前面的数据） </p>
</li>
<li><p>自动化检测、无人工调节</p>
</li>
<li>适用性广泛，具有泛化性</li>
</ol>
<h4 id="1-2-Intro"><a href="#1-2-Intro" class="headerlink" title="1.2 Intro"></a>1.2 Intro</h4><p>静态基准不适合用于实时性算法。Precision和Recall无法反应出早检测这个效果。人工划分训练集测试集不适合流场景。NAB设计了新的评价标准，整合了各类数据集。其他数据集还有the UC- Irvine dataset ，Yahoo Labs。本论文比较了HTM、Skyline、与Twitter的两种方法<a href="https://blog.twitter.com/engineering/en_us/a/2015/introducing-practical-and-robust-anomaly-detection-in-a-time-series.html" target="_blank" rel="noopener">Twitter 方法，翻</a> （AnomalyDetectionTs and AnomalyDetectionVec. ）。</p>
<h3 id="2，NAB-scoring"><a href="#2，NAB-scoring" class="headerlink" title="2，NAB scoring"></a>2，NAB scoring</h3><h4 id="2-1-基础"><a href="#2-1-基础" class="headerlink" title="2.1 基础"></a>2.1 基础</h4><p>异常定义：We define anomalies in a data stream to be patterns that do not conform to past patterns of behavior for the stream. 包括空间异常和时间异常。</p>
<p><img src="/images/20191210anomaly.jpg" alt="20191210anomaly"></p>
<p>Dataset：范围从IT指标（例如网络利用率）到工业机器上的传感器再到社交媒体聊天。我们还包括一些人工生成的数据文件，用于测试尚未在语料库的真实数据中表示的异常行为，以及几个没有任何异常的数据文件。当前的NAB数据集包含58个数据文件，每个文件具有1000-22,000个数据实例（github里有）</p>
<p>标记异常：按一定规则，标记ground truth label</p>
<h4 id="2-2-算法"><a href="#2-2-算法" class="headerlink" title="2.2 算法"></a>2.2 算法</h4><p>算法核心三个方面：anomaly Window，the scoring function，application Profiles（配置文件）</p>
<h5 id="2-2-1-异常窗口"><a href="#2-2-1-异常窗口" class="headerlink" title="2.2.1 异常窗口"></a>2.2.1 异常窗口</h5><p>异常窗口是代表一系列以真实异常标签（ a ground truth anomaly label ）为中心的数据点。</p>
<p>异常窗口的作用是判断真假检测，检测在窗外的话是FP。</p>
<p>评分函数基于窗口识别、加权TP，FP，FN。前面紫色部分只用来初始学习，不需测试。</p>
<p>1，窗口内最早的TP检测被计分，其他忽略。</p>
<p>2，sigmoidal scoring function 给早检测的TP高分。给FP负分数。</p>
<p>3，窗口大小 = 10%*总数据长度/异常数量。实验测试了5% - 20%，由于缩放评分函数，这个百分比对最后结果不敏感。</p>
<p><img src="/images/20191210AnomalyWindow.jpg" alt="20191210AnomalyWindow"></p>
<p>application profile配置：FN对工业机器来说会造成损失，FP要求技术人员查看。（对监视数据中心中各个服务器状态的应用程序可能对误报的数量敏感，并且由于大多数服务器群集都相对容错，因此偶尔会遗漏异常情况很好。）因此配置文件用于：对于TP，FP，FN和TN，NAB应用与每个配置文件相关的不同相对权重以获得每个配置文件的单独分数。</p>
<h5 id="2-2-2-计算过程"><a href="#2-2-2-计算过程" class="headerlink" title="2.2.2 计算过程"></a>2.2.2 计算过程</h5><p>1，配置权重$A$</p>
<script type="math/tex; mode=display">A_{T P}, A_{F P}, A_{F N}, A_{T N}, 0 \leq A_{TP},A_{TN} \leq 1, -1 \leq A_{FP},A_{FN} \leq 0</script><p>$D$ 是数据集，$Y_d$是数据 $d$ 中被检测出来的异常。$f_d$表示没有检测到任何异常的窗口数量，</p>
<p><img src="/images/20191210NABScoring.jpg" alt="20191210NABScoring"></p>
<p>2，单个窗口的得分计算</p>
<p>图中TP：早检测则，增加NAB score；点2：早检测的TP，贡献+0.999 。</p>
<p>FP：减分（窗外后面的FP的减分更大）；点1：FP，贡献-1，点4：权重为-0.8093是根据$\sigma^{A}(y)$得到的。5：5更有害，因此5贡献-1。</p>
<p>FN：完全没有检测到，减分。</p>
<p>总的来看这个窗口的得分就是：$−1.0A_{FP} + 0.9999A_{TP} −0.8093A_{FP} − 1.0A_{FP} $ ，公式是：</p>
<script type="math/tex; mode=display">\sigma^{A}(y)=\left(A_{T P}-A_{F P}\right)\left(\frac{1}{1+e^{5 y}}\right)-1</script><p>$\sigma^{A}(y)$中，y表示是检测在异常检测窗的相对位置，参数被设置为窗口右侧，$\sigma ( y = 0.0 ) = 0$。 </p>
<p>3，一个数据文件的得分计算</p>
<p>得分是每个检测的得分+错过的Window</p>
<script type="math/tex; mode=display">S_{d}^{A}=\left(\sum_{y \in Y_{d}} \sigma^{A}(y)\right)+A_{F N} f_{d}</script><p>4，一个异常检测算法对所有数据集的得分</p>
<script type="math/tex; mode=display">S ^ { A } = \sum _ { d \in D } S _ { d } ^ { A }</script><p>5，归一化这个算法的分数，normalized NAB score</p>
<script type="math/tex; mode=display">S _ { N A B } ^ { A } = 100 \cdot \frac { S ^ { A } - S _ { \text {null} } ^ { A } } { S _ { \text {perfect} } ^ { A } - S _ { \text {null} } ^ { A } }</script><p>完美检测器检测到所有TP，无FP。NULL检测器就是没有检测到任何异常。</p>
<h5 id="2-2-3-其他"><a href="#2-2-3-其他" class="headerlink" title="2.2.3 其他"></a>2.2.3 其他</h5><p>HTM算法，Skyline统计算法，Twitter统计算法等</p>
<p>每个异常检测器输出是0-1之间的分数，使用固定阈值对分数进行阈值处理，以检测异常。 NAB包括自动爬坡搜索，用于为每种算法选择最佳阈值。其中要最大化的目标函数是NAB评分函数。一个阈值针对所有的数据集dataset（The detection threshold is thus tuned based on the full NAB dataset）。</p>
<h3 id="3-result"><a href="#3-result" class="headerlink" title="3 result"></a>3 result</h3><p>见github首页</p>
<p>一些小结论</p>
<p>1，HTM和Skyline对漂移适应得更快</p>
<p>2，HTM和Skyline各自也有误报但HTM可以早检测（3h，机器温度传感器数据）</p>
<p>3，行为的时间变化通常先于容易检测到的大变化（做提前检测）。 </p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，Lavin A, Ahmad S. Evaluating Real-Time Anomaly Detection Algorithms—The Numenta Anomaly Benchmark[C]//2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA). IEEE, 2015: 38-44.</p>
<p>2, <a href="https://github.com/numenta/NAB" target="_blank" rel="noopener">https://github.com/numenta/NAB</a> 很好的学习项目</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/24/%E8%A3%85window%E3%80%81ubuntu%E5%8F%8C%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="WangXue">
      <meta itemprop="description" content="本科重庆大学CS，研究生南京大学MS，主要研究AIOps，机器学习等，语言Python&C++">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WangXue">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/04/24/%E8%A3%85window%E3%80%81ubuntu%E5%8F%8C%E7%B3%BB%E7%BB%9F/" class="post-title-link" itemprop="url">装window、ubuntu双系统</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-04-24 09:09:12" itemprop="dateCreated datePublished" datetime="2019-04-24T09:09:12+08:00">2019-04-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-11-06 11:07:09" itemprop="dateModified" datetime="2019-11-06T11:07:09+08:00">2019-11-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%85%8D%E7%BD%AE/" itemprop="url" rel="index">
                    <span itemprop="name">配置</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2019/04/24/%E8%A3%85window%E3%80%81ubuntu%E5%8F%8C%E7%B3%BB%E7%BB%9F/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2019/04/24/%E8%A3%85window%E3%80%81ubuntu%E5%8F%8C%E7%B3%BB%E7%BB%9F/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="装window10、ubuntu16-04双系统"><a href="#装window10、ubuntu16-04双系统" class="headerlink" title="装window10、ubuntu16.04双系统"></a>装window10、ubuntu16.04双系统</h2><p>周末趁空装了个双系统，记录记录过程吧。</p>
<h3 id="装windows10"><a href="#装windows10" class="headerlink" title="装windows10"></a>装windows10</h3><ol>
<li>首先下载好win10的系统镜像ISO文件，由于我不咋用win10就装了家庭版<br>链接: <a href="http://pan.baidu.com/s/1sj3JNRJ" target="_blank" rel="noopener">http://pan.baidu.com/s/1sj3JNRJ</a> 密码: z49r</li>
</ol>
<ol>
<li><p>准备好空的U盘，准备做系统启动盘。<br>下载安装好UltraISO，插入U盘。<br>点击打开，选择ISO文件<br>点击启动 - 写入硬盘映像<br>写入方式选择的是USB-HDD，USB-HDD+，一般默认就好<br>在点击写入，就等着他默默写好就好了<br><img src="https://img-blog.csdnimg.cn/20190422141325858.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_16,color_FFFFFF,t_70" alt="ULtraISO刻录系统启动盘"></p>
</li>
<li><p>制作好的系统启动U盘插入要装系统的电脑。开启电脑，一直按 F2或在F12等（这个键根据电脑确定，可以查查，但一般就是这个），进入电脑的Bios设置。<br>选择usb storage device，放到最前面，表示系统启动优先从USB开始。点击apply，再点exit。</p>
</li>
<li><p>之后电脑自动重启，然后进入windows10的安装。<br>默认简体中文，下一步<br>哪种类型的安装：选择自定义，以前windows的东西会变成windows.old<br>输入产品密钥那里跳过。<br>你想将windows安装在哪？ 选择分区，选择之前C盘所在分区位置。我这选择的是分区1，476G的盘。<br>后面就等着自己装就好了。</p>
</li>
<li><p>装完后注意，系统会重新启动。此时要拔掉U盘。产品密钥那个后面可以去找破解工具破解。暂时不管，然后设置用户密码进入就好。</p>
</li>
</ol>
<h3 id="装ubuntu16-04"><a href="#装ubuntu16-04" class="headerlink" title="装ubuntu16.04"></a>装ubuntu16.04</h3><ol>
<li>同理下载好U盘，将ubuntu的系统镜像刻录到U盘里。</li>
<li>设置好bios优先从U盘启动。</li>
<li>preparing to install Ubuntu: 这里可以选择第二项（Erase disk and install Ubuntu 单独装个Ubuntu系统）或者something else（我这装双系统，本来电脑里分区比较多，因此要选择之前从window划分出来的空闲空间）</li>
<li>挂载分区到根路径 / ,如果空间足够大，就只挂载这个，剩下的Ubuntu自己会分。如果不够，可以单独跟/home , /boot那些单独分。<br><img src="https://img-blog.csdnimg.cn/2019042409082143.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNjczNDUz,size_16,color_FFFFFF,t_70" alt="挂载"></li>
<li>继续时区，创建用户，后面就会重启了。重启的时候，注意拔掉U盘。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/08/20190408AnomalyDetectionBackground/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="WangXue">
      <meta itemprop="description" content="本科重庆大学CS，研究生南京大学MS，主要研究AIOps，机器学习等，语言Python&C++">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WangXue">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/04/08/20190408AnomalyDetectionBackground/" class="post-title-link" itemprop="url">20190408AnomalyDetectionBackground</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-04-08 12:35:30" itemprop="dateCreated datePublished" datetime="2019-04-08T12:35:30+08:00">2019-04-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-12-12 12:37:18" itemprop="dateModified" datetime="2019-12-12T12:37:18+08:00">2019-12-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AIOps/" itemprop="url" rel="index">
                    <span itemprop="name">AIOps</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2019/04/08/20190408AnomalyDetectionBackground/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2019/04/08/20190408AnomalyDetectionBackground/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h3><h4 id="1-1-企业背景"><a href="#1-1-企业背景" class="headerlink" title="1.1 企业背景"></a>1.1 企业背景</h4><p>分布式系统结构的广泛应用。具有高并发，低时延，高可靠性等特点，但同时由于需求的增长，其规模，复杂性和动态生成的数据也急剧增加，这使其可靠性降低。为了避免系统故障，因此异常检测故障预判很重要。</p>
<p>简单来说目前的一些应用痛点，也是我企业调研的结果：</p>
<p>1，测试人员时间有限，不能有效测试，全覆盖测试。系统BUG是难免的。</p>
<p>2，系统故障后排查困难，需要及时定位。</p>
<p>3，运维人员希望可以提前预测故障，越早越好，从而进行排查。</p>
<p>4，目前企业的监控数据是有的，如何利用起来对系统更好的运维。</p>
<h4 id="2-1-研究背景"><a href="#2-1-研究背景" class="headerlink" title="2.1 研究背景"></a>2.1 研究背景</h4><p>流数据的异常检测难点有：</p>
<p>1，流数据高速实时产生  ，传统的对整个数据集离线学习很难。</p>
<p>2，异常行为很少发生，异常检测器训练困难，难以学习对于重要的不平衡数据集的满意模型。</p>
<p>3，流数据的时变特性。两类异常，空间异常和上下文异常。概念漂移问题。</p>
<p>4，Precision与Recall之前的权衡问题。</p>
<p>5，不同的时序数据有不同属性。周期性，平稳性，非平稳性等等性质，对不同的方法有要求。</p>
<p>6，异常数据的标记很难得。</p>
<p>7，提前检测很重要，也很困难。</p>
<h4 id="2-2-智能运维背景"><a href="#2-2-智能运维背景" class="headerlink" title="2.2 智能运维背景"></a>2.2 智能运维背景</h4><p>于是Gartner首先推出了人工智能运算（AIOP，这个方向国内还有清华大学的裴丹老师），包括性能监视，异常检测和系统故障检测任务等。理想的智能运维具有以下能力：历史数据管理、流数据（即时序数据）管理、日志数据提取、网络数据提取、性能数据提取、文本数据提取、自动化模型的发现和预测、异常检测、根因分析、按需交付等  </p>
<blockquote>
<p>AIOps is the application of artificial intelligence for IT operations. It is the future of ITOps, combining algorithmic and human intelligence to provide full visibility into the state and performance of the IT systems that businesses rely on.</p>
</blockquote>
<p>性能监控里包括了对系统的CPU、memory，storage，网络，进程等资源使用的监控信息。通过对性能监控的时间序列进行异常检测，发现故障之前的征兆。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1, “Everything you need to know about AIOps”, from <a href="https://www.moogsoft.com/resources/aiops/guide/everything-aiops/" target="_blank" rel="noopener">https://www.moogsoft.com/resources/aiops/guide/everything-aiops/</a> (retrieved as of Feb. 12, 2019)</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/27/20190327PCL%E5%BA%93%E5%8D%87%E7%BA%A7%E9%97%AE%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="WangXue">
      <meta itemprop="description" content="本科重庆大学CS，研究生南京大学MS，主要研究AIOps，机器学习等，语言Python&C++">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WangXue">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/03/27/20190327PCL%E5%BA%93%E5%8D%87%E7%BA%A7%E9%97%AE%E9%A2%98/" class="post-title-link" itemprop="url">PCL库升级问题</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-03-27 10:58:04" itemprop="dateCreated datePublished" datetime="2019-03-27T10:58:04+08:00">2019-03-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-01-02 10:59:52" itemprop="dateModified" datetime="2020-01-02T10:59:52+08:00">2020-01-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2019/03/27/20190327PCL%E5%BA%93%E5%8D%87%E7%BA%A7%E9%97%AE%E9%A2%98/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2019/03/27/20190327PCL%E5%BA%93%E5%8D%87%E7%BA%A7%E9%97%AE%E9%A2%98/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="PCL库"><a href="#PCL库" class="headerlink" title="PCL库"></a>PCL库</h3><h6 id="1、安装过程参考官网，环境是Mac10-14-4，mojave"><a href="#1、安装过程参考官网，环境是Mac10-14-4，mojave" class="headerlink" title="1、安装过程参考官网，环境是Mac10.14.4，mojave"></a>1、安装过程参考官网，环境是Mac10.14.4，mojave</h6><p><a href="http://www.pointclouds.org/documentation/tutorials/installing_homebrew.php" target="_blank" rel="noopener">pcl install on Mac</a><br><code>brew install pcl</code> ，一直装就好了</p>
<h6 id="2、使用xcode创建pcl工程"><a href="#2、使用xcode创建pcl工程" class="headerlink" title="2、使用xcode创建pcl工程"></a>2、使用xcode创建pcl工程</h6><p><a href="http://dragonwood-blastevil.blogspot.com/2013/02/install-pcl-and-first-project-in-xcode.html" target="_blank" rel="noopener">翻墙搜的pcl project in xcode</a><br>此处注意编译器的选择，Switch Compiler for C/C++/Objective-C from Apple LLVM compiler 4.2 -&gt; LLVM GCC 4.2，注意”Header Search Paths”的配置，链接里没有全部配置完全，项目要用到的库都应该加进去。</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTQyNjUxLThhYzQxZGFkYjIyNjA0MzEucG5n?x-oss-process=image/format,png" alt="工程配置"></p>
<p>然后注意还有添加Link binary with libraries，点击下面的加号，add other把lib文件夹里的都加进来，只要你用到boost库，其他库类似这样处理。<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTQyNjUxLTg1NzNiNjZmMThiYzdjNmEucG5n?x-oss-process=image/format,png" alt="lib库添加1"><br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xNTQyNjUxLTYzNDA3MDZhYTIyMGUyODAucG5n?x-oss-process=image/format,png" alt="lib库添加2"></p>
<h6 id="3、问题1：undifine-symbols-基本就是下面提示的库没有添加进去"><a href="#3、问题1：undifine-symbols-基本就是下面提示的库没有添加进去" class="headerlink" title="3、问题1：undifine symbols 基本就是下面提示的库没有添加进去"></a>3、问题1：undifine symbols 基本就是下面提示的库没有添加进去</h6><p><code>Undefined symbols for architecture x86_64: 
  &quot;boost::this_thread::interruption_point()</code><br><code>&quot;vtkSphereSource::New()&quot;, referenced from:
  vtkSmartPointer&lt;vtkSphereSource&gt;::New() in 4viewtest.o</code><br>一般这种报错就是因为上面的lib库没有加进去的原因。这个问题，我居然被困了半天，气死了。。。。</p>
<h6 id="4、由于我升级了Mac到mojave，出现问题Reason-image-not-found"><a href="#4、由于我升级了Mac到mojave，出现问题Reason-image-not-found" class="headerlink" title="4、由于我升级了Mac到mojave，出现问题Reason: image not found"></a>4、由于我升级了Mac到mojave，出现问题Reason: image not found</h6><p><code>dylid: Library not loaded: /opt/X11/lib/libglut.3.dylib
  Referenced from: /usr/local/opt/pcl/lib/libpcl_simulation_io.1.9.dylib
  Reason: image not found</code><br><a href="https://tex.stackexchange.com/questions/208001/cant-compile-image-after-upgrading-to-os-x-yosemite" target="_blank" rel="noopener">X11 is not erased but moved to /opt/X11</a><br>还要安装 <a href="http://xquartz.macosforge.org/landing" target="_blank" rel="noopener">installing the latest XQuartz</a></p>
<p>升级就是麻烦多，各位开发者别随便升级了</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/25/20191225%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="WangXue">
      <meta itemprop="description" content="本科重庆大学CS，研究生南京大学MS，主要研究AIOps，机器学习等，语言Python&C++">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WangXue">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/12/25/20191225%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" class="post-title-link" itemprop="url">集成学习</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-12-25 11:23:38" itemprop="dateCreated datePublished" datetime="2018-12-25T11:23:38+08:00">2018-12-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-12-28 16:18:09" itemprop="dateModified" datetime="2019-12-28T16:18:09+08:00">2019-12-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2018/12/25/20191225%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2018/12/25/20191225%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h3><p>集成学习（Ensemble learning）通过组合几种模型来提高机器学习的效果。构建并结合多个学习器，个体学习器要“好而不同”，一定的准确性/多样性。</p>
<h3 id="2-提升方法"><a href="#2-提升方法" class="headerlink" title="2 提升方法"></a>2 提升方法</h3><h4 id="2-1-提升方法之Adaboost"><a href="#2-1-提升方法之Adaboost" class="headerlink" title="2.1 提升方法之Adaboost"></a>2.1 提升方法之Adaboost</h4><p>一般过程：训练—基学习器—调整训练样本分布—重复得到更多基学习器 T个—将这T个基学习器加权结合。代表是Adaboost：提高那些被前一轮弱分类器分错的样本的权值。最后加权多数表决方法、加大分类误差率小的弱分类器的权值。属于序列集成。</p>
<p>算法（书P156）：</p>
<p>输入训练集$T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$，其中实例$x_{i} \in \mathcal{X}=\mathbf{R}^{n}$，$y_i \in \mathcal{Y} = \left\{ -1,+1 \right\}$</p>
<p>1，初始化训练数据的权值分布为均匀分布 。$w_{1i} = \frac{1}{N}$。</p>
<p>2，使用具有权值分布的$D_m$的训练数据集学习得到基分类器$G_{m}(x): \mathcal{X} \rightarrow\{-1,+1\}$。</p>
<p>3，计算$G_m(x)$在训练数据集上的分类误差率:</p>
<script type="math/tex; mode=display">e_{m}=\sum_{i=1}^{N} P\left(G_{m}\left(x_{i}\right) \neq y_{i}\right)=\sum_{i=1}^{N} w_{m i} I\left(G_{m}\left(x_{i}\right) \neq y_{i}\right)</script><p>计算得到$G_m(x)$的系数，它表示了$G_m(x)$在最终分类器中的重要性。他随$e_m$的减小而增大。</p>
<script type="math/tex; mode=display">\alpha_{m}=\frac{1}{2} \log \frac{1-e_{m}}{e_{m}}</script><p>在更新训练数据集的权值分布</p>
<script type="math/tex; mode=display">D_{m+1}=\left(w_{m+1,1}, \cdots, w_{m+1, i}, \cdots, w_{m+1, N}\right)</script><script type="math/tex; mode=display">w_{m+1, i}=\frac{w_{m i}}{Z_{m}} \exp \left(-\alpha_{m} y_{i} G_{m}\left(x_{i}\right)\right), \quad i=1,2, \cdots, N</script><p>其中$Z_m$是规范化因子：</p>
<script type="math/tex; mode=display">Z_{m}=\sum_{i=1}^{N} w_{m i} \exp \left(-\alpha_{m} y_{i} G_{m}\left(x_{i}\right)\right)</script><p>4，构建基分类器的线性组合 $f(x) = \sum_{m=1}^M  \alpha_m  G_m(x)$</p>
<p>得到最终分类器：</p>
<script type="math/tex; mode=display">G(x) = \operatorname{sign}\left(\sum_{m=1}^{M} \alpha_{m} G_{m}(x)\right)</script><h4 id="2-2-提升方法之提升树-Boosting"><a href="#2-2-提升方法之提升树-Boosting" class="headerlink" title="2.2 提升方法之提升树 Boosting"></a>2.2 提升方法之提升树 Boosting</h4><p>采用加法模型（基函数的线性组合，基函数为树的时候叫Boosting tree），前向分步算法。减小偏差。</p>
<h5 id="2-2-1-前向分步算法："><a href="#2-2-1-前向分步算法：" class="headerlink" title="2.2.1 前向分步算法："></a>2.2.1 前向分步算法：</h5><p>1，确定初始提升树$f_0(x) = 0$</p>
<p>2，第m步的模型是$f_m(x) = f_{m-1}(x) + T(x: \theta_m)$</p>
<p>这里需要通过经验风险极小化来确定下一棵决策树参数参数:</p>
<script type="math/tex; mode=display">\hat{\theta_m} = argmin_{\theta_m} \sum_{i=1}^N L(y_i, f_{m-1}(x_i) + T(x_i:\theta_m))</script><p>不同问题的提升树学习算法区别在于使用的损失函数不同。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>问题</th>
<th>学习算法</th>
</tr>
</thead>
<tbody>
<tr>
<td>回归树</td>
<td>平方误差（拟合残差）</td>
</tr>
<tr>
<td>分类问题</td>
<td>指数损失函数</td>
</tr>
<tr>
<td>一般决策问题</td>
<td>一般损失函数</td>
</tr>
</tbody>
</table>
</div>
<p>对于二分类问题，提升树算法只需将Adaboost算法中基本分类器限制为二分类树即可。</p>
<h5 id="2-2-2-回归问题的提升树，拟合残差"><a href="#2-2-2-回归问题的提升树，拟合残差" class="headerlink" title="2.2.2 回归问题的提升树，拟合残差"></a>2.2.2 回归问题的提升树，拟合残差</h5><p>1，初始化$f0(x)=0$</p>
<p>2，对m=1,2..M计算残差，N是样本数。当前模型拟合数据的残差。</p>
<script type="math/tex; mode=display">r_{mi} = y_i -f_{m-1}(x_i), i=1.2..N</script><p>拟合残差$r_{mi}$学习一个回归树$T(x: \theta_m)$。更新：</p>
<script type="math/tex; mode=display">f_m(x) = f_{m-1}(xi) + T(x: \theta_m)</script><p>3，得到回归问题提升树 </p>
<script type="math/tex; mode=display">f_M(x) = \sum_{m=1}^M T(x; \theta_m)</script><h5 id="2-2-3-一般决策问题GBDT"><a href="#2-2-3-一般决策问题GBDT" class="headerlink" title="2.2.3 一般决策问题GBDT"></a>2.2.3 一般决策问题GBDT</h5><p>一般损失函数：</p>
<p>梯度提升gradientBoosting （GBDT）：利用最速下降法的近似方法，关键是利用损失函数的负梯度在当前模型的值</p>
<script type="math/tex; mode=display">-\left[\frac{\partial L\left(y, f\left(x_{i}\right)\right)}{\partial f\left(x_{i}\right)}\right]_{f(x)=f_{m-1}(x)}</script><p>作为回归问题提升树算法中的残差的近似值，拟合一个回归树。</p>
<p>过程：</p>
<p>输入训练集$T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$，其中实例$x_{i} \in \mathcal{X} \subseteq \mathbf{R}^{n}, y_{i} \in \mathcal{Y} \subseteq \mathbf{R}$</p>
<p>输出回归树： $\hat{f(x)}$</p>
<p>(1) 初始化</p>
<script type="math/tex; mode=display">f_{0}(x)=\arg \min _{c} \sum_{i=1}^{N} L\left(y_{i}, c\right)</script><p>(2) 对m = 1,2…M</p>
<p>对 i = 1,2,…N 计算：</p>
<script type="math/tex; mode=display">r_{m i}=-\left[\frac{\partial L\left(y_{i}, f\left(x_{i}\right)\right)}{\partial f\left(x_{i}\right)}\right]_{f(x)=f_{m-1}(x)}</script><p>对$r_{mi}$ 拟合一个回归树。得到第m棵树的叶节点区域$R_{m j}, j=1,2, \cdots, J$</p>
<p>对 j = 1,2 …J 计算：</p>
<script type="math/tex; mode=display">c_{m j}=\arg \min _{c} \sum_{x_{i} \in R_{m j}} L\left(y_{i}, f_{m-1}\left(x_{i}\right)+c\right)</script><p>更新</p>
<script type="math/tex; mode=display">f_{m}(x)=f_{m-1}(x)+\sum_{j=1}^{J} c_{m j} I\left(x \in R_{m j}\right)</script><p>(3) 得到回归树</p>
<script type="math/tex; mode=display">\hat{f}(x)=f_{M}(x)=\sum_{m=1}^{M} \sum_{j=1}^{J} c_{m j} I\left(x \in R_{m j}\right)</script><h4 id="2-3-其他"><a href="#2-3-其他" class="headerlink" title="2.3 其他"></a>2.3 其他</h4><p>XGBoost：</p>
<p>经过优化的分布式梯度提升（Gradient Boosting）库，实现了并行方式的决策树提升(Tree Boosting)。XGBoost采用的是level（depth）-wise生长策略，如下所示，能够同时分裂同一层的叶子，从而进行多线程优化，不容易过拟合；但不加区分的对待同一层的叶子，带来了很多没必要的开销。</p>
<p>XGBoost使用的是pre-sorted算法，能够更精确的找到数据分隔点；XGBoost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。</p>
<p>XGBoost在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。</p>
<p><img src="/images/20191225Xgboost.jpg" alt="20191225Xgboost"></p>
<p>LightGBM：</p>
<p>LightGBM的设计思路主要是两点：1. 减小数据对内存的使用，保证单个机器在不牺牲速度的情况下，尽可能地用上更多的数据；2. 减小通信的代价，提升多机并行时的效率，实现在计算上的线性加速。</p>
<p>LightGBM采用leaf-wise生长策略，如Figure 2所示，每次从当前所有叶子中找到分裂增益最大（一般也是数据量最大）的一个叶子，然后分裂，如此循环；但会生长出比较深的决策树，产生过拟合。</p>
<p>LightGBM使用的是histogram算法，占用的内存更低，数据分隔的复杂度更低。</p>
<p><img src="/images/20191225LightGBM.jpg" alt="20191225LightGBM"></p>
<h3 id="3-Bagging"><a href="#3-Bagging" class="headerlink" title="3 Bagging"></a>3 Bagging</h3><h4 id="3-1-Bagging"><a href="#3-1-Bagging" class="headerlink" title="3.1 Bagging"></a>3.1 Bagging</h4><p>Bagging是有放回样本采样boostrap——产生互相有交叠的采样子集63.2% 。一般对分类任务使用简单投票法。剩下36.8%的数据可以用作验证集对泛化性能进行包外估计out-of-bag-estimate。</p>
<script type="math/tex; mode=display">f(x)=1 / M \sum_{m=1}^{M} f_{m}(x)</script><p>在不同样本集上训练不同的树，通常分类任务使用投票的方式集成，而回归任务通过平均的方式集成。减小方差。</p>
<h4 id="3-2-随机森林"><a href="#3-2-随机森林" class="headerlink" title="3.2 随机森林"></a>3.2 随机森林</h4><p>随机森林：样本采样+属性采样构建多棵决策树，最终决定结果。方差小，偏差也小。</p>
<h3 id="4-Stacking方法"><a href="#4-Stacking方法" class="headerlink" title="4 Stacking方法"></a>4 Stacking方法</h3><p>Stacking是通过一个元分类器或者元回归器来整合多个分类模型或回归模型的集成学习技术。基础模型利用整个训练集做训练，元模型将基础模型的特征作为特征进行训练。</p>
<p>其实就是先训练多个初级分类器，然后基于初级分类器对样本预测，将预测值作为新的训练集训练次级学习器。</p>
<p><img src="/images/20191225Stacking.jpg" alt="20191225Stacking"></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，李航《统计学习方法》</p>
<p>2，<a href="https://zhuanlan.zhihu.com/p/36161812" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/36161812</a> 集成学习</p>
<p>3， <a href="https://blog.csdn.net/v_JULY_v/article/details/81410574" target="_blank" rel="noopener">https://blog.csdn.net/v_JULY_v/article/details/81410574</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/25/20200104EM%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="WangXue">
      <meta itemprop="description" content="本科重庆大学CS，研究生南京大学MS，主要研究AIOps，机器学习等，语言Python&C++">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WangXue">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/12/25/20200104EM%E7%AE%97%E6%B3%95/" class="post-title-link" itemprop="url">EM算法</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-12-25 10:02:19" itemprop="dateCreated datePublished" datetime="2018-12-25T10:02:19+08:00">2018-12-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-01-04 12:22:23" itemprop="dateModified" datetime="2020-01-04T12:22:23+08:00">2020-01-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2018/12/25/20200104EM%E7%AE%97%E6%B3%95/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2018/12/25/20200104EM%E7%AE%97%E6%B3%95/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h3><p>EM算法是一种迭代算法，用于含有隐变量的概率模型参数的极大似然估计。 </p>
<p>E步：求期望；M步，求极大。 </p>
<h4 id="1-1-例子"><a href="#1-1-例子" class="headerlink" title="1.1 例子"></a>1.1 例子</h4><p>P176三硬币模型： </p>
<script type="math/tex; mode=display">p_{(y/\theta)}=\sum_{\mathcal{Z}} P(y, z | \theta)=\sum_{\mathcal{Z}} P(z | \theta) P(y | z, \theta)</script><script type="math/tex; mode=display">= \pi p^y(1-p)^{(1-y)} + (1-\pi)q^y (1-q)^{(1-y)}</script><p>y是观测变量，表示一次试验结果是1或0； </p>
<p>z（随机变量）是隐变量，表示未观测到的抛硬币A的结果 </p>
<p>$\theta = (\pi,p,q)$ 是模型参数。 </p>
<p>这个模型是以上数据的生成模型 </p>
<h4 id="1-2-模型"><a href="#1-2-模型" class="headerlink" title="1.2 模型"></a>1.2 模型</h4><p>观测数据是$Y=\left(Y_{1}, Y_{2}, \cdots, Y_{n}\right)^{\mathrm{T}}$，未观测数据表示为$Z=(Z_1,Z_2…Z_n)^{\mathrm{T}}$，则观测数据的似然函数是： </p>
<script type="math/tex; mode=display">P(Y | \theta)=\sum_{Z} P(Z | \theta) P(Y | Z, \theta)</script><p>即： </p>
<script type="math/tex; mode=display">P(Y | \theta)=\prod_{j=1}^{n}\left[\pi p^{y_{j}}(1-p)^{1-y_{j}}+(1-\pi) q^{y_{j}}(1-q)^{1-y_{j}}\right]</script><p>求模型参数 $\theta = (\pi,p,q)$的极大似然估计是： </p>
<script type="math/tex; mode=display">\hat{\theta} = argmax_{\theta} log(P(Y|\theta))</script><h4 id="1-3-迭代算法"><a href="#1-3-迭代算法" class="headerlink" title="1.3 迭代算法"></a>1.3 迭代算法</h4><p>这个问题只能通过迭代的方法求解，EM算法就是用于求解这个问题的一种迭代算法。 </p>
<p>1，选取参数的初值，记作 $\theta^0 = (\pi^0,p^0,q^0)$，然后迭代计算参数的估计值，直至收敛为止。第i次迭代的参数估计值是 $\theta^i = (\pi^i,p^i,q^i)$ </p>
<p>2, E步，计算在模型参数$\theta^i$下观测数据$y_i$来自硬币B的概率： </p>
<script type="math/tex; mode=display">\mu_{j}^{(i+1)}=\frac{\pi^{(i)}\left(p^{(i)}\right)^{y_{j}}\left(1-p^{(i)}\right)^{1-y_{j}}}{\pi^{(i)}\left(p^{(i)}\right)^{y_{j}}\left(1-p^{(i)}\right)^{1-y_{j}}+\left(1-\pi^{(i)}\right)\left(q^{(i)}\right)^{y_{j}}\left(1-q^{(i)}\right)^{1-y_{j}}}</script><p>M步计算模型参数的新估计值(n是独立重复n次实验)：</p>
<script type="math/tex; mode=display">\pi^{i+1} = \frac{1}{n}\sum_{j=1}^n \mu_j^{i+1}</script><script type="math/tex; mode=display">p^{(i+1)}=\frac{\sum_{j=1}^{n} \mu_{j}^{(i+1)} y_{j}}{\sum_{j=1}^{n} \mu_{j}^{(i+1)}}</script><script type="math/tex; mode=display">q^{(i+1)}=\frac{\sum_{j=1}^{n}\left(1-\mu_{j}^{(i+1)}\right) y_{j}}{\sum_{j=1}^{n}\left(1-\mu_{j}^{(i+1)}\right)}</script><p>P177的计算例子，不同的初值得到不同的参数估计值。</p>
<h3 id="2-EM算法"><a href="#2-EM算法" class="headerlink" title="2 EM算法"></a>2 EM算法</h3><p>Y表示观测随机变量的数据，Z表示隐随机变量的数据。Y和Z连到一起称为完全数据。不完全数据Y的似然函数是$P(Y|\theta)$，Y和Z的联合概率分布是$P(Y,Z|\theta)$，完全数据的对数似然函数是$logP(Y,Z|\theta)$，EM算法通过迭代求$L(\theta) = logP(Y|\theta)$</p>
<p>(1) 选择参数初始值$\theta^{(0)}$，开始迭代。</p>
<p>(2) <strong>E步</strong>，记$\theta^i$是第i次迭代参数$\theta$的估计值，在第i+1次迭代的E步，计算：</p>
<script type="math/tex; mode=display">Q\left(\theta, \theta^{(i)}\right)=E_{Z}\left[\log P(Y, Z | \theta) | Y, \theta^{(i)}\right] = \sum_{Z} \log P(Y, Z | \theta) P\left(Z | Y, \theta^{(i)}\right)</script><p>这离的$P(Z|Y,\theta^{(i)})$是在给定观测数据Y和当前参数估计$\theta^{(i)}$下隐变量数据Z的条件分布。</p>
<p>(3) <strong>M步</strong>，求使得$Q\left(\theta, \theta^{(i)}\right)$ 极大化的$\theta$，确定第i+1次迭代的参数估计值$\theta^{(i+1)}$。</p>
<script type="math/tex; mode=display">\theta^{(i+1)}=\arg \max _{\theta} Q\left(\theta, \theta^{(i)}\right)</script><p>(4) 重复2、3步直到收敛。Q函数是EM算法的核心。</p>
<p>EM算法也是要先假设数据分布的。EM算法就是当抽取得到的每个样本都不知道是从哪个分布来的时候，通过迭代计算的方法来近似实现对观测数据的极大似然估计。EM 算法解决这个的思路是使用启发式的迭代方法，既然我们无法直接求出模型分布参数，那么我们可以先猜想隐含参数（EM 算法的 E 步），接着基于观察数据和猜测的隐含参数一起来极大化对数似然，求解我们的模型参数（EM算法的M步)。</p>
<h3 id="3-Reference"><a href="#3-Reference" class="headerlink" title="3 Reference"></a>3 Reference</h3><p>1，<a href="https://zhuanlan.zhihu.com/p/36331115" target="_blank" rel="noopener">知乎 EM算法</a></p>
<p>2，《李航 统计学习方法》</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/24/20191224%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="WangXue">
      <meta itemprop="description" content="本科重庆大学CS，研究生南京大学MS，主要研究AIOps，机器学习等，语言Python&C++">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WangXue">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/12/24/20191224%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/" class="post-title-link" itemprop="url">朴素贝叶斯</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-12-24 20:36:12" itemprop="dateCreated datePublished" datetime="2018-12-24T20:36:12+08:00">2018-12-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-12-24 22:32:48" itemprop="dateModified" datetime="2019-12-24T22:32:48+08:00">2019-12-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2018/12/24/20191224%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2018/12/24/20191224%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1 简介"></a>1 简介</h3><p>朴素贝叶斯法基于<u>贝叶斯定理</u>与<u>特征条件独立</u>假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入输出的联合概率分布（学习到生成数据的机制，是生成模型），然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出 $y$。</p>
<p>输入空间 $\mathcal{X} \subseteq \mathbf{R}^{n}$ 为n维向量的集合。</p>
<p>输出空间 $\mathcal{Y} = \left\{c_{1}, c_{2}, \cdots, c_{K}\right\}$</p>
<p>输入特征向量 $x$，输出类标记 $y$</p>
<p>随机向量$X$是定义在输入空间 $\mathcal{X}$，$Y$是定义在输出空间 $\mathcal{Y}$ 的随机变量。</p>
<p>训练数据集 $T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$ 由$P(X,Y)$ 独立同分布产生。</p>
<h4 id="1-1-学习"><a href="#1-1-学习" class="headerlink" title="1.1 学习"></a>1.1 学习</h4><p>朴素贝叶斯法先学习先验概率分布及条件概率分布。</p>
<p>先验概率分布：</p>
<script type="math/tex; mode=display">P(Y = c_k), k=1,2 \cdots K</script><p>条件概率分布：它有指数级数量的参数，基于条件独立性假设</p>
<script type="math/tex; mode=display">P\left(X=x | Y=c_{k}\right)=P\left(X^{(1)}=x^{(1)}, \cdots, X^{(n)}=x^{(n)} | Y=c_{k}\right), \quad k=1,2, \cdots, K</script><script type="math/tex; mode=display">=\prod_{j=1}^{n} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)</script><p>条件独立假设：用于分类的特征在类确定的条件下，都是属于条件独立的</p>
<h4 id="1-2-预测"><a href="#1-2-预测" class="headerlink" title="1.2 预测"></a>1.2 预测</h4><p>对给定的输入$x$，通过学习到的模型计算后验概率，最大的类作为预测结果。</p>
<p>后验概率计算根据的是贝叶斯定理：</p>
<script type="math/tex; mode=display">P\left(Y=c_{k} | X=x\right)=\frac{P\left(X=x | Y=c_{k}\right) P\left(Y=c_{k}\right)}{\sum_{k} P\left(X=x | Y=c_{k}\right) P\left(Y=c_{k}\right)}</script><p>将前面学习到的代入得：</p>
<script type="math/tex; mode=display">P\left(Y=c_{k} | X=x\right)=\frac{P\left(Y=c_{k}\right) \prod_{j}^n P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}{\sum_{k} P\left(Y=c_{k}\right) \prod_{j}^n P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}, \quad k=1,2, \cdots, K</script><p>！！！因此<strong>朴素贝叶斯分类器</strong>就是这样子了：</p>
<script type="math/tex; mode=display">y = f(x)=argmin_{c_k} \frac{P\left(Y=c_{k}\right) \prod_{j}^n P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}{\sum_{k} P\left(Y=c_{k}\right) \prod_{j}^n P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}, \quad k=1,2, \cdots, K</script><h4 id="1-3-后验概率最大化的含义"><a href="#1-3-后验概率最大化的含义" class="headerlink" title="1.3 后验概率最大化的含义"></a>1.3 后验概率最大化的含义</h4><p>将实例分到后验概率最大的类中，等价于期望风险最小化。</p>
<p>假设损失函数：</p>
<script type="math/tex; mode=display">L(Y, f(X))=\left\{\begin{array}{ll}{1,} & {Y \neq f(X)} \\ {0,} & {Y=f(X)}\end{array}\right.</script><p>期望风险函数:</p>
<script type="math/tex; mode=display">R_{\mathrm{exp}}(f)=E[L(Y, f(X))]</script><p>取条件期望</p>
<script type="math/tex; mode=display">R_{\exp }(f)=E_{X} \sum_{k=1}^{K}\left[L\left(c_{k}, f(X)\right)\right] P\left(c_{k} | X\right)</script><p>为了使得期望风险最小化，需要对$X = x$ 逐个极小化:</p>
<script type="math/tex; mode=display">f(x)=\arg \min _{y \in \mathcal{Y}} \sum_{k=1}^{K} L\left(c_{k}, y\right) P\left(c_{k} | X=x\right)</script><script type="math/tex; mode=display">= \arg \min _{y \in \mathcal{Y}} \sum_{k=1}^{K} P\left(y \neq c_{k} | X=x\right)</script><script type="math/tex; mode=display">= \arg \max _{y \in \mathcal{Y}} P\left(y=c_{k} | X=x\right)</script><h3 id="2-极大似然估计"><a href="#2-极大似然估计" class="headerlink" title="2 极大似然估计"></a>2 极大似然估计</h3><p>学习即估计先验概率分布与条件概率分布：</p>
<script type="math/tex; mode=display">P\left(Y=c_{k}\right)=\frac{\sum_{i=1}^{N} I\left(y_{i}=c_{k}\right)}{N}, \quad k=1,2, \cdots, K</script><p>设第$j$个特征$x^{(j)}$的可能取值的集合为 $\left\{a_{j 1}, a_{j 2}, \cdots, a_{j S_{j}}\right\}$，条件概率 $P\left(X^{(j)}=a_{j l} | Y = c_k )\right.$ 的极大似然估计是：</p>
<script type="math/tex; mode=display">P\left(X^{(j)}=a_{j l} | Y=c_{k}\right)=\frac{\sum_{i=1}^{N} I\left(x_{i}^{(j)}=a_{j l}, y_{i}=c_{k}\right)}{\sum_{i=1}^{N} I\left(y_{i}=c_{k}\right)}</script><script type="math/tex; mode=display">j=1,2, \cdots, n ; \quad l=1,2, \cdots, S_{j} ; \quad k=1,2, \cdots, K</script><h3 id="3-算法过程"><a href="#3-算法过程" class="headerlink" title="3 算法过程"></a>3 算法过程</h3><p>(1) 计算先验概率和条件概率（见2，极大似然估计部分）</p>
<p>(2) 对于给定实例 $x=\left(x^{(1)}, x^{(2)}, \cdots, x^{(n)}\right)^{\mathrm{T}}$计算，取最大值</p>
<script type="math/tex; mode=display">y = f(x)=argmin_{c_k} \frac{P\left(Y=c_{k}\right) \prod_{j}^n P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}{\sum_{k} P\left(Y=c_{k}\right) \prod_{j}^n P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}, \quad k=1,2, \cdots, K</script>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/09/20191224%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8EKNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="WangXue">
      <meta itemprop="description" content="本科重庆大学CS，研究生南京大学MS，主要研究AIOps，机器学习等，语言Python&C++">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WangXue">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2018/12/09/20191224%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8EKNN/" class="post-title-link" itemprop="url">感知机 & KNN</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-12-09 18:52:35" itemprop="dateCreated datePublished" datetime="2018-12-09T18:52:35+08:00">2018-12-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-12-25 17:45:18" itemprop="dateModified" datetime="2019-12-25T17:45:18+08:00">2019-12-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2018/12/09/20191224%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8EKNN/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2018/12/09/20191224%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8EKNN/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-感知机"><a href="#1-感知机" class="headerlink" title="1 感知机"></a>1 感知机</h3><h4 id="1-1-简介"><a href="#1-1-简介" class="headerlink" title="1.1 简介"></a>1.1 简介</h4><p>感知机是二分类<u>线性分类</u>模型，感知机对输入空间中将实例划分为正负两类的分离超平面，属于判别模型。使用基于误分类的损失函数，利用梯度下降法对损失函数进行最小化。</p>
<p>感知机：</p>
<script type="math/tex; mode=display">f(x)=\operatorname{sign}(w \cdot x+b)</script><script type="math/tex; mode=display">\operatorname{sign}(x)=\left\{\begin{array}{ll}{+1,} & {x \geqslant 0} \\ {-1,} & {x<0}\end{array}\right.</script><p><img src="/images/20181204InceptionMachine.jpg" alt="20181204InceptionMachine"></p>
<h4 id="1-2-学习策略"><a href="#1-2-学习策略" class="headerlink" title="1.2 学习策略"></a>1.2 学习策略</h4><p>损失函数的自然选择是误分类点的总数（但这样$w,b$不是连续可导函数，不易优化）</p>
<p>故采用误分类点到超平面$S$的总距离：</p>
<script type="math/tex; mode=display">\frac{1}{\|w\|}\left|w \cdot x_{0}+b\right|</script><p>由于对于一个误分类的数据$(x_i,y_i)$来说：</p>
<script type="math/tex; mode=display">-y_i(w \cdot x_i + b) > 0</script><p>因此感知机的损失函数是（忽略常数）：</p>
<script type="math/tex; mode=display">L(w, b)=-\sum_{x_{i} \in M} y_{i}\left(w \cdot x_{i}+b\right)</script><h4 id="1-3-随机梯度下降"><a href="#1-3-随机梯度下降" class="headerlink" title="1.3 随机梯度下降"></a>1.3 随机梯度下降</h4><p>一次随机选取一个误分类点使其梯度下降。</p>
<p>损失函数的梯度：</p>
<script type="math/tex; mode=display">\nabla_{w} L(w, b)=-\sum_{x_{i} \in M} y_{i} x_{i}</script><script type="math/tex; mode=display">\nabla_{b} L(w, b)=-\sum_{x_{i} \in M} y_{i}</script><p>选取一个误分类点$(x_i,y_i)$进行更新w，b。</p>
<script type="math/tex; mode=display">w = w + \alpha y_i x_i , b = b + \alpha y_i</script><h4 id="1-4-感知机算法过程"><a href="#1-4-感知机算法过程" class="headerlink" title="1.4 感知机算法过程"></a>1.4 感知机算法过程</h4><p>输入：训练数据集$T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$，其中$x_{i} \in \mathcal{X}=\mathbf{R}^{n}, y_i \in y=\{-1,+1\}, i=1,2, \cdots, N$ 。学习率 $\alpha$，</p>
<p>输出： 求解感知机模型 $f(x) = sign(w \cdot x + b)$</p>
<p>(1) 选取初值$w_0,b_0$</p>
<p>(2) 在训练数据中选取数据 $(x_i,y_i)$</p>
<p>(3) 如果$y_{i}\left(w \cdot x_{i}+b\right) \leqslant 0$ ，则 $w = w + \alpha y_i x_i, b = b + \alpha y_i$</p>
<h3 id="2-K近邻KNN"><a href="#2-K近邻KNN" class="headerlink" title="2 K近邻KNN"></a>2 K近邻KNN</h3><h4 id="2-1-简介"><a href="#2-1-简介" class="headerlink" title="2.1 简介"></a>2.1 简介</h4><p>KNN是一种基本的<u>分类</u>与回归方法。KNN法假设给定一个训练数据集，其中实例类别已定。分类时，对新的实例根据其K个最近邻的训练实例的类别，通过多数表决来预测。</p>
<p>基本要素：K值的选择，距离度量，分类决策规则</p>
<h4 id="2-2-K近邻法算法"><a href="#2-2-K近邻法算法" class="headerlink" title="2.2 K近邻法算法"></a>2.2 K近邻法算法</h4><p>输入：训练数据集$T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$，其中 $x_{i} \in \mathcal{X}=\mathbf{R}^{n}, y_i \in y=\{c_1,c_2,\cdot \cdot, c_k\}, i=1,2, \cdots, N$</p>
<p>输出：新实例 $x$ 所属的类别 $y$</p>
<p>(1) 根据给定的距离度量，在训练集中找出与x最临近的k个点，涵盖这k个点的x的邻域记作$N_k(x)$</p>
<p>(2) 在$N_k(x)$中根据分类决策规则（如多数表决）来判定x的类别y</p>
<script type="math/tex; mode=display">y=\arg \max _{c_{j}} \sum_{x_{i} \in N_{k}(x)} I\left(y_{i}=c_{j}\right), \quad i=1,2, \cdots, N ; j=1,2, \cdots, K</script><p>$I$是指示函数，当$y_i = c_j$ 时为1。</p>
<h4 id="2-3-距离度量"><a href="#2-3-距离度量" class="headerlink" title="2.3 距离度量"></a>2.3 距离度量</h4><p>距离是两个点相似度的反映。设特征空间$\mathcal{X}$是n维实数向量空间$\mathbf{R}^{n}$, </p>
<script type="math/tex; mode=display">x_{i}, x_{j} \in \mathcal{X}, x_{i}=\left(x_{i}^{(1)}, x_{i}^{(2)}, \cdots, x_{i}^{(n)}\right)^{\mathrm{T}}</script><script type="math/tex; mode=display">x_{j}=\left(x_{j}^{(1)}, x_{j}^{(2)}, \cdots, x_{j}^{(n)}\right)^{\mathrm{T}}</script><p>则P范数距离是：</p>
<script type="math/tex; mode=display">L_p(x_i,x_j) = ( \sum_{l=1}^n |x_i^{(l)} - x_j^{(l)}|^p)^{\frac{1}{p}}</script><p>p=1 曼哈顿距离，p=2 欧氏距离，p=$\infty$，是切比雪夫距离，各个坐标距离的最大值。</p>
<script type="math/tex; mode=display">L_{\infty}\left(x_{i}, x_{j}\right)=\max _{l}\left|x_{i}^{(l)}-x_{j}^{(l)}\right|</script><h4 id="2-4-K值的影响"><a href="#2-4-K值的影响" class="headerlink" title="2.4 K值的影响"></a>2.4 K值的影响</h4><p>1，k较小时，使用较小的邻域中的训练实例进行预测，“学习”的近似误差减小，但是估计误差增大。即预测结果对邻近点非常敏感，如果邻近的点是噪声则会预测出错（容易过拟合）。</p>
<h4 id="2-5-分类决策规则"><a href="#2-5-分类决策规则" class="headerlink" title="2.5 分类决策规则"></a>2.5 分类决策规则</h4><p>一般多数表决。误分类的概率是：</p>
<script type="math/tex; mode=display">P(Y \neq f(X))=1-P(Y=f(X))</script><p>则误分类率是：</p>
<script type="math/tex; mode=display">\frac{1}{k} \sum_{x_{i} \in N_{k}(x)} I\left(y_{i} \neq c_{j}\right)=1-\frac{1}{k} \sum_{x_{i} \in N_{k}(x)} I\left(y_{i}=c_{j}\right)</script><h4 id="2-6-k-d-tree"><a href="#2-6-k-d-tree" class="headerlink" title="2.6 k-d tree"></a>2.6 k-d tree</h4><p>为了提高k近邻的搜索效率。用特殊的结构存储训练数据，减少计算距离的次数。构造kd树相当于不断地用垂直于坐标轴的超平面将k维空间切分（递归），构成一系列的k维超矩形矩阵区域。（李航书P53）</p>
<p>搜索：首先找到包含目标点的叶节点，然后从该叶节点出发依次回退到父节点，不断查找与目标点最邻近的节点。当确定不存在更近的结点时终止。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>1，《统计学习方法》李航</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="WangXue"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">WangXue</p>
  <div class="site-description" itemprop="description">本科重庆大学CS，研究生南京大学MS，主要研究AIOps，机器学习等，语言Python&C++</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">30</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">23</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WangXue</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.5.0
  </div>

        
<div class="busuanzi-count">
  <script pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>
  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.getAttribute('pjax') !== null) {
      element.setAttribute('pjax', '');
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  <script src="/js/local-search.js"></script>












    <div id="pjax">

  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: '0TVJlt2cIYmtVMl43kgpM5x9-gzGzoHsz',
    appKey: 'nBjNpIkIeApmj8vOtnjsjUTT',
    placeholder: "Just go go",
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn',
    path: location.pathname,
    recordIP: false,
    serverURLs: ''
  });
}, window.Valine);
</script>

    </div>
</body>
</html>
